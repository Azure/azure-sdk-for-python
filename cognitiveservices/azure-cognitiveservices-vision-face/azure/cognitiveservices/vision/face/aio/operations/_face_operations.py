# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
from typing import Any, Callable, Dict, Generic, IO, List, Optional, TypeVar, Union
import warnings

from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
from azure.core.pipeline import PipelineResponse
from azure.core.pipeline.transport import AsyncHttpResponse, HttpRequest

from ... import models as _models

T = TypeVar('T')
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]

class FaceOperations:
    """FaceOperations async operations.

    You should not instantiate this class directly. Instead, you should create a Client instance that
    instantiates it for you and attaches it as an attribute.

    :ivar models: Alias to model classes used in this operation group.
    :type models: ~azure.cognitiveservices.vision.face.models
    :param client: Client for service requests.
    :param config: Configuration of service client.
    :param serializer: An object model serializer.
    :param deserializer: An object model deserializer.
    """

    models = _models

    def __init__(self, client, config, serializer, deserializer) -> None:
        self._client = client
        self._serialize = serializer
        self._deserialize = deserializer
        self._config = config

    async def find_similar(
        self,
        face_id: str,
        face_list_id: Optional[str] = None,
        large_face_list_id: Optional[str] = None,
        face_ids: Optional[List[str]] = None,
        max_num_of_candidates_returned: Optional[int] = 20,
        mode: Optional[Union[str, "_models.FindSimilarMatchMode"]] = "matchPerson",
        **kwargs
    ) -> List["_models.SimilarFace"]:
        """Given query face's faceId, to search the similar-looking faces from a faceId array, a face list
        or a large face list. faceId array contains the faces created by `Face - Detect With Url
        <https://docs.microsoft.com/rest/api/faceapi/face/detectwithurl>`_ or `Face - Detect With
        Stream <https://docs.microsoft.com/rest/api/faceapi/face/detectwithstream>`_\ , which will
        expire at the time specified by faceIdTimeToLive after creation. A "faceListId" is created by
        `FaceList - Create <https://docs.microsoft.com/rest/api/faceapi/facelist/create>`_ containing
        persistedFaceIds that will not expire. And a "largeFaceListId" is created by `LargeFaceList -
        Create <https://docs.microsoft.com/rest/api/faceapi/largefacelist/create>`_ containing
        persistedFaceIds that will also not expire. Depending on the input the returned similar faces
        list contains faceIds or persistedFaceIds ranked by similarity.
        :code:`<br/>`Find similar has two working modes, "matchPerson" and "matchFace". "matchPerson"
        is the default mode that it tries to find faces of the same person as possible by using
        internal same-person thresholds. It is useful to find a known person's other photos. Note that
        an empty list will be returned if no faces pass the internal thresholds. "matchFace" mode
        ignores same-person thresholds and returns ranked similar faces anyway, even the similarity is
        low. It can be used in the cases like searching celebrity-looking faces.
        :code:`<br/>`The 'recognitionModel' associated with the query face's faceId should be the same
        as the 'recognitionModel' used by the target faceId array, face list or large face list.

        :param face_id: FaceId of the query face. User needs to call Face - Detect first to get a valid
         faceId. Note that this faceId is not persisted and will expire at the time specified by
         faceIdTimeToLive after the detection call.
        :type face_id: str
        :param face_list_id: An existing user-specified unique candidate face list, created in Face
         List - Create a Face List. Face list contains a set of persistedFaceIds which are persisted and
         will never expire. Parameter faceListId, largeFaceListId and faceIds should not be provided at
         the same time.
        :type face_list_id: str
        :param large_face_list_id: An existing user-specified unique candidate large face list, created
         in LargeFaceList - Create. Large face list contains a set of persistedFaceIds which are
         persisted and will never expire. Parameter faceListId, largeFaceListId and faceIds should not
         be provided at the same time.
        :type large_face_list_id: str
        :param face_ids: An array of candidate faceIds. All of them are created by Face - Detect and
         the faceIds will expire at the time specified by faceIdTimeToLive after the detection call. The
         number of faceIds is limited to 1000. Parameter faceListId, largeFaceListId and faceIds should
         not be provided at the same time.
        :type face_ids: list[str]
        :param max_num_of_candidates_returned: The number of top similar faces returned. The valid
         range is [1, 1000].
        :type max_num_of_candidates_returned: int
        :param mode: Similar face searching mode. It can be "matchPerson" or "matchFace".
        :type mode: str or ~azure.cognitiveservices.vision.face.models.FindSimilarMatchMode
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: list of SimilarFace, or the result of cls(response)
        :rtype: list[~azure.cognitiveservices.vision.face.models.SimilarFace]
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType[List["_models.SimilarFace"]]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))

        _body = _models.FindSimilarRequest(face_id=face_id, face_list_id=face_list_id, large_face_list_id=large_face_list_id, face_ids=face_ids, max_num_of_candidates_returned=max_num_of_candidates_returned, mode=mode)
        content_type = kwargs.pop("content_type", "application/json")
        accept = "application/json"

        # Construct URL
        url = self.find_similar.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Content-Type'] = self._serialize.header("content_type", content_type, 'str')
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        body_content_kwargs = {}  # type: Dict[str, Any]
        body_content = self._serialize.body(_body, 'FindSimilarRequest')
        body_content_kwargs['content'] = body_content
        request = self._client.post(url, query_parameters, header_parameters, **body_content_kwargs)
        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize('[SimilarFace]', pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized
    find_similar.metadata = {'url': '/findsimilars'}  # type: ignore

    async def group(
        self,
        face_ids: List[str],
        **kwargs
    ) -> "_models.GroupResult":
        """Divide candidate faces into groups based on face similarity.:code:`<br />`


        * The output is one or more disjointed face groups and a messyGroup. A face group contains
        faces that have similar looking, often of the same person. Face groups are ranked by group
        size, i.e. number of faces. Notice that faces belonging to a same person might be split into
        several groups in the result.
        * MessyGroup is a special face group containing faces that cannot find any similar counterpart
        face from original faces. The messyGroup will not appear in the result if all faces found their
        counterparts.
        * Group API needs at least 2 candidate faces and 1000 at most. We suggest to try `Face - Verify
        <https://docs.microsoft.com/rest/api/faceapi/face/verifyfacetoface>`_ when you only have 2
        candidate faces.
        * The 'recognitionModel' associated with the query faces' faceIds should be the same.

        :param face_ids: Array of candidate faceId created by Face - Detect. The maximum is 1000 faces.
        :type face_ids: list[str]
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: GroupResult, or the result of cls(response)
        :rtype: ~azure.cognitiveservices.vision.face.models.GroupResult
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType["_models.GroupResult"]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))

        _body = _models.GroupRequest(face_ids=face_ids)
        content_type = kwargs.pop("content_type", "application/json")
        accept = "application/json"

        # Construct URL
        url = self.group.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Content-Type'] = self._serialize.header("content_type", content_type, 'str')
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        body_content_kwargs = {}  # type: Dict[str, Any]
        body_content = self._serialize.body(_body, 'GroupRequest')
        body_content_kwargs['content'] = body_content
        request = self._client.post(url, query_parameters, header_parameters, **body_content_kwargs)
        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize('GroupResult', pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized
    group.metadata = {'url': '/group'}  # type: ignore

    async def identify(
        self,
        face_ids: List[str],
        person_group_id: Optional[str] = None,
        large_person_group_id: Optional[str] = None,
        max_num_of_candidates_returned: Optional[int] = 1,
        confidence_threshold: Optional[float] = None,
        **kwargs
    ) -> List["_models.IdentifyResult"]:
        """1-to-many identification to find the closest matches of the specific query person face from a
        person group or large person group.
        :code:`<br/>` For each face in the faceIds array, Face Identify will compute similarities
        between the query face and all the faces in the person group (given by personGroupId) or large
        person group (given by largePersonGroupId), and return candidate person(s) for that face ranked
        by similarity confidence. The person group/large person group should be trained to make it
        ready for identification. See more in `PersonGroup - Train
        <https://docs.microsoft.com/rest/api/faceapi/persongroup/train>`_ and `LargePersonGroup - Train
        <https://docs.microsoft.com/rest/api/faceapi/largepersongroup/train>`_.
        :code:`<br/>`

        Remarks::code:`<br />`


        * The algorithm allows more than one face to be identified independently at the same request,
        but no more than 10 faces.
        * Each person in the person group/large person group could have more than one face, but no more
        than 248 faces.
        * Higher face image quality means better identification precision. Please consider high-quality
        faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        * Number of candidates returned is restricted by maxNumOfCandidatesReturned and
        confidenceThreshold. If no person is identified, the returned candidates will be an empty
        array.
        * Try `Face - Find Similar <https://docs.microsoft.com/rest/api/faceapi/face/findsimilar>`_
        when you need to find similar faces from a face list/large face list instead of a person
        group/large person group.
        * The 'recognitionModel' associated with the query faces' faceIds should be the same as the
        'recognitionModel' used by the target person group or large person group.

        :param face_ids: Array of query faces faceIds, created by the Face - Detect. Each of the faces
         are identified independently. The valid number of faceIds is between [1, 10].
        :type face_ids: list[str]
        :param person_group_id: PersonGroupId of the target person group, created by PersonGroup -
         Create. Parameter personGroupId and largePersonGroupId should not be provided at the same time.
        :type person_group_id: str
        :param large_person_group_id: LargePersonGroupId of the target large person group, created by
         LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId should not be
         provided at the same time.
        :type large_person_group_id: str
        :param max_num_of_candidates_returned: The range of maxNumOfCandidatesReturned is between 1 and
         5 (default is 1).
        :type max_num_of_candidates_returned: int
        :param confidence_threshold: Confidence threshold of identification, used to judge whether one
         face belong to one person. The range of confidenceThreshold is [0, 1] (default specified by
         algorithm).
        :type confidence_threshold: float
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: list of IdentifyResult, or the result of cls(response)
        :rtype: list[~azure.cognitiveservices.vision.face.models.IdentifyResult]
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType[List["_models.IdentifyResult"]]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))

        _body = _models.IdentifyRequest(face_ids=face_ids, person_group_id=person_group_id, large_person_group_id=large_person_group_id, max_num_of_candidates_returned=max_num_of_candidates_returned, confidence_threshold=confidence_threshold)
        content_type = kwargs.pop("content_type", "application/json")
        accept = "application/json"

        # Construct URL
        url = self.identify.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Content-Type'] = self._serialize.header("content_type", content_type, 'str')
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        body_content_kwargs = {}  # type: Dict[str, Any]
        body_content = self._serialize.body(_body, 'IdentifyRequest')
        body_content_kwargs['content'] = body_content
        request = self._client.post(url, query_parameters, header_parameters, **body_content_kwargs)
        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize('[IdentifyResult]', pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized
    identify.metadata = {'url': '/identify'}  # type: ignore

    async def verify_face_to_face(
        self,
        face_id1: str,
        face_id2: str,
        **kwargs
    ) -> "_models.VerifyResult":
        """Verify whether two faces belong to a same person or whether one face belongs to a person.
        :code:`<br/>`
        Remarks::code:`<br />`


        * Higher face image quality means better identification precision. Please consider high-quality
        faces: frontal, clear, and face size is 200x200 pixels (100 pixels between eyes) or bigger.
        * For the scenarios that are sensitive to accuracy please make your own judgment.
        * The 'recognitionModel' associated with the query faces' faceIds should be the same as the
        'recognitionModel' used by the target face, person group or large person group.

        :param face_id1: FaceId of the first face, comes from Face - Detect.
        :type face_id1: str
        :param face_id2: FaceId of the second face, comes from Face - Detect.
        :type face_id2: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: VerifyResult, or the result of cls(response)
        :rtype: ~azure.cognitiveservices.vision.face.models.VerifyResult
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType["_models.VerifyResult"]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))

        _body = _models.VerifyFaceToFaceRequest(face_id1=face_id1, face_id2=face_id2)
        content_type = kwargs.pop("content_type", "application/json")
        accept = "application/json"

        # Construct URL
        url = self.verify_face_to_face.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Content-Type'] = self._serialize.header("content_type", content_type, 'str')
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        body_content_kwargs = {}  # type: Dict[str, Any]
        body_content = self._serialize.body(_body, 'VerifyFaceToFaceRequest')
        body_content_kwargs['content'] = body_content
        request = self._client.post(url, query_parameters, header_parameters, **body_content_kwargs)
        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize('VerifyResult', pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized
    verify_face_to_face.metadata = {'url': '/verify'}  # type: ignore

    async def detect_with_url(
        self,
        url: str,
        return_face_id: Optional[bool] = True,
        return_face_landmarks: Optional[bool] = False,
        return_face_attributes: Optional[List[Union[str, "_models.FaceAttributeType"]]] = None,
        recognition_model: Optional[Union[str, "_models.RecognitionModel"]] = None,
        return_recognition_model: Optional[bool] = False,
        detection_model: Optional[Union[str, "_models.DetectionModel"]] = "detection_01",
        face_id_time_to_live: Optional[int] = 86400,
        **kwargs
    ) -> List["_models.DetectedFace"]:
        """Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks,
        and attributes.:code:`<br />`


        * No image will be stored. Only the extracted face feature will be stored on server. The faceId
        is an identifier of the face feature and will be used in `Face - Identify
        <https://docs.microsoft.com/rest/api/faceapi/face/identify>`_\ , `Face - Verify
        <https://docs.microsoft.com/rest/api/faceapi/face/verifyfacetoface>`_\ , and `Face - Find
        Similar <https://docs.microsoft.com/rest/api/faceapi/face/findsimilar>`_. The stored face
        feature(s) will expire and be deleted at the time specified by faceIdTimeToLive after the
        original detection call.
        * Optional parameters include faceId, landmarks, and attributes. Attributes include age,
        gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories,
        blur, exposure, noise, and mask. Some of the results returned for specific attributes may not
        be highly accurate.
        * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size
        is from 1KB to 6MB.
        * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from
        large to small.
        * For optimal results when querying `Face - Identify
        <https://docs.microsoft.com/rest/api/faceapi/face/identify>`_\ , `Face - Verify
        <https://docs.microsoft.com/rest/api/faceapi/face/verifyfacetoface>`_\ , and `Face - Find
        Similar <https://docs.microsoft.com/rest/api/faceapi/face/findsimilar>`_ ('returnFaceId' is
        true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels
        (100 pixels between eyes).
        * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels.
        Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum
        face size.
        *
          Different 'detectionModel' values can be provided. To use and compare different detection
        models, please refer to `How to specify a detection model
        <https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-
        detection-model>`_.

        *
          Different 'recognitionModel' values are provided. If follow-up operations like Verify,
        Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel'
        parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model
        needed, please explicitly specify the model you need in this parameter. Once specified, the
        detected faceIds will be associated with the specified recognition model. More details, please
        refer to `Specify a recognition model <https://docs.microsoft.com/azure/cognitive-
        services/face/face-api-how-to-topics/specify-recognition-model>`_.

        :param url: Publicly reachable URL of an image.
        :type url: str
        :param return_face_id: A value indicating whether the operation should return faceIds of
         detected faces.
        :type return_face_id: bool
        :param return_face_landmarks: A value indicating whether the operation should return landmarks
         of the detected faces.
        :type return_face_landmarks: bool
        :param return_face_attributes: Analyze and return the one or more specified face attributes in
         the comma-separated string like "returnFaceAttributes=age,gender". The available attributes
         depends on the 'detectionModel' specified. 'detection_01' supports age, gender, headPose,
         smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure, and
         noise. While 'detection_02' does not support any attributes and 'detection_03' only supports
         mask. Note that each face attribute analysis has additional computational and time cost.
        :type return_face_attributes: list[str or ~azure.cognitiveservices.vision.face.models.FaceAttributeType]
        :param recognition_model: Name of recognition model. Recognition model is used when the face
         features are extracted and associated with detected faceIds, (Large)FaceList or
         (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or
         (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01',
         if latest model needed, please explicitly specify the model you need.
        :type recognition_model: str or ~azure.cognitiveservices.vision.face.models.RecognitionModel
        :param return_recognition_model: A value indicating whether the operation should return
         'recognitionModel' in response.
        :type return_recognition_model: bool
        :param detection_model: Name of detection model. Detection model is used to detect faces in the
         submitted image. A detection model name can be provided when performing Face - Detect or
         (Large)FaceList - Add Face or (Large)PersonGroup - Add Face. The default value is
         'detection_01', if another model is needed, please explicitly specify it.
        :type detection_model: str or ~azure.cognitiveservices.vision.face.models.DetectionModel
        :param face_id_time_to_live: The number of seconds for the faceId being cached. Supported range
         from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours).
        :type face_id_time_to_live: int
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: list of DetectedFace, or the result of cls(response)
        :rtype: list[~azure.cognitiveservices.vision.face.models.DetectedFace]
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType[List["_models.DetectedFace"]]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))

        _image_url = _models.ImageUrl(url=url)
        content_type = kwargs.pop("content_type", "application/json")
        accept = "application/json"

        # Construct URL
        url = self.detect_with_url.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]
        if return_face_id is not None:
            query_parameters['returnFaceId'] = self._serialize.query("return_face_id", return_face_id, 'bool')
        if return_face_landmarks is not None:
            query_parameters['returnFaceLandmarks'] = self._serialize.query("return_face_landmarks", return_face_landmarks, 'bool')
        if return_face_attributes is not None:
            query_parameters['returnFaceAttributes'] = self._serialize.query("return_face_attributes", return_face_attributes, '[str]', div=',')
        if recognition_model is not None:
            query_parameters['recognitionModel'] = self._serialize.query("recognition_model", recognition_model, 'str')
        if return_recognition_model is not None:
            query_parameters['returnRecognitionModel'] = self._serialize.query("return_recognition_model", return_recognition_model, 'bool')
        if detection_model is not None:
            query_parameters['detectionModel'] = self._serialize.query("detection_model", detection_model, 'str')
        if face_id_time_to_live is not None:
            query_parameters['faceIdTimeToLive'] = self._serialize.query("face_id_time_to_live", face_id_time_to_live, 'int', maximum=86400, minimum=60)

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Content-Type'] = self._serialize.header("content_type", content_type, 'str')
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        body_content_kwargs = {}  # type: Dict[str, Any]
        body_content = self._serialize.body(_image_url, 'ImageUrl')
        body_content_kwargs['content'] = body_content
        request = self._client.post(url, query_parameters, header_parameters, **body_content_kwargs)
        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize('[DetectedFace]', pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized
    detect_with_url.metadata = {'url': '/detect'}  # type: ignore

    async def verify_face_to_person(
        self,
        face_id: str,
        person_id: str,
        person_group_id: Optional[str] = None,
        large_person_group_id: Optional[str] = None,
        **kwargs
    ) -> "_models.VerifyResult":
        """Verify whether two faces belong to a same person. Compares a face Id with a Person Id.

        :param face_id: FaceId of the face, comes from Face - Detect.
        :type face_id: str
        :param person_id: Specify a certain person in a person group or a large person group. personId
         is created in PersonGroup Person - Create or LargePersonGroup Person - Create.
        :type person_id: str
        :param person_group_id: Using existing personGroupId and personId for fast loading a specified
         person. personGroupId is created in PersonGroup - Create. Parameter personGroupId and
         largePersonGroupId should not be provided at the same time.
        :type person_group_id: str
        :param large_person_group_id: Using existing largePersonGroupId and personId for fast loading a
         specified person. largePersonGroupId is created in LargePersonGroup - Create. Parameter
         personGroupId and largePersonGroupId should not be provided at the same time.
        :type large_person_group_id: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: VerifyResult, or the result of cls(response)
        :rtype: ~azure.cognitiveservices.vision.face.models.VerifyResult
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType["_models.VerifyResult"]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))

        _body = _models.VerifyFaceToPersonRequest(face_id=face_id, person_group_id=person_group_id, large_person_group_id=large_person_group_id, person_id=person_id)
        content_type = kwargs.pop("content_type", "application/json")
        accept = "application/json"

        # Construct URL
        url = self.verify_face_to_person.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Content-Type'] = self._serialize.header("content_type", content_type, 'str')
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        body_content_kwargs = {}  # type: Dict[str, Any]
        body_content = self._serialize.body(_body, 'VerifyFaceToPersonRequest')
        body_content_kwargs['content'] = body_content
        request = self._client.post(url, query_parameters, header_parameters, **body_content_kwargs)
        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize('VerifyResult', pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized
    verify_face_to_person.metadata = {'url': '/verify'}  # type: ignore

    async def detect_with_stream(
        self,
        image: IO,
        return_face_id: Optional[bool] = True,
        return_face_landmarks: Optional[bool] = False,
        return_face_attributes: Optional[List[Union[str, "_models.FaceAttributeType"]]] = None,
        recognition_model: Optional[Union[str, "_models.RecognitionModel"]] = None,
        return_recognition_model: Optional[bool] = False,
        detection_model: Optional[Union[str, "_models.DetectionModel"]] = "detection_01",
        face_id_time_to_live: Optional[int] = 86400,
        **kwargs
    ) -> List["_models.DetectedFace"]:
        """Detect human faces in an image, return face rectangles, and optionally with faceIds, landmarks,
        and attributes.:code:`<br />`


        * No image will be stored. Only the extracted face feature will be stored on server. The faceId
        is an identifier of the face feature and will be used in `Face - Identify
        <https://docs.microsoft.com/rest/api/faceapi/face/identify>`_\ , `Face - Verify
        <https://docs.microsoft.com/rest/api/faceapi/face/verifyfacetoface>`_\ , and `Face - Find
        Similar <https://docs.microsoft.com/rest/api/faceapi/face/findsimilar>`_. The stored face
        feature(s) will expire and be deleted at the time specified by faceIdTimeToLive after the
        original detection call.
        * Optional parameters include faceId, landmarks, and attributes. Attributes include age,
        gender, headPose, smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories,
        blur, exposure, noise, and mask. Some of the results returned for specific attributes may not
        be highly accurate.
        * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed image file size
        is from 1KB to 6MB.
        * Up to 100 faces can be returned for an image. Faces are ranked by face rectangle size from
        large to small.
        * For optimal results when querying `Face - Identify
        <https://docs.microsoft.com/rest/api/faceapi/face/identify>`_\ , `Face - Verify
        <https://docs.microsoft.com/rest/api/faceapi/face/verifyfacetoface>`_\ , and `Face - Find
        Similar <https://docs.microsoft.com/rest/api/faceapi/face/findsimilar>`_ ('returnFaceId' is
        true), please use faces that are: frontal, clear, and with a minimum size of 200x200 pixels
        (100 pixels between eyes).
        * The minimum detectable face size is 36x36 pixels in an image no larger than 1920x1080 pixels.
        Images with dimensions higher than 1920x1080 pixels will need a proportionally larger minimum
        face size.
        * Different 'detectionModel' values can be provided. To use and compare different detection
        models, please refer to `How to specify a detection model
        <https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-
        detection-model>`_
        * Different 'recognitionModel' values are provided. If follow-up operations like Verify,
        Identify, Find Similar are needed, please specify the recognition model with 'recognitionModel'
        parameter. The default value for 'recognitionModel' is 'recognition_01', if latest model
        needed, please explicitly specify the model you need in this parameter. Once specified, the
        detected faceIds will be associated with the specified recognition model. More details, please
        refer to `Specify a recognition model <https://docs.microsoft.com/azure/cognitive-
        services/face/face-api-how-to-topics/specify-recognition-model>`_.

        :param image: An image stream.
        :type image: IO
        :param return_face_id: A value indicating whether the operation should return faceIds of
         detected faces.
        :type return_face_id: bool
        :param return_face_landmarks: A value indicating whether the operation should return landmarks
         of the detected faces.
        :type return_face_landmarks: bool
        :param return_face_attributes: Analyze and return the one or more specified face attributes in
         the comma-separated string like "returnFaceAttributes=age,gender". The available attributes
         depends on the 'detectionModel' specified. 'detection_01' supports age, gender, headPose,
         smile, facialHair, glasses, emotion, hair, makeup, occlusion, accessories, blur, exposure, and
         noise. While 'detection_02' does not support any attributes and 'detection_03' only supports
         mask. Note that each face attribute analysis has additional computational and time cost.
        :type return_face_attributes: list[str or ~azure.cognitiveservices.vision.face.models.FaceAttributeType]
        :param recognition_model: Name of recognition model. Recognition model is used when the face
         features are extracted and associated with detected faceIds, (Large)FaceList or
         (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or
         (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01',
         if latest model needed, please explicitly specify the model you need.
        :type recognition_model: str or ~azure.cognitiveservices.vision.face.models.RecognitionModel
        :param return_recognition_model: A value indicating whether the operation should return
         'recognitionModel' in response.
        :type return_recognition_model: bool
        :param detection_model: Name of detection model. Detection model is used to detect faces in the
         submitted image. A detection model name can be provided when performing Face - Detect or
         (Large)FaceList - Add Face or (Large)PersonGroup - Add Face. The default value is
         'detection_01', if another model is needed, please explicitly specify it.
        :type detection_model: str or ~azure.cognitiveservices.vision.face.models.DetectionModel
        :param face_id_time_to_live: The number of seconds for the faceId being cached. Supported range
         from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours).
        :type face_id_time_to_live: int
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: list of DetectedFace, or the result of cls(response)
        :rtype: list[~azure.cognitiveservices.vision.face.models.DetectedFace]
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType[List["_models.DetectedFace"]]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))
        content_type = kwargs.pop("content_type", "application/octet-stream")
        accept = "application/json"

        # Construct URL
        url = self.detect_with_stream.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]
        if return_face_id is not None:
            query_parameters['returnFaceId'] = self._serialize.query("return_face_id", return_face_id, 'bool')
        if return_face_landmarks is not None:
            query_parameters['returnFaceLandmarks'] = self._serialize.query("return_face_landmarks", return_face_landmarks, 'bool')
        if return_face_attributes is not None:
            query_parameters['returnFaceAttributes'] = self._serialize.query("return_face_attributes", return_face_attributes, '[str]', div=',')
        if recognition_model is not None:
            query_parameters['recognitionModel'] = self._serialize.query("recognition_model", recognition_model, 'str')
        if return_recognition_model is not None:
            query_parameters['returnRecognitionModel'] = self._serialize.query("return_recognition_model", return_recognition_model, 'bool')
        if detection_model is not None:
            query_parameters['detectionModel'] = self._serialize.query("detection_model", detection_model, 'str')
        if face_id_time_to_live is not None:
            query_parameters['faceIdTimeToLive'] = self._serialize.query("face_id_time_to_live", face_id_time_to_live, 'int', maximum=86400, minimum=60)

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Content-Type'] = self._serialize.header("content_type", content_type, 'str')
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        body_content_kwargs = {}  # type: Dict[str, Any]
        body_content_kwargs['stream_content'] = image
        request = self._client.post(url, query_parameters, header_parameters, **body_content_kwargs)
        pipeline_response = await self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize('[DetectedFace]', pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized
    detect_with_stream.metadata = {'url': '/detect'}  # type: ignore
