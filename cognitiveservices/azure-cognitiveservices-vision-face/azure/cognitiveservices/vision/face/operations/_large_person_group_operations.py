# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
from typing import TYPE_CHECKING
import warnings

from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
from azure.core.pipeline import PipelineResponse
from azure.core.pipeline.transport import HttpRequest, HttpResponse

from .. import models as _models

if TYPE_CHECKING:
    # pylint: disable=unused-import,ungrouped-imports
    from typing import Any, Callable, Dict, Generic, List, Optional, TypeVar, Union

    T = TypeVar('T')
    ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]

class LargePersonGroupOperations(object):
    """LargePersonGroupOperations operations.

    You should not instantiate this class directly. Instead, you should create a Client instance that
    instantiates it for you and attaches it as an attribute.

    :ivar models: Alias to model classes used in this operation group.
    :type models: ~azure.cognitiveservices.vision.face.models
    :param client: Client for service requests.
    :param config: Configuration of service client.
    :param serializer: An object model serializer.
    :param deserializer: An object model deserializer.
    """

    models = _models

    def __init__(self, client, config, serializer, deserializer):
        self._client = client
        self._serialize = serializer
        self._deserialize = deserializer
        self._config = config

    def create(
        self,
        large_person_group_id,  # type: str
        name=None,  # type: Optional[str]
        user_data=None,  # type: Optional[str]
        recognition_model=None,  # type: Optional[Union[str, "_models.RecognitionModel"]]
        **kwargs  # type: Any
    ):
        # type: (...) -> None
        """Create a new large person group with user-specified largePersonGroupId, name, an optional
        userData and recognitionModel.
        :code:`<br />` A large person group is the container of the uploaded person data, including
        face recognition feature, and up to 1,000,000
        people.
        :code:`<br />` After creation, use `LargePersonGroup Person - Create
        <https://docs.microsoft.com/rest/api/faceapi/largepersongroupperson/create>`_ to add person
        into the group, and call `LargePersonGroup - Train
        <https://docs.microsoft.com/rest/api/faceapi/largepersongroup/train>`_ to get this group ready
        for `Face - Identify <https://docs.microsoft.com/rest/api/faceapi/face/identify>`_.
        :code:`<br />` No image will be stored. Only the person's extracted face features and userData
        will be stored on server until `LargePersonGroup Person - Delete
        <https://docs.microsoft.com/rest/api/faceapi/largepersongroupperson/delete>`_ or
        `LargePersonGroup - Delete
        <https://docs.microsoft.com/rest/api/faceapi/largepersongroup/delete>`_ is called.
        :code:`<br/>`'recognitionModel' should be specified to associate with this large person group.
        The default value for 'recognitionModel' is 'recognition_01', if the latest model needed,
        please explicitly specify the model you need in this parameter. New faces that are added to an
        existing large person group will use the recognition model that's already associated with the
        collection. Existing face features in a large person group can't be updated to features
        extracted by another version of recognition model. Please refer to `Specify a face recognition
        model <https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-
        recognition-model>`_.

        Large person group quota:


        * Free-tier subscription quota: 1,000 large person groups.
        * S0-tier subscription quota: 1,000,000 large person groups.

        :param large_person_group_id: Id referencing a particular large person group.
        :type large_person_group_id: str
        :param name: User defined name, maximum length is 128.
        :type name: str
        :param user_data: User specified data. Length should not exceed 16KB.
        :type user_data: str
        :param recognition_model: Name of recognition model. Recognition model is used when the face
         features are extracted and associated with detected faceIds, (Large)FaceList or
         (Large)PersonGroup. A recognition model name can be provided when performing Face - Detect or
         (Large)FaceList - Create or (Large)PersonGroup - Create. The default value is 'recognition_01',
         if latest model needed, please explicitly specify the model you need.
        :type recognition_model: str or ~azure.cognitiveservices.vision.face.models.RecognitionModel
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: None, or the result of cls(response)
        :rtype: None
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType[None]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))

        _body = _models.MetaDataContract(name=name, user_data=user_data, recognition_model=recognition_model)
        content_type = kwargs.pop("content_type", "application/json")
        accept = "application/json"

        # Construct URL
        url = self.create.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
            'largePersonGroupId': self._serialize.url("large_person_group_id", large_person_group_id, 'str', max_length=64, min_length=0, pattern=r'^[a-z0-9-_]+$'),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Content-Type'] = self._serialize.header("content_type", content_type, 'str')
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        body_content_kwargs = {}  # type: Dict[str, Any]
        body_content = self._serialize.body(_body, 'MetaDataContract')
        body_content_kwargs['content'] = body_content
        request = self._client.put(url, query_parameters, header_parameters, **body_content_kwargs)
        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        if cls:
            return cls(pipeline_response, None, {})

    create.metadata = {'url': '/largepersongroups/{largePersonGroupId}'}  # type: ignore

    def delete(
        self,
        large_person_group_id,  # type: str
        **kwargs  # type: Any
    ):
        # type: (...) -> None
        """Delete an existing large person group. Persisted face features of all people in the large
        person group will also be deleted.

        :param large_person_group_id: Id referencing a particular large person group.
        :type large_person_group_id: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: None, or the result of cls(response)
        :rtype: None
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType[None]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))
        accept = "application/json"

        # Construct URL
        url = self.delete.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
            'largePersonGroupId': self._serialize.url("large_person_group_id", large_person_group_id, 'str', max_length=64, min_length=0, pattern=r'^[a-z0-9-_]+$'),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        request = self._client.delete(url, query_parameters, header_parameters)
        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        if cls:
            return cls(pipeline_response, None, {})

    delete.metadata = {'url': '/largepersongroups/{largePersonGroupId}'}  # type: ignore

    def get(
        self,
        large_person_group_id,  # type: str
        return_recognition_model=False,  # type: Optional[bool]
        **kwargs  # type: Any
    ):
        # type: (...) -> "_models.LargePersonGroup"
        """Retrieve the information of a large person group, including its name, userData and
        recognitionModel. This API returns large person group information only, use `LargePersonGroup
        Person - List <https://docs.microsoft.com/rest/api/faceapi/largepersongroupperson/list>`_
        instead to retrieve person information under the large person group.

        :param large_person_group_id: Id referencing a particular large person group.
        :type large_person_group_id: str
        :param return_recognition_model: A value indicating whether the operation should return
         'recognitionModel' in response.
        :type return_recognition_model: bool
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: LargePersonGroup, or the result of cls(response)
        :rtype: ~azure.cognitiveservices.vision.face.models.LargePersonGroup
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType["_models.LargePersonGroup"]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))
        accept = "application/json"

        # Construct URL
        url = self.get.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
            'largePersonGroupId': self._serialize.url("large_person_group_id", large_person_group_id, 'str', max_length=64, min_length=0, pattern=r'^[a-z0-9-_]+$'),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]
        if return_recognition_model is not None:
            query_parameters['returnRecognitionModel'] = self._serialize.query("return_recognition_model", return_recognition_model, 'bool')

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        request = self._client.get(url, query_parameters, header_parameters)
        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize('LargePersonGroup', pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized
    get.metadata = {'url': '/largepersongroups/{largePersonGroupId}'}  # type: ignore

    def update(
        self,
        large_person_group_id,  # type: str
        name=None,  # type: Optional[str]
        user_data=None,  # type: Optional[str]
        **kwargs  # type: Any
    ):
        # type: (...) -> None
        """Update an existing large person group's display name and userData. The properties which does
        not appear in request body will not be updated.

        :param large_person_group_id: Id referencing a particular large person group.
        :type large_person_group_id: str
        :param name: User defined name, maximum length is 128.
        :type name: str
        :param user_data: User specified data. Length should not exceed 16KB.
        :type user_data: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: None, or the result of cls(response)
        :rtype: None
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType[None]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))

        _body = _models.NameAndUserDataContract(name=name, user_data=user_data)
        content_type = kwargs.pop("content_type", "application/json")
        accept = "application/json"

        # Construct URL
        url = self.update.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
            'largePersonGroupId': self._serialize.url("large_person_group_id", large_person_group_id, 'str', max_length=64, min_length=0, pattern=r'^[a-z0-9-_]+$'),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Content-Type'] = self._serialize.header("content_type", content_type, 'str')
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        body_content_kwargs = {}  # type: Dict[str, Any]
        body_content = self._serialize.body(_body, 'NameAndUserDataContract')
        body_content_kwargs['content'] = body_content
        request = self._client.patch(url, query_parameters, header_parameters, **body_content_kwargs)
        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        if cls:
            return cls(pipeline_response, None, {})

    update.metadata = {'url': '/largepersongroups/{largePersonGroupId}'}  # type: ignore

    def get_training_status(
        self,
        large_person_group_id,  # type: str
        **kwargs  # type: Any
    ):
        # type: (...) -> "_models.TrainingStatus"
        """Retrieve the training status of a large person group (completed or ongoing).

        :param large_person_group_id: Id referencing a particular large person group.
        :type large_person_group_id: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: TrainingStatus, or the result of cls(response)
        :rtype: ~azure.cognitiveservices.vision.face.models.TrainingStatus
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType["_models.TrainingStatus"]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))
        accept = "application/json"

        # Construct URL
        url = self.get_training_status.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
            'largePersonGroupId': self._serialize.url("large_person_group_id", large_person_group_id, 'str', max_length=64, min_length=0, pattern=r'^[a-z0-9-_]+$'),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        request = self._client.get(url, query_parameters, header_parameters)
        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize('TrainingStatus', pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized
    get_training_status.metadata = {'url': '/largepersongroups/{largePersonGroupId}/training'}  # type: ignore

    def list(
        self,
        start=None,  # type: Optional[str]
        top=1000,  # type: Optional[int]
        return_recognition_model=False,  # type: Optional[bool]
        **kwargs  # type: Any
    ):
        # type: (...) -> List["_models.LargePersonGroup"]
        """List all existing large person groups’ largePersonGroupId, name, userData and
        recognitionModel.:code:`<br />`


        * Large person groups are stored in alphabetical order of largePersonGroupId.
        * "start" parameter (string, optional) is a user-provided largePersonGroupId value that
        returned entries have larger ids by string comparison. "start" set to empty to indicate return
        from the first item.
        * "top" parameter (int, optional) specifies the number of entries to return. A maximal of 1000
        entries can be returned in one call. To fetch more, you can specify "start" with the last
        returned entry’s Id of the current call.
          :code:`<br />`
          For example, total 5 large person groups: "group1", ..., "group5".
          :code:`<br />` "start=&top=" will return all 5 groups.
          :code:`<br />` "start=&top=2" will return "group1", "group2".
          :code:`<br />` "start=group2&top=3" will return "group3", "group4", "group5".

        :param start: List large person groups from the least largePersonGroupId greater than the
         "start".
        :type start: str
        :param top: The number of large person groups to list.
        :type top: int
        :param return_recognition_model: A value indicating whether the operation should return
         'recognitionModel' in response.
        :type return_recognition_model: bool
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: list of LargePersonGroup, or the result of cls(response)
        :rtype: list[~azure.cognitiveservices.vision.face.models.LargePersonGroup]
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType[List["_models.LargePersonGroup"]]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))
        accept = "application/json"

        # Construct URL
        url = self.list.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]
        if start is not None:
            query_parameters['start'] = self._serialize.query("start", start, 'str', max_length=64, min_length=0)
        if top is not None:
            query_parameters['top'] = self._serialize.query("top", top, 'int', maximum=1000, minimum=1)
        if return_recognition_model is not None:
            query_parameters['returnRecognitionModel'] = self._serialize.query("return_recognition_model", return_recognition_model, 'bool')

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        request = self._client.get(url, query_parameters, header_parameters)
        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize('[LargePersonGroup]', pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized
    list.metadata = {'url': '/largepersongroups'}  # type: ignore

    def train(
        self,
        large_person_group_id,  # type: str
        **kwargs  # type: Any
    ):
        # type: (...) -> None
        """Queue a large person group training task, the training task may not be started immediately.

        :param large_person_group_id: Id referencing a particular large person group.
        :type large_person_group_id: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: None, or the result of cls(response)
        :rtype: None
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        cls = kwargs.pop('cls', None)  # type: ClsType[None]
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}))
        accept = "application/json"

        # Construct URL
        url = self.train.metadata['url']  # type: ignore
        path_format_arguments = {
            'Endpoint': self._serialize.url("self._config.endpoint", self._config.endpoint, 'str', skip_quote=True),
            'largePersonGroupId': self._serialize.url("large_person_group_id", large_person_group_id, 'str', max_length=64, min_length=0, pattern=r'^[a-z0-9-_]+$'),
        }
        url = self._client.format_url(url, **path_format_arguments)

        # Construct parameters
        query_parameters = {}  # type: Dict[str, Any]

        # Construct headers
        header_parameters = {}  # type: Dict[str, Any]
        header_parameters['Accept'] = self._serialize.header("accept", accept, 'str')

        request = self._client.post(url, query_parameters, header_parameters)
        pipeline_response = self._client._pipeline.run(request, stream=False, **kwargs)
        response = pipeline_response.http_response

        if response.status_code not in [202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.APIError, response)
            raise HttpResponseError(response=response, model=error)

        if cls:
            return cls(pipeline_response, None, {})

    train.metadata = {'url': '/largepersongroups/{largePersonGroupId}/train'}  # type: ignore
