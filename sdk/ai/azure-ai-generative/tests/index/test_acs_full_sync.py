import json
import logging

import pytest

logger = logging.getLogger(__name__)


@pytest.fixture(scope="session")
def uri_full_sync_acs_pipeline(crack_and_chunk_and_embed_component_local, update_acs_index_component, register_mlindex_asset_component):
    from azure.ai.ml import Output
    from azure.ai.ml.dsl import pipeline
    from azure.ai.ml.entities._job.pipeline._io import PipelineInput

    def use_automatic_compute(component, instance_count=1, instance_type="Standard_E8s_v3"):
        component.set_resources(instance_count=instance_count, instance_type=instance_type, properties={"compute_specification": {"automatic": True}})
        return component

    def optional_pipeline_input_provided(input: PipelineInput):
        return input._data is not None

    @pipeline(default_compute="serverless")
    def uri_full_sync_acs(
        input_data,
        input_glob,
        citation_url,
        citation_replacement_regex,
        acs_config,
        acs_connection_id,
        embeddings_model,
        asset_name,
        aoai_connection_id=None,
        embeddings_container=None,
    ):
        crack_and_chunk_and_embed = crack_and_chunk_and_embed_component_local(
            input_data=input_data,
            input_glob=input_glob,
            chunk_size=1024,
            citation_url=citation_url,
            citation_replacement_regex=citation_replacement_regex,
            embeddings_container=embeddings_container,
            embeddings_model=embeddings_model,
            embeddings_connection_id=aoai_connection_id,
        )
        use_automatic_compute(crack_and_chunk_and_embed)

        if optional_pipeline_input_provided(embeddings_container):
            # If provided, previous_embeddings is expected to be a URI to an 'embeddings container' folder.
            # Each folder under this folder is generated by a `generate_embeddings_parallel_component` run and can be reused for subsequent embeddings runs.
            crack_and_chunk_and_embed.outputs.embeddings = Output(type="uri_folder", path=f"{embeddings_container.path}/{{name}}")

        update_acs_index = update_acs_index_component(
            embeddings=crack_and_chunk_and_embed.outputs.embeddings,
            #embeddings=Input(type="uri_folder", path=f"azureml://datastores/workspaceblobstore/paths/embeddings/azure_docs_aoai_acs_rcts/69a579ac-9892-4788-ba2d-6ae4891c343e"),
            acs_config=acs_config,
            connection_id=acs_connection_id,
        )
        use_automatic_compute(update_acs_index)
        if optional_pipeline_input_provided(acs_connection_id):
            update_acs_index.environment_variables["AZUREML_WORKSPACE_CONNECTION_ID_ACS"] = acs_connection_id

        register_mlindex = register_mlindex_asset_component(
            storage_uri=update_acs_index.outputs.index,
            asset_name=asset_name,
        )
        use_automatic_compute(register_mlindex)
        return {
            "mlindex_asset_uri": update_acs_index.outputs.index,
            "mlindex_asset_id": register_mlindex.outputs.asset_id
        }

    return uri_full_sync_acs


def test_incremental_many_docs_full_sync_acs(local_components_base, azureml_workspace_v2, azureml_workspace_v1, experiment_name,
                                uri_full_sync_acs_pipeline, test_data_dir,
                                aoai_connection, acs_connection, acs_temp_index, stream_run_output):
    from azure.ai.ml import Input

    incremental_many_docs = test_data_dir / "documents" / "incremental_many_docs" / "first_run"
    input_glob = "**/*"
    #citation_url = "https://learn.microsoft.com/en-us/azure"
    #citation_replacement_regex = r'{"match_pattern": "(.*)/articles/(.*)(\\.[^.]+)$", "replacement_pattern": "\\1/\\2"}'
    asset_name = "incremental_many_docs_full_sync_acs"

    pipeline_job = uri_full_sync_acs_pipeline(
        input_data=Input(type="uri_folder", path=incremental_many_docs),
        input_glob=input_glob,
        #citation_url=citation_url,
        #citation_replacement_regex=citation_replacement_regex,
        embeddings_model="azure_open_ai://deployment/text-embedding-ada-002/model/text-embedding-ada-002",
        #embeddings_model='hugging_face://model/sentence-transformers/all-mpnet-base-v2',
        aoai_connection_id=aoai_connection["id"],
        embeddings_container=Input(type="uri_folder", path=f"azureml://datastores/workspaceblobstore/paths/embeddings/{asset_name}"),
        acs_config=json.dumps({
            #'index_name': f'{asset_name.replace("_", "-")}',
            "index_name": acs_temp_index,
            "sync_index": True
            #'push_embeddings': "False"
        }),
        acs_connection_id=acs_connection["id"],
        asset_name=asset_name
    )
    pipeline_job.display_name = asset_name

    #pipeline_job.settings.default_compute = "cpu-e16"
    #pipeline_job.settings.force_rerun = True # Rerun each time so that git_clone isn't cached, if intent is to ingest latest data.

    # These are added so that in progress index generations can be listed in UI, this tagging is done automatically by UI.
    pipeline_job.properties["azureml.mlIndexAssetName"] = asset_name
    pipeline_job.properties["azureml.mlIndexAssetKind"] = "acs"
    pipeline_job.properties["azureml.mlIndexAssetSource"] = "AzureML Data"

    logger.info(f"Submitting pipeline job to experiment: {experiment_name}")
    running_pipeline_job = azureml_workspace_v2.jobs.create_or_update(
        pipeline_job, experiment_name=experiment_name
    )

    logger.info(f'Submitted run "{running_pipeline_job}", url: {running_pipeline_job.studio_url}')

    if stream_run_output:
        azureml_workspace_v2.jobs.stream(running_pipeline_job.name)
    else:
        run = azureml_workspace_v1.get_run(running_pipeline_job.name)
        run.wait_for_completion(show_output=False)

    output = azureml_workspace_v2.jobs._get_named_output_uri(running_pipeline_job.name, "mlindex_asset_uri")
    logger.info(f"mlindex_asset_uri: {output['mlindex_asset_uri']}")

    #index_asset = azureml_workspace_v2.data.get(output['mlindex_asset'], label='latest')

    from azureml.rag.mlindex import MLIndex

    retriever = MLIndex(output["mlindex_asset_uri"]).as_langchain_retriever()
    docs = retriever.get_relevant_documents("What is Baby Shark and why does Microsoft care?")

    for doc in docs:
        logger.info(f"doc: {doc}")
