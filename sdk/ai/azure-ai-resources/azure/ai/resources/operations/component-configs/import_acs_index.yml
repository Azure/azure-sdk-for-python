$schema: https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json
type: pipeline

version: 0.0.5
name: llm_ingest_existing_acs_basic
display_name: LLM - Existing ACS Pipeline
is_deterministic: false

description: Single job pipeline to import embedded data from ACS index, and create MlIndex, generate test/prompt data, and create PF

settings:
   default_compute: serverless

inputs:
  # register settings
  embeddings_dataset_name:
    type: string
    optional: true
    default: "VectorIndexDS"
    description: "Name of the vector index"
  # compute settings
  serverless_instance_count:
    type: integer
    default: 1
    optional: true
    description: "Instance count to use for the serverless compute"
  serverless_instance_type:
    type: string
    default: "Standard_E8s_v3"
    optional: true
    description: "The Instance Type to be used for the serverless compute"
  # acs import component
  acs_import_connection:
    type: string
    optional: true
    description: "Azure Cognitive Search workspace connection ARM ID"
  acs_import_config:
    type: string
    description: "JSON containing information about the ACS resource"
  num_docs_to_import:
    type: integer
    default: 50
    description: "Number of documents to retreive from ACS for QA/Prompt Generation"
  # Data Chunker
  chunk_size:
    type: integer
    default: 1024
    description: "Chunk size (by token) to pass into the text splitter before performing embeddings"
  chunk_overlap:
    type: integer
    default: 0
    description: "Overlap of content (by token) between the chunks"
  input_glob:
    type: string
    optional: true
    description: "Glob pattern to filter files from the input folder. e.g. 'articles/**/*''"
  max_sample_files:
    type: integer
    default: -1
    optional: true
    description: "Number of files read in during QA test data generation"
  chunk_prepend_summary:
    type: string
    enum:
    - "True"
    - "False"
    default: "False"
    optional: true
    description:  "Whether to include summary of document on top of every chunk for that document."
  data_source_url:
    type: string
    optional: true
    description: "The url which can be appended to file names to form citation links for documents"
  document_path_replacement_regex:
    type: string
    optional: true
    description: "A JSON string with two fields, 'match_pattern' and 'replacement_pattern' to be used with re.sub on the source url. e.g. '{\"match_pattern\": \"(.*)/articles/(.*)\", \"replacement_pattern\": \"\\1/\\2\"}' would remove '/articles' from the middle of the url."
  # Embedding connection
  embedding_connection:
    type: string
    optional: true
    description: "Azure OpenAI workspace connection ARM ID for what embeddings were used to embed ACS index"
outputs:
   acs_index:
     type: uri_folder
     description: "Folder containing the FAISS MLIndex. Deserialized using azureml.rag.mlindex._mlindex(uri)."

#defaults:
#  compute: azureml:cpu-cluster
jobs:
  #############
  data_import_job:
    type: command
    resources:
      instance_count: ${{parent.inputs.serverless_instance_count}}
      instance_type: ${{parent.inputs.serverless_instance_type}}
      properties:
        compute_specification:
          automatic: true
    component: 'azureml://registries/azureml-preview/components/llm_rag_data_import_acs/versions/0.0.8'
    inputs:
      num_docs: ${{parent.inputs.num_docs_to_import}}
      acs_config: ${{parent.inputs.acs_import_config}}
      use_existing: true
    outputs:
      output_data:
        type: uri_folder
      ml_index:
        type: uri_folder
    environment_variables:
       AZUREML_WORKSPACE_CONNECTION_ID_ACS : ${{parent.inputs.acs_import_connection}}
       AZUREML_WORKSPACE_CONNECTION_ID_AOAI: ${{parent.inputs.embedding_connection}}
  ############
  data_chunking_job:
    type: command
    resources:
      instance_count: ${{parent.inputs.serverless_instance_count}}
      instance_type: ${{parent.inputs.serverless_instance_type}}
      properties:
        compute_specification:
          automatic: true
    component: 'azureml://registries/azureml-preview/components/llm_rag_crack_and_chunk/versions/0.0.8'
    inputs:
      input_data: ${{parent.jobs.data_import_job.outputs.output_data}}
      input_glob: ${{parent.inputs.input_glob}}
      chunk_size: ${{parent.inputs.chunk_size}}
      chunk_overlap: ${{parent.inputs.chunk_overlap}}
      data_source_url: ${{parent.inputs.data_source_url}}
      document_path_replacement_regex: ${{parent.inputs.document_path_replacement_regex}}
      include_summary: ${{parent.inputs.chunk_prepend_summary}}
      max_sample_files: ${{parent.inputs.max_sample_files}}
    outputs:
      output_chunks:
        type: uri_folder
  ############
  register_mlindex_asset_job:
    type: command
    resources:
      instance_count: ${{parent.inputs.serverless_instance_count}}
      instance_type: ${{parent.inputs.serverless_instance_type}}
      properties:
        compute_specification:
          automatic: true
    component: 'azureml://registries/azureml-preview/components/llm_rag_register_mlindex_asset/versions/0.0.8'
    inputs:
      storage_uri: ${{parent.jobs.data_import_job.outputs.ml_index}}
      asset_name: ${{parent.inputs.embeddings_dataset_name}}
    outputs:
      asset_id:
        type: uri_file
