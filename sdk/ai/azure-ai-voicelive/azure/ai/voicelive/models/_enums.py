# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------

from enum import Enum
from azure.core import CaseInsensitiveEnumMeta


class CreateSpeechResponseStreamEventType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of CreateSpeechResponseStreamEventType."""

    SPEECH_AUDIO_DELTA = "speech.audio.delta"
    SPEECH_AUDIO_DONE = "speech.audio.done"


class TranscriptTextUsageType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of TranscriptTextUsageType."""

    TOKENS = "tokens"
    DURATION = "duration"


class VoiceIdsShared(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of VoiceIdsShared."""

    ALLOY = "alloy"
    ASH = "ash"
    BALLAD = "ballad"
    CORAL = "coral"
    ECHO = "echo"
    FABLE = "fable"
    ONYX = "onyx"
    NOVA = "nova"
    SAGE = "sage"
    SHIMMER = "shimmer"
    VERSE = "verse"


class VoiceLiveAudioFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of VoiceLiveAudioFormat."""

    PCM16 = "pcm16"
    G711_ULAW = "g711_ulaw"
    G711_ALAW = "g711_alaw"


class VoiceLiveAudioInputTranscriptionModel(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of VoiceLiveAudioInputTranscriptionModel."""

    WHISPER1 = "whisper-1"


class VoiceLiveAudioNoiseReductionType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of VoiceLiveAudioNoiseReductionType."""

    NEAR_FIELD = "near_field"
    FAR_FIELD = "far_field"


class VoiceLiveClientEventType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of VoiceLiveClientEventType."""

    SESSION_UPDATE = "session.update"
    INPUT_AUDIO_BUFFER_APPEND = "input_audio_buffer.append"
    INPUT_AUDIO_BUFFER_COMMIT = "input_audio_buffer.commit"
    INPUT_AUDIO_BUFFER_CLEAR = "input_audio_buffer.clear"
    OUTPUT_AUDIO_BUFFER_CLEAR = "output_audio_buffer.clear"
    CONVERSATION_ITEM_CREATE = "conversation.item.create"
    CONVERSATION_ITEM_RETRIEVE = "conversation.item.retrieve"
    CONVERSATION_ITEM_TRUNCATE = "conversation.item.truncate"
    CONVERSATION_ITEM_DELETE = "conversation.item.delete"
    RESPONSE_CREATE = "response.create"
    RESPONSE_CANCEL = "response.cancel"
    TRANSCRIPTION_SESSION_UPDATE = "transcription_session.update"


class VoiceLiveContentPartType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of VoiceLiveContentPartType."""

    INPUT_TEXT = "input_text"
    INPUT_AUDIO = "input_audio"
    TEXT = "text"
    AUDIO = "audio"


class VoiceLiveItemStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of VoiceLiveItemStatus."""

    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    INCOMPLETE = "incomplete"


class VoiceLiveItemType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of VoiceLiveItemType."""

    MESSAGE = "message"
    FUNCTION_CALL = "function_call"
    FUNCTION_CALL_OUTPUT = "function_call_output"


class VoiceLiveMessageRole(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of VoiceLiveMessageRole."""

    SYSTEM = "system"
    USER = "user"
    ASSISTANT = "assistant"


class VoiceLiveModality(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of VoiceLiveModality."""

    TEXT = "text"
    AUDIO = "audio"


class VoiceLiveServerEventType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of VoiceLiveServerEventType."""

    ERROR = "error"
    SESSION_CREATED = "session.created"
    SESSION_UPDATED = "session.updated"
    CONVERSATION_CREATED = "conversation.created"
    CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_COMPLETED = "conversation.item.input_audio_transcription.completed"
    CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_DELTA = "conversation.item.input_audio_transcription.delta"
    CONVERSATION_ITEM_INPUT_AUDIO_TRANSCRIPTION_FAILED = "conversation.item.input_audio_transcription.failed"
    CONVERSATION_ITEM_CREATED = "conversation.item.created"
    CONVERSATION_ITEM_RETRIEVED = "conversation.item.retrieved"
    CONVERSATION_ITEM_TRUNCATED = "conversation.item.truncated"
    CONVERSATION_ITEM_DELETED = "conversation.item.deleted"
    INPUT_AUDIO_BUFFER_COMMITTED = "input_audio_buffer.committed"
    INPUT_AUDIO_BUFFER_CLEARED = "input_audio_buffer.cleared"
    INPUT_AUDIO_BUFFER_SPEECH_STARTED = "input_audio_buffer.speech_started"
    INPUT_AUDIO_BUFFER_SPEECH_STOPPED = "input_audio_buffer.speech_stopped"
    OUTPUT_AUDIO_BUFFER_CLEARED = "output_audio_buffer.cleared"
    OUTPUT_AUDIO_BUFFER_STARTED = "output_audio_buffer.started"
    OUTPUT_AUDIO_BUFFER_STOPPED = "output_audio_buffer.stopped"
    RESPONSE_CREATED = "response.created"
    RESPONSE_DONE = "response.done"
    RESPONSE_OUTPUT_ITEM_ADDED = "response.output_item.added"
    RESPONSE_OUTPUT_ITEM_DONE = "response.output_item.done"
    RESPONSE_CONTENT_PART_ADDED = "response.content_part.added"
    RESPONSE_CONTENT_PART_DONE = "response.content_part.done"
    RESPONSE_TEXT_DELTA = "response.text.delta"
    RESPONSE_TEXT_DONE = "response.text.done"
    RESPONSE_AUDIO_TRANSCRIPT_DELTA = "response.audio_transcript.delta"
    RESPONSE_AUDIO_TRANSCRIPT_DONE = "response.audio_transcript.done"
    RESPONSE_AUDIO_DELTA = "response.audio.delta"
    RESPONSE_AUDIO_DONE = "response.audio.done"
    RESPONSE_FUNCTION_CALL_ARGUMENTS_DELTA = "response.function_call_arguments.delta"
    RESPONSE_FUNCTION_CALL_ARGUMENTS_DONE = "response.function_call_arguments.done"
    TRANSCRIPTION_SESSION_UPDATED = "transcription_session.updated"
    RATE_LIMITS_UPDATED = "rate_limits.updated"


class VoiceLiveToolChoiceLiteral(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The available set of mode-level, string literal tool_choice options for the voicelive endpoint."""

    AUTO = "auto"
    """Specifies that the model should freely determine which tool or tools, if any, to call."""
    NONE = "none"
    """Specifies that the model should call no tools whatsoever."""
    REQUIRED = "required"
    """Specifies that the model should call at least one tool."""


class VoiceLiveToolType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The supported tool type discriminators for voicelive tools.
    Currently, only 'function' tools are supported.
    """

    FUNCTION = "function"


class VoiceLiveTurnDetectionType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of VoiceLiveTurnDetectionType."""

    SERVER_VAD = "server_vad"
    """Indicates that server-side voice activity detection (VAD) should be enabled, allowing the
    server to determine when
    add_user_audio commands present ends of speech and should be automatically committed.
    
    The API will also detect when the user begins talking, sending a generation_canceled command."""
    SEMANTIC_VAD = "semantic_vad"
