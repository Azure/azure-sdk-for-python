# pylint: disable=line-too-long,useless-suppression,too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
# pylint: disable=useless-super-delegation

import datetime
from typing import Any, Dict, List, Literal, Mapping, Optional, TYPE_CHECKING, Union, overload

from .._utils.model_base import Model as _Model, rest_discriminator, rest_field
from ._enums import (
    CreateSpeechResponseStreamEventType,
    VoiceLiveAudioNoiseReductionType,
    VoiceLiveClientEventType,
    VoiceLiveServerEventType,
    VoiceLiveToolType,
    VoiceLiveTurnDetectionType,
)

if TYPE_CHECKING:
    from .. import _types, models as _models


class CreateSpeechRequest(_Model):
    """CreateSpeechRequest.

    :ivar model: One of the available `TTS models </docs/models#tts>`_: ``tts-1``, ``tts-1-hd`` or
     ``gpt-4o-mini-tts``. Required. Is one of the following types: Literal["tts-1"],
     Literal["tts-1-hd"], Literal["gpt-4o-mini-tts"], str
    :vartype model: str or str or str or str
    :ivar input: The text to generate audio for. The maximum length is 4096 characters. Required.
    :vartype input: str
    :ivar instructions: Control the voice of your generated audio with additional instructions.
     Does not work with ``tts-1`` or ``tts-1-hd``.
    :vartype instructions: str
    :ivar voice: The voice to use when generating the audio. Supported voices are ``alloy``,
     ``ash``, ``ballad``, ``coral``, ``echo``, ``fable``, ``onyx``, ``nova``, ``sage``, ``shimmer``,
     and ``verse``. Previews of the voices are available in the `Text to speech guide
     </docs/guides/text-to-speech#voice-options>`_. Required. Known values are: "alloy", "ash",
     "ballad", "coral", "echo", "fable", "onyx", "nova", "sage", "shimmer", and "verse".
    :vartype voice: str or ~azure.ai.voicelive.models.VoiceIdsShared
    :ivar response_format: The format to audio in. Supported formats are ``mp3``, ``opus``,
     ``aac``, ``flac``, ``wav``, and ``pcm``. Is one of the following types: Literal["mp3"],
     Literal["opus"], Literal["aac"], Literal["flac"], Literal["wav"], Literal["pcm"]
    :vartype response_format: str or str or str or str or str or str
    :ivar speed: The speed of the generated audio. Select a value from ``0.25`` to ``4.0``. ``1.0``
     is the default.
    :vartype speed: float
    :ivar stream_format: The format to stream the audio in. Supported formats are ``sse`` and
     ``audio``. ``sse`` is not supported for ``tts-1`` or ``tts-1-hd``. Is either a Literal["sse"]
     type or a Literal["audio"] type.
    :vartype stream_format: str or str
    """

    model: Union[Literal["tts-1"], Literal["tts-1-hd"], Literal["gpt-4o-mini-tts"], str] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """One of the available `TTS models </docs/models#tts>`_: ``tts-1``, ``tts-1-hd`` or
     ``gpt-4o-mini-tts``. Required. Is one of the following types: Literal[\"tts-1\"],
     Literal[\"tts-1-hd\"], Literal[\"gpt-4o-mini-tts\"], str"""
    input: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The text to generate audio for. The maximum length is 4096 characters. Required."""
    instructions: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Control the voice of your generated audio with additional instructions. Does not work with
     ``tts-1`` or ``tts-1-hd``."""
    voice: Union[str, "_models.VoiceIdsShared"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The voice to use when generating the audio. Supported voices are ``alloy``, ``ash``,
     ``ballad``, ``coral``, ``echo``, ``fable``, ``onyx``, ``nova``, ``sage``, ``shimmer``, and
     ``verse``. Previews of the voices are available in the `Text to speech guide
     </docs/guides/text-to-speech#voice-options>`_. Required. Known values are: \"alloy\", \"ash\",
     \"ballad\", \"coral\", \"echo\", \"fable\", \"onyx\", \"nova\", \"sage\", \"shimmer\", and
     \"verse\"."""
    response_format: Optional[Literal["mp3", "opus", "aac", "flac", "wav", "pcm"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The format to audio in. Supported formats are ``mp3``, ``opus``, ``aac``, ``flac``, ``wav``,
     and ``pcm``. Is one of the following types: Literal[\"mp3\"], Literal[\"opus\"],
     Literal[\"aac\"], Literal[\"flac\"], Literal[\"wav\"], Literal[\"pcm\"]"""
    speed: Optional[float] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The speed of the generated audio. Select a value from ``0.25`` to ``4.0``. ``1.0`` is the
     default."""
    stream_format: Optional[Literal["sse", "audio"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The format to stream the audio in. Supported formats are ``sse`` and ``audio``. ``sse`` is not
     supported for ``tts-1`` or ``tts-1-hd``. Is either a Literal[\"sse\"] type or a
     Literal[\"audio\"] type."""

    @overload
    def __init__(
        self,
        *,
        model: Union[Literal["tts-1"], Literal["tts-1-hd"], Literal["gpt-4o-mini-tts"], str],
        input: str,
        voice: Union[str, "_models.VoiceIdsShared"],
        instructions: Optional[str] = None,
        response_format: Optional[Literal["mp3", "opus", "aac", "flac", "wav", "pcm"]] = None,
        speed: Optional[float] = None,
        stream_format: Optional[Literal["sse", "audio"]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class CreateSpeechResponseStreamEvent(_Model):
    """CreateSpeechResponseStreamEvent.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    SpeechAudioDeltaEvent, SpeechAudioDoneEvent

    :ivar type: Required. Known values are: "speech.audio.delta" and "speech.audio.done".
    :vartype type: str or ~azure.ai.voicelive.models.CreateSpeechResponseStreamEventType
    """

    __mapping__: Dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"speech.audio.delta\" and \"speech.audio.done\"."""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class Error(_Model):
    """Error.

    :ivar code: Required.
    :vartype code: str
    :ivar message: Required.
    :vartype message: str
    :ivar param: Required.
    :vartype param: str
    :ivar type: Required.
    :vartype type: str
    """

    code: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    message: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    param: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    type: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        code: str,
        message: str,
        param: str,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ErrorResponse(_Model):
    """ErrorResponse.

    :ivar error: Required.
    :vartype error: ~azure.ai.voicelive.models.Error
    """

    error: "_models.Error" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        error: "_models.Error",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class SpeechAudioDeltaEvent(CreateSpeechResponseStreamEvent, discriminator="speech.audio.delta"):
    """Emitted for each chunk of audio data generated during speech synthesis.

    :ivar type: The type of the event. Always ``speech.audio.delta``. Required.
    :vartype type: str or ~azure.ai.voicelive.models.SPEECH_AUDIO_DELTA
    :ivar audio: A chunk of Base64-encoded audio data. Required.
    :vartype audio: bytes
    """

    type: Literal[CreateSpeechResponseStreamEventType.SPEECH_AUDIO_DELTA] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``speech.audio.delta``. Required."""
    audio: bytes = rest_field(visibility=["read", "create", "update", "delete", "query"], format="base64")
    """A chunk of Base64-encoded audio data. Required."""

    @overload
    def __init__(
        self,
        *,
        audio: bytes,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type=CreateSpeechResponseStreamEventType.SPEECH_AUDIO_DELTA, **kwargs)


class SpeechAudioDoneEvent(CreateSpeechResponseStreamEvent, discriminator="speech.audio.done"):
    """Emitted when the speech synthesis is complete and all audio has been streamed.

    :ivar type: The type of the event. Always ``speech.audio.done``. Required.
    :vartype type: str or ~azure.ai.voicelive.models.SPEECH_AUDIO_DONE
    :ivar usage: Token usage statistics for the request. Required.
    :vartype usage: ~azure.ai.voicelive.models.SpeechAudioDoneEventUsage
    """

    type: Literal[CreateSpeechResponseStreamEventType.SPEECH_AUDIO_DONE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``speech.audio.done``. Required."""
    usage: "_models.SpeechAudioDoneEventUsage" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Token usage statistics for the request. Required."""

    @overload
    def __init__(
        self,
        *,
        usage: "_models.SpeechAudioDoneEventUsage",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type=CreateSpeechResponseStreamEventType.SPEECH_AUDIO_DONE, **kwargs)


class SpeechAudioDoneEventUsage(_Model):
    """SpeechAudioDoneEventUsage.

    :ivar input_tokens: Number of input tokens in the prompt. Required.
    :vartype input_tokens: int
    :ivar output_tokens: Number of output tokens generated. Required.
    :vartype output_tokens: int
    :ivar total_tokens: Total number of tokens used (input + output). Required.
    :vartype total_tokens: int
    """

    input_tokens: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Number of input tokens in the prompt. Required."""
    output_tokens: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Number of output tokens generated. Required."""
    total_tokens: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Total number of tokens used (input + output). Required."""

    @overload
    def __init__(
        self,
        *,
        input_tokens: int,
        output_tokens: int,
        total_tokens: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class VoiceLiveAudioNoiseReduction(_Model):
    """VoiceLiveAudioNoiseReduction.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    VoiceLiveAudioFarFieldNoiseReduction, VoiceLiveAudioNearFieldNoiseReduction

    :ivar type: Required. Known values are: "near_field" and "far_field".
    :vartype type: str or ~azure.ai.voicelive.models.VoiceLiveAudioNoiseReductionType
    """

    __mapping__: Dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"near_field\" and \"far_field\"."""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class VoiceLiveAudioFarFieldNoiseReduction(VoiceLiveAudioNoiseReduction, discriminator="far_field"):
    """VoiceLiveAudioFarFieldNoiseReduction.

    :ivar type: Required.
    :vartype type: str or ~azure.ai.voicelive.models.FAR_FIELD
    """

    type: Literal[VoiceLiveAudioNoiseReductionType.FAR_FIELD] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""

    @overload
    def __init__(
        self,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type=VoiceLiveAudioNoiseReductionType.FAR_FIELD, **kwargs)


class VoiceLiveAudioInputTranscriptionSettings(_Model):
    """VoiceLiveAudioInputTranscriptionSettings.

    :ivar model: "whisper-1"
    :vartype model: str or ~azure.ai.voicelive.models.VoiceLiveAudioInputTranscriptionModel
    :ivar language:
    :vartype language: str
    :ivar prompt:
    :vartype prompt: str
    """

    model: Optional[Union[str, "_models.VoiceLiveAudioInputTranscriptionModel"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """\"whisper-1\""""
    language: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    prompt: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])

    @overload
    def __init__(
        self,
        *,
        model: Optional[Union[str, "_models.VoiceLiveAudioInputTranscriptionModel"]] = None,
        language: Optional[str] = None,
        prompt: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class VoiceLiveAudioNearFieldNoiseReduction(VoiceLiveAudioNoiseReduction, discriminator="near_field"):
    """VoiceLiveAudioNearFieldNoiseReduction.

    :ivar type: Required.
    :vartype type: str or ~azure.ai.voicelive.models.NEAR_FIELD
    """

    type: Literal[VoiceLiveAudioNoiseReductionType.NEAR_FIELD] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""

    @overload
    def __init__(
        self,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type=VoiceLiveAudioNoiseReductionType.NEAR_FIELD, **kwargs)


class VoiceLiveClientEvent(_Model):
    """A voicelive client event.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    VoiceLiveClientEventConversationItemCreate, VoiceLiveClientEventConversationItemDelete,
    VoiceLiveClientEventConversationItemRetrieve, VoiceLiveClientEventConversationItemTruncate,
    VoiceLiveClientEventInputAudioBufferAppend, VoiceLiveClientEventInputAudioBufferClear,
    VoiceLiveClientEventInputAudioBufferCommit, VoiceLiveClientEventOutputAudioBufferClear,
    VoiceLiveClientEventResponseCancel, VoiceLiveClientEventResponseCreate,
    VoiceLiveClientEventSessionUpdate, VoiceLiveClientEventTranscriptionSessionUpdate

    :ivar type: The type of event. Required. Known values are: "session.update",
     "input_audio_buffer.append", "input_audio_buffer.commit", "input_audio_buffer.clear",
     "output_audio_buffer.clear", "conversation.item.create", "conversation.item.retrieve",
     "conversation.item.truncate", "conversation.item.delete", "response.create", "response.cancel",
     and "transcription_session.update".
    :vartype type: str or ~azure.ai.voicelive.models.VoiceLiveClientEventType
    :ivar event_id:
    :vartype event_id: str
    """

    __mapping__: Dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """The type of event. Required. Known values are: \"session.update\",
     \"input_audio_buffer.append\", \"input_audio_buffer.commit\", \"input_audio_buffer.clear\",
     \"output_audio_buffer.clear\", \"conversation.item.create\", \"conversation.item.retrieve\",
     \"conversation.item.truncate\", \"conversation.item.delete\", \"response.create\",
     \"response.cancel\", and \"transcription_session.update\"."""
    event_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])

    @overload
    def __init__(
        self,
        *,
        type: str,
        event_id: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class VoiceLiveClientEventSessionUpdate(VoiceLiveClientEvent, discriminator="session.update"):
    """Send this event to update the session’s default configuration.
    The client may send this event at any time to update any field,
    except for ``voice``. However, note that once a session has been
    initialized with a particular ``model``, it can’t be changed to
    another model using ``session.update``.

    When the server receives a ``session.update``, it will respond
    with a ``session.updated`` event showing the full, effective configuration.
    Only the fields that are present are updated. To clear a field like
    ``instructions``, pass an empty string.

    :ivar event_id:
    :vartype event_id: str
    :ivar type: The event type, must be ``session.update``. Required.
    :vartype type: str or ~azure.ai.voicelive.models.SESSION_UPDATE
    :ivar session: Required.
    :vartype session: ~azure.ai.voicelive.models.VoiceLiveRequestSession
    """

    type: Literal[VoiceLiveClientEventType.SESSION_UPDATE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The event type, must be ``session.update``. Required."""
    session: "_models.VoiceLiveRequestSession" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        session: "_models.VoiceLiveRequestSession",
        event_id: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type=VoiceLiveClientEventType.SESSION_UPDATE, **kwargs)


class VoiceLiveTool(_Model):
    """The base representation of a voicelive tool definition.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    VoiceLiveFunctionTool

    :ivar type: Required. "function"
    :vartype type: str or ~azure.ai.voicelive.models.VoiceLiveToolType
    """

    __mapping__: Dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. \"function\""""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class VoiceLiveFunctionTool(VoiceLiveTool, discriminator="function"):
    """The definition of a function tool as used by the voicelive endpoint.

    :ivar type: Required.
    :vartype type: str or ~azure.ai.voicelive.models.FUNCTION
    :ivar name: Required.
    :vartype name: str
    :ivar description:
    :vartype description: str
    :ivar parameters:
    :vartype parameters: any
    """

    type: Literal[VoiceLiveToolType.FUNCTION] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    description: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    parameters: Optional[Any] = rest_field(visibility=["read", "create", "update", "delete", "query"])

    @overload
    def __init__(
        self,
        *,
        name: str,
        description: Optional[str] = None,
        parameters: Optional[Any] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type=VoiceLiveToolType.FUNCTION, **kwargs)


class VoiceLiveRequestSession(_Model):
    """VoiceLiveRequestSession.

    :ivar modalities:
    :vartype modalities: list[str or ~azure.ai.voicelive.models.VoiceLiveModality]
    :ivar instructions:
    :vartype instructions: str
    :ivar model: Is one of the following types: Literal["gpt-4o-realtime-preview"],
     Literal["gpt-4o-realtime-preview-2024-10-01"], Literal["gpt-4o-realtime-preview-2024-12-17"],
     Literal["gpt-4o-mini-realtime-preview"], Literal["gpt-4o-mini-realtime-preview-2024-12-17"]
    :vartype model: str or str or str or str or str
    :ivar voice: Known values are: "alloy", "ash", "ballad", "coral", "echo", "fable", "onyx",
     "nova", "sage", "shimmer", and "verse".
    :vartype voice: str or ~azure.ai.voicelive.models.VoiceIdsShared
    :ivar input_audio_format: Known values are: "pcm16", "g711_ulaw", and "g711_alaw".
    :vartype input_audio_format: str or ~azure.ai.voicelive.models.VoiceLiveAudioFormat
    :ivar output_audio_format: Known values are: "pcm16", "g711_ulaw", and "g711_alaw".
    :vartype output_audio_format: str or ~azure.ai.voicelive.models.VoiceLiveAudioFormat
    :ivar input_audio_transcription:
    :vartype input_audio_transcription:
     ~azure.ai.voicelive.models.VoiceLiveAudioInputTranscriptionSettings
    :ivar turn_detection:
    :vartype turn_detection: ~azure.ai.voicelive.models.VoiceLiveTurnDetection
    :ivar input_audio_noise_reduction:
    :vartype input_audio_noise_reduction: ~azure.ai.voicelive.models.VoiceLiveAudioNoiseReduction
    :ivar tools:
    :vartype tools: list[~azure.ai.voicelive.models.VoiceLiveTool]
    :ivar tool_choice: Is either a Union[str, "_models.VoiceLiveToolChoiceLiteral"] type or a
     VoiceLiveToolChoiceObject type.
    :vartype tool_choice: str or ~azure.ai.voicelive.models.VoiceLiveToolChoiceLiteral or
     ~azure.ai.voicelive.models.VoiceLiveToolChoiceObject
    :ivar temperature:
    :vartype temperature: float
    :ivar max_response_output_tokens: Is either a int type or a Literal["inf"] type.
    :vartype max_response_output_tokens: int or str
    """

    modalities: Optional[List[Union[str, "_models.VoiceLiveModality"]]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    instructions: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    model: Optional[
        Literal[
            "gpt-4o-realtime-preview",
            "gpt-4o-realtime-preview-2024-10-01",
            "gpt-4o-realtime-preview-2024-12-17",
            "gpt-4o-mini-realtime-preview",
            "gpt-4o-mini-realtime-preview-2024-12-17",
        ]
    ] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Is one of the following types: Literal[\"gpt-4o-realtime-preview\"],
     Literal[\"gpt-4o-realtime-preview-2024-10-01\"],
     Literal[\"gpt-4o-realtime-preview-2024-12-17\"], Literal[\"gpt-4o-mini-realtime-preview\"],
     Literal[\"gpt-4o-mini-realtime-preview-2024-12-17\"]"""
    voice: Optional[Union[str, "_models.VoiceIdsShared"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Known values are: \"alloy\", \"ash\", \"ballad\", \"coral\", \"echo\", \"fable\", \"onyx\",
     \"nova\", \"sage\", \"shimmer\", and \"verse\"."""
    input_audio_format: Optional[Union[str, "_models.VoiceLiveAudioFormat"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Known values are: \"pcm16\", \"g711_ulaw\", and \"g711_alaw\"."""
    output_audio_format: Optional[Union[str, "_models.VoiceLiveAudioFormat"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Known values are: \"pcm16\", \"g711_ulaw\", and \"g711_alaw\"."""
    input_audio_transcription: Optional["_models.VoiceLiveAudioInputTranscriptionSettings"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    turn_detection: Optional["_models.VoiceLiveTurnDetection"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    input_audio_noise_reduction: Optional["_models.VoiceLiveAudioNoiseReduction"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    tools: Optional[List["_models.VoiceLiveTool"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    tool_choice: Optional["_types.VoiceLiveToolChoice"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Is either a Union[str, \"_models.VoiceLiveToolChoiceLiteral\"] type or a
     VoiceLiveToolChoiceObject type."""
    temperature: Optional[float] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    max_response_output_tokens: Optional[Union[int, Literal["inf"]]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Is either a int type or a Literal[\"inf\"] type."""

    @overload
    def __init__(
        self,
        *,
        modalities: Optional[List[Union[str, "_models.VoiceLiveModality"]]] = None,
        instructions: Optional[str] = None,
        model: Optional[
            Literal[
                "gpt-4o-realtime-preview",
                "gpt-4o-realtime-preview-2024-10-01",
                "gpt-4o-realtime-preview-2024-12-17",
                "gpt-4o-mini-realtime-preview",
                "gpt-4o-mini-realtime-preview-2024-12-17",
            ]
        ] = None,
        voice: Optional[Union[str, "_models.VoiceIdsShared"]] = None,
        input_audio_format: Optional[Union[str, "_models.VoiceLiveAudioFormat"]] = None,
        output_audio_format: Optional[Union[str, "_models.VoiceLiveAudioFormat"]] = None,
        input_audio_transcription: Optional["_models.VoiceLiveAudioInputTranscriptionSettings"] = None,
        turn_detection: Optional["_models.VoiceLiveTurnDetection"] = None,
        input_audio_noise_reduction: Optional["_models.VoiceLiveAudioNoiseReduction"] = None,
        tools: Optional[List["_models.VoiceLiveTool"]] = None,
        tool_choice: Optional["_types.VoiceLiveToolChoice"] = None,
        temperature: Optional[float] = None,
        max_response_output_tokens: Optional[Union[int, Literal["inf"]]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class VoiceLiveResponseSession(_Model):
    """VoiceLiveResponseSession.

    :ivar object: Required. Default value is "voicelive.session".
    :vartype object: str
    :ivar id: Required.
    :vartype id: str
    :ivar model: Required.
    :vartype model: str
    :ivar modalities: Required.
    :vartype modalities: list[str or ~azure.ai.voicelive.models.VoiceLiveModality]
    :ivar instructions: Required.
    :vartype instructions: str
    :ivar voice: Required. Known values are: "alloy", "ash", "ballad", "coral", "echo", "fable",
     "onyx", "nova", "sage", "shimmer", and "verse".
    :vartype voice: str or ~azure.ai.voicelive.models.VoiceIdsShared
    :ivar input_audio_format: Required. Known values are: "pcm16", "g711_ulaw", and "g711_alaw".
    :vartype input_audio_format: str or ~azure.ai.voicelive.models.VoiceLiveAudioFormat
    :ivar output_audio_format: Required. Known values are: "pcm16", "g711_ulaw", and "g711_alaw".
    :vartype output_audio_format: str or ~azure.ai.voicelive.models.VoiceLiveAudioFormat
    :ivar input_audio_transcription: Required.
    :vartype input_audio_transcription:
     ~azure.ai.voicelive.models.VoiceLiveAudioInputTranscriptionSettings
    :ivar turn_detection: Required.
    :vartype turn_detection: ~azure.ai.voicelive.models.VoiceLiveTurnDetection
    :ivar input_audio_noise_reduction: Required.
    :vartype input_audio_noise_reduction: ~azure.ai.voicelive.models.VoiceLiveAudioNoiseReduction
    :ivar tools: Required.
    :vartype tools: list[~azure.ai.voicelive.models.VoiceLiveTool]
    :ivar tool_choice: Required. Is either a Union[str, "_models.VoiceLiveToolChoiceLiteral"] type
     or a VoiceLiveToolChoiceObject type.
    :vartype tool_choice: str or ~azure.ai.voicelive.models.VoiceLiveToolChoiceLiteral or
     ~azure.ai.voicelive.models.VoiceLiveToolChoiceObject
    :ivar temperature: Required.
    :vartype temperature: float
    :ivar max_response_output_tokens: Required. Is either a int type or a Literal["inf"] type.
    :vartype max_response_output_tokens: int or str
    """

    object: Literal["voicelive.session"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required. Default value is \"voicelive.session\"."""
    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    model: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    modalities: List[Union[str, "_models.VoiceLiveModality"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required."""
    instructions: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    voice: Union[str, "_models.VoiceIdsShared"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"alloy\", \"ash\", \"ballad\", \"coral\", \"echo\", \"fable\",
     \"onyx\", \"nova\", \"sage\", \"shimmer\", and \"verse\"."""
    input_audio_format: Union[str, "_models.VoiceLiveAudioFormat"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required. Known values are: \"pcm16\", \"g711_ulaw\", and \"g711_alaw\"."""
    output_audio_format: Union[str, "_models.VoiceLiveAudioFormat"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required. Known values are: \"pcm16\", \"g711_ulaw\", and \"g711_alaw\"."""
    input_audio_transcription: "_models.VoiceLiveAudioInputTranscriptionSettings" = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required."""
    turn_detection: "_models.VoiceLiveTurnDetection" = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required."""
    input_audio_noise_reduction: "_models.VoiceLiveAudioNoiseReduction" = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required."""
    tools: List["_models.VoiceLiveTool"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    tool_choice: "_types.VoiceLiveToolChoice" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required. Is either a Union[str, \"_models.VoiceLiveToolChoiceLiteral\"] type or a
     VoiceLiveToolChoiceObject type."""
    temperature: float = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    max_response_output_tokens: Union[int, Literal["inf"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required. Is either a int type or a Literal[\"inf\"] type."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        model: str,
        modalities: List[Union[str, "_models.VoiceLiveModality"]],
        instructions: str,
        voice: Union[str, "_models.VoiceIdsShared"],
        input_audio_format: Union[str, "_models.VoiceLiveAudioFormat"],
        output_audio_format: Union[str, "_models.VoiceLiveAudioFormat"],
        input_audio_transcription: "_models.VoiceLiveAudioInputTranscriptionSettings",
        turn_detection: "_models.VoiceLiveTurnDetection",
        input_audio_noise_reduction: "_models.VoiceLiveAudioNoiseReduction",
        tools: List["_models.VoiceLiveTool"],
        tool_choice: "_types.VoiceLiveToolChoice",
        temperature: float,
        max_response_output_tokens: Union[int, Literal["inf"]],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["voicelive.session"] = "voicelive.session"


class VoiceLiveTurnDetection(_Model):
    """VoiceLiveTurnDetection.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    VoiceLiveSemanticVadTurnDetection, VoiceLiveServerVadTurnDetection

    :ivar type: Required. Known values are: "server_vad" and "semantic_vad".
    :vartype type: str or ~azure.ai.voicelive.models.VoiceLiveTurnDetectionType
    :ivar create_response: Whether or not to automatically generate a response when VAD is enabled.
     true by default.
    :vartype create_response: bool
    :ivar interrupt_response: Whether or not to automatically interrupt any ongoing response with
     output to the default conversation (i.e. ``conversation`` of ``auto``) when a VAD start event
     occurs.
    :vartype interrupt_response: bool
    """

    __mapping__: Dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"server_vad\" and \"semantic_vad\"."""
    create_response: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether or not to automatically generate a response when VAD is enabled. true by default."""
    interrupt_response: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether or not to automatically interrupt any ongoing response with output to the default
     conversation (i.e. ``conversation`` of ``auto``) when a VAD start event occurs."""

    @overload
    def __init__(
        self,
        *,
        type: str,
        create_response: Optional[bool] = None,
        interrupt_response: Optional[bool] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class VoiceLiveSemanticVadTurnDetection(VoiceLiveTurnDetection, discriminator="semantic_vad"):
    """VoiceLiveSemanticVadTurnDetection.

    :ivar create_response: Whether or not to automatically generate a response when VAD is enabled.
     true by default.
    :vartype create_response: bool
    :ivar interrupt_response: Whether or not to automatically interrupt any ongoing response with
     output to the default conversation (i.e. ``conversation`` of ``auto``) when a VAD start event
     occurs.
    :vartype interrupt_response: bool
    :ivar type: Required.
    :vartype type: str or ~azure.ai.voicelive.models.SEMANTIC_VAD
    :ivar eagerness: Used only for ``semantic_vad`` mode. The eagerness of the model to respond.
     ``low`` will wait longer for the user to continue speaking, ``high`` will respond more quickly.
     ``auto`` is the default and is equivalent to ``medium``. Is one of the following types:
     Literal["low"], Literal["medium"], Literal["high"], Literal["auto"]
    :vartype eagerness: str or str or str or str
    """

    type: Literal[VoiceLiveTurnDetectionType.SEMANTIC_VAD] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    eagerness: Optional[Literal["low", "medium", "high", "auto"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Used only for ``semantic_vad`` mode. The eagerness of the model to respond. ``low`` will wait
     longer for the user to continue speaking, ``high`` will respond more quickly. ``auto`` is the
     default and is equivalent to ``medium``. Is one of the following types: Literal[\"low\"],
     Literal[\"medium\"], Literal[\"high\"], Literal[\"auto\"]"""

    @overload
    def __init__(
        self,
        *,
        create_response: Optional[bool] = None,
        interrupt_response: Optional[bool] = None,
        eagerness: Optional[Literal["low", "medium", "high", "auto"]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type=VoiceLiveTurnDetectionType.SEMANTIC_VAD, **kwargs)


class VoiceLiveServerEvent(_Model):
    """A voicelive server event.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    VoiceLiveServerEventConversationCreated, VoiceLiveServerEventConversationItemCreated,
    VoiceLiveServerEventConversationItemDeleted,
    VoiceLiveServerEventConversationItemInputAudioTranscriptionCompleted,
    VoiceLiveServerEventConversationItemInputAudioTranscriptionDelta,
    VoiceLiveServerEventConversationItemInputAudioTranscriptionFailed,
    VoiceLiveServerEventConversationItemRetrieved, VoiceLiveServerEventConversationItemTruncated,
    VoiceLiveServerEventError, VoiceLiveServerEventInputAudioBufferCleared,
    VoiceLiveServerEventInputAudioBufferCommitted,
    VoiceLiveServerEventInputAudioBufferSpeechStarted,
    VoiceLiveServerEventInputAudioBufferSpeechStopped,
    VoiceLiveServerEventOutputAudioBufferCleared, VoiceLiveServerEventOutputAudioBufferStarted,
    VoiceLiveServerEventOutputAudioBufferStopped, VoiceLiveServerEventRateLimitsUpdated,
    VoiceLiveServerEventResponseAudioDelta, VoiceLiveServerEventResponseAudioDone,
    VoiceLiveServerEventResponseAudioTranscriptDelta,
    VoiceLiveServerEventResponseAudioTranscriptDone, VoiceLiveServerEventResponseContentPartAdded,
    VoiceLiveServerEventResponseContentPartDone, VoiceLiveServerEventResponseCreated,
    VoiceLiveServerEventResponseDone, VoiceLiveServerEventResponseFunctionCallArgumentsDelta,
    VoiceLiveServerEventResponseFunctionCallArgumentsDone,
    VoiceLiveServerEventResponseOutputItemAdded, VoiceLiveServerEventResponseOutputItemDone,
    VoiceLiveServerEventResponseTextDelta, VoiceLiveServerEventResponseTextDone,
    VoiceLiveServerEventSessionCreated, VoiceLiveServerEventSessionUpdated,
    VoiceLiveServerEventTranscriptionSessionUpdated

    :ivar type: The type of event. Required. Known values are: "error", "session.created",
     "session.updated", "conversation.created",
     "conversation.item.input_audio_transcription.completed",
     "conversation.item.input_audio_transcription.delta",
     "conversation.item.input_audio_transcription.failed", "conversation.item.created",
     "conversation.item.retrieved", "conversation.item.truncated", "conversation.item.deleted",
     "input_audio_buffer.committed", "input_audio_buffer.cleared",
     "input_audio_buffer.speech_started", "input_audio_buffer.speech_stopped",
     "output_audio_buffer.cleared", "output_audio_buffer.started", "output_audio_buffer.stopped",
     "response.created", "response.done", "response.output_item.added", "response.output_item.done",
     "response.content_part.added", "response.content_part.done", "response.text.delta",
     "response.text.done", "response.audio_transcript.delta", "response.audio_transcript.done",
     "response.audio.delta", "response.audio.done", "response.function_call_arguments.delta",
     "response.function_call_arguments.done", "transcription_session.updated", and
     "rate_limits.updated".
    :vartype type: str or ~azure.ai.voicelive.models.VoiceLiveServerEventType
    :ivar event_id:
    :vartype event_id: str
    """

    __mapping__: Dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """The type of event. Required. Known values are: \"error\", \"session.created\",
     \"session.updated\", \"conversation.created\",
     \"conversation.item.input_audio_transcription.completed\",
     \"conversation.item.input_audio_transcription.delta\",
     \"conversation.item.input_audio_transcription.failed\", \"conversation.item.created\",
     \"conversation.item.retrieved\", \"conversation.item.truncated\",
     \"conversation.item.deleted\", \"input_audio_buffer.committed\",
     \"input_audio_buffer.cleared\", \"input_audio_buffer.speech_started\",
     \"input_audio_buffer.speech_stopped\", \"output_audio_buffer.cleared\",
     \"output_audio_buffer.started\", \"output_audio_buffer.stopped\", \"response.created\",
     \"response.done\", \"response.output_item.added\", \"response.output_item.done\",
     \"response.content_part.added\", \"response.content_part.done\", \"response.text.delta\",
     \"response.text.done\", \"response.audio_transcript.delta\",
     \"response.audio_transcript.done\", \"response.audio.delta\", \"response.audio.done\",
     \"response.function_call_arguments.delta\", \"response.function_call_arguments.done\",
     \"transcription_session.updated\", and \"rate_limits.updated\"."""
    event_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])

    @overload
    def __init__(
        self,
        *,
        type: str,
        event_id: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class VoiceLiveServerEventSessionUpdated(VoiceLiveServerEvent, discriminator="session.updated"):
    """Returned when a session is updated with a ``session.update`` event, unless
    there is an error.

    :ivar event_id:
    :vartype event_id: str
    :ivar type: The event type, must be ``session.updated``. Required.
    :vartype type: str or ~azure.ai.voicelive.models.SESSION_UPDATED
    :ivar session: Required.
    :vartype session: ~azure.ai.voicelive.models.VoiceLiveResponseSession
    """

    type: Literal[VoiceLiveServerEventType.SESSION_UPDATED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The event type, must be ``session.updated``. Required."""
    session: "_models.VoiceLiveResponseSession" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        session: "_models.VoiceLiveResponseSession",
        event_id: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type=VoiceLiveServerEventType.SESSION_UPDATED, **kwargs)


class VoiceLiveServerVadTurnDetection(VoiceLiveTurnDetection, discriminator="server_vad"):
    """VoiceLiveServerVadTurnDetection.

    :ivar create_response: Whether or not to automatically generate a response when VAD is enabled.
     true by default.
    :vartype create_response: bool
    :ivar interrupt_response: Whether or not to automatically interrupt any ongoing response with
     output to the default conversation (i.e. ``conversation`` of ``auto``) when a VAD start event
     occurs.
    :vartype interrupt_response: bool
    :ivar type: Required. Indicates that server-side voice activity detection (VAD) should be
     enabled, allowing the server to determine when
     add_user_audio commands present ends of speech and should be automatically committed.

     The API will also detect when the user begins talking, sending a generation_canceled command.
    :vartype type: str or ~azure.ai.voicelive.models.SERVER_VAD
    :ivar threshold: Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher
     threshold will require louder audio to activate the model, and thus might perform better in
     noisy environments.
    :vartype threshold: float
    :ivar prefix_padding_ms: Amount of audio to include before the VAD detected speech (in
     milliseconds). Defaults to 300ms.
    :vartype prefix_padding_ms: ~datetime.timedelta
    :ivar silence_duration_ms: Duration of silence to detect speech stop (in milliseconds).
     Defaults to 500ms. With shorter values the model will respond more quickly, but may jump in on
     short pauses from the user.
    :vartype silence_duration_ms: ~datetime.timedelta
    """

    type: Literal[VoiceLiveTurnDetectionType.SERVER_VAD] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required. Indicates that server-side voice activity detection (VAD) should be enabled, allowing
     the server to determine when
     add_user_audio commands present ends of speech and should be automatically committed.
     
     The API will also detect when the user begins talking, sending a generation_canceled command."""
    threshold: Optional[float] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A higher threshold will
     require louder audio to activate the model, and thus might perform better in noisy
     environments."""
    prefix_padding_ms: Optional[datetime.timedelta] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Amount of audio to include before the VAD detected speech (in milliseconds). Defaults to 300ms."""
    silence_duration_ms: Optional[datetime.timedelta] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Duration of silence to detect speech stop (in milliseconds). Defaults to 500ms. With shorter
     values the model will respond more quickly, but may jump in on short pauses from the user."""

    @overload
    def __init__(
        self,
        *,
        create_response: Optional[bool] = None,
        interrupt_response: Optional[bool] = None,
        threshold: Optional[float] = None,
        prefix_padding_ms: Optional[datetime.timedelta] = None,
        silence_duration_ms: Optional[datetime.timedelta] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type=VoiceLiveTurnDetectionType.SERVER_VAD, **kwargs)


class VoiceLiveToolChoiceObject(_Model):
    """A base representation for a voicelive tool_choice selecting a named tool.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    VoiceLiveToolChoiceFunctionObject

    :ivar type: Required. "function"
    :vartype type: str or ~azure.ai.voicelive.models.VoiceLiveToolType
    """

    __mapping__: Dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. \"function\""""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class VoiceLiveToolChoiceFunctionObject(VoiceLiveToolChoiceObject, discriminator="function"):
    """The representation of a voicelive tool_choice selecting a named function tool.

    :ivar type: Required.
    :vartype type: str or ~azure.ai.voicelive.models.FUNCTION
    :ivar function: Required.
    :vartype function: ~azure.ai.voicelive.models.VoiceLiveToolChoiceFunctionObjectFunction
    """

    type: Literal[VoiceLiveToolType.FUNCTION] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    function: "_models.VoiceLiveToolChoiceFunctionObjectFunction" = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required."""

    @overload
    def __init__(
        self,
        *,
        function: "_models.VoiceLiveToolChoiceFunctionObjectFunction",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, type=VoiceLiveToolType.FUNCTION, **kwargs)


class VoiceLiveToolChoiceFunctionObjectFunction(_Model):  # pylint: disable=name-too-long
    """VoiceLiveToolChoiceFunctionObjectFunction.

    :ivar name: Required.
    :vartype name: str
    """

    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        name: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
