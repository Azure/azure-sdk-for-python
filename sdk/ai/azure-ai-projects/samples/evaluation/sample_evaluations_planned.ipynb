{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Evaluations\n",
    "\n",
    "This notebook demonstrates how to use methods to create, get, and list cloud evaluations using the Azure AI Project SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have the following:\n",
    "- Python 3.8 or later.\n",
    "- The Azure AI Project SDK installed. You can install it using the following command:\n",
    "  ```bash\n",
    "  pip install azure-ai-projects azure-identity\n",
    "  ```\n",
    "- Set the following environment variables with your own values:\n",
    "  - `PROJECT_ENDPOINT`: The Azure AI Project endpoint, as found in the overview page of your Azure AI Foundry project.\n",
    "  - `DATASET_NAME`: The name of the dataset to create and use in this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    Evaluation,\n",
    "    InputDataset,\n",
    "    EvaluatorConfiguration,\n",
    "    EvaluatorIds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Environment Variables\n",
    "\n",
    "Ensure the following environment variables are set before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "endpoint = os.environ[\"PROJECT_ENDPOINT\"]  # Example: https://<account_name>.services.ai.azure.com/api/projects/<project_name>\n",
    "model_endpoint = os.environ[\"MODEL_ENDPOINT\"]  # Example: https://<account_name>.services.ai.azure.com\n",
    "model_api_key = os.environ[\"MODEL_API_KEY\"]\n",
    "model_deployment_name = os.environ[\"MODEL_DEPLOYMENT_NAME\"]  # Example: gpt-4o-mini\n",
    "dataset_name = os.environ[\"DATASET_NAME\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate and Initialize the Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate and initialize the client\n",
    "credential = DefaultAzureCredential(exclude_interactive_browser_credential=False)\n",
    "project_client = AIProjectClient(endpoint=endpoint, credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload a Dataset\n",
    "\n",
    "Upload a single file and create a new dataset to reference the file. Here, we explicitly specify the dataset version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a dataset\n",
    "print(\"Uploading dataset...\")\n",
    "dataset = project_client.datasets.upload_file(\n",
    "    name=dataset_name,\n",
    "    version=\"1\",\n",
    "    file=\"./samples_folder/sample_data_evaluation.jsonl\",\n",
    ")\n",
    "print(\"Dataset uploaded:\", dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Evaluation\n",
    "\n",
    "Define common data mapping and initialization parameters that will apply to all evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common data mapping and initialization parameters\n",
    "common_data_mapping = {\n",
    "    \"query\": \"${data.query}\",\n",
    "    \"response\": \"${data.response}\",\n",
    "}\n",
    "\n",
    "common_init_params = {\n",
    "    \"deployment_name\": model_deployment_name,\n",
    "}\n",
    "\n",
    "# Create an evaluation\n",
    "evaluation = Evaluation(\n",
    "    display_name=\"Sample Evaluation Test\",\n",
    "    description=\"Sample evaluation for testing\",\n",
    "    data=InputDataset(id=\"<>\"),\n",
    "    data_mapping=common_data_mapping,\n",
    "    init_params=common_init_params,\n",
    "    evaluators={\n",
    "        \"relevance\": EvaluatorConfiguration(\n",
    "            id=EvaluatorIds.RELEVANCE.value,\n",
    "        ),\n",
    "        \"violence\": EvaluatorConfiguration(\n",
    "            id=EvaluatorIds.VIOLENCE.value,\n",
    "        ),\n",
    "        \"bleu_score\": EvaluatorConfiguration(\n",
    "            id=EvaluatorIds.BLEU_SCORE.value,\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "\n",
    "evaluation_response = project_client.evaluations.create(\n",
    "    evaluation,\n",
    "    headers={\n",
    "        \"model-endpoint\": model_endpoint,\n",
    "        \"api-key\": model_api_key,\n",
    "    },\n",
    ")\n",
    "print(\"Evaluation created:\", evaluation_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get an Evaluation\n",
    "\n",
    "Retrieve the details of the created evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get evaluation details\n",
    "print(\"Getting evaluation details...\")\n",
    "get_evaluation_response = project_client.evaluations.get(evaluation_response.name)\n",
    "print(\"Evaluation details:\", get_evaluation_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Evaluations\n",
    "\n",
    "List all evaluations in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all evaluations\n",
    "print(\"Listing all evaluations...\")\n",
    "for evaluation in project_client.evaluations.list():\n",
    "    print(evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
