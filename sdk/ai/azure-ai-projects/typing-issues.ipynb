{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f20efe",
   "metadata": {},
   "source": [
    "# Python notebook to show issues with Typing\n",
    "\n",
    "## General Links\n",
    "\n",
    "* OpenAI TypeSpec package: https://www.npmjs.com/package/@azure-tools/openai-typespec\n",
    "* OpenAI TypeSpec repo: https://github.com/microsoft/openai-openapi-pr/tree/main/packages/openai-typespec/src\n",
    "* Our current OpenAI TypeSpec files: https://github.com/Azure/azure-rest-api-specs-pr/tree/feature/ai-foundry/agents-v2/specification/ai/Azure.AI.Projects/.external-readonly/openai.external.typespec\n",
    "* OpenAI Python reference: https://platform.openai.com/docs/api-reference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda52a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e45759b",
   "metadata": {},
   "source": [
    "\n",
    "## Issues\n",
    "\n",
    "### 'model' in ImageGenTool\n",
    "\n",
    "OpenAI defines model as `Literal['gpt-image-1']` in our current TypeSpec, and `\"gpt-image-1\" | \"gpt-image-1-mini\"` in the [published OpenAI TypeSpec package](https://github.com/microsoft/openai-openapi-pr/blob/main/packages/openai-typespec/src/responses/models.tsp#L1742). But we try to pass in any str (with potentially different model name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bb1a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import cast\n",
    "from azure.ai.projects.models import ImageGenTool\n",
    "\n",
    "image_generation_model = cast(str, os.getenv(\"IMAGE_GENERATION_MODEL_DEPLOYMENT_NAME\"))\n",
    "\n",
    "# OpenAI defines model as `Literal['gpt-image-1']` but we try to pass in any str (with potentially different mode name)\n",
    "tool = ImageGenTool(model=image_generation_model, quality=\"low\", size=\"1024x1024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e5fdaa",
   "metadata": {},
   "source": [
    "### '.evals.create'\n",
    "\n",
    "Example taken from sample: samples\\evaluations\\sample_continuous_evaluation_rule.py\n",
    "Link to OpenAI Python reference code for .evals.create(): https://platform.openai.com/docs/api-reference/evals/create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241964c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "endpoint = os.environ[\"AZURE_AI_PROJECT_ENDPOINT\"]\n",
    "\n",
    "with (\n",
    "    DefaultAzureCredential() as credential,\n",
    "    AIProjectClient(endpoint=endpoint, credential=credential) as project_client,\n",
    "    project_client.get_openai_client() as openai_client,\n",
    "):\n",
    "\n",
    "    data_source_config = {\"type\": \"azure_ai_source\", \"scenario\": \"responses\"}\n",
    "    testing_criteria = [\n",
    "        {\"type\": \"azure_ai_evaluator\", \"name\": \"violence_detection\", \"evaluator_name\": \"builtin.violence\"}\n",
    "    ]\n",
    "    eval_object = openai_client.evals.create(\n",
    "        name=\"Continuous Evaluation\",\n",
    "        data_source_config=data_source_config,\n",
    "        testing_criteria=testing_criteria,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
