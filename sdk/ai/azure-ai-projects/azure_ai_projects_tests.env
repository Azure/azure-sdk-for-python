#
# Environment variables required for running tests.
#
# All values should be empty by default. Fill them in locally before running live tests on your dev box,
# but do not commit these changes to the repository.
#

########################################################################################################################
# Connection tests
#
# To run connection tests you need an AI Foundry project with
# - A default connected AI Services resource that uses api-key auth, with two models deployed:
#   OpenAI chat-completions and non-OpenAI chat-completions.
#   This is the AI Services resource that gets created automatically when you create a new AI Foundry project.
# - Another AI Services resource that was added manually, that uses Entra-ID auth, with the same two models.
# 
# Note: See Azure OpenAI api-versions here: https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#api-specs
# use api-version from the "Data plane - Inference" row, "Latest GA release" column.
#
AZURE_AI_PROJECTS_CONNECTIONS_TESTS_PROJECT_CONNECTION_STRING=
AZURE_AI_PROJECTS_CONNECTIONS_TESTS_DEFAULT_KEY_AUTH_AOAI_CONNECTION_NAME=
AZURE_AI_PROJECTS_CONNECTIONS_TESTS_DEFAULT_KEY_AUTH_AISERVICES_CONNECTION_NAME=
AZURE_AI_PROJECTS_CONNECTIONS_TESTS_ENTRAID_AUTH_AISERVICES_CONNECTION_NAME=
AZURE_AI_PROJECTS_CONNECTIONS_TESTS_ENTRAID_AUTH_AOAI_CONNECTION_NAME=
AZURE_AI_PROJECTS_CONNECTIONS_TESTS_AOAI_API_VERSION=
AZURE_AI_PROJECTS_CONNECTIONS_TESTS_AOAI_MODEL_DEPLOYMENT_NAME=
AZURE_AI_PROJECTS_CONNECTIONS_TESTS_CHAT_COMPLETIONS_MODEL_DEPLOYMENT_NAME=


########################################################################################################################
# Inference tests
#
# To run inference tests you need an AI Foundry project with
# - A default connected AI Services resource that uses api-key auth, with three models deployed:
#   OpenAI chat-completions, non-OpenAI chat-completions, non-OpenAI text embeddings.
#   This is the AI Services resource that gets created automatically when you create a new AI Foundry project.
#   The tests will use .inference.get_xyz_client() method to set up an inference client
#   for the default connection, without giving connection name. It is assumed to use api-key auth.
# - Another AI Services resource that was added manually, that uses Entra-ID auth, with the same three models.
#   The tests will use .inference.get_xyz_client(connection_name=...) method to set up an inference client
#   for the connected resource, with the connection name given below.
# 
# Note: See Azure OpenAI api-versions here: https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#api-specs
# use api-version from the "Data plane - Inference" row, "Latest GA release" column.
#
AZURE_AI_PROJECTS_INFERENCE_TESTS_PROJECT_CONNECTION_STRING=${AZURE_AI_PROJECTS_CONNECTIONS_TESTS_PROJECT_CONNECTION_STRING}
AZURE_AI_PROJECTS_INFERENCE_TESTS_ENTRAID_AUTH_AISERVICES_CONNECTION_NAME=${AZURE_AI_PROJECTS_CONNECTIONS_TESTS_ENTRAID_AUTH_AISERVICES_CONNECTION_NAME}
AZURE_AI_PROJECTS_INFERENCE_TESTS_ENTRAID_AUTH_AOAI_CONNECTION_NAME=${AZURE_AI_PROJECTS_CONNECTIONS_TESTS_ENTRAID_AUTH_AOAI_CONNECTION_NAME}
AZURE_AI_PROJECTS_INFERENCE_TESTS_AOAI_API_VERSION=${AZURE_AI_PROJECTS_CONNECTIONS_TESTS_AOAI_API_VERSION}
AZURE_AI_PROJECTS_INFERENCE_TESTS_AOAI_MODEL_DEPLOYMENT_NAME=${AZURE_AI_PROJECTS_CONNECTIONS_TESTS_AOAI_MODEL_DEPLOYMENT_NAME}
AZURE_AI_PROJECTS_INFERENCE_TESTS_CHAT_COMPLETIONS_MODEL_DEPLOYMENT_NAME=${AZURE_AI_PROJECTS_CONNECTIONS_TESTS_CHAT_COMPLETIONS_MODEL_DEPLOYMENT_NAME}
AZURE_AI_PROJECTS_INFERENCE_TESTS_EMBEDDINGS_MODEL_DEPLOYMENT_NAME=

########################################################################################################################
# Telemetry tests
#
# To run telemetry tests you need an AI Foundry project with a connected Application Insights resource.
#
AZURE_AI_PROJECTS_TELEMETRY_TESTS_PROJECT_CONNECTION_STRING=${AZURE_AI_PROJECTS_CONNECTIONS_TESTS_PROJECT_CONNECTION_STRING}

########################################################################################################################
# Agents tests
#
AZURE_AI_PROJECTS_AGENTS_TESTS_PROJECT_CONNECTION_STRING=
AZURE_AI_PROJECTS_AGENTS_TESTS_DATA_PATH=
AZURE_AI_PROJECTS_AGENTS_TESTS_STORAGE_QUEUE=

########################################################################################################################
# Evaluations tests
#
# To run evaluation test you need an AI Foundry project with an Azure OpenAI connection, and a chat-completions 
# model deployed.
#
# Note: See Azure OpenAI api-versions here: https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#api-specs
# use api-version from the "Data plane - Inference" row, "Latest GA release" column.
#
AZURE_AI_PROJECTS_EVALUATIONS_TESTS_PROJECT_CONNECTION_STRING=${AZURE_AI_PROJECTS_CONNECTIONS_TESTS_PROJECT_CONNECTION_STRING}
AZURE_AI_PROJECTS_EVALUATIONS_TESTS_DEFAULT_AOAI_CONNECTION_NAME=
AZURE_AI_PROJECTS_EVALUATIONS_TESTS_DEPLOYMENT_NAME=
AZURE_AI_PROJECTS_EVALUATIONS_TESTS_API_VERSION=
AZURE_AI_PROJECTS_EVALUATIONS_TESTS_DATASET_ID=

