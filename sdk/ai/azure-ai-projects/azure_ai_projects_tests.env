#
# Environment variables required for running tests.
#
# All values should be empty by default. Fill them in locally before running live tests on your dev box,
# but do not commit these changes to the repository.
#

########################################################################################################################
# Connection tests
#
# To run connection tests you need an AI Foundry project with
# - At least one AIServices resource connected
# - At least one Azure OpenAI resource connected
# and you will need to define the 5 environment variables below.
# Ideally you have more than one AIServices and Azure OpenAI resources connected,
# such that you set a connection name that is different than the default connection name.
#
AZURE_AI_PROJECTS_CONNECTIONS_TESTS_PROJECT_CONNECTION_STRING=
AZURE_AI_PROJECTS_CONNECTIONS_TESTS_AOAI_CONNECTION_NAME=
AZURE_AI_PROJECTS_CONNECTIONS_TESTS_AISERVICES_CONNECTION_NAME=
# TODO: Define different defaults, once you have a proper AI project set up for testing
#AZURE_AI_PROJECTS_CONNECTIONS_TESTS_DEFAULT_AOAI_CONNECTION_NAME=
#AZURE_AI_PROJECTS_CONNECTIONS_TESTS_DEFAULT_AISERVICES_CONNECTION_NAME=


########################################################################################################################
# Inference tests
#
# To run inference tests you need an AI Foundry project with
# - A default AI Services resource that uses api-key auth, with three models deployed:
#   OpenAI chat-completions, non-OpenAI chat-completions, non-OpenAI text embeddings.
# - Another AI Services resource, that uses Entra-ID auth, with the same three models models.
# 
# Note: See Azure OpenAI api-versions here: https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#api-specs
# use api-version from the "Data plane - Inference" row, "Latest GA release" column.
#
AZURE_AI_PROJECTS_INFERENCE_TESTS_PROJECT_CONNECTION_STRING=${AZURE_AI_PROJECTS_CONNECTIONS_TESTS_PROJECT_CONNECTION_STRING}
AZURE_AI_PROJECTS_INFERENCE_TESTS_AOAI_API_VERSION=
AZURE_AI_PROJECTS_INFERENCE_TESTS_AOAI_MODEL_DEPLOYMENT_NAME=
AZURE_AI_PROJECTS_INFERENCE_TESTS_CHAT_COMPLETIONS_MODEL_DEPLOYMENT_NAME=
AZURE_AI_PROJECTS_INFERENCE_TESTS_EMBEDDINGS_MODEL_DEPLOYMENT_NAME=
AZURE_AI_PROJECTS_INFERENCE_TESTS_AISERVICES_CONNECTION_NAME=
AZURE_AI_PROJECTS_INFERENCE_TESTS_AOAI_CONNECTION_NAME=

########################################################################################################################
# Telemetry tests
#
# To run telemetry tests you need an AI Foundry project with a connected Application Insights resource.
#
AZURE_AI_PROJECTS_TELEMETRY_TESTS_PROJECT_CONNECTION_STRING=${AZURE_AI_PROJECTS_CONNECTIONS_TESTS_PROJECT_CONNECTION_STRING}

########################################################################################################################
# Agents tests
#
AZURE_AI_PROJECTS_AGENTS_TESTS_PROJECT_CONNECTION_STRING=
AZURE_AI_PROJECTS_AGENTS_TESTS_DATA_PATH=
AZURE_AI_PROJECTS_AGENTS_TESTS_STORAGE_QUEUE=

########################################################################################################################
# Evaluations tests
#
# To run evaluation test you need an AI Foundry project with an Azure OpenAI connection, and a chat-completions 
# model deployed.
#
# Note: See Azure OpenAI api-versions here: https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#api-specs
# use api-version from the "Data plane - Inference" row, "Latest GA release" column.
#
AZURE_AI_PROJECTS_EVALUATIONS_TESTS_PROJECT_CONNECTION_STRING=${AZURE_AI_PROJECTS_CONNECTIONS_TESTS_PROJECT_CONNECTION_STRING}
AZURE_AI_PROJECTS_EVALUATIONS_TESTS_DEFAULT_AOAI_CONNECTION_NAME=
AZURE_AI_PROJECTS_EVALUATIONS_TESTS_DEPLOYMENT_NAME=
AZURE_AI_PROJECTS_EVALUATIONS_TESTS_API_VERSION=
AZURE_AI_PROJECTS_EVALUATIONS_TESTS_DATASET_ID=

