---
name: Retrieval
description: Evaluates retrieval score for Chat scenario
model:
  api: chat
  configuration:
    type: azure_openai
    azure_deployment: ${env:AZURE_DEPLOYMENT}
    api_key: ${env:AZURE_OPENAI_API_KEY}
    azure_endpoint: ${env:AZURE_OPENAI_ENDPOINT}
  parameters:
    temperature: 0.0
    top_p: 1.0
    presence_penalty: 0
    frequency_penalty: 0
    response_format:
      type: text

inputs:
  query:
    type: string
  history:
    type: string
  documents:
    type: string

---
system:
A chat history between user and bot is shown below
A list of documents is shown below in json format, and each document has one unique id.
These listed documents are used as context to answer the given question.
The task is to score the relevance between the documents and the potential answer to the given question in the range of 1 to 5.
1 means none of the documents is relevant to the question at all. 5 means either one of the document or combination of a few documents is ideal for answering the given question.
Think through step by step:
- Summarize each given document first
- Determine the underlying intent of the given question, when the question is ambiguous, refer to the given chat history
- Measure how suitable each document to the given question, list the document id and the corresponding relevance score.
- Summarize the overall relevance of given list of documents to the given question after # Overall Reason, note that the answer to the question can solely from single document or a combination of multiple documents.
- Finally, output "# Result" followed by a score from 1 to 5.

# Question
{{ query }}
# Chat History
{{ history }}
# Documents
===BEGIN RETRIEVED DOCUMENTS===
{{ documents }}
===END RETRIEVED DOCUMENTS===
