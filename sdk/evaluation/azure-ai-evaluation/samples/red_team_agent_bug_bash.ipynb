{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before the bug bash\n",
    "Thank you for setting up your environment ahead of the bug bash!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install uv \n",
    "uv is a very fast Python package manager. It will help make the installation of azure-ai-evaluation with extras faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting uv\n",
      "  Downloading uv-0.6.9-py3-none-win_amd64.whl.metadata (11 kB)\n",
      "Downloading uv-0.6.9-py3-none-win_amd64.whl (17.4 MB)\n",
      "   ---------------------------------------- 0.0/17.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/17.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/17.4 MB 217.9 kB/s eta 0:01:20\n",
      "   ---------------------------------------- 0.0/17.4 MB 330.3 kB/s eta 0:00:53\n",
      "   ---------------------------------------- 0.2/17.4 MB 833.5 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.6/17.4 MB 2.9 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.4/17.4 MB 5.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 3.3/17.4 MB 10.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.9/17.4 MB 13.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 7.0/17.4 MB 17.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.8/17.4 MB 19.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.8/17.4 MB 19.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.8/17.4 MB 19.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 9.5/17.4 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 12.0/17.4 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 12.0/17.4 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 12.0/17.4 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 12.0/17.4 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 12.0/17.4 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 12.6/17.4 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 13.0/17.4 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 13.0/17.4 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 13.0/17.4 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 13.4/17.4 MB 13.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 13.9/17.4 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 14.7/17.4 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 15.7/17.4 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  17.4/17.4 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 17.4/17.4 MB 11.7 MB/s eta 0:00:00\n",
      "Installing collected packages: uv\n",
      "Successfully installed uv-0.6.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install uv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a virtual environment using uv\n",
    "Create a virtual environment using uv and specify a Python version >= 3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%uv` not found.\n"
     ]
    }
   ],
   "source": [
    "%uv venv --python 3.11 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you are running the following scripts using the virtual environment created. To do so, activate the virtual environment using: \n",
    "`.venv\\Scripts\\activate` on Windows or `source .venv/bin/activate` on macOS and Linux. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Azure AI Evaluation SDK with Red Team extra\n",
    "\n",
    "With the virtual environment activated, you can now install Azure AI Evaluation SDK with Red Team extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%uv pip install --upgrade \"git+https://github.com/slister1001/azure-sdk-for-python.git@red-team-agent-init#subdirectory=sdk/evaluation/azure-ai-evaluation&egg=azure-ai-evaluation[redteam]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for setting up your environment ahead of the bug bash!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Team Agent Bug Bash Configuration\n",
    "To run RedTeamAgent, you first need to import packages and configure your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to an Azure AI Project\n",
    "Navigate to this [Azure AI Foundry Hub](https://int.ai.azure.com/managementCenter/hub/overview?wsid=/subscriptions/4bf6b28a-452b-4af4-8080-8a196ee0ca4b/resourceGroups/naposani/providers/Microsoft.MachineLearningServices/workspaces/sydneylister-1523&flight=AIRedTeaming=true,EvalConvergence&tid=72f988bf-86f1-41af-91ab-2d7cd011db47), and select a project. Insert the project name in the below code as `<your-project-name>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ai_project = {\n",
    "    \"subscription_id\": \"4bf6b28a-452b-4af4-8080-8a196ee0ca4b\",\n",
    "    \"resource_group_name\": \"naposani\",\n",
    "    \"project_name\": \"<your_project_name>\", # INSERT THE PROJECT NAME HERE\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation.red_team_agent import RedTeamAgent, AttackStrategy, RiskCategory\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from typing import Dict, List, Optional, Any\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Team Agent Examples\n",
    "\n",
    "Below are several examples demonstrating the various ways to use the RedTeamAgent for vulnerability scanning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Red Team Scan with Callback Function\n",
    "\n",
    "This example shows how to use the RedTeamAgent with a simple callback function to test your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize credentials and RedTeamAgent\n",
    "credential = DefaultAzureCredential()\n",
    "agent = RedTeamAgent(azure_ai_project=azure_ai_project, credential=credential)\n",
    "\n",
    "# Create a simple application callback function\n",
    "def simple_app_callback(query: str) -> str:\n",
    "    \"\"\"A simple application callback function that responds to user queries\"\"\"\n",
    "    return f\"I'm an AI assistant that follows ethical guidelines. I cannot provide harmful content.\"\n",
    "\n",
    "# Run a basic scan with the callback function (baseline is added by default)\n",
    "results = await agent.scan(\n",
    "    target=simple_app_callback,\n",
    "    scan_name=\"Basic-Callback-Test\",\n",
    "    risk_categories=[RiskCategory.Violence, RiskCategory.HateUnfairness],\n",
    "    num_objectives=2,  # Limit to 2 objectives per category for the example\n",
    "    application_scenario=\"A customer service chatbot for a retail company\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Advanced Callback with Conversation State\n",
    "\n",
    "This example demonstrates using a more complex callback that maintains conversation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize credentials and RedTeamAgent\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "agent = RedTeamAgent(azure_ai_project=azure_ai_project, credential=credential)\n",
    "\n",
    "# Create a more complex callback function that handles full conversation context\n",
    "async def advanced_callback(messages: Dict, stream: bool = False, session_state: Any = None, context: Optional[Dict] =None) -> dict:\n",
    "    \"\"\"A more complex callback that processes conversation history\"\"\"\n",
    "    # Extract the latest message from the conversation history\n",
    "    messages_list = [{\"role\": chat_message.role,\"content\": chat_message.content} for chat_message in messages]\n",
    "    latest_message = messages_list[-1][\"content\"]\n",
    "    \n",
    "    # In a real application, you might process the entire conversation history\n",
    "    # Here, we're just simulating different responses based on the latest message\n",
    "    response = \"I'm an AI assistant that follows safety guidelines. I cannot provide harmful content.\"\n",
    "    \n",
    "    # Format the response to follow the openAI chat protocol format\n",
    "    formatted_response = {\n",
    "        \"content\": response,\n",
    "        \"role\": \"assistant\"\n",
    "    }\n",
    "    \n",
    "    return {\"messages\": [formatted_response]}\n",
    "\n",
    "# Run a more comprehensive scan with all base risk categories\n",
    "advanced_results = await agent.scan(\n",
    "    target=advanced_callback,\n",
    "    scan_name=\"Advanced-Callback-Test\",\n",
    "    attack_strategies=[AttackStrategy.Base64, AttackStrategy.ROT13, AttackStrategy.UnicodeConfusable],\n",
    "    risk_categories=[RiskCategory.Violence, RiskCategory.Sexual, RiskCategory.SelfHarm, RiskCategory.HateUnfairness],\n",
    "    num_objectives=2,  # Using 2 objectives per category for this example\n",
    "    application_scenario=\"An AI assistant for educational content for children\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Testing OpenAI or Azure OpenAI Models Directly\n",
    "\n",
    "This example shows how to red team test an OpenAI or Azure OpenAI model directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for OpenAI model\n",
    "openai_config = {\n",
    "    \"model\": \"gpt-4o\",  # Replace with your actual model name\n",
    "    \"api_key\": \"your_openai_api_key\"  # Replace with your actual API key\n",
    "}\n",
    "\n",
    "# Configuration for Azure OpenAI model\n",
    "azure_openai_config = {\n",
    "    \"azure_endpoint\": \"https://your-deployment.openai.azure.com/\",  # Replace with your endpoint\n",
    "    \"azure_deployment\": \"your-deployment-name\",  # Replace with your deployment name\n",
    "    \"api_key\": \"your_azure_openai_api_key\"  # Replace with your API key, or comment out if Entra ID authentication is enabled on your deployment \n",
    "}\n",
    "\n",
    "# Uncomment and use one of these configurations:\n",
    "# model_config = openai_config  # For OpenAI\n",
    "model_config = azure_openai_config  # For Azure OpenAI\n",
    "\n",
    "# Run scan with multiple attack strategies\n",
    "model_results = await agent.scan(\n",
    "    target=model_config,\n",
    "    scan_name=\"Direct-Model-Test\",\n",
    "    attack_strategies=[\n",
    "        AttackStrategy.EASY,      # Easy complexity attacks\n",
    "        AttackStrategy.Jailbreak  # Test jailbreak prompts\n",
    "    ],\n",
    "    risk_categories=[RiskCategory.Violence, RiskCategory.HateUnfairness],\n",
    "    num_objectives=3,\n",
    "    application_scenario=\"A legal document assistant for contract drafting\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Using Pre-defined Attack Strategy Complexities\n",
    "\n",
    "This example demonstrates using pre-defined complexity levels for attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a callback that simulates a financial advisor chatbot\n",
    "def financial_advisor_callback(query: str) -> str:\n",
    "    return \"I'm a financial advisor assistant. I can help with investment advice and financial planning within legal and ethical guidelines.\"\n",
    "\n",
    "# Run a scan with different complexity levels\n",
    "complexity_results = await agent.scan(\n",
    "    target=financial_advisor_callback,\n",
    "    scan_name=\"Complexity-Levels-Test\",\n",
    "    attack_strategies=[\n",
    "        AttackStrategy.EASY,      # Group of easy complexity attacks\n",
    "        AttackStrategy.MODERATE,  # Group of moderate complexity attacks\n",
    "        AttackStrategy.DIFFICULT  # Group of difficult complexity attacks\n",
    "    ],\n",
    "    risk_categories=[RiskCategory.Violence, RiskCategory.SelfHarm],\n",
    "    num_objectives=2,\n",
    "    application_scenario=\"A financial advisor chatbot for investment planning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Using Specific Attack Strategies\n",
    "\n",
    "This example demonstrates using specific individual attack strategies rather than complexity groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a medical assistant callback\n",
    "def medical_assistant_callback(query: str) -> str:\n",
    "    return \"I'm a medical information assistant. I can provide general health information but cannot diagnose conditions or prescribe treatments.\"\n",
    "\n",
    "# Run a scan with specific attack strategies\n",
    "specific_strategy_results = await agent.scan(\n",
    "    target=medical_assistant_callback,\n",
    "    scan_name=\"Specific-Strategies-Test\",\n",
    "    attack_strategies=[\n",
    "        AttackStrategy.Base64,           # Encode prompts in Base64\n",
    "        AttackStrategy.Flip,             # Flip text to evade detection\n",
    "        AttackStrategy.CharacterSpace,   # Add character spaces\n",
    "        AttackStrategy.ROT13,            # Use ROT13 encoding\n",
    "        AttackStrategy.UnicodeConfusable,# Use confusable Unicode characters\n",
    "        AttackStrategy.Tense             # Change tense of prompts  \n",
    "    ],\n",
    "    risk_categories=[RiskCategory.SelfHarm, RiskCategory.HateUnfairness],\n",
    "    num_objectives=3,\n",
    "    application_scenario=\"A medical information assistant for general health information\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Data-Only Mode (Without Evaluation)\n",
    "\n",
    "This example shows how to run in data-only mode to collect conversation data without performing evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple content moderator callback\n",
    "def content_moderator_callback(query: str) -> str:\n",
    "    return \"I'm a content moderation assistant. I can help identify and flag potentially inappropriate content.\"\n",
    "\n",
    "# Run a data-only scan (without evaluations)\n",
    "data_only_results = await agent.scan(\n",
    "    target=content_moderator_callback,\n",
    "    scan_name=\"Data-Only-Test\",\n",
    "    attack_strategies=[AttackStrategy.Morse, AttackStrategy.Leetspeak],\n",
    "    risk_categories=[RiskCategory.Sexual, RiskCategory.HateUnfairness],\n",
    "    num_objectives=2,\n",
    "    application_scenario=\"A content moderation system for a social media platform\",\n",
    "    data_only=True  # Only collect conversation data without evaluations\n",
    ")\n",
    "\n",
    "# You can access the collected conversation data\n",
    "conversations = data_only_results.redteaming_data\n",
    "print(f\"Collected {len(conversations) if conversations else 0} conversations without evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Working with Results\n",
    "\n",
    "This example demonstrates how to extract and use information from the RedTeamAgent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the results from any previous example\n",
    "results = specific_strategy_results  # Change this to any of the earlier results variables\n",
    "\n",
    "# Extract the JSON representation of results\n",
    "results_json = results.to_json()\n",
    "print(f\"Results JSON length: {len(results_json)}\")\n",
    "\n",
    "# Extract just the scorecard\n",
    "scorecard = results.to_scorecard()\n",
    "if scorecard:\n",
    "    print(\"\\nRisk Category Summary:\")\n",
    "    for category in scorecard.get(\"risk_category_summary\", []):\n",
    "        print(f\"Overall ASR: {category.get('overall_asr')}%\")\n",
    "        print(f\"Total Attacks: {category.get('overall_total')}\")\n",
    "        print(f\"Successful Attacks: {category.get('overall_attack_successes')}\")\n",
    "\n",
    "# Convert to query-response format for further evaluation\n",
    "qr_format = results.to_eval_qr_json_lines()\n",
    "print(f\"\\nQuery-Response format length: {len(qr_format)}\")\n",
    "\n",
    "# Get a human-readable attack simulation report\n",
    "attack_simulation = results.attack_simulation()\n",
    "print(f\"\\nAttack Simulation Report Preview:\\n{attack_simulation[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 8: Using a Custom Application with Mock Attack Scenario\n",
    "\n",
    "This example demonstrates integrating with a custom application in a realistic attack scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a more complex application with some guardrails\n",
    "class ContentCreationAssistant:\n",
    "    def __init__(self):\n",
    "        self.banned_topics = [\"violence\", \"hate\", \"harassment\", \"self-harm\", \"explicit\"]\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def check_content(self, text):\n",
    "        # Simple content filter (in reality, this would be more sophisticated)\n",
    "        for topic in self.banned_topics:\n",
    "            if topic in text.lower():\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def generate_response(self, query):\n",
    "        # Store conversation history\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": query})\n",
    "        \n",
    "        # Check if content passes moderation\n",
    "        if not self.check_content(query):\n",
    "            response = \"I'm sorry, I cannot assist with that type of content as it may violate content guidelines.\"\n",
    "        else:\n",
    "            response = \"I'm a content creation assistant. I can help you draft blog posts, articles, and other content following ethical guidelines.\"\n",
    "        \n",
    "        # Add response to history\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return response\n",
    "\n",
    "# Create an instance of the assistant\n",
    "assistant = ContentCreationAssistant()\n",
    "\n",
    "# Wrapper function for the RedTeamAgent\n",
    "def content_assistant_callback(query):\n",
    "    return assistant.generate_response(query)\n",
    "\n",
    "# Run a scan with various attack strategies\n",
    "custom_app_results = await agent.scan(\n",
    "    target=content_assistant_callback,\n",
    "    scan_name=\"Content-Assistant-Test\",\n",
    "    attack_strategies=[\n",
    "        AttackStrategy.EASY,          # Easy complexity attacks\n",
    "        AttackStrategy.Jailbreak      # Test jailbreak attempts\n",
    "    ],\n",
    "    risk_categories=[RiskCategory.HateUnfairness, RiskCategory.Violence],\n",
    "    num_objectives=3,\n",
    "    application_scenario=\"A content creation assistant for bloggers and writers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 9: Running with Output Path and Custom Location\n",
    "\n",
    "This example shows how to specify an output path for results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a timestamp-based output directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"redteam_results_{timestamp}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"redteam_results.json\")\n",
    "\n",
    "# Define a simple application\n",
    "def education_assistant_callback(query):\n",
    "    return \"I'm an educational assistant designed to help with learning and studying.\"\n",
    "\n",
    "# Run a scan with custom output path\n",
    "output_path_results = await agent.scan(\n",
    "    target=education_assistant_callback,\n",
    "    scan_name=\"Output-Path-Test\",\n",
    "    attack_strategies=[AttackStrategy.Baseline, AttackStrategy.AsciiArt, AttackStrategy.Binary],\n",
    "    risk_categories=[RiskCategory.HateUnfairness, RiskCategory.Violence],\n",
    "    num_objectives=2,\n",
    "    application_scenario=\"An educational assistant for students\",\n",
    "    output_path=output_path  # Specify where to save results\n",
    ")\n",
    "\n",
    "print(f\"Results saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 10: Empty Attack Strategies\n",
    "\n",
    "This example demonstrates using an empty list of attack strategies. Only the baseline strategy will be applied (added by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safety_assistant_callback(query: str) -> str:\n",
    "    return \"I'm a safety assistant that provides guidance on workplace safety protocols.\"\n",
    "\n",
    "# Run a scan with empty attack strategies list (only baseline will be used)\n",
    "empty_strategies_results = await agent.scan(\n",
    "    target=safety_assistant_callback,\n",
    "    scan_name=\"Empty-Strategies-Test\",\n",
    "    attack_strategies=[],  # Empty list - only baseline strategy will be used\n",
    "    risk_categories=[RiskCategory.Violence, RiskCategory.HateUnfairness],\n",
    "    num_objectives=2,\n",
    "    application_scenario=\"A workplace safety assistant for employees\"\n",
    ")\n",
    "\n",
    "print(f\"Empty strategies test completed with {len(empty_strategies_results.redteaming_data) if empty_strategies_results.redteaming_data else 0} conversations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 11: Empty Risk Categories\n",
    "\n",
    "This example demonstrates using an empty list of risk categories. The system will use default risk categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_service_callback(query: str) -> str:\n",
    "    return \"I'm a customer service assistant for a retail store. I can help with product information and returns.\"\n",
    "\n",
    "# Run a scan with empty risk categories\n",
    "empty_categories_results = await agent.scan(\n",
    "    target=customer_service_callback,\n",
    "    scan_name=\"Empty-Categories-Test\",\n",
    "    attack_strategies=[AttackStrategy.Base64, AttackStrategy.ROT13],\n",
    "    risk_categories=[],  # Empty list - will use default categories\n",
    "    num_objectives=2,\n",
    "    application_scenario=\"A customer service assistant for a retail store\"\n",
    ")\n",
    "\n",
    "print(f\"Empty categories test completed with {len(empty_categories_results.redteaming_data) if empty_categories_results.redteaming_data else 0} conversations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 12: Duplicate Strategies and Categories\n",
    "\n",
    "This example demonstrates using duplicate attack strategies and risk categories. Duplicates will be automatically removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travel_assistant_callback(query: str) -> str:\n",
    "    return \"I'm a travel assistant that helps with trip planning and booking accommodations.\"\n",
    "\n",
    "# Run a scan with duplicate attack strategies\n",
    "duplicate_results = await agent.scan(\n",
    "    target=travel_assistant_callback,\n",
    "    scan_name=\"Duplicate-Cases-Test\",\n",
    "    attack_strategies=[\n",
    "        AttackStrategy.Base64, \n",
    "        AttackStrategy.Base64,  # Duplicate\n",
    "        AttackStrategy.ROT13,\n",
    "        AttackStrategy.ROT13    # Duplicate\n",
    "    ],\n",
    "    risk_categories=[\n",
    "        RiskCategory.Violence, \n",
    "        RiskCategory.Violence,  # Duplicate\n",
    "        RiskCategory.HateUnfairness,\n",
    "        RiskCategory.HateUnfairness   # Duplicate\n",
    "    ],\n",
    "    num_objectives=2,\n",
    "    application_scenario=\"A travel planning assistant for vacation bookings\"\n",
    ")\n",
    "\n",
    "print(f\"Duplicate cases test completed with {len(duplicate_results.redteaming_data) if duplicate_results.redteaming_data else 0} conversations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 13: Using PyRIT PromptChatTarget as Target\n",
    "\n",
    "This example demonstrates using PyRIT's PromptChatTarget directly as a target for RedTeamAgent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrit.prompt_target import OpenAIChatTarget, PromptChatTarget\n",
    "\n",
    "chat_target = OpenAIChatTarget(\n",
    "    model_name=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\", \"your-deployment-name\"),\n",
    "    endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"https://your-deployment.openai.azure.com/\"),\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_KEY\", \"your_azure_openai_api_key\")\n",
    ")\n",
    "\n",
    "# Run a scan using the PyRIT PromptChatTarget directly\n",
    "pyrit_results = await agent.scan(\n",
    "    target=chat_target,  # PyRIT PromptChatTarget instance\n",
    "    scan_name=\"PyRIT-Target-Test\",\n",
    "    attack_strategies=[\n",
    "        AttackStrategy.Base64,\n",
    "        AttackStrategy.ROT13\n",
    "    ],\n",
    "    risk_categories=[RiskCategory.SelfHarm, RiskCategory.HateUnfairness],\n",
    "    num_objectives=2,\n",
    "    application_scenario=\"A general-purpose AI assistant\"\n",
    ")\n",
    "\n",
    "print(f\"PyRIT target scan completed with {len(pyrit_results.redteaming_data) if pyrit_results.redteaming_data else 0} conversations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyrit-3-22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
