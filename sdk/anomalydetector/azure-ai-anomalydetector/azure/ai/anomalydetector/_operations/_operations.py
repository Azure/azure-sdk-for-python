# pylint: disable=too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
import sys
from typing import Any, Callable, Dict, IO, Iterable, Optional, TypeVar, Union, cast, overload

from azure.core.exceptions import (
    ClientAuthenticationError,
    HttpResponseError,
    ResourceExistsError,
    ResourceNotFoundError,
    ResourceNotModifiedError,
    map_error,
)
from azure.core.paging import ItemPaged
from azure.core.pipeline import PipelineResponse
from azure.core.pipeline.transport import HttpResponse
from azure.core.rest import HttpRequest
from azure.core.tracing.decorator import distributed_trace
from azure.core.utils import case_insensitive_dict

from .._serialization import Serializer
from .._vendor import MixinABC, _format_url_section

if sys.version_info >= (3, 9):
    from collections.abc import MutableMapping
else:
    from typing import MutableMapping  # type: ignore  # pylint: disable=ungrouped-imports
JSON = MutableMapping[str, Any]  # pylint: disable=unsubscriptable-object
T = TypeVar("T")
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]

_SERIALIZER = Serializer()
_SERIALIZER.client_side_validation = False


def build_detect_entire_series_request(**kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/timeseries/entire/detect"

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, headers=_headers, **kwargs)


def build_detect_last_point_request(**kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/timeseries/last/detect"

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, headers=_headers, **kwargs)


def build_detect_change_point_request(**kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/timeseries/changepoint/detect"

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, headers=_headers, **kwargs)


def build_get_batch_detection_result_request(result_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/multivariate/detect-batch/{resultId}"
    path_format_arguments = {
        "resultId": _SERIALIZER.url("result_id", result_id, "str"),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, headers=_headers, **kwargs)


def build_create_multivariate_model_request(**kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/multivariate/models"

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, headers=_headers, **kwargs)


def build_list_multivariate_model_request(*, skip: int = 0, top: Optional[int] = None, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/multivariate/models"

    # Construct parameters
    if skip is not None:
        _params["skip"] = _SERIALIZER.query("skip", skip, "int")
    if top is not None:
        _params["top"] = _SERIALIZER.query("top", top, "int")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_delete_multivariate_model_request(model_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/multivariate/models/{modelId}"
    path_format_arguments = {
        "modelId": _SERIALIZER.url("model_id", model_id, "str"),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="DELETE", url=_url, headers=_headers, **kwargs)


def build_get_multivariate_model_request(model_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/multivariate/models/{modelId}"
    path_format_arguments = {
        "modelId": _SERIALIZER.url("model_id", model_id, "str"),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, headers=_headers, **kwargs)


def build_batch_detect_anomaly_request(model_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/multivariate/models/{modelId}:detect-batch"
    path_format_arguments = {
        "modelId": _SERIALIZER.url("model_id", model_id, "str"),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, headers=_headers, **kwargs)


def build_last_detect_anomaly_request(model_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/multivariate/models/{modelId}:detect-last"
    path_format_arguments = {
        "modelId": _SERIALIZER.url("model_id", model_id, "str"),
    }

    _url = _format_url_section(_url, **path_format_arguments)

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, headers=_headers, **kwargs)


class AnomalyDetectorClientOperationsMixin(MixinABC):
    @overload
    def detect_entire_series(self, body: JSON, *, content_type: str = "application/json", **kwargs: Any) -> JSON:
        """Detect anomalies for the entire series in batch.

        This operation generates a model with an entire series, each point is detected with the same
        model. With this method, points before and after a certain point are used to determine whether
        it is an anomaly. The entire detection can give user an overall status of the time series.

        :param body: Time series points and period if needed. Advanced model parameters can also be set
         in the request. Required.
        :type body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                body = {
                    "series": [
                        {
                            "value": 0.0,  # The measurement of that point, should be
                              float. Required.
                            "timestamp": "2020-02-20 00:00:00"  # Optional. Optional
                              argument, timestamp of a data point (ISO8601 format).
                        }
                    ],
                    "customInterval": 0,  # Optional. Custom Interval is used to set non-standard
                      time interval, for example, if the series is 5 minutes, request can be set as
                      {"granularity":"minutely", "customInterval":5}.
                    "granularity": "str",  # Optional. Optional argument, can be one of yearly,
                      monthly, weekly, daily, hourly, minutely, secondly, microsecond or none. If
                      granularity is not present, it will be none by default. If granularity is none,
                      the timestamp property in time series point can be absent. Known values are:
                      "yearly", "monthly", "weekly", "daily", "hourly", "minutely", "secondly",
                      "microsecond", and "none".
                    "imputeFixedValue": 0.0,  # Optional. Used to specify the value to fill, it's
                      used when granularity is not "none" and imputeMode is "fixed".
                    "imputeMode": "str",  # Optional. Used to specify how to deal with missing
                      values in the input series, it's used when granularity is not "none". Known
                      values are: "auto", "previous", "linear", "fixed", "zero", and "notFill".
                    "maxAnomalyRatio": 0.0,  # Optional. Optional argument, advanced model
                      parameter, max anomaly ratio in a time series.
                    "period": 0,  # Optional. Optional argument, periodic value of a time series.
                      If the value is null or does not present, the API will determine the period
                      automatically.
                    "sensitivity": 0  # Optional. Optional argument, advanced model parameter,
                      between 0-99, the lower the value is, the larger the margin value will be which
                      means less anomalies will be accepted.
                }

                # response body for status code(s): 200
                response == {
                    "expectedValues": [
                        0.0  # ExpectedValues contain expected value for each input point.
                          The index of the array is consistent with the input series. Required.
                    ],
                    "isAnomaly": [
                        bool  # IsAnomaly contains anomaly properties for each input point.
                          True means an anomaly either negative or positive has been detected. The
                          index of the array is consistent with the input series. Required.
                    ],
                    "isNegativeAnomaly": [
                        bool  # IsNegativeAnomaly contains anomaly status in negative
                          direction for each input point. True means a negative anomaly has been
                          detected. A negative anomaly means the point is detected as an anomaly and
                          its real value is smaller than the expected one. The index of the array is
                          consistent with the input series. Required.
                    ],
                    "isPositiveAnomaly": [
                        bool  # IsPositiveAnomaly contain anomaly status in positive
                          direction for each input point. True means a positive anomaly has been
                          detected. A positive anomaly means the point is detected as an anomaly and
                          its real value is larger than the expected one. The index of the array is
                          consistent with the input series. Required.
                    ],
                    "lowerMargins": [
                        0.0  # LowerMargins contain lower margin of each input point.
                          LowerMargin is used to calculate lowerBoundary, which equals to expectedValue
                          - (100 - marginScale)*lowerMargin. Points between the boundary can be marked
                          as normal ones in client side. The index of the array is consistent with the
                          input series. Required.
                    ],
                    "period": 0,  # Frequency extracted from the series, zero means no recurrent
                      pattern has been found. Required.
                    "upperMargins": [
                        0.0  # UpperMargins contain upper margin of each input point.
                          UpperMargin is used to calculate upperBoundary, which equals to expectedValue
                          + (100 - marginScale)*upperMargin. Anomalies in response can be filtered by
                          upperBoundary and lowerBoundary. By adjusting marginScale value, less
                          significant anomalies can be filtered in client side. The index of the array
                          is consistent with the input series. Required.
                    ],
                    "severity": [
                        0.0  # Optional. The severity score for each input point. The larger
                          the value is, the more sever the anomaly is. For normal points, the
                          "severity" is always 0.
                    ]
                }
        """

    @overload
    def detect_entire_series(self, body: IO, *, content_type: str = "application/json", **kwargs: Any) -> JSON:
        """Detect anomalies for the entire series in batch.

        This operation generates a model with an entire series, each point is detected with the same
        model. With this method, points before and after a certain point are used to determine whether
        it is an anomaly. The entire detection can give user an overall status of the time series.

        :param body: Time series points and period if needed. Advanced model parameters can also be set
         in the request. Required.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "expectedValues": [
                        0.0  # ExpectedValues contain expected value for each input point.
                          The index of the array is consistent with the input series. Required.
                    ],
                    "isAnomaly": [
                        bool  # IsAnomaly contains anomaly properties for each input point.
                          True means an anomaly either negative or positive has been detected. The
                          index of the array is consistent with the input series. Required.
                    ],
                    "isNegativeAnomaly": [
                        bool  # IsNegativeAnomaly contains anomaly status in negative
                          direction for each input point. True means a negative anomaly has been
                          detected. A negative anomaly means the point is detected as an anomaly and
                          its real value is smaller than the expected one. The index of the array is
                          consistent with the input series. Required.
                    ],
                    "isPositiveAnomaly": [
                        bool  # IsPositiveAnomaly contain anomaly status in positive
                          direction for each input point. True means a positive anomaly has been
                          detected. A positive anomaly means the point is detected as an anomaly and
                          its real value is larger than the expected one. The index of the array is
                          consistent with the input series. Required.
                    ],
                    "lowerMargins": [
                        0.0  # LowerMargins contain lower margin of each input point.
                          LowerMargin is used to calculate lowerBoundary, which equals to expectedValue
                          - (100 - marginScale)*lowerMargin. Points between the boundary can be marked
                          as normal ones in client side. The index of the array is consistent with the
                          input series. Required.
                    ],
                    "period": 0,  # Frequency extracted from the series, zero means no recurrent
                      pattern has been found. Required.
                    "upperMargins": [
                        0.0  # UpperMargins contain upper margin of each input point.
                          UpperMargin is used to calculate upperBoundary, which equals to expectedValue
                          + (100 - marginScale)*upperMargin. Anomalies in response can be filtered by
                          upperBoundary and lowerBoundary. By adjusting marginScale value, less
                          significant anomalies can be filtered in client side. The index of the array
                          is consistent with the input series. Required.
                    ],
                    "severity": [
                        0.0  # Optional. The severity score for each input point. The larger
                          the value is, the more sever the anomaly is. For normal points, the
                          "severity" is always 0.
                    ]
                }
        """

    @distributed_trace
    def detect_entire_series(self, body: Union[JSON, IO], **kwargs: Any) -> JSON:
        """Detect anomalies for the entire series in batch.

        This operation generates a model with an entire series, each point is detected with the same
        model. With this method, points before and after a certain point are used to determine whether
        it is an anomaly. The entire detection can give user an overall status of the time series.

        :param body: Time series points and period if needed. Advanced model parameters can also be set
         in the request. Is either a model type or a IO type. Required.
        :type body: JSON or IO
        :keyword content_type: Body Parameter content-type. Known values are: 'application/json'.
         Default value is None.
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "expectedValues": [
                        0.0  # ExpectedValues contain expected value for each input point.
                          The index of the array is consistent with the input series. Required.
                    ],
                    "isAnomaly": [
                        bool  # IsAnomaly contains anomaly properties for each input point.
                          True means an anomaly either negative or positive has been detected. The
                          index of the array is consistent with the input series. Required.
                    ],
                    "isNegativeAnomaly": [
                        bool  # IsNegativeAnomaly contains anomaly status in negative
                          direction for each input point. True means a negative anomaly has been
                          detected. A negative anomaly means the point is detected as an anomaly and
                          its real value is smaller than the expected one. The index of the array is
                          consistent with the input series. Required.
                    ],
                    "isPositiveAnomaly": [
                        bool  # IsPositiveAnomaly contain anomaly status in positive
                          direction for each input point. True means a positive anomaly has been
                          detected. A positive anomaly means the point is detected as an anomaly and
                          its real value is larger than the expected one. The index of the array is
                          consistent with the input series. Required.
                    ],
                    "lowerMargins": [
                        0.0  # LowerMargins contain lower margin of each input point.
                          LowerMargin is used to calculate lowerBoundary, which equals to expectedValue
                          - (100 - marginScale)*lowerMargin. Points between the boundary can be marked
                          as normal ones in client side. The index of the array is consistent with the
                          input series. Required.
                    ],
                    "period": 0,  # Frequency extracted from the series, zero means no recurrent
                      pattern has been found. Required.
                    "upperMargins": [
                        0.0  # UpperMargins contain upper margin of each input point.
                          UpperMargin is used to calculate upperBoundary, which equals to expectedValue
                          + (100 - marginScale)*upperMargin. Anomalies in response can be filtered by
                          upperBoundary and lowerBoundary. By adjusting marginScale value, less
                          significant anomalies can be filtered in client side. The index of the array
                          is consistent with the input series. Required.
                    ],
                    "severity": [
                        0.0  # Optional. The severity score for each input point. The larger
                          the value is, the more sever the anomaly is. For normal points, the
                          "severity" is always 0.
                    ]
                }
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
        cls = kwargs.pop("cls", None)  # type: ClsType[JSON]

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            _json = body

        request = build_detect_entire_series_request(
            content_type=content_type,
            json=_json,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "Endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
            "ApiVersion": self._serialize.url(
                "self._config.api_version", self._config.api_version, "str", skip_quote=True
            ),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if response.content:
            deserialized = response.json()
        else:
            deserialized = None

        if cls:
            return cls(pipeline_response, cast(JSON, deserialized), {})

        return cast(JSON, deserialized)

    @overload
    def detect_last_point(self, body: JSON, *, content_type: str = "application/json", **kwargs: Any) -> JSON:
        """Detect anomaly status of the latest point in time series.

        This operation generates a model using the points that you sent into the API, and based on all
        data to determine whether the last point is anomalous.

        :param body: Time series points and period if needed. Advanced model parameters can also be set
         in the request. Required.
        :type body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                body = {
                    "series": [
                        {
                            "value": 0.0,  # The measurement of that point, should be
                              float. Required.
                            "timestamp": "2020-02-20 00:00:00"  # Optional. Optional
                              argument, timestamp of a data point (ISO8601 format).
                        }
                    ],
                    "customInterval": 0,  # Optional. Custom Interval is used to set non-standard
                      time interval, for example, if the series is 5 minutes, request can be set as
                      {"granularity":"minutely", "customInterval":5}.
                    "granularity": "str",  # Optional. Optional argument, can be one of yearly,
                      monthly, weekly, daily, hourly, minutely, secondly, microsecond or none. If
                      granularity is not present, it will be none by default. If granularity is none,
                      the timestamp property in time series point can be absent. Known values are:
                      "yearly", "monthly", "weekly", "daily", "hourly", "minutely", "secondly",
                      "microsecond", and "none".
                    "imputeFixedValue": 0.0,  # Optional. Used to specify the value to fill, it's
                      used when granularity is not "none" and imputeMode is "fixed".
                    "imputeMode": "str",  # Optional. Used to specify how to deal with missing
                      values in the input series, it's used when granularity is not "none". Known
                      values are: "auto", "previous", "linear", "fixed", "zero", and "notFill".
                    "maxAnomalyRatio": 0.0,  # Optional. Optional argument, advanced model
                      parameter, max anomaly ratio in a time series.
                    "period": 0,  # Optional. Optional argument, periodic value of a time series.
                      If the value is null or does not present, the API will determine the period
                      automatically.
                    "sensitivity": 0  # Optional. Optional argument, advanced model parameter,
                      between 0-99, the lower the value is, the larger the margin value will be which
                      means less anomalies will be accepted.
                }

                # response body for status code(s): 200
                response == {
                    "expectedValue": 0.0,  # Expected value of the latest point. Required.
                    "isAnomaly": bool,  # Anomaly status of the latest point, true means the
                      latest point is an anomaly either in negative direction or positive direction.
                      Required.
                    "isNegativeAnomaly": bool,  # Anomaly status in negative direction of the
                      latest point. True means the latest point is an anomaly and its real value is
                      smaller than the expected one. Required.
                    "isPositiveAnomaly": bool,  # Anomaly status in positive direction of the
                      latest point. True means the latest point is an anomaly and its real value is
                      larger than the expected one. Required.
                    "lowerMargin": 0.0,  # Lower margin of the latest point. LowerMargin is used
                      to calculate lowerBoundary, which equals to expectedValue - (100 -
                      marginScale)*lowerMargin. Required.
                    "period": 0,  # Frequency extracted from the series, zero means no recurrent
                      pattern has been found. Required.
                    "suggestedWindow": 0,  # Suggested input series points needed for detecting
                      the latest point. Required.
                    "upperMargin": 0.0,  # Upper margin of the latest point. UpperMargin is used
                      to calculate upperBoundary, which equals to expectedValue + (100 -
                      marginScale)*upperMargin. If the value of latest point is between upperBoundary
                      and lowerBoundary, it should be treated as normal value. By adjusting marginScale
                      value, anomaly status of latest point can be changed. Required.
                    "severity": 0.0  # Optional. The severity score for the last input point. The
                      larger the value is, the more sever the anomaly is. For normal points, the
                      "severity" is always 0.
                }
        """

    @overload
    def detect_last_point(self, body: IO, *, content_type: str = "application/json", **kwargs: Any) -> JSON:
        """Detect anomaly status of the latest point in time series.

        This operation generates a model using the points that you sent into the API, and based on all
        data to determine whether the last point is anomalous.

        :param body: Time series points and period if needed. Advanced model parameters can also be set
         in the request. Required.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "expectedValue": 0.0,  # Expected value of the latest point. Required.
                    "isAnomaly": bool,  # Anomaly status of the latest point, true means the
                      latest point is an anomaly either in negative direction or positive direction.
                      Required.
                    "isNegativeAnomaly": bool,  # Anomaly status in negative direction of the
                      latest point. True means the latest point is an anomaly and its real value is
                      smaller than the expected one. Required.
                    "isPositiveAnomaly": bool,  # Anomaly status in positive direction of the
                      latest point. True means the latest point is an anomaly and its real value is
                      larger than the expected one. Required.
                    "lowerMargin": 0.0,  # Lower margin of the latest point. LowerMargin is used
                      to calculate lowerBoundary, which equals to expectedValue - (100 -
                      marginScale)*lowerMargin. Required.
                    "period": 0,  # Frequency extracted from the series, zero means no recurrent
                      pattern has been found. Required.
                    "suggestedWindow": 0,  # Suggested input series points needed for detecting
                      the latest point. Required.
                    "upperMargin": 0.0,  # Upper margin of the latest point. UpperMargin is used
                      to calculate upperBoundary, which equals to expectedValue + (100 -
                      marginScale)*upperMargin. If the value of latest point is between upperBoundary
                      and lowerBoundary, it should be treated as normal value. By adjusting marginScale
                      value, anomaly status of latest point can be changed. Required.
                    "severity": 0.0  # Optional. The severity score for the last input point. The
                      larger the value is, the more sever the anomaly is. For normal points, the
                      "severity" is always 0.
                }
        """

    @distributed_trace
    def detect_last_point(self, body: Union[JSON, IO], **kwargs: Any) -> JSON:
        """Detect anomaly status of the latest point in time series.

        This operation generates a model using the points that you sent into the API, and based on all
        data to determine whether the last point is anomalous.

        :param body: Time series points and period if needed. Advanced model parameters can also be set
         in the request. Is either a model type or a IO type. Required.
        :type body: JSON or IO
        :keyword content_type: Body Parameter content-type. Known values are: 'application/json'.
         Default value is None.
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "expectedValue": 0.0,  # Expected value of the latest point. Required.
                    "isAnomaly": bool,  # Anomaly status of the latest point, true means the
                      latest point is an anomaly either in negative direction or positive direction.
                      Required.
                    "isNegativeAnomaly": bool,  # Anomaly status in negative direction of the
                      latest point. True means the latest point is an anomaly and its real value is
                      smaller than the expected one. Required.
                    "isPositiveAnomaly": bool,  # Anomaly status in positive direction of the
                      latest point. True means the latest point is an anomaly and its real value is
                      larger than the expected one. Required.
                    "lowerMargin": 0.0,  # Lower margin of the latest point. LowerMargin is used
                      to calculate lowerBoundary, which equals to expectedValue - (100 -
                      marginScale)*lowerMargin. Required.
                    "period": 0,  # Frequency extracted from the series, zero means no recurrent
                      pattern has been found. Required.
                    "suggestedWindow": 0,  # Suggested input series points needed for detecting
                      the latest point. Required.
                    "upperMargin": 0.0,  # Upper margin of the latest point. UpperMargin is used
                      to calculate upperBoundary, which equals to expectedValue + (100 -
                      marginScale)*upperMargin. If the value of latest point is between upperBoundary
                      and lowerBoundary, it should be treated as normal value. By adjusting marginScale
                      value, anomaly status of latest point can be changed. Required.
                    "severity": 0.0  # Optional. The severity score for the last input point. The
                      larger the value is, the more sever the anomaly is. For normal points, the
                      "severity" is always 0.
                }
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
        cls = kwargs.pop("cls", None)  # type: ClsType[JSON]

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            _json = body

        request = build_detect_last_point_request(
            content_type=content_type,
            json=_json,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "Endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
            "ApiVersion": self._serialize.url(
                "self._config.api_version", self._config.api_version, "str", skip_quote=True
            ),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if response.content:
            deserialized = response.json()
        else:
            deserialized = None

        if cls:
            return cls(pipeline_response, cast(JSON, deserialized), {})

        return cast(JSON, deserialized)

    @overload
    def detect_change_point(self, body: JSON, *, content_type: str = "application/json", **kwargs: Any) -> JSON:
        """Detect change point for the entire series.

        Evaluate change point score of every series point.

        :param body: Time series points and granularity is needed. Advanced model parameters can also
         be set in the request if needed. Required.
        :type body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                body = {
                    "granularity": "str",  # Can only be one of yearly, monthly, weekly, daily,
                      hourly, minutely or secondly. Granularity is used for verify whether input series
                      is valid. Required. Known values are: "yearly", "monthly", "weekly", "daily",
                      "hourly", "minutely", "secondly", "microsecond", and "none".
                    "series": [
                        {
                            "value": 0.0,  # The measurement of that point, should be
                              float. Required.
                            "timestamp": "2020-02-20 00:00:00"  # Optional. Optional
                              argument, timestamp of a data point (ISO8601 format).
                        }
                    ],
                    "customInterval": 0,  # Optional. Custom Interval is used to set non-standard
                      time interval, for example, if the series is 5 minutes, request can be set as
                      {"granularity":"minutely", "customInterval":5}.
                    "period": 0,  # Optional. Optional argument, periodic value of a time series.
                      If the value is null or does not present, the API will determine the period
                      automatically.
                    "stableTrendWindow": 0,  # Optional. Optional argument, advanced model
                      parameter, a default stableTrendWindow will be used in detection.
                    "threshold": 0.0  # Optional. Optional argument, advanced model parameter,
                      between 0.0-1.0, the lower the value is, the larger the trend error will be which
                      means less change point will be accepted.
                }

                # response body for status code(s): 200
                response == {
                    "confidenceScores": [
                        0.0  # Optional. the change point confidence of each point.
                    ],
                    "isChangePoint": [
                        bool  # Optional. isChangePoint contains change point properties for
                          each input point. True means an anomaly either negative or positive has been
                          detected. The index of the array is consistent with the input series.
                    ],
                    "period": 0  # Optional. Frequency extracted from the series, zero means no
                      recurrent pattern has been found.
                }
        """

    @overload
    def detect_change_point(self, body: IO, *, content_type: str = "application/json", **kwargs: Any) -> JSON:
        """Detect change point for the entire series.

        Evaluate change point score of every series point.

        :param body: Time series points and granularity is needed. Advanced model parameters can also
         be set in the request if needed. Required.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "confidenceScores": [
                        0.0  # Optional. the change point confidence of each point.
                    ],
                    "isChangePoint": [
                        bool  # Optional. isChangePoint contains change point properties for
                          each input point. True means an anomaly either negative or positive has been
                          detected. The index of the array is consistent with the input series.
                    ],
                    "period": 0  # Optional. Frequency extracted from the series, zero means no
                      recurrent pattern has been found.
                }
        """

    @distributed_trace
    def detect_change_point(self, body: Union[JSON, IO], **kwargs: Any) -> JSON:
        """Detect change point for the entire series.

        Evaluate change point score of every series point.

        :param body: Time series points and granularity is needed. Advanced model parameters can also
         be set in the request if needed. Is either a model type or a IO type. Required.
        :type body: JSON or IO
        :keyword content_type: Body Parameter content-type. Known values are: 'application/json'.
         Default value is None.
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "confidenceScores": [
                        0.0  # Optional. the change point confidence of each point.
                    ],
                    "isChangePoint": [
                        bool  # Optional. isChangePoint contains change point properties for
                          each input point. True means an anomaly either negative or positive has been
                          detected. The index of the array is consistent with the input series.
                    ],
                    "period": 0  # Optional. Frequency extracted from the series, zero means no
                      recurrent pattern has been found.
                }
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
        cls = kwargs.pop("cls", None)  # type: ClsType[JSON]

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            _json = body

        request = build_detect_change_point_request(
            content_type=content_type,
            json=_json,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "Endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
            "ApiVersion": self._serialize.url(
                "self._config.api_version", self._config.api_version, "str", skip_quote=True
            ),
        }
        request.url = self._client.format_url(request.url, **path_format_arguments)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if response.content:
            deserialized = response.json()
        else:
            deserialized = None

        if cls:
            return cls(pipeline_response, cast(JSON, deserialized), {})

        return cast(JSON, deserialized)

    @distributed_trace
    def get_batch_detection_result(self, result_id: str, **kwargs: Any) -> JSON:
        """Get Multivariate Anomaly Detection Result.

        For asynchronous inference, get multivariate anomaly detection result based on resultId
        returned by the BatchDetectAnomaly api.

        :param result_id: Result identifier. Required.
        :type result_id: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "resultId": "str",  # Result identifier, which is used to fetch the results
                      of an inference call. Required.
                    "results": [
                        {
                            "timestamp": "2020-02-20 00:00:00",  # The timestamp for this
                              anomaly. Required.
                            "errors": [
                                {
                                    "code": "str",  # The error code. Required.
                                    "message": "str"  # The message explaining
                                      the error reported by the service. Required.
                                }
                            ],
                            "value": {
                                "isAnomaly": bool,  # True if an anomaly is detected
                                  at the current timestamp. Required.
                                "score": 0.0,  # Raw anomaly score of severity, will
                                  help indicate the degree of abnormality as well. Required.
                                "severity": 0.0,  # Indicates the significance of the
                                  anomaly. The higher the severity, the more significant the anomaly
                                  is. Required.
                                "interpretation": [
                                    {
                                        "contributionScore": 0.0,  #
                                          Optional. This score shows the percentage contributing to the
                                          anomalous timestamp. A number between 0 and 1.
                                        "correlationChanges": {
                                            "changedVariables": [
                                                "str"  # Optional.
                                                  The correlated variables that have correlation
                                                  changes under an anomaly.
                                            ]
                                        },
                                        "variable": "str"  # Optional.
                                          Variable.
                                    }
                                ]
                            }
                        }
                    ],
                    "summary": {
                        "setupInfo": {
                            "dataSource": "str",  # Source link to the input data to
                              indicate an accessible Azure storage Uri, either pointed to an Azure blob
                              storage folder, or pointed to a CSV file in Azure blob storage based on
                              you data schema selection. The data schema should be exactly the same
                              with those used in the training phase. Required.
                            "endTime": "2020-02-20 00:00:00",  # A required field,
                              indicating the end time of data for detection, which should be date-time
                              of ISO 8601 format. Required.
                            "startTime": "2020-02-20 00:00:00",  # A required field,
                              indicating the start time of data for detection, which should be
                              date-time of ISO 8601 format. Required.
                            "topContributorCount": 0  # An optional field, which is used
                              to specify the number of top contributed variables for one anomalous
                              timestamp in the response. The default number is 10. Required.
                        },
                        "status": "str",  # Status of detection results. One of CREATED,
                          RUNNING, READY, and FAILED. Required. Known values are: "CREATED", "RUNNING",
                          "READY", and "FAILED".
                        "errors": [
                            {
                                "code": "str",  # The error code. Required.
                                "message": "str"  # The message explaining the error
                                  reported by the service. Required.
                            }
                        ],
                        "variableStates": [
                            {
                                "effectiveCount": 0,  # Optional. Number of effective
                                  data points before applying fillNAMethod.
                                "filledNARatio": 0.0,  # Optional. Proportion of
                                  missing values that need to be filled by fillNAMethod.
                                "firstTimestamp": "2020-02-20 00:00:00",  # Optional.
                                  First valid timestamp with value of input data.
                                "lastTimestamp": "2020-02-20 00:00:00",  # Optional.
                                  Last valid timestamp with value of input data.
                                "variable": "str"  # Optional. Variable name in
                                  variable states.
                            }
                        ]
                    }
                }
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls = kwargs.pop("cls", None)  # type: ClsType[JSON]

        request = build_get_batch_detection_result_request(
            result_id=result_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if response.content:
            deserialized = response.json()
        else:
            deserialized = None

        if cls:
            return cls(pipeline_response, cast(JSON, deserialized), {})

        return cast(JSON, deserialized)

    @overload
    def create_multivariate_model(self, body: JSON, *, content_type: str = "application/json", **kwargs: Any) -> JSON:
        """Train a Multivariate Anomaly Detection Model.

        Create and train a multivariate anomaly detection model. The request must include a source
        parameter to indicate an externally accessible Azure blob storage URI.There are two types of
        data input: An URI pointed to an Azure blob storage folder which contains multiple CSV files,
        and each CSV file contains two columns, timestamp and variable. Another type of input is an URI
        pointed to a CSV file in Azure blob storage, which contains all the variables and a timestamp
        column.

        :param body: Training request. Required.
        :type body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                body = {
                    "dataSource": "str",  # Source link to the input data to indicate an
                      accessible Azure storage Uri, either pointed to an Azure blob storage folder, or
                      pointed to a CSV file in Azure blob storage based on you data schema selection.
                      Required.
                    "endTime": "2020-02-20 00:00:00",  # A required field, indicating the end
                      time of training data, which should be date-time of ISO 8601 format. Required.
                    "startTime": "2020-02-20 00:00:00",  # A required field, indicating the start
                      time of training data, which should be date-time of ISO 8601 format. Required.
                    "alignPolicy": {
                        "alignMode": "str",  # Optional. An optional field, indicating how to
                          align different variables to the same time-range. Either Inner or Outer.
                          Known values are: "Inner" and "Outer".
                        "fillNAMethod": "str",  # Optional. An optional field, indicating how
                          missing values will be filled. One of Previous, Subsequent, Linear, Zero,
                          Fixed. Known values are: "Previous", "Subsequent", "Linear", "Zero", and
                          "Fixed".
                        "paddingValue": 0.0  # Optional. An optional field. Required when
                          fillNAMethod is Fixed.
                    },
                    "dataSchema": "str",  # Optional. Data schema of input data source: OneTable
                      or MultiTable. The default DataSchema is OneTable. Known values are: "OneTable"
                      and "MultiTable".
                    "diagnosticsInfo": {
                        "modelState": {
                            "epochIds": [
                                0  # Optional. This indicates the number of passes of
                                  the entire training dataset the algorithm has completed.
                            ],
                            "latenciesInSeconds": [
                                0.0  # Optional. Latency for each epoch.
                            ],
                            "trainLosses": [
                                0.0  # Optional. List of metrics used to assess how
                                  the model fits the training data for each epoch.
                            ],
                            "validationLosses": [
                                0.0  # Optional. List of metrics used to assess how
                                  the model fits the validation set for each epoch.
                            ]
                        },
                        "variableStates": [
                            {
                                "effectiveCount": 0,  # Optional. Number of effective
                                  data points before applying fillNAMethod.
                                "filledNARatio": 0.0,  # Optional. Proportion of
                                  missing values that need to be filled by fillNAMethod.
                                "firstTimestamp": "2020-02-20 00:00:00",  # Optional.
                                  First valid timestamp with value of input data.
                                "lastTimestamp": "2020-02-20 00:00:00",  # Optional.
                                  Last valid timestamp with value of input data.
                                "variable": "str"  # Optional. Variable name in
                                  variable states.
                            }
                        ]
                    },
                    "displayName": "str",  # Optional. An optional field. The display name of the
                      model whose maximum length is 24 characters.
                    "errors": [
                        {
                            "code": "str",  # The error code. Required.
                            "message": "str"  # The message explaining the error reported
                              by the service. Required.
                        }
                    ],
                    "slidingWindow": 0,  # Optional. An optional field, indicating how many
                      previous timestamps will be used to detect whether the timestamp is anomaly or
                      not.
                    "status": "str"  # Optional. Model status. One of CREATED, RUNNING, READY,
                      and FAILED. Known values are: "CREATED", "RUNNING", "READY", and "FAILED".
                }

                # response body for status code(s): 201
                response == {
                    "createdTime": "2020-02-20 00:00:00",  # Date and time (UTC) when the model
                      was created. Required.
                    "lastUpdatedTime": "2020-02-20 00:00:00",  # Date and time (UTC) when the
                      model was last updated. Required.
                    "modelId": "str",  # Model identifier. Required.
                    "modelInfo": {
                        "dataSource": "str",  # Source link to the input data to indicate an
                          accessible Azure storage Uri, either pointed to an Azure blob storage folder,
                          or pointed to a CSV file in Azure blob storage based on you data schema
                          selection. Required.
                        "endTime": "2020-02-20 00:00:00",  # A required field, indicating the
                          end time of training data, which should be date-time of ISO 8601 format.
                          Required.
                        "startTime": "2020-02-20 00:00:00",  # A required field, indicating
                          the start time of training data, which should be date-time of ISO 8601
                          format. Required.
                        "alignPolicy": {
                            "alignMode": "str",  # Optional. An optional field,
                              indicating how to align different variables to the same time-range.
                              Either Inner or Outer. Known values are: "Inner" and "Outer".
                            "fillNAMethod": "str",  # Optional. An optional field,
                              indicating how missing values will be filled. One of Previous,
                              Subsequent, Linear, Zero, Fixed. Known values are: "Previous",
                              "Subsequent", "Linear", "Zero", and "Fixed".
                            "paddingValue": 0.0  # Optional. An optional field. Required
                              when fillNAMethod is Fixed.
                        },
                        "dataSchema": "str",  # Optional. Data schema of input data source:
                          OneTable or MultiTable. The default DataSchema is OneTable. Known values are:
                          "OneTable" and "MultiTable".
                        "diagnosticsInfo": {
                            "modelState": {
                                "epochIds": [
                                    0  # Optional. This indicates the number of
                                      passes of the entire training dataset the algorithm has
                                      completed.
                                ],
                                "latenciesInSeconds": [
                                    0.0  # Optional. Latency for each epoch.
                                ],
                                "trainLosses": [
                                    0.0  # Optional. List of metrics used to
                                      assess how the model fits the training data for each epoch.
                                ],
                                "validationLosses": [
                                    0.0  # Optional. List of metrics used to
                                      assess how the model fits the validation set for each epoch.
                                ]
                            },
                            "variableStates": [
                                {
                                    "effectiveCount": 0,  # Optional. Number of
                                      effective data points before applying fillNAMethod.
                                    "filledNARatio": 0.0,  # Optional. Proportion
                                      of missing values that need to be filled by fillNAMethod.
                                    "firstTimestamp": "2020-02-20 00:00:00",  #
                                      Optional. First valid timestamp with value of input data.
                                    "lastTimestamp": "2020-02-20 00:00:00",  #
                                      Optional. Last valid timestamp with value of input data.
                                    "variable": "str"  # Optional. Variable name
                                      in variable states.
                                }
                            ]
                        },
                        "displayName": "str",  # Optional. An optional field. The display
                          name of the model whose maximum length is 24 characters.
                        "errors": [
                            {
                                "code": "str",  # The error code. Required.
                                "message": "str"  # The message explaining the error
                                  reported by the service. Required.
                            }
                        ],
                        "slidingWindow": 0,  # Optional. An optional field, indicating how
                          many previous timestamps will be used to detect whether the timestamp is
                          anomaly or not.
                        "status": "str"  # Optional. Model status. One of CREATED, RUNNING,
                          READY, and FAILED. Known values are: "CREATED", "RUNNING", "READY", and
                          "FAILED".
                    }
                }
        """

    @overload
    def create_multivariate_model(self, body: IO, *, content_type: str = "application/json", **kwargs: Any) -> JSON:
        """Train a Multivariate Anomaly Detection Model.

        Create and train a multivariate anomaly detection model. The request must include a source
        parameter to indicate an externally accessible Azure blob storage URI.There are two types of
        data input: An URI pointed to an Azure blob storage folder which contains multiple CSV files,
        and each CSV file contains two columns, timestamp and variable. Another type of input is an URI
        pointed to a CSV file in Azure blob storage, which contains all the variables and a timestamp
        column.

        :param body: Training request. Required.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 201
                response == {
                    "createdTime": "2020-02-20 00:00:00",  # Date and time (UTC) when the model
                      was created. Required.
                    "lastUpdatedTime": "2020-02-20 00:00:00",  # Date and time (UTC) when the
                      model was last updated. Required.
                    "modelId": "str",  # Model identifier. Required.
                    "modelInfo": {
                        "dataSource": "str",  # Source link to the input data to indicate an
                          accessible Azure storage Uri, either pointed to an Azure blob storage folder,
                          or pointed to a CSV file in Azure blob storage based on you data schema
                          selection. Required.
                        "endTime": "2020-02-20 00:00:00",  # A required field, indicating the
                          end time of training data, which should be date-time of ISO 8601 format.
                          Required.
                        "startTime": "2020-02-20 00:00:00",  # A required field, indicating
                          the start time of training data, which should be date-time of ISO 8601
                          format. Required.
                        "alignPolicy": {
                            "alignMode": "str",  # Optional. An optional field,
                              indicating how to align different variables to the same time-range.
                              Either Inner or Outer. Known values are: "Inner" and "Outer".
                            "fillNAMethod": "str",  # Optional. An optional field,
                              indicating how missing values will be filled. One of Previous,
                              Subsequent, Linear, Zero, Fixed. Known values are: "Previous",
                              "Subsequent", "Linear", "Zero", and "Fixed".
                            "paddingValue": 0.0  # Optional. An optional field. Required
                              when fillNAMethod is Fixed.
                        },
                        "dataSchema": "str",  # Optional. Data schema of input data source:
                          OneTable or MultiTable. The default DataSchema is OneTable. Known values are:
                          "OneTable" and "MultiTable".
                        "diagnosticsInfo": {
                            "modelState": {
                                "epochIds": [
                                    0  # Optional. This indicates the number of
                                      passes of the entire training dataset the algorithm has
                                      completed.
                                ],
                                "latenciesInSeconds": [
                                    0.0  # Optional. Latency for each epoch.
                                ],
                                "trainLosses": [
                                    0.0  # Optional. List of metrics used to
                                      assess how the model fits the training data for each epoch.
                                ],
                                "validationLosses": [
                                    0.0  # Optional. List of metrics used to
                                      assess how the model fits the validation set for each epoch.
                                ]
                            },
                            "variableStates": [
                                {
                                    "effectiveCount": 0,  # Optional. Number of
                                      effective data points before applying fillNAMethod.
                                    "filledNARatio": 0.0,  # Optional. Proportion
                                      of missing values that need to be filled by fillNAMethod.
                                    "firstTimestamp": "2020-02-20 00:00:00",  #
                                      Optional. First valid timestamp with value of input data.
                                    "lastTimestamp": "2020-02-20 00:00:00",  #
                                      Optional. Last valid timestamp with value of input data.
                                    "variable": "str"  # Optional. Variable name
                                      in variable states.
                                }
                            ]
                        },
                        "displayName": "str",  # Optional. An optional field. The display
                          name of the model whose maximum length is 24 characters.
                        "errors": [
                            {
                                "code": "str",  # The error code. Required.
                                "message": "str"  # The message explaining the error
                                  reported by the service. Required.
                            }
                        ],
                        "slidingWindow": 0,  # Optional. An optional field, indicating how
                          many previous timestamps will be used to detect whether the timestamp is
                          anomaly or not.
                        "status": "str"  # Optional. Model status. One of CREATED, RUNNING,
                          READY, and FAILED. Known values are: "CREATED", "RUNNING", "READY", and
                          "FAILED".
                    }
                }
        """

    @distributed_trace
    def create_multivariate_model(self, body: Union[JSON, IO], **kwargs: Any) -> JSON:
        """Train a Multivariate Anomaly Detection Model.

        Create and train a multivariate anomaly detection model. The request must include a source
        parameter to indicate an externally accessible Azure blob storage URI.There are two types of
        data input: An URI pointed to an Azure blob storage folder which contains multiple CSV files,
        and each CSV file contains two columns, timestamp and variable. Another type of input is an URI
        pointed to a CSV file in Azure blob storage, which contains all the variables and a timestamp
        column.

        :param body: Training request. Is either a model type or a IO type. Required.
        :type body: JSON or IO
        :keyword content_type: Body Parameter content-type. Known values are: 'application/json'.
         Default value is None.
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 201
                response == {
                    "createdTime": "2020-02-20 00:00:00",  # Date and time (UTC) when the model
                      was created. Required.
                    "lastUpdatedTime": "2020-02-20 00:00:00",  # Date and time (UTC) when the
                      model was last updated. Required.
                    "modelId": "str",  # Model identifier. Required.
                    "modelInfo": {
                        "dataSource": "str",  # Source link to the input data to indicate an
                          accessible Azure storage Uri, either pointed to an Azure blob storage folder,
                          or pointed to a CSV file in Azure blob storage based on you data schema
                          selection. Required.
                        "endTime": "2020-02-20 00:00:00",  # A required field, indicating the
                          end time of training data, which should be date-time of ISO 8601 format.
                          Required.
                        "startTime": "2020-02-20 00:00:00",  # A required field, indicating
                          the start time of training data, which should be date-time of ISO 8601
                          format. Required.
                        "alignPolicy": {
                            "alignMode": "str",  # Optional. An optional field,
                              indicating how to align different variables to the same time-range.
                              Either Inner or Outer. Known values are: "Inner" and "Outer".
                            "fillNAMethod": "str",  # Optional. An optional field,
                              indicating how missing values will be filled. One of Previous,
                              Subsequent, Linear, Zero, Fixed. Known values are: "Previous",
                              "Subsequent", "Linear", "Zero", and "Fixed".
                            "paddingValue": 0.0  # Optional. An optional field. Required
                              when fillNAMethod is Fixed.
                        },
                        "dataSchema": "str",  # Optional. Data schema of input data source:
                          OneTable or MultiTable. The default DataSchema is OneTable. Known values are:
                          "OneTable" and "MultiTable".
                        "diagnosticsInfo": {
                            "modelState": {
                                "epochIds": [
                                    0  # Optional. This indicates the number of
                                      passes of the entire training dataset the algorithm has
                                      completed.
                                ],
                                "latenciesInSeconds": [
                                    0.0  # Optional. Latency for each epoch.
                                ],
                                "trainLosses": [
                                    0.0  # Optional. List of metrics used to
                                      assess how the model fits the training data for each epoch.
                                ],
                                "validationLosses": [
                                    0.0  # Optional. List of metrics used to
                                      assess how the model fits the validation set for each epoch.
                                ]
                            },
                            "variableStates": [
                                {
                                    "effectiveCount": 0,  # Optional. Number of
                                      effective data points before applying fillNAMethod.
                                    "filledNARatio": 0.0,  # Optional. Proportion
                                      of missing values that need to be filled by fillNAMethod.
                                    "firstTimestamp": "2020-02-20 00:00:00",  #
                                      Optional. First valid timestamp with value of input data.
                                    "lastTimestamp": "2020-02-20 00:00:00",  #
                                      Optional. Last valid timestamp with value of input data.
                                    "variable": "str"  # Optional. Variable name
                                      in variable states.
                                }
                            ]
                        },
                        "displayName": "str",  # Optional. An optional field. The display
                          name of the model whose maximum length is 24 characters.
                        "errors": [
                            {
                                "code": "str",  # The error code. Required.
                                "message": "str"  # The message explaining the error
                                  reported by the service. Required.
                            }
                        ],
                        "slidingWindow": 0,  # Optional. An optional field, indicating how
                          many previous timestamps will be used to detect whether the timestamp is
                          anomaly or not.
                        "status": "str"  # Optional. Model status. One of CREATED, RUNNING,
                          READY, and FAILED. Known values are: "CREATED", "RUNNING", "READY", and
                          "FAILED".
                    }
                }
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
        cls = kwargs.pop("cls", None)  # type: ClsType[JSON]

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            _json = body

        request = build_create_multivariate_model_request(
            content_type=content_type,
            json=_json,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [201]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))

        if response.content:
            deserialized = response.json()
        else:
            deserialized = None

        if cls:
            return cls(pipeline_response, cast(JSON, deserialized), response_headers)

        return cast(JSON, deserialized)

    @distributed_trace
    def list_multivariate_model(self, *, skip: int = 0, top: Optional[int] = None, **kwargs: Any) -> Iterable[JSON]:
        """List Multivariate Models.

        List models of a resource.

        :keyword skip: Skip indicates how many models will be skipped. Default value is 0.
        :paramtype skip: int
        :keyword top: Top indicates how many models will be fetched. Default value is None.
        :paramtype top: int
        :return: An iterator like instance of JSON object
        :rtype: ~azure.core.paging.ItemPaged[JSON]
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "createdTime": "2020-02-20 00:00:00",  # Date and time (UTC) when the model
                      was created. Required.
                    "lastUpdatedTime": "2020-02-20 00:00:00",  # Date and time (UTC) when the
                      model was last updated. Required.
                    "modelId": "str",  # Model identifier. Required.
                    "modelInfo": {
                        "dataSource": "str",  # Source link to the input data to indicate an
                          accessible Azure storage Uri, either pointed to an Azure blob storage folder,
                          or pointed to a CSV file in Azure blob storage based on you data schema
                          selection. Required.
                        "endTime": "2020-02-20 00:00:00",  # A required field, indicating the
                          end time of training data, which should be date-time of ISO 8601 format.
                          Required.
                        "startTime": "2020-02-20 00:00:00",  # A required field, indicating
                          the start time of training data, which should be date-time of ISO 8601
                          format. Required.
                        "alignPolicy": {
                            "alignMode": "str",  # Optional. An optional field,
                              indicating how to align different variables to the same time-range.
                              Either Inner or Outer. Known values are: "Inner" and "Outer".
                            "fillNAMethod": "str",  # Optional. An optional field,
                              indicating how missing values will be filled. One of Previous,
                              Subsequent, Linear, Zero, Fixed. Known values are: "Previous",
                              "Subsequent", "Linear", "Zero", and "Fixed".
                            "paddingValue": 0.0  # Optional. An optional field. Required
                              when fillNAMethod is Fixed.
                        },
                        "dataSchema": "str",  # Optional. Data schema of input data source:
                          OneTable or MultiTable. The default DataSchema is OneTable. Known values are:
                          "OneTable" and "MultiTable".
                        "diagnosticsInfo": {
                            "modelState": {
                                "epochIds": [
                                    0  # Optional. This indicates the number of
                                      passes of the entire training dataset the algorithm has
                                      completed.
                                ],
                                "latenciesInSeconds": [
                                    0.0  # Optional. Latency for each epoch.
                                ],
                                "trainLosses": [
                                    0.0  # Optional. List of metrics used to
                                      assess how the model fits the training data for each epoch.
                                ],
                                "validationLosses": [
                                    0.0  # Optional. List of metrics used to
                                      assess how the model fits the validation set for each epoch.
                                ]
                            },
                            "variableStates": [
                                {
                                    "effectiveCount": 0,  # Optional. Number of
                                      effective data points before applying fillNAMethod.
                                    "filledNARatio": 0.0,  # Optional. Proportion
                                      of missing values that need to be filled by fillNAMethod.
                                    "firstTimestamp": "2020-02-20 00:00:00",  #
                                      Optional. First valid timestamp with value of input data.
                                    "lastTimestamp": "2020-02-20 00:00:00",  #
                                      Optional. Last valid timestamp with value of input data.
                                    "variable": "str"  # Optional. Variable name
                                      in variable states.
                                }
                            ]
                        },
                        "displayName": "str",  # Optional. An optional field. The display
                          name of the model whose maximum length is 24 characters.
                        "errors": [
                            {
                                "code": "str",  # The error code. Required.
                                "message": "str"  # The message explaining the error
                                  reported by the service. Required.
                            }
                        ],
                        "slidingWindow": 0,  # Optional. An optional field, indicating how
                          many previous timestamps will be used to detect whether the timestamp is
                          anomaly or not.
                        "status": "str"  # Optional. Model status. One of CREATED, RUNNING,
                          READY, and FAILED. Known values are: "CREATED", "RUNNING", "READY", and
                          "FAILED".
                    }
                }
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls = kwargs.pop("cls", None)  # type: ClsType[JSON]

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_list_multivariate_model_request(
                    skip=skip,
                    top=top,
                    headers=_headers,
                    params=_params,
                )
                request.url = self._client.format_url(request.url)  # type: ignore

            else:
                request = HttpRequest("GET", next_link)
                request.url = self._client.format_url(request.url)  # type: ignore

            return request

        def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = deserialized["models"]
            if cls:
                list_of_elem = cls(list_of_elem)
            return deserialized.get("nextLink", None), iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                request, stream=False, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                raise HttpResponseError(response=response)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @distributed_trace
    def delete_multivariate_model(  # pylint: disable=inconsistent-return-statements
        self, model_id: str, **kwargs: Any
    ) -> None:
        """Delete Multivariate Model.

        Delete an existing multivariate model according to the modelId.

        :param model_id: Model identifier. Required.
        :type model_id: str
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls = kwargs.pop("cls", None)  # type: ClsType[None]

        request = build_delete_multivariate_model_request(
            model_id=model_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [204]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if cls:
            return cls(pipeline_response, None, {})

    @distributed_trace
    def get_multivariate_model(self, model_id: str, **kwargs: Any) -> JSON:
        """Get Multivariate Model.

        Get detailed information of multivariate model, including the training status and variables
        used in the model.

        :param model_id: Model identifier. Required.
        :type model_id: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "createdTime": "2020-02-20 00:00:00",  # Date and time (UTC) when the model
                      was created. Required.
                    "lastUpdatedTime": "2020-02-20 00:00:00",  # Date and time (UTC) when the
                      model was last updated. Required.
                    "modelId": "str",  # Model identifier. Required.
                    "modelInfo": {
                        "dataSource": "str",  # Source link to the input data to indicate an
                          accessible Azure storage Uri, either pointed to an Azure blob storage folder,
                          or pointed to a CSV file in Azure blob storage based on you data schema
                          selection. Required.
                        "endTime": "2020-02-20 00:00:00",  # A required field, indicating the
                          end time of training data, which should be date-time of ISO 8601 format.
                          Required.
                        "startTime": "2020-02-20 00:00:00",  # A required field, indicating
                          the start time of training data, which should be date-time of ISO 8601
                          format. Required.
                        "alignPolicy": {
                            "alignMode": "str",  # Optional. An optional field,
                              indicating how to align different variables to the same time-range.
                              Either Inner or Outer. Known values are: "Inner" and "Outer".
                            "fillNAMethod": "str",  # Optional. An optional field,
                              indicating how missing values will be filled. One of Previous,
                              Subsequent, Linear, Zero, Fixed. Known values are: "Previous",
                              "Subsequent", "Linear", "Zero", and "Fixed".
                            "paddingValue": 0.0  # Optional. An optional field. Required
                              when fillNAMethod is Fixed.
                        },
                        "dataSchema": "str",  # Optional. Data schema of input data source:
                          OneTable or MultiTable. The default DataSchema is OneTable. Known values are:
                          "OneTable" and "MultiTable".
                        "diagnosticsInfo": {
                            "modelState": {
                                "epochIds": [
                                    0  # Optional. This indicates the number of
                                      passes of the entire training dataset the algorithm has
                                      completed.
                                ],
                                "latenciesInSeconds": [
                                    0.0  # Optional. Latency for each epoch.
                                ],
                                "trainLosses": [
                                    0.0  # Optional. List of metrics used to
                                      assess how the model fits the training data for each epoch.
                                ],
                                "validationLosses": [
                                    0.0  # Optional. List of metrics used to
                                      assess how the model fits the validation set for each epoch.
                                ]
                            },
                            "variableStates": [
                                {
                                    "effectiveCount": 0,  # Optional. Number of
                                      effective data points before applying fillNAMethod.
                                    "filledNARatio": 0.0,  # Optional. Proportion
                                      of missing values that need to be filled by fillNAMethod.
                                    "firstTimestamp": "2020-02-20 00:00:00",  #
                                      Optional. First valid timestamp with value of input data.
                                    "lastTimestamp": "2020-02-20 00:00:00",  #
                                      Optional. Last valid timestamp with value of input data.
                                    "variable": "str"  # Optional. Variable name
                                      in variable states.
                                }
                            ]
                        },
                        "displayName": "str",  # Optional. An optional field. The display
                          name of the model whose maximum length is 24 characters.
                        "errors": [
                            {
                                "code": "str",  # The error code. Required.
                                "message": "str"  # The message explaining the error
                                  reported by the service. Required.
                            }
                        ],
                        "slidingWindow": 0,  # Optional. An optional field, indicating how
                          many previous timestamps will be used to detect whether the timestamp is
                          anomaly or not.
                        "status": "str"  # Optional. Model status. One of CREATED, RUNNING,
                          READY, and FAILED. Known values are: "CREATED", "RUNNING", "READY", and
                          "FAILED".
                    }
                }
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls = kwargs.pop("cls", None)  # type: ClsType[JSON]

        request = build_get_multivariate_model_request(
            model_id=model_id,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if response.content:
            deserialized = response.json()
        else:
            deserialized = None

        if cls:
            return cls(pipeline_response, cast(JSON, deserialized), {})

        return cast(JSON, deserialized)

    @overload
    def batch_detect_anomaly(
        self, model_id: str, body: JSON, *, content_type: str = "application/json", **kwargs: Any
    ) -> JSON:
        """Detect Multivariate Anomaly.

        Submit multivariate anomaly detection task with the modelId of trained model and inference
        data, the input schema should be the same with the training request. The request will complete
        asynchronously and return a resultId to query the detection result.The request should be a
        source link to indicate an externally accessible Azure storage Uri, either pointed to an Azure
        blob storage folder, or pointed to a CSV file in Azure blob storage.

        :param model_id: Model identifier. Required.
        :type model_id: str
        :param body: Detect anomaly request. Required.
        :type body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                body = {
                    "dataSource": "str",  # Source link to the input data to indicate an
                      accessible Azure storage Uri, either pointed to an Azure blob storage folder, or
                      pointed to a CSV file in Azure blob storage based on you data schema selection.
                      The data schema should be exactly the same with those used in the training phase.
                      Required.
                    "endTime": "2020-02-20 00:00:00",  # A required field, indicating the end
                      time of data for detection, which should be date-time of ISO 8601 format.
                      Required.
                    "startTime": "2020-02-20 00:00:00",  # A required field, indicating the start
                      time of data for detection, which should be date-time of ISO 8601 format.
                      Required.
                    "topContributorCount": 0  # An optional field, which is used to specify the
                      number of top contributed variables for one anomalous timestamp in the response.
                      The default number is 10. Required.
                }

                # response body for status code(s): 202
                response == {
                    "resultId": "str",  # Result identifier, which is used to fetch the results
                      of an inference call. Required.
                    "results": [
                        {
                            "timestamp": "2020-02-20 00:00:00",  # The timestamp for this
                              anomaly. Required.
                            "errors": [
                                {
                                    "code": "str",  # The error code. Required.
                                    "message": "str"  # The message explaining
                                      the error reported by the service. Required.
                                }
                            ],
                            "value": {
                                "isAnomaly": bool,  # True if an anomaly is detected
                                  at the current timestamp. Required.
                                "score": 0.0,  # Raw anomaly score of severity, will
                                  help indicate the degree of abnormality as well. Required.
                                "severity": 0.0,  # Indicates the significance of the
                                  anomaly. The higher the severity, the more significant the anomaly
                                  is. Required.
                                "interpretation": [
                                    {
                                        "contributionScore": 0.0,  #
                                          Optional. This score shows the percentage contributing to the
                                          anomalous timestamp. A number between 0 and 1.
                                        "correlationChanges": {
                                            "changedVariables": [
                                                "str"  # Optional.
                                                  The correlated variables that have correlation
                                                  changes under an anomaly.
                                            ]
                                        },
                                        "variable": "str"  # Optional.
                                          Variable.
                                    }
                                ]
                            }
                        }
                    ],
                    "summary": {
                        "setupInfo": {
                            "dataSource": "str",  # Source link to the input data to
                              indicate an accessible Azure storage Uri, either pointed to an Azure blob
                              storage folder, or pointed to a CSV file in Azure blob storage based on
                              you data schema selection. The data schema should be exactly the same
                              with those used in the training phase. Required.
                            "endTime": "2020-02-20 00:00:00",  # A required field,
                              indicating the end time of data for detection, which should be date-time
                              of ISO 8601 format. Required.
                            "startTime": "2020-02-20 00:00:00",  # A required field,
                              indicating the start time of data for detection, which should be
                              date-time of ISO 8601 format. Required.
                            "topContributorCount": 0  # An optional field, which is used
                              to specify the number of top contributed variables for one anomalous
                              timestamp in the response. The default number is 10. Required.
                        },
                        "status": "str",  # Status of detection results. One of CREATED,
                          RUNNING, READY, and FAILED. Required. Known values are: "CREATED", "RUNNING",
                          "READY", and "FAILED".
                        "errors": [
                            {
                                "code": "str",  # The error code. Required.
                                "message": "str"  # The message explaining the error
                                  reported by the service. Required.
                            }
                        ],
                        "variableStates": [
                            {
                                "effectiveCount": 0,  # Optional. Number of effective
                                  data points before applying fillNAMethod.
                                "filledNARatio": 0.0,  # Optional. Proportion of
                                  missing values that need to be filled by fillNAMethod.
                                "firstTimestamp": "2020-02-20 00:00:00",  # Optional.
                                  First valid timestamp with value of input data.
                                "lastTimestamp": "2020-02-20 00:00:00",  # Optional.
                                  Last valid timestamp with value of input data.
                                "variable": "str"  # Optional. Variable name in
                                  variable states.
                            }
                        ]
                    }
                }
        """

    @overload
    def batch_detect_anomaly(
        self, model_id: str, body: IO, *, content_type: str = "application/json", **kwargs: Any
    ) -> JSON:
        """Detect Multivariate Anomaly.

        Submit multivariate anomaly detection task with the modelId of trained model and inference
        data, the input schema should be the same with the training request. The request will complete
        asynchronously and return a resultId to query the detection result.The request should be a
        source link to indicate an externally accessible Azure storage Uri, either pointed to an Azure
        blob storage folder, or pointed to a CSV file in Azure blob storage.

        :param model_id: Model identifier. Required.
        :type model_id: str
        :param body: Detect anomaly request. Required.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 202
                response == {
                    "resultId": "str",  # Result identifier, which is used to fetch the results
                      of an inference call. Required.
                    "results": [
                        {
                            "timestamp": "2020-02-20 00:00:00",  # The timestamp for this
                              anomaly. Required.
                            "errors": [
                                {
                                    "code": "str",  # The error code. Required.
                                    "message": "str"  # The message explaining
                                      the error reported by the service. Required.
                                }
                            ],
                            "value": {
                                "isAnomaly": bool,  # True if an anomaly is detected
                                  at the current timestamp. Required.
                                "score": 0.0,  # Raw anomaly score of severity, will
                                  help indicate the degree of abnormality as well. Required.
                                "severity": 0.0,  # Indicates the significance of the
                                  anomaly. The higher the severity, the more significant the anomaly
                                  is. Required.
                                "interpretation": [
                                    {
                                        "contributionScore": 0.0,  #
                                          Optional. This score shows the percentage contributing to the
                                          anomalous timestamp. A number between 0 and 1.
                                        "correlationChanges": {
                                            "changedVariables": [
                                                "str"  # Optional.
                                                  The correlated variables that have correlation
                                                  changes under an anomaly.
                                            ]
                                        },
                                        "variable": "str"  # Optional.
                                          Variable.
                                    }
                                ]
                            }
                        }
                    ],
                    "summary": {
                        "setupInfo": {
                            "dataSource": "str",  # Source link to the input data to
                              indicate an accessible Azure storage Uri, either pointed to an Azure blob
                              storage folder, or pointed to a CSV file in Azure blob storage based on
                              you data schema selection. The data schema should be exactly the same
                              with those used in the training phase. Required.
                            "endTime": "2020-02-20 00:00:00",  # A required field,
                              indicating the end time of data for detection, which should be date-time
                              of ISO 8601 format. Required.
                            "startTime": "2020-02-20 00:00:00",  # A required field,
                              indicating the start time of data for detection, which should be
                              date-time of ISO 8601 format. Required.
                            "topContributorCount": 0  # An optional field, which is used
                              to specify the number of top contributed variables for one anomalous
                              timestamp in the response. The default number is 10. Required.
                        },
                        "status": "str",  # Status of detection results. One of CREATED,
                          RUNNING, READY, and FAILED. Required. Known values are: "CREATED", "RUNNING",
                          "READY", and "FAILED".
                        "errors": [
                            {
                                "code": "str",  # The error code. Required.
                                "message": "str"  # The message explaining the error
                                  reported by the service. Required.
                            }
                        ],
                        "variableStates": [
                            {
                                "effectiveCount": 0,  # Optional. Number of effective
                                  data points before applying fillNAMethod.
                                "filledNARatio": 0.0,  # Optional. Proportion of
                                  missing values that need to be filled by fillNAMethod.
                                "firstTimestamp": "2020-02-20 00:00:00",  # Optional.
                                  First valid timestamp with value of input data.
                                "lastTimestamp": "2020-02-20 00:00:00",  # Optional.
                                  Last valid timestamp with value of input data.
                                "variable": "str"  # Optional. Variable name in
                                  variable states.
                            }
                        ]
                    }
                }
        """

    @distributed_trace
    def batch_detect_anomaly(self, model_id: str, body: Union[JSON, IO], **kwargs: Any) -> JSON:
        """Detect Multivariate Anomaly.

        Submit multivariate anomaly detection task with the modelId of trained model and inference
        data, the input schema should be the same with the training request. The request will complete
        asynchronously and return a resultId to query the detection result.The request should be a
        source link to indicate an externally accessible Azure storage Uri, either pointed to an Azure
        blob storage folder, or pointed to a CSV file in Azure blob storage.

        :param model_id: Model identifier. Required.
        :type model_id: str
        :param body: Detect anomaly request. Is either a model type or a IO type. Required.
        :type body: JSON or IO
        :keyword content_type: Body Parameter content-type. Known values are: 'application/json'.
         Default value is None.
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 202
                response == {
                    "resultId": "str",  # Result identifier, which is used to fetch the results
                      of an inference call. Required.
                    "results": [
                        {
                            "timestamp": "2020-02-20 00:00:00",  # The timestamp for this
                              anomaly. Required.
                            "errors": [
                                {
                                    "code": "str",  # The error code. Required.
                                    "message": "str"  # The message explaining
                                      the error reported by the service. Required.
                                }
                            ],
                            "value": {
                                "isAnomaly": bool,  # True if an anomaly is detected
                                  at the current timestamp. Required.
                                "score": 0.0,  # Raw anomaly score of severity, will
                                  help indicate the degree of abnormality as well. Required.
                                "severity": 0.0,  # Indicates the significance of the
                                  anomaly. The higher the severity, the more significant the anomaly
                                  is. Required.
                                "interpretation": [
                                    {
                                        "contributionScore": 0.0,  #
                                          Optional. This score shows the percentage contributing to the
                                          anomalous timestamp. A number between 0 and 1.
                                        "correlationChanges": {
                                            "changedVariables": [
                                                "str"  # Optional.
                                                  The correlated variables that have correlation
                                                  changes under an anomaly.
                                            ]
                                        },
                                        "variable": "str"  # Optional.
                                          Variable.
                                    }
                                ]
                            }
                        }
                    ],
                    "summary": {
                        "setupInfo": {
                            "dataSource": "str",  # Source link to the input data to
                              indicate an accessible Azure storage Uri, either pointed to an Azure blob
                              storage folder, or pointed to a CSV file in Azure blob storage based on
                              you data schema selection. The data schema should be exactly the same
                              with those used in the training phase. Required.
                            "endTime": "2020-02-20 00:00:00",  # A required field,
                              indicating the end time of data for detection, which should be date-time
                              of ISO 8601 format. Required.
                            "startTime": "2020-02-20 00:00:00",  # A required field,
                              indicating the start time of data for detection, which should be
                              date-time of ISO 8601 format. Required.
                            "topContributorCount": 0  # An optional field, which is used
                              to specify the number of top contributed variables for one anomalous
                              timestamp in the response. The default number is 10. Required.
                        },
                        "status": "str",  # Status of detection results. One of CREATED,
                          RUNNING, READY, and FAILED. Required. Known values are: "CREATED", "RUNNING",
                          "READY", and "FAILED".
                        "errors": [
                            {
                                "code": "str",  # The error code. Required.
                                "message": "str"  # The message explaining the error
                                  reported by the service. Required.
                            }
                        ],
                        "variableStates": [
                            {
                                "effectiveCount": 0,  # Optional. Number of effective
                                  data points before applying fillNAMethod.
                                "filledNARatio": 0.0,  # Optional. Proportion of
                                  missing values that need to be filled by fillNAMethod.
                                "firstTimestamp": "2020-02-20 00:00:00",  # Optional.
                                  First valid timestamp with value of input data.
                                "lastTimestamp": "2020-02-20 00:00:00",  # Optional.
                                  Last valid timestamp with value of input data.
                                "variable": "str"  # Optional. Variable name in
                                  variable states.
                            }
                        ]
                    }
                }
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
        cls = kwargs.pop("cls", None)  # type: ClsType[JSON]

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            _json = body

        request = build_batch_detect_anomaly_request(
            model_id=model_id,
            content_type=content_type,
            json=_json,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        response_headers = {}
        response_headers["Operation-Location"] = self._deserialize("str", response.headers.get("Operation-Location"))
        response_headers["Operation-Id"] = self._deserialize("str", response.headers.get("Operation-Id"))

        if response.content:
            deserialized = response.json()
        else:
            deserialized = None

        if cls:
            return cls(pipeline_response, cast(JSON, deserialized), response_headers)

        return cast(JSON, deserialized)

    @overload
    def last_detect_anomaly(
        self, model_id: str, body: JSON, *, content_type: str = "application/json", **kwargs: Any
    ) -> JSON:
        """Detect anomalies in the last point of the request body.

        Submit multivariate anomaly detection task with the modelId of trained model and inference
        data, and the inference data should be put into request body in a JSON format. The request will
        complete synchronously and return the detection immediately in the response body.

        :param model_id: Model identifier. Required.
        :type model_id: str
        :param body: Request for last detection. Required.
        :type body: JSON
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # JSON input template you can fill out and use as your body input.
                body = {
                    "topContributorCount": 0,  # An optional field, which is used to specify the
                      number of top contributed variables for one anomalous timestamp in the response.
                      The default number is 10. Required.
                    "variables": [
                        {
                            "timestamps": [
                                "str"  # Timestamps of last detection request.
                                  Required.
                            ],
                            "values": [
                                0.0  # Values of variables. Required.
                            ],
                            "variable": "str"  # Variable name of last detection request.
                              Required.
                        }
                    ]
                }

                # response body for status code(s): 200
                response == {
                    "results": [
                        {
                            "timestamp": "2020-02-20 00:00:00",  # The timestamp for this
                              anomaly. Required.
                            "errors": [
                                {
                                    "code": "str",  # The error code. Required.
                                    "message": "str"  # The message explaining
                                      the error reported by the service. Required.
                                }
                            ],
                            "value": {
                                "isAnomaly": bool,  # True if an anomaly is detected
                                  at the current timestamp. Required.
                                "score": 0.0,  # Raw anomaly score of severity, will
                                  help indicate the degree of abnormality as well. Required.
                                "severity": 0.0,  # Indicates the significance of the
                                  anomaly. The higher the severity, the more significant the anomaly
                                  is. Required.
                                "interpretation": [
                                    {
                                        "contributionScore": 0.0,  #
                                          Optional. This score shows the percentage contributing to the
                                          anomalous timestamp. A number between 0 and 1.
                                        "correlationChanges": {
                                            "changedVariables": [
                                                "str"  # Optional.
                                                  The correlated variables that have correlation
                                                  changes under an anomaly.
                                            ]
                                        },
                                        "variable": "str"  # Optional.
                                          Variable.
                                    }
                                ]
                            }
                        }
                    ],
                    "variableStates": [
                        {
                            "effectiveCount": 0,  # Optional. Number of effective data
                              points before applying fillNAMethod.
                            "filledNARatio": 0.0,  # Optional. Proportion of missing
                              values that need to be filled by fillNAMethod.
                            "firstTimestamp": "2020-02-20 00:00:00",  # Optional. First
                              valid timestamp with value of input data.
                            "lastTimestamp": "2020-02-20 00:00:00",  # Optional. Last
                              valid timestamp with value of input data.
                            "variable": "str"  # Optional. Variable name in variable
                              states.
                        }
                    ]
                }
        """

    @overload
    def last_detect_anomaly(
        self, model_id: str, body: IO, *, content_type: str = "application/json", **kwargs: Any
    ) -> JSON:
        """Detect anomalies in the last point of the request body.

        Submit multivariate anomaly detection task with the modelId of trained model and inference
        data, and the inference data should be put into request body in a JSON format. The request will
        complete synchronously and return the detection immediately in the response body.

        :param model_id: Model identifier. Required.
        :type model_id: str
        :param body: Request for last detection. Required.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "results": [
                        {
                            "timestamp": "2020-02-20 00:00:00",  # The timestamp for this
                              anomaly. Required.
                            "errors": [
                                {
                                    "code": "str",  # The error code. Required.
                                    "message": "str"  # The message explaining
                                      the error reported by the service. Required.
                                }
                            ],
                            "value": {
                                "isAnomaly": bool,  # True if an anomaly is detected
                                  at the current timestamp. Required.
                                "score": 0.0,  # Raw anomaly score of severity, will
                                  help indicate the degree of abnormality as well. Required.
                                "severity": 0.0,  # Indicates the significance of the
                                  anomaly. The higher the severity, the more significant the anomaly
                                  is. Required.
                                "interpretation": [
                                    {
                                        "contributionScore": 0.0,  #
                                          Optional. This score shows the percentage contributing to the
                                          anomalous timestamp. A number between 0 and 1.
                                        "correlationChanges": {
                                            "changedVariables": [
                                                "str"  # Optional.
                                                  The correlated variables that have correlation
                                                  changes under an anomaly.
                                            ]
                                        },
                                        "variable": "str"  # Optional.
                                          Variable.
                                    }
                                ]
                            }
                        }
                    ],
                    "variableStates": [
                        {
                            "effectiveCount": 0,  # Optional. Number of effective data
                              points before applying fillNAMethod.
                            "filledNARatio": 0.0,  # Optional. Proportion of missing
                              values that need to be filled by fillNAMethod.
                            "firstTimestamp": "2020-02-20 00:00:00",  # Optional. First
                              valid timestamp with value of input data.
                            "lastTimestamp": "2020-02-20 00:00:00",  # Optional. Last
                              valid timestamp with value of input data.
                            "variable": "str"  # Optional. Variable name in variable
                              states.
                        }
                    ]
                }
        """

    @distributed_trace
    def last_detect_anomaly(self, model_id: str, body: Union[JSON, IO], **kwargs: Any) -> JSON:
        """Detect anomalies in the last point of the request body.

        Submit multivariate anomaly detection task with the modelId of trained model and inference
        data, and the inference data should be put into request body in a JSON format. The request will
        complete synchronously and return the detection immediately in the response body.

        :param model_id: Model identifier. Required.
        :type model_id: str
        :param body: Request for last detection. Is either a model type or a IO type. Required.
        :type body: JSON or IO
        :keyword content_type: Body Parameter content-type. Known values are: 'application/json'.
         Default value is None.
        :paramtype content_type: str
        :return: JSON object
        :rtype: JSON
        :raises ~azure.core.exceptions.HttpResponseError:

        Example:
            .. code-block:: python

                # response body for status code(s): 200
                response == {
                    "results": [
                        {
                            "timestamp": "2020-02-20 00:00:00",  # The timestamp for this
                              anomaly. Required.
                            "errors": [
                                {
                                    "code": "str",  # The error code. Required.
                                    "message": "str"  # The message explaining
                                      the error reported by the service. Required.
                                }
                            ],
                            "value": {
                                "isAnomaly": bool,  # True if an anomaly is detected
                                  at the current timestamp. Required.
                                "score": 0.0,  # Raw anomaly score of severity, will
                                  help indicate the degree of abnormality as well. Required.
                                "severity": 0.0,  # Indicates the significance of the
                                  anomaly. The higher the severity, the more significant the anomaly
                                  is. Required.
                                "interpretation": [
                                    {
                                        "contributionScore": 0.0,  #
                                          Optional. This score shows the percentage contributing to the
                                          anomalous timestamp. A number between 0 and 1.
                                        "correlationChanges": {
                                            "changedVariables": [
                                                "str"  # Optional.
                                                  The correlated variables that have correlation
                                                  changes under an anomaly.
                                            ]
                                        },
                                        "variable": "str"  # Optional.
                                          Variable.
                                    }
                                ]
                            }
                        }
                    ],
                    "variableStates": [
                        {
                            "effectiveCount": 0,  # Optional. Number of effective data
                              points before applying fillNAMethod.
                            "filledNARatio": 0.0,  # Optional. Proportion of missing
                              values that need to be filled by fillNAMethod.
                            "firstTimestamp": "2020-02-20 00:00:00",  # Optional. First
                              valid timestamp with value of input data.
                            "lastTimestamp": "2020-02-20 00:00:00",  # Optional. Last
                              valid timestamp with value of input data.
                            "variable": "str"  # Optional. Variable name in variable
                              states.
                        }
                    ]
                }
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type = kwargs.pop("content_type", _headers.pop("Content-Type", None))  # type: Optional[str]
        cls = kwargs.pop("cls", None)  # type: ClsType[JSON]

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            _json = body

        request = build_last_detect_anomaly_request(
            model_id=model_id,
            content_type=content_type,
            json=_json,
            content=_content,
            headers=_headers,
            params=_params,
        )
        request.url = self._client.format_url(request.url)  # type: ignore

        pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request, stream=False, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            raise HttpResponseError(response=response)

        if response.content:
            deserialized = response.json()
        else:
            deserialized = None

        if cls:
            return cls(pipeline_response, cast(JSON, deserialized), {})

        return cast(JSON, deserialized)
