# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------

import datetime
from typing import Any, Dict, List, Optional, Union

import msrest.serialization

from ._data_factory_management_client_enums import *


class AccessPolicyResponse(msrest.serialization.Model):
    """Get Data Plane read only token response definition.

    :ivar policy: The user access policy.
    :vartype policy: ~azure.mgmt.datafactory.models.UserAccessPolicy
    :ivar access_token: Data Plane read only access token.
    :vartype access_token: str
    :ivar data_plane_url: Data Plane service base URL.
    :vartype data_plane_url: str
    """

    _attribute_map = {
        'policy': {'key': 'policy', 'type': 'UserAccessPolicy'},
        'access_token': {'key': 'accessToken', 'type': 'str'},
        'data_plane_url': {'key': 'dataPlaneUrl', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        policy: Optional["UserAccessPolicy"] = None,
        access_token: Optional[str] = None,
        data_plane_url: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword policy: The user access policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.UserAccessPolicy
        :keyword access_token: Data Plane read only access token.
        :paramtype access_token: str
        :keyword data_plane_url: Data Plane service base URL.
        :paramtype data_plane_url: str
        """
        super(AccessPolicyResponse, self).__init__(**kwargs)
        self.policy = policy
        self.access_token = access_token
        self.data_plane_url = data_plane_url


class Activity(msrest.serialization.Model):
    """A pipeline activity.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: ControlActivity, ExecuteWranglingDataflowActivity, ExecutionActivity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
    }

    _subtype_map = {
        'type': {'Container': 'ControlActivity', 'ExecuteWranglingDataflow': 'ExecuteWranglingDataflowActivity', 'Execution': 'ExecutionActivity'}
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        """
        super(Activity, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.name = name
        self.type = 'Activity'  # type: str
        self.description = description
        self.depends_on = depends_on
        self.user_properties = user_properties


class ActivityDependency(msrest.serialization.Model):
    """Activity dependency information.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar activity: Required. Activity name.
    :vartype activity: str
    :ivar dependency_conditions: Required. Match-Condition for the dependency.
    :vartype dependency_conditions: list[str or ~azure.mgmt.datafactory.models.DependencyCondition]
    """

    _validation = {
        'activity': {'required': True},
        'dependency_conditions': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'activity': {'key': 'activity', 'type': 'str'},
        'dependency_conditions': {'key': 'dependencyConditions', 'type': '[str]'},
    }

    def __init__(
        self,
        *,
        activity: str,
        dependency_conditions: List[Union[str, "DependencyCondition"]],
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword activity: Required. Activity name.
        :paramtype activity: str
        :keyword dependency_conditions: Required. Match-Condition for the dependency.
        :paramtype dependency_conditions: list[str or
         ~azure.mgmt.datafactory.models.DependencyCondition]
        """
        super(ActivityDependency, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.activity = activity
        self.dependency_conditions = dependency_conditions


class ActivityPolicy(msrest.serialization.Model):
    """Execution policy for an activity.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar timeout: Specifies the timeout for the activity to run. The default timeout is 7 days.
     Type: string (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype timeout: any
    :ivar retry: Maximum ordinary retry attempts. Default is 0. Type: integer (or Expression with
     resultType integer), minimum: 0.
    :vartype retry: any
    :ivar retry_interval_in_seconds: Interval between each retry attempt (in seconds). The default
     is 30 sec.
    :vartype retry_interval_in_seconds: int
    :ivar secure_input: When set to true, Input from activity is considered as secure and will not
     be logged to monitoring.
    :vartype secure_input: bool
    :ivar secure_output: When set to true, Output from activity is considered as secure and will
     not be logged to monitoring.
    :vartype secure_output: bool
    """

    _validation = {
        'retry_interval_in_seconds': {'maximum': 86400, 'minimum': 30},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'timeout': {'key': 'timeout', 'type': 'object'},
        'retry': {'key': 'retry', 'type': 'object'},
        'retry_interval_in_seconds': {'key': 'retryIntervalInSeconds', 'type': 'int'},
        'secure_input': {'key': 'secureInput', 'type': 'bool'},
        'secure_output': {'key': 'secureOutput', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        timeout: Optional[Any] = None,
        retry: Optional[Any] = None,
        retry_interval_in_seconds: Optional[int] = None,
        secure_input: Optional[bool] = None,
        secure_output: Optional[bool] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword timeout: Specifies the timeout for the activity to run. The default timeout is 7 days.
         Type: string (or Expression with resultType string), pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype timeout: any
        :keyword retry: Maximum ordinary retry attempts. Default is 0. Type: integer (or Expression
         with resultType integer), minimum: 0.
        :paramtype retry: any
        :keyword retry_interval_in_seconds: Interval between each retry attempt (in seconds). The
         default is 30 sec.
        :paramtype retry_interval_in_seconds: int
        :keyword secure_input: When set to true, Input from activity is considered as secure and will
         not be logged to monitoring.
        :paramtype secure_input: bool
        :keyword secure_output: When set to true, Output from activity is considered as secure and will
         not be logged to monitoring.
        :paramtype secure_output: bool
        """
        super(ActivityPolicy, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.timeout = timeout
        self.retry = retry
        self.retry_interval_in_seconds = retry_interval_in_seconds
        self.secure_input = secure_input
        self.secure_output = secure_output


class ActivityRun(msrest.serialization.Model):
    """Information about an activity run in a pipeline.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar pipeline_name: The name of the pipeline.
    :vartype pipeline_name: str
    :ivar pipeline_run_id: The id of the pipeline run.
    :vartype pipeline_run_id: str
    :ivar activity_name: The name of the activity.
    :vartype activity_name: str
    :ivar activity_type: The type of the activity.
    :vartype activity_type: str
    :ivar activity_run_id: The id of the activity run.
    :vartype activity_run_id: str
    :ivar linked_service_name: The name of the compute linked service.
    :vartype linked_service_name: str
    :ivar status: The status of the activity run.
    :vartype status: str
    :ivar activity_run_start: The start time of the activity run in 'ISO 8601' format.
    :vartype activity_run_start: ~datetime.datetime
    :ivar activity_run_end: The end time of the activity run in 'ISO 8601' format.
    :vartype activity_run_end: ~datetime.datetime
    :ivar duration_in_ms: The duration of the activity run.
    :vartype duration_in_ms: int
    :ivar input: The input for the activity.
    :vartype input: any
    :ivar output: The output for the activity.
    :vartype output: any
    :ivar error: The error if any from the activity run.
    :vartype error: any
    """

    _validation = {
        'pipeline_name': {'readonly': True},
        'pipeline_run_id': {'readonly': True},
        'activity_name': {'readonly': True},
        'activity_type': {'readonly': True},
        'activity_run_id': {'readonly': True},
        'linked_service_name': {'readonly': True},
        'status': {'readonly': True},
        'activity_run_start': {'readonly': True},
        'activity_run_end': {'readonly': True},
        'duration_in_ms': {'readonly': True},
        'input': {'readonly': True},
        'output': {'readonly': True},
        'error': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'pipeline_name': {'key': 'pipelineName', 'type': 'str'},
        'pipeline_run_id': {'key': 'pipelineRunId', 'type': 'str'},
        'activity_name': {'key': 'activityName', 'type': 'str'},
        'activity_type': {'key': 'activityType', 'type': 'str'},
        'activity_run_id': {'key': 'activityRunId', 'type': 'str'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'activity_run_start': {'key': 'activityRunStart', 'type': 'iso-8601'},
        'activity_run_end': {'key': 'activityRunEnd', 'type': 'iso-8601'},
        'duration_in_ms': {'key': 'durationInMs', 'type': 'int'},
        'input': {'key': 'input', 'type': 'object'},
        'output': {'key': 'output', 'type': 'object'},
        'error': {'key': 'error', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(ActivityRun, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.pipeline_name = None
        self.pipeline_run_id = None
        self.activity_name = None
        self.activity_type = None
        self.activity_run_id = None
        self.linked_service_name = None
        self.status = None
        self.activity_run_start = None
        self.activity_run_end = None
        self.duration_in_ms = None
        self.input = None
        self.output = None
        self.error = None


class ActivityRunsQueryResponse(msrest.serialization.Model):
    """A list activity runs.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of activity runs.
    :vartype value: list[~azure.mgmt.datafactory.models.ActivityRun]
    :ivar continuation_token: The continuation token for getting the next page of results, if any
     remaining results exist, null otherwise.
    :vartype continuation_token: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[ActivityRun]'},
        'continuation_token': {'key': 'continuationToken', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["ActivityRun"],
        continuation_token: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of activity runs.
        :paramtype value: list[~azure.mgmt.datafactory.models.ActivityRun]
        :keyword continuation_token: The continuation token for getting the next page of results, if
         any remaining results exist, null otherwise.
        :paramtype continuation_token: str
        """
        super(ActivityRunsQueryResponse, self).__init__(**kwargs)
        self.value = value
        self.continuation_token = continuation_token


class AddDataFlowToDebugSessionResponse(msrest.serialization.Model):
    """Response body structure for starting data flow debug session.

    :ivar job_version: The ID of data flow debug job version.
    :vartype job_version: str
    """

    _attribute_map = {
        'job_version': {'key': 'jobVersion', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        job_version: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword job_version: The ID of data flow debug job version.
        :paramtype job_version: str
        """
        super(AddDataFlowToDebugSessionResponse, self).__init__(**kwargs)
        self.job_version = job_version


class AdditionalColumns(msrest.serialization.Model):
    """Specify the column name and value of additional columns.

    :ivar name: Additional column name. Type: string (or Expression with resultType string).
    :vartype name: any
    :ivar value: Additional column value. Type: string (or Expression with resultType string).
    :vartype value: any
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'object'},
        'value': {'key': 'value', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: Optional[Any] = None,
        value: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword name: Additional column name. Type: string (or Expression with resultType string).
        :paramtype name: any
        :keyword value: Additional column value. Type: string (or Expression with resultType string).
        :paramtype value: any
        """
        super(AdditionalColumns, self).__init__(**kwargs)
        self.name = name
        self.value = value


class LinkedService(msrest.serialization.Model):
    """The Azure Data Factory nested object which contains the information and credential which can be used to connect with related store or compute resource.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AmazonMWSLinkedService, AmazonRdsForOracleLinkedService, AmazonRdsForSqlServerLinkedService, AmazonRedshiftLinkedService, AmazonS3LinkedService, AmazonS3CompatibleLinkedService, AppFiguresLinkedService, AsanaLinkedService, AzureBatchLinkedService, AzureBlobFSLinkedService, AzureBlobStorageLinkedService, AzureDataExplorerLinkedService, AzureDataLakeAnalyticsLinkedService, AzureDataLakeStoreLinkedService, AzureDatabricksLinkedService, AzureDatabricksDeltaLakeLinkedService, AzureFileStorageLinkedService, AzureFunctionLinkedService, AzureKeyVaultLinkedService, AzureMLLinkedService, AzureMLServiceLinkedService, AzureMariaDBLinkedService, AzureMySqlLinkedService, AzurePostgreSqlLinkedService, AzureSearchLinkedService, AzureSqlDWLinkedService, AzureSqlDatabaseLinkedService, AzureSqlMILinkedService, AzureStorageLinkedService, AzureTableStorageLinkedService, CassandraLinkedService, CommonDataServiceForAppsLinkedService, ConcurLinkedService, CosmosDbLinkedService, CosmosDbMongoDbApiLinkedService, CouchbaseLinkedService, CustomDataSourceLinkedService, DataworldLinkedService, Db2LinkedService, DrillLinkedService, DynamicsLinkedService, DynamicsAXLinkedService, DynamicsCrmLinkedService, EloquaLinkedService, FileServerLinkedService, FtpServerLinkedService, GoogleAdWordsLinkedService, GoogleBigQueryLinkedService, GoogleCloudStorageLinkedService, GreenplumLinkedService, HBaseLinkedService, HDInsightLinkedService, HDInsightOnDemandLinkedService, HdfsLinkedService, HiveLinkedService, HttpLinkedService, HubspotLinkedService, ImpalaLinkedService, InformixLinkedService, JiraLinkedService, MagentoLinkedService, MariaDBLinkedService, MarketoLinkedService, MicrosoftAccessLinkedService, MongoDbLinkedService, MongoDbAtlasLinkedService, MongoDbV2LinkedService, MySqlLinkedService, NetezzaLinkedService, ODataLinkedService, OdbcLinkedService, Office365LinkedService, OracleLinkedService, OracleCloudStorageLinkedService, OracleServiceCloudLinkedService, PaypalLinkedService, PhoenixLinkedService, PostgreSqlLinkedService, PrestoLinkedService, QuickBooksLinkedService, QuickbaseLinkedService, ResponsysLinkedService, RestServiceLinkedService, SalesforceLinkedService, SalesforceMarketingCloudLinkedService, SalesforceServiceCloudLinkedService, SapBWLinkedService, SapCloudForCustomerLinkedService, SapEccLinkedService, SapHanaLinkedService, SapOpenHubLinkedService, SapTableLinkedService, ServiceNowLinkedService, SftpServerLinkedService, SharePointOnlineListLinkedService, ShopifyLinkedService, SmartsheetLinkedService, SnowflakeLinkedService, SparkLinkedService, SqlServerLinkedService, SquareLinkedService, SybaseLinkedService, TeamDeskLinkedService, TeradataLinkedService, TwilioLinkedService, VerticaLinkedService, WebLinkedService, XeroLinkedService, ZendeskLinkedService, ZohoLinkedService.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
    }

    _subtype_map = {
        'type': {'AmazonMWS': 'AmazonMWSLinkedService', 'AmazonRdsForOracle': 'AmazonRdsForOracleLinkedService', 'AmazonRdsForSqlServer': 'AmazonRdsForSqlServerLinkedService', 'AmazonRedshift': 'AmazonRedshiftLinkedService', 'AmazonS3': 'AmazonS3LinkedService', 'AmazonS3Compatible': 'AmazonS3CompatibleLinkedService', 'AppFigures': 'AppFiguresLinkedService', 'Asana': 'AsanaLinkedService', 'AzureBatch': 'AzureBatchLinkedService', 'AzureBlobFS': 'AzureBlobFSLinkedService', 'AzureBlobStorage': 'AzureBlobStorageLinkedService', 'AzureDataExplorer': 'AzureDataExplorerLinkedService', 'AzureDataLakeAnalytics': 'AzureDataLakeAnalyticsLinkedService', 'AzureDataLakeStore': 'AzureDataLakeStoreLinkedService', 'AzureDatabricks': 'AzureDatabricksLinkedService', 'AzureDatabricksDeltaLake': 'AzureDatabricksDeltaLakeLinkedService', 'AzureFileStorage': 'AzureFileStorageLinkedService', 'AzureFunction': 'AzureFunctionLinkedService', 'AzureKeyVault': 'AzureKeyVaultLinkedService', 'AzureML': 'AzureMLLinkedService', 'AzureMLService': 'AzureMLServiceLinkedService', 'AzureMariaDB': 'AzureMariaDBLinkedService', 'AzureMySql': 'AzureMySqlLinkedService', 'AzurePostgreSql': 'AzurePostgreSqlLinkedService', 'AzureSearch': 'AzureSearchLinkedService', 'AzureSqlDW': 'AzureSqlDWLinkedService', 'AzureSqlDatabase': 'AzureSqlDatabaseLinkedService', 'AzureSqlMI': 'AzureSqlMILinkedService', 'AzureStorage': 'AzureStorageLinkedService', 'AzureTableStorage': 'AzureTableStorageLinkedService', 'Cassandra': 'CassandraLinkedService', 'CommonDataServiceForApps': 'CommonDataServiceForAppsLinkedService', 'Concur': 'ConcurLinkedService', 'CosmosDb': 'CosmosDbLinkedService', 'CosmosDbMongoDbApi': 'CosmosDbMongoDbApiLinkedService', 'Couchbase': 'CouchbaseLinkedService', 'CustomDataSource': 'CustomDataSourceLinkedService', 'Dataworld': 'DataworldLinkedService', 'Db2': 'Db2LinkedService', 'Drill': 'DrillLinkedService', 'Dynamics': 'DynamicsLinkedService', 'DynamicsAX': 'DynamicsAXLinkedService', 'DynamicsCrm': 'DynamicsCrmLinkedService', 'Eloqua': 'EloquaLinkedService', 'FileServer': 'FileServerLinkedService', 'FtpServer': 'FtpServerLinkedService', 'GoogleAdWords': 'GoogleAdWordsLinkedService', 'GoogleBigQuery': 'GoogleBigQueryLinkedService', 'GoogleCloudStorage': 'GoogleCloudStorageLinkedService', 'Greenplum': 'GreenplumLinkedService', 'HBase': 'HBaseLinkedService', 'HDInsight': 'HDInsightLinkedService', 'HDInsightOnDemand': 'HDInsightOnDemandLinkedService', 'Hdfs': 'HdfsLinkedService', 'Hive': 'HiveLinkedService', 'HttpServer': 'HttpLinkedService', 'Hubspot': 'HubspotLinkedService', 'Impala': 'ImpalaLinkedService', 'Informix': 'InformixLinkedService', 'Jira': 'JiraLinkedService', 'Magento': 'MagentoLinkedService', 'MariaDB': 'MariaDBLinkedService', 'Marketo': 'MarketoLinkedService', 'MicrosoftAccess': 'MicrosoftAccessLinkedService', 'MongoDb': 'MongoDbLinkedService', 'MongoDbAtlas': 'MongoDbAtlasLinkedService', 'MongoDbV2': 'MongoDbV2LinkedService', 'MySql': 'MySqlLinkedService', 'Netezza': 'NetezzaLinkedService', 'OData': 'ODataLinkedService', 'Odbc': 'OdbcLinkedService', 'Office365': 'Office365LinkedService', 'Oracle': 'OracleLinkedService', 'OracleCloudStorage': 'OracleCloudStorageLinkedService', 'OracleServiceCloud': 'OracleServiceCloudLinkedService', 'Paypal': 'PaypalLinkedService', 'Phoenix': 'PhoenixLinkedService', 'PostgreSql': 'PostgreSqlLinkedService', 'Presto': 'PrestoLinkedService', 'QuickBooks': 'QuickBooksLinkedService', 'Quickbase': 'QuickbaseLinkedService', 'Responsys': 'ResponsysLinkedService', 'RestService': 'RestServiceLinkedService', 'Salesforce': 'SalesforceLinkedService', 'SalesforceMarketingCloud': 'SalesforceMarketingCloudLinkedService', 'SalesforceServiceCloud': 'SalesforceServiceCloudLinkedService', 'SapBW': 'SapBWLinkedService', 'SapCloudForCustomer': 'SapCloudForCustomerLinkedService', 'SapEcc': 'SapEccLinkedService', 'SapHana': 'SapHanaLinkedService', 'SapOpenHub': 'SapOpenHubLinkedService', 'SapTable': 'SapTableLinkedService', 'ServiceNow': 'ServiceNowLinkedService', 'Sftp': 'SftpServerLinkedService', 'SharePointOnlineList': 'SharePointOnlineListLinkedService', 'Shopify': 'ShopifyLinkedService', 'Smartsheet': 'SmartsheetLinkedService', 'Snowflake': 'SnowflakeLinkedService', 'Spark': 'SparkLinkedService', 'SqlServer': 'SqlServerLinkedService', 'Square': 'SquareLinkedService', 'Sybase': 'SybaseLinkedService', 'TeamDesk': 'TeamDeskLinkedService', 'Teradata': 'TeradataLinkedService', 'Twilio': 'TwilioLinkedService', 'Vertica': 'VerticaLinkedService', 'Web': 'WebLinkedService', 'Xero': 'XeroLinkedService', 'Zendesk': 'ZendeskLinkedService', 'Zoho': 'ZohoLinkedService'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        """
        super(LinkedService, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'LinkedService'  # type: str
        self.connect_via = connect_via
        self.description = description
        self.parameters = parameters
        self.annotations = annotations


class AmazonMWSLinkedService(LinkedService):
    """Amazon Marketplace Web Service linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar endpoint: Required. The endpoint of the Amazon MWS server, (i.e. mws.amazonservices.com).
    :vartype endpoint: any
    :ivar marketplace_id: Required. The Amazon Marketplace ID you want to retrieve data from. To
     retrieve data from multiple Marketplace IDs, separate them with a comma (,). (i.e.
     A2EUQ1WTGCTBG2).
    :vartype marketplace_id: any
    :ivar seller_id: Required. The Amazon seller ID.
    :vartype seller_id: any
    :ivar mws_auth_token: The Amazon MWS authentication token.
    :vartype mws_auth_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar access_key_id: Required. The access key id used to access data.
    :vartype access_key_id: any
    :ivar secret_key: The secret key used to access data.
    :vartype secret_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
        'marketplace_id': {'required': True},
        'seller_id': {'required': True},
        'access_key_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'object'},
        'marketplace_id': {'key': 'typeProperties.marketplaceID', 'type': 'object'},
        'seller_id': {'key': 'typeProperties.sellerID', 'type': 'object'},
        'mws_auth_token': {'key': 'typeProperties.mwsAuthToken', 'type': 'SecretBase'},
        'access_key_id': {'key': 'typeProperties.accessKeyId', 'type': 'object'},
        'secret_key': {'key': 'typeProperties.secretKey', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        endpoint: Any,
        marketplace_id: Any,
        seller_id: Any,
        access_key_id: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        mws_auth_token: Optional["SecretBase"] = None,
        secret_key: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword endpoint: Required. The endpoint of the Amazon MWS server, (i.e.
         mws.amazonservices.com).
        :paramtype endpoint: any
        :keyword marketplace_id: Required. The Amazon Marketplace ID you want to retrieve data from. To
         retrieve data from multiple Marketplace IDs, separate them with a comma (,). (i.e.
         A2EUQ1WTGCTBG2).
        :paramtype marketplace_id: any
        :keyword seller_id: Required. The Amazon seller ID.
        :paramtype seller_id: any
        :keyword mws_auth_token: The Amazon MWS authentication token.
        :paramtype mws_auth_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword access_key_id: Required. The access key id used to access data.
        :paramtype access_key_id: any
        :keyword secret_key: The secret key used to access data.
        :paramtype secret_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true.
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true.
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(AmazonMWSLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AmazonMWS'  # type: str
        self.endpoint = endpoint
        self.marketplace_id = marketplace_id
        self.seller_id = seller_id
        self.mws_auth_token = mws_auth_token
        self.access_key_id = access_key_id
        self.secret_key = secret_key
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class Dataset(msrest.serialization.Model):
    """The Azure Data Factory nested object which identifies data within different data stores, such as tables, files, folders, and documents.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AmazonMWSObjectDataset, AmazonRdsForOracleTableDataset, AmazonRdsForSqlServerTableDataset, AmazonRedshiftTableDataset, AmazonS3Dataset, AvroDataset, AzureBlobDataset, AzureBlobFSDataset, AzureDataExplorerTableDataset, AzureDataLakeStoreDataset, AzureDatabricksDeltaLakeDataset, AzureMariaDBTableDataset, AzureMySqlTableDataset, AzurePostgreSqlTableDataset, AzureSearchIndexDataset, AzureSqlDWTableDataset, AzureSqlMITableDataset, AzureSqlTableDataset, AzureTableDataset, BinaryDataset, CassandraTableDataset, CommonDataServiceForAppsEntityDataset, ConcurObjectDataset, CosmosDbMongoDbApiCollectionDataset, CosmosDbSqlApiCollectionDataset, CouchbaseTableDataset, CustomDataset, Db2TableDataset, DelimitedTextDataset, DocumentDbCollectionDataset, DrillTableDataset, DynamicsAXResourceDataset, DynamicsCrmEntityDataset, DynamicsEntityDataset, EloquaObjectDataset, ExcelDataset, FileShareDataset, GoogleAdWordsObjectDataset, GoogleBigQueryObjectDataset, GreenplumTableDataset, HBaseObjectDataset, HiveObjectDataset, HttpDataset, HubspotObjectDataset, ImpalaObjectDataset, InformixTableDataset, JiraObjectDataset, JsonDataset, MagentoObjectDataset, MariaDBTableDataset, MarketoObjectDataset, MicrosoftAccessTableDataset, MongoDbAtlasCollectionDataset, MongoDbCollectionDataset, MongoDbV2CollectionDataset, MySqlTableDataset, NetezzaTableDataset, ODataResourceDataset, OdbcTableDataset, Office365Dataset, OracleServiceCloudObjectDataset, OracleTableDataset, OrcDataset, ParquetDataset, PaypalObjectDataset, PhoenixObjectDataset, PostgreSqlTableDataset, PrestoObjectDataset, QuickBooksObjectDataset, RelationalTableDataset, ResponsysObjectDataset, RestResourceDataset, SalesforceMarketingCloudObjectDataset, SalesforceObjectDataset, SalesforceServiceCloudObjectDataset, SapBwCubeDataset, SapCloudForCustomerResourceDataset, SapEccResourceDataset, SapHanaTableDataset, SapOpenHubTableDataset, SapTableResourceDataset, ServiceNowObjectDataset, SharePointOnlineListResourceDataset, ShopifyObjectDataset, SnowflakeDataset, SparkObjectDataset, SqlServerTableDataset, SquareObjectDataset, SybaseTableDataset, TeradataTableDataset, VerticaTableDataset, WebTableDataset, XeroObjectDataset, XmlDataset, ZohoObjectDataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
    }

    _subtype_map = {
        'type': {'AmazonMWSObject': 'AmazonMWSObjectDataset', 'AmazonRdsForOracleTable': 'AmazonRdsForOracleTableDataset', 'AmazonRdsForSqlServerTable': 'AmazonRdsForSqlServerTableDataset', 'AmazonRedshiftTable': 'AmazonRedshiftTableDataset', 'AmazonS3Object': 'AmazonS3Dataset', 'Avro': 'AvroDataset', 'AzureBlob': 'AzureBlobDataset', 'AzureBlobFSFile': 'AzureBlobFSDataset', 'AzureDataExplorerTable': 'AzureDataExplorerTableDataset', 'AzureDataLakeStoreFile': 'AzureDataLakeStoreDataset', 'AzureDatabricksDeltaLakeDataset': 'AzureDatabricksDeltaLakeDataset', 'AzureMariaDBTable': 'AzureMariaDBTableDataset', 'AzureMySqlTable': 'AzureMySqlTableDataset', 'AzurePostgreSqlTable': 'AzurePostgreSqlTableDataset', 'AzureSearchIndex': 'AzureSearchIndexDataset', 'AzureSqlDWTable': 'AzureSqlDWTableDataset', 'AzureSqlMITable': 'AzureSqlMITableDataset', 'AzureSqlTable': 'AzureSqlTableDataset', 'AzureTable': 'AzureTableDataset', 'Binary': 'BinaryDataset', 'CassandraTable': 'CassandraTableDataset', 'CommonDataServiceForAppsEntity': 'CommonDataServiceForAppsEntityDataset', 'ConcurObject': 'ConcurObjectDataset', 'CosmosDbMongoDbApiCollection': 'CosmosDbMongoDbApiCollectionDataset', 'CosmosDbSqlApiCollection': 'CosmosDbSqlApiCollectionDataset', 'CouchbaseTable': 'CouchbaseTableDataset', 'CustomDataset': 'CustomDataset', 'Db2Table': 'Db2TableDataset', 'DelimitedText': 'DelimitedTextDataset', 'DocumentDbCollection': 'DocumentDbCollectionDataset', 'DrillTable': 'DrillTableDataset', 'DynamicsAXResource': 'DynamicsAXResourceDataset', 'DynamicsCrmEntity': 'DynamicsCrmEntityDataset', 'DynamicsEntity': 'DynamicsEntityDataset', 'EloquaObject': 'EloquaObjectDataset', 'Excel': 'ExcelDataset', 'FileShare': 'FileShareDataset', 'GoogleAdWordsObject': 'GoogleAdWordsObjectDataset', 'GoogleBigQueryObject': 'GoogleBigQueryObjectDataset', 'GreenplumTable': 'GreenplumTableDataset', 'HBaseObject': 'HBaseObjectDataset', 'HiveObject': 'HiveObjectDataset', 'HttpFile': 'HttpDataset', 'HubspotObject': 'HubspotObjectDataset', 'ImpalaObject': 'ImpalaObjectDataset', 'InformixTable': 'InformixTableDataset', 'JiraObject': 'JiraObjectDataset', 'Json': 'JsonDataset', 'MagentoObject': 'MagentoObjectDataset', 'MariaDBTable': 'MariaDBTableDataset', 'MarketoObject': 'MarketoObjectDataset', 'MicrosoftAccessTable': 'MicrosoftAccessTableDataset', 'MongoDbAtlasCollection': 'MongoDbAtlasCollectionDataset', 'MongoDbCollection': 'MongoDbCollectionDataset', 'MongoDbV2Collection': 'MongoDbV2CollectionDataset', 'MySqlTable': 'MySqlTableDataset', 'NetezzaTable': 'NetezzaTableDataset', 'ODataResource': 'ODataResourceDataset', 'OdbcTable': 'OdbcTableDataset', 'Office365Table': 'Office365Dataset', 'OracleServiceCloudObject': 'OracleServiceCloudObjectDataset', 'OracleTable': 'OracleTableDataset', 'Orc': 'OrcDataset', 'Parquet': 'ParquetDataset', 'PaypalObject': 'PaypalObjectDataset', 'PhoenixObject': 'PhoenixObjectDataset', 'PostgreSqlTable': 'PostgreSqlTableDataset', 'PrestoObject': 'PrestoObjectDataset', 'QuickBooksObject': 'QuickBooksObjectDataset', 'RelationalTable': 'RelationalTableDataset', 'ResponsysObject': 'ResponsysObjectDataset', 'RestResource': 'RestResourceDataset', 'SalesforceMarketingCloudObject': 'SalesforceMarketingCloudObjectDataset', 'SalesforceObject': 'SalesforceObjectDataset', 'SalesforceServiceCloudObject': 'SalesforceServiceCloudObjectDataset', 'SapBwCube': 'SapBwCubeDataset', 'SapCloudForCustomerResource': 'SapCloudForCustomerResourceDataset', 'SapEccResource': 'SapEccResourceDataset', 'SapHanaTable': 'SapHanaTableDataset', 'SapOpenHubTable': 'SapOpenHubTableDataset', 'SapTableResource': 'SapTableResourceDataset', 'ServiceNowObject': 'ServiceNowObjectDataset', 'SharePointOnlineListResource': 'SharePointOnlineListResourceDataset', 'ShopifyObject': 'ShopifyObjectDataset', 'SnowflakeTable': 'SnowflakeDataset', 'SparkObject': 'SparkObjectDataset', 'SqlServerTable': 'SqlServerTableDataset', 'SquareObject': 'SquareObjectDataset', 'SybaseTable': 'SybaseTableDataset', 'TeradataTable': 'TeradataTableDataset', 'VerticaTable': 'VerticaTableDataset', 'WebTable': 'WebTableDataset', 'XeroObject': 'XeroObjectDataset', 'Xml': 'XmlDataset', 'ZohoObject': 'ZohoObjectDataset'}
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        """
        super(Dataset, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'Dataset'  # type: str
        self.description = description
        self.structure = structure
        self.schema = schema
        self.linked_service_name = linked_service_name
        self.parameters = parameters
        self.annotations = annotations
        self.folder = folder


class AmazonMWSObjectDataset(Dataset):
    """Amazon Marketplace Web Service dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(AmazonMWSObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AmazonMWSObject'  # type: str
        self.table_name = table_name


class CopySource(msrest.serialization.Model):
    """A copy activity source.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AmazonRdsForOracleSource, AvroSource, AzureBlobFSSource, AzureDataExplorerSource, AzureDataLakeStoreSource, AzureDatabricksDeltaLakeSource, BinarySource, BlobSource, CommonDataServiceForAppsSource, CosmosDbMongoDbApiSource, CosmosDbSqlApiSource, DelimitedTextSource, DocumentDbCollectionSource, DynamicsCrmSource, DynamicsSource, ExcelSource, FileSystemSource, HdfsSource, HttpSource, JsonSource, MicrosoftAccessSource, MongoDbAtlasSource, MongoDbSource, MongoDbV2Source, ODataSource, Office365Source, OracleSource, OrcSource, ParquetSource, RelationalSource, RestSource, SalesforceServiceCloudSource, SharePointOnlineListSource, SnowflakeSource, TabularSource, WebSource, XmlSource.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
    }

    _subtype_map = {
        'type': {'AmazonRdsForOracleSource': 'AmazonRdsForOracleSource', 'AvroSource': 'AvroSource', 'AzureBlobFSSource': 'AzureBlobFSSource', 'AzureDataExplorerSource': 'AzureDataExplorerSource', 'AzureDataLakeStoreSource': 'AzureDataLakeStoreSource', 'AzureDatabricksDeltaLakeSource': 'AzureDatabricksDeltaLakeSource', 'BinarySource': 'BinarySource', 'BlobSource': 'BlobSource', 'CommonDataServiceForAppsSource': 'CommonDataServiceForAppsSource', 'CosmosDbMongoDbApiSource': 'CosmosDbMongoDbApiSource', 'CosmosDbSqlApiSource': 'CosmosDbSqlApiSource', 'DelimitedTextSource': 'DelimitedTextSource', 'DocumentDbCollectionSource': 'DocumentDbCollectionSource', 'DynamicsCrmSource': 'DynamicsCrmSource', 'DynamicsSource': 'DynamicsSource', 'ExcelSource': 'ExcelSource', 'FileSystemSource': 'FileSystemSource', 'HdfsSource': 'HdfsSource', 'HttpSource': 'HttpSource', 'JsonSource': 'JsonSource', 'MicrosoftAccessSource': 'MicrosoftAccessSource', 'MongoDbAtlasSource': 'MongoDbAtlasSource', 'MongoDbSource': 'MongoDbSource', 'MongoDbV2Source': 'MongoDbV2Source', 'ODataSource': 'ODataSource', 'Office365Source': 'Office365Source', 'OracleSource': 'OracleSource', 'OrcSource': 'OrcSource', 'ParquetSource': 'ParquetSource', 'RelationalSource': 'RelationalSource', 'RestSource': 'RestSource', 'SalesforceServiceCloudSource': 'SalesforceServiceCloudSource', 'SharePointOnlineListSource': 'SharePointOnlineListSource', 'SnowflakeSource': 'SnowflakeSource', 'TabularSource': 'TabularSource', 'WebSource': 'WebSource', 'XmlSource': 'XmlSource'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        """
        super(CopySource, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'CopySource'  # type: str
        self.source_retry_count = source_retry_count
        self.source_retry_wait = source_retry_wait
        self.max_concurrent_connections = max_concurrent_connections
        self.disable_metrics_collection = disable_metrics_collection


class TabularSource(CopySource):
    """Copy activity sources of tabular type.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AmazonMWSSource, AmazonRdsForSqlServerSource, AmazonRedshiftSource, AzureMariaDBSource, AzureMySqlSource, AzurePostgreSqlSource, AzureSqlSource, AzureTableSource, CassandraSource, ConcurSource, CouchbaseSource, Db2Source, DrillSource, DynamicsAXSource, EloquaSource, GoogleAdWordsSource, GoogleBigQuerySource, GreenplumSource, HBaseSource, HiveSource, HubspotSource, ImpalaSource, InformixSource, JiraSource, MagentoSource, MariaDBSource, MarketoSource, MySqlSource, NetezzaSource, OdbcSource, OracleServiceCloudSource, PaypalSource, PhoenixSource, PostgreSqlSource, PrestoSource, QuickBooksSource, ResponsysSource, SalesforceMarketingCloudSource, SalesforceSource, SapBwSource, SapCloudForCustomerSource, SapEccSource, SapHanaSource, SapOpenHubSource, SapTableSource, ServiceNowSource, ShopifySource, SparkSource, SqlDWSource, SqlMISource, SqlServerSource, SqlSource, SquareSource, SybaseSource, TeradataSource, VerticaSource, XeroSource, ZohoSource.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    _subtype_map = {
        'type': {'AmazonMWSSource': 'AmazonMWSSource', 'AmazonRdsForSqlServerSource': 'AmazonRdsForSqlServerSource', 'AmazonRedshiftSource': 'AmazonRedshiftSource', 'AzureMariaDBSource': 'AzureMariaDBSource', 'AzureMySqlSource': 'AzureMySqlSource', 'AzurePostgreSqlSource': 'AzurePostgreSqlSource', 'AzureSqlSource': 'AzureSqlSource', 'AzureTableSource': 'AzureTableSource', 'CassandraSource': 'CassandraSource', 'ConcurSource': 'ConcurSource', 'CouchbaseSource': 'CouchbaseSource', 'Db2Source': 'Db2Source', 'DrillSource': 'DrillSource', 'DynamicsAXSource': 'DynamicsAXSource', 'EloquaSource': 'EloquaSource', 'GoogleAdWordsSource': 'GoogleAdWordsSource', 'GoogleBigQuerySource': 'GoogleBigQuerySource', 'GreenplumSource': 'GreenplumSource', 'HBaseSource': 'HBaseSource', 'HiveSource': 'HiveSource', 'HubspotSource': 'HubspotSource', 'ImpalaSource': 'ImpalaSource', 'InformixSource': 'InformixSource', 'JiraSource': 'JiraSource', 'MagentoSource': 'MagentoSource', 'MariaDBSource': 'MariaDBSource', 'MarketoSource': 'MarketoSource', 'MySqlSource': 'MySqlSource', 'NetezzaSource': 'NetezzaSource', 'OdbcSource': 'OdbcSource', 'OracleServiceCloudSource': 'OracleServiceCloudSource', 'PaypalSource': 'PaypalSource', 'PhoenixSource': 'PhoenixSource', 'PostgreSqlSource': 'PostgreSqlSource', 'PrestoSource': 'PrestoSource', 'QuickBooksSource': 'QuickBooksSource', 'ResponsysSource': 'ResponsysSource', 'SalesforceMarketingCloudSource': 'SalesforceMarketingCloudSource', 'SalesforceSource': 'SalesforceSource', 'SapBwSource': 'SapBwSource', 'SapCloudForCustomerSource': 'SapCloudForCustomerSource', 'SapEccSource': 'SapEccSource', 'SapHanaSource': 'SapHanaSource', 'SapOpenHubSource': 'SapOpenHubSource', 'SapTableSource': 'SapTableSource', 'ServiceNowSource': 'ServiceNowSource', 'ShopifySource': 'ShopifySource', 'SparkSource': 'SparkSource', 'SqlDWSource': 'SqlDWSource', 'SqlMISource': 'SqlMISource', 'SqlServerSource': 'SqlServerSource', 'SqlSource': 'SqlSource', 'SquareSource': 'SquareSource', 'SybaseSource': 'SybaseSource', 'TeradataSource': 'TeradataSource', 'VerticaSource': 'VerticaSource', 'XeroSource': 'XeroSource', 'ZohoSource': 'ZohoSource'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(TabularSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'TabularSource'  # type: str
        self.query_timeout = query_timeout
        self.additional_columns = additional_columns


class AmazonMWSSource(TabularSource):
    """A copy activity Amazon Marketplace Web Service source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(AmazonMWSSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AmazonMWSSource'  # type: str
        self.query = query


class AmazonRdsForOracleLinkedService(LinkedService):
    """AmazonRdsForOracle database.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar password: The Azure key vault secret reference of password in connection string.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword password: The Azure key vault secret reference of password in connection string.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(AmazonRdsForOracleLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AmazonRdsForOracle'  # type: str
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class AmazonRdsForOraclePartitionSettings(msrest.serialization.Model):
    """The settings that will be leveraged for AmazonRdsForOracle source partitioning.

    :ivar partition_names: Names of the physical partitions of AmazonRdsForOracle table.
    :vartype partition_names: any
    :ivar partition_column_name: The name of the column in integer type that will be used for
     proceeding range partitioning. Type: string (or Expression with resultType string).
    :vartype partition_column_name: any
    :ivar partition_upper_bound: The maximum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :vartype partition_upper_bound: any
    :ivar partition_lower_bound: The minimum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :vartype partition_lower_bound: any
    """

    _attribute_map = {
        'partition_names': {'key': 'partitionNames', 'type': 'object'},
        'partition_column_name': {'key': 'partitionColumnName', 'type': 'object'},
        'partition_upper_bound': {'key': 'partitionUpperBound', 'type': 'object'},
        'partition_lower_bound': {'key': 'partitionLowerBound', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        partition_names: Optional[Any] = None,
        partition_column_name: Optional[Any] = None,
        partition_upper_bound: Optional[Any] = None,
        partition_lower_bound: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword partition_names: Names of the physical partitions of AmazonRdsForOracle table.
        :paramtype partition_names: any
        :keyword partition_column_name: The name of the column in integer type that will be used for
         proceeding range partitioning. Type: string (or Expression with resultType string).
        :paramtype partition_column_name: any
        :keyword partition_upper_bound: The maximum value of column specified in partitionColumnName
         that will be used for proceeding range partitioning. Type: string (or Expression with
         resultType string).
        :paramtype partition_upper_bound: any
        :keyword partition_lower_bound: The minimum value of column specified in partitionColumnName
         that will be used for proceeding range partitioning. Type: string (or Expression with
         resultType string).
        :paramtype partition_lower_bound: any
        """
        super(AmazonRdsForOraclePartitionSettings, self).__init__(**kwargs)
        self.partition_names = partition_names
        self.partition_column_name = partition_column_name
        self.partition_upper_bound = partition_upper_bound
        self.partition_lower_bound = partition_lower_bound


class AmazonRdsForOracleSource(CopySource):
    """A copy activity AmazonRdsForOracle source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar oracle_reader_query: AmazonRdsForOracle reader query. Type: string (or Expression with
     resultType string).
    :vartype oracle_reader_query: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar partition_option: The partition mechanism that will be used for AmazonRdsForOracle read
     in parallel. Type: string (or Expression with resultType string).
    :vartype partition_option: any
    :ivar partition_settings: The settings that will be leveraged for AmazonRdsForOracle source
     partitioning.
    :vartype partition_settings: ~azure.mgmt.datafactory.models.AmazonRdsForOraclePartitionSettings
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'oracle_reader_query': {'key': 'oracleReaderQuery', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'partition_option': {'key': 'partitionOption', 'type': 'object'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'AmazonRdsForOraclePartitionSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        oracle_reader_query: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        partition_option: Optional[Any] = None,
        partition_settings: Optional["AmazonRdsForOraclePartitionSettings"] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword oracle_reader_query: AmazonRdsForOracle reader query. Type: string (or Expression with
         resultType string).
        :paramtype oracle_reader_query: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword partition_option: The partition mechanism that will be used for AmazonRdsForOracle
         read in parallel. Type: string (or Expression with resultType string).
        :paramtype partition_option: any
        :keyword partition_settings: The settings that will be leveraged for AmazonRdsForOracle source
         partitioning.
        :paramtype partition_settings:
         ~azure.mgmt.datafactory.models.AmazonRdsForOraclePartitionSettings
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(AmazonRdsForOracleSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AmazonRdsForOracleSource'  # type: str
        self.oracle_reader_query = oracle_reader_query
        self.query_timeout = query_timeout
        self.partition_option = partition_option
        self.partition_settings = partition_settings
        self.additional_columns = additional_columns


class AmazonRdsForOracleTableDataset(Dataset):
    """The AmazonRdsForOracle database dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar schema_type_properties_schema: The schema name of the AmazonRdsForOracle database. Type:
     string (or Expression with resultType string).
    :vartype schema_type_properties_schema: any
    :ivar table: The table name of the AmazonRdsForOracle database. Type: string (or Expression
     with resultType string).
    :vartype table: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        schema_type_properties_schema: Optional[Any] = None,
        table: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword schema_type_properties_schema: The schema name of the AmazonRdsForOracle database.
         Type: string (or Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        :keyword table: The table name of the AmazonRdsForOracle database. Type: string (or Expression
         with resultType string).
        :paramtype table: any
        """
        super(AmazonRdsForOracleTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AmazonRdsForOracleTable'  # type: str
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class AmazonRdsForSqlServerLinkedService(LinkedService):
    """Amazon RDS for SQL Server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar user_name: The on-premises Windows authentication user name. Type: string (or Expression
     with resultType string).
    :vartype user_name: any
    :ivar password: The on-premises Windows authentication password.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar always_encrypted_settings: Sql always encrypted properties.
    :vartype always_encrypted_settings: ~azure.mgmt.datafactory.models.SqlAlwaysEncryptedProperties
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'always_encrypted_settings': {'key': 'typeProperties.alwaysEncryptedSettings', 'type': 'SqlAlwaysEncryptedProperties'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        always_encrypted_settings: Optional["SqlAlwaysEncryptedProperties"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword user_name: The on-premises Windows authentication user name. Type: string (or
         Expression with resultType string).
        :paramtype user_name: any
        :keyword password: The on-premises Windows authentication password.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword always_encrypted_settings: Sql always encrypted properties.
        :paramtype always_encrypted_settings:
         ~azure.mgmt.datafactory.models.SqlAlwaysEncryptedProperties
        """
        super(AmazonRdsForSqlServerLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AmazonRdsForSqlServer'  # type: str
        self.connection_string = connection_string
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential
        self.always_encrypted_settings = always_encrypted_settings


class AmazonRdsForSqlServerSource(TabularSource):
    """A copy activity Amazon RDS for SQL Server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar sql_reader_query: SQL reader query. Type: string (or Expression with resultType string).
    :vartype sql_reader_query: any
    :ivar sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Database source.
     This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression with
     resultType string).
    :vartype sql_reader_stored_procedure_name: any
    :ivar stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}".
    :vartype stored_procedure_parameters: dict[str,
     ~azure.mgmt.datafactory.models.StoredProcedureParameter]
    :ivar produce_additional_types: Which additional types to produce.
    :vartype produce_additional_types: any
    :ivar partition_option: The partition mechanism that will be used for Sql read in parallel.
     Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
    :vartype partition_option: any
    :ivar partition_settings: The settings that will be leveraged for Sql source partitioning.
    :vartype partition_settings: ~azure.mgmt.datafactory.models.SqlPartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'sql_reader_query': {'key': 'sqlReaderQuery', 'type': 'object'},
        'sql_reader_stored_procedure_name': {'key': 'sqlReaderStoredProcedureName', 'type': 'object'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'produce_additional_types': {'key': 'produceAdditionalTypes', 'type': 'object'},
        'partition_option': {'key': 'partitionOption', 'type': 'object'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'SqlPartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        sql_reader_query: Optional[Any] = None,
        sql_reader_stored_procedure_name: Optional[Any] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        produce_additional_types: Optional[Any] = None,
        partition_option: Optional[Any] = None,
        partition_settings: Optional["SqlPartitionSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword sql_reader_query: SQL reader query. Type: string (or Expression with resultType
         string).
        :paramtype sql_reader_query: any
        :keyword sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Database
         source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression
         with resultType string).
        :paramtype sql_reader_stored_procedure_name: any
        :keyword stored_procedure_parameters: Value and type setting for stored procedure parameters.
         Example: "{Parameter1: {value: "1", type: "int"}}".
        :paramtype stored_procedure_parameters: dict[str,
         ~azure.mgmt.datafactory.models.StoredProcedureParameter]
        :keyword produce_additional_types: Which additional types to produce.
        :paramtype produce_additional_types: any
        :keyword partition_option: The partition mechanism that will be used for Sql read in parallel.
         Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
        :paramtype partition_option: any
        :keyword partition_settings: The settings that will be leveraged for Sql source partitioning.
        :paramtype partition_settings: ~azure.mgmt.datafactory.models.SqlPartitionSettings
        """
        super(AmazonRdsForSqlServerSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AmazonRdsForSqlServerSource'  # type: str
        self.sql_reader_query = sql_reader_query
        self.sql_reader_stored_procedure_name = sql_reader_stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters
        self.produce_additional_types = produce_additional_types
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class AmazonRdsForSqlServerTableDataset(Dataset):
    """The Amazon RDS for SQL Server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar schema_type_properties_schema: The schema name of the SQL Server dataset. Type: string
     (or Expression with resultType string).
    :vartype schema_type_properties_schema: any
    :ivar table: The table name of the SQL Server dataset. Type: string (or Expression with
     resultType string).
    :vartype table: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        schema_type_properties_schema: Optional[Any] = None,
        table: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword schema_type_properties_schema: The schema name of the SQL Server dataset. Type: string
         (or Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        :keyword table: The table name of the SQL Server dataset. Type: string (or Expression with
         resultType string).
        :paramtype table: any
        """
        super(AmazonRdsForSqlServerTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AmazonRdsForSqlServerTable'  # type: str
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class AmazonRedshiftLinkedService(LinkedService):
    """Linked service for Amazon Redshift.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar server: Required. The name of the Amazon Redshift server. Type: string (or Expression
     with resultType string).
    :vartype server: any
    :ivar username: The username of the Amazon Redshift source. Type: string (or Expression with
     resultType string).
    :vartype username: any
    :ivar password: The password of the Amazon Redshift source.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar database: Required. The database name of the Amazon Redshift source. Type: string (or
     Expression with resultType string).
    :vartype database: any
    :ivar port: The TCP port number that the Amazon Redshift server uses to listen for client
     connections. The default value is 5439. Type: integer (or Expression with resultType integer).
    :vartype port: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'server': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'server': {'key': 'typeProperties.server', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'database': {'key': 'typeProperties.database', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        server: Any,
        database: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        port: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword server: Required. The name of the Amazon Redshift server. Type: string (or Expression
         with resultType string).
        :paramtype server: any
        :keyword username: The username of the Amazon Redshift source. Type: string (or Expression with
         resultType string).
        :paramtype username: any
        :keyword password: The password of the Amazon Redshift source.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword database: Required. The database name of the Amazon Redshift source. Type: string (or
         Expression with resultType string).
        :paramtype database: any
        :keyword port: The TCP port number that the Amazon Redshift server uses to listen for client
         connections. The default value is 5439. Type: integer (or Expression with resultType integer).
        :paramtype port: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(AmazonRedshiftLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AmazonRedshift'  # type: str
        self.server = server
        self.username = username
        self.password = password
        self.database = database
        self.port = port
        self.encrypted_credential = encrypted_credential


class AmazonRedshiftSource(TabularSource):
    """A copy activity source for Amazon Redshift Source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: Database query. Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar redshift_unload_settings: The Amazon S3 settings needed for the interim Amazon S3 when
     copying from Amazon Redshift with unload. With this, data from Amazon Redshift source will be
     unloaded into S3 first and then copied into the targeted sink from the interim S3.
    :vartype redshift_unload_settings: ~azure.mgmt.datafactory.models.RedshiftUnloadSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'redshift_unload_settings': {'key': 'redshiftUnloadSettings', 'type': 'RedshiftUnloadSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        redshift_unload_settings: Optional["RedshiftUnloadSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: Database query. Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword redshift_unload_settings: The Amazon S3 settings needed for the interim Amazon S3 when
         copying from Amazon Redshift with unload. With this, data from Amazon Redshift source will be
         unloaded into S3 first and then copied into the targeted sink from the interim S3.
        :paramtype redshift_unload_settings: ~azure.mgmt.datafactory.models.RedshiftUnloadSettings
        """
        super(AmazonRedshiftSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AmazonRedshiftSource'  # type: str
        self.query = query
        self.redshift_unload_settings = redshift_unload_settings


class AmazonRedshiftTableDataset(Dataset):
    """The Amazon Redshift table dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar table: The Amazon Redshift table name. Type: string (or Expression with resultType
     string).
    :vartype table: any
    :ivar schema_type_properties_schema: The Amazon Redshift schema name. Type: string (or
     Expression with resultType string).
    :vartype schema_type_properties_schema: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword table: The Amazon Redshift table name. Type: string (or Expression with resultType
         string).
        :paramtype table: any
        :keyword schema_type_properties_schema: The Amazon Redshift schema name. Type: string (or
         Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        """
        super(AmazonRedshiftTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AmazonRedshiftTable'  # type: str
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class AmazonS3CompatibleLinkedService(LinkedService):
    """Linked service for Amazon S3 Compatible.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar access_key_id: The access key identifier of the Amazon S3 Compatible Identity and Access
     Management (IAM) user. Type: string (or Expression with resultType string).
    :vartype access_key_id: any
    :ivar secret_access_key: The secret access key of the Amazon S3 Compatible Identity and Access
     Management (IAM) user.
    :vartype secret_access_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar service_url: This value specifies the endpoint to access with the Amazon S3 Compatible
     Connector. This is an optional property; change it only if you want to try a different service
     endpoint or want to switch between https and http. Type: string (or Expression with resultType
     string).
    :vartype service_url: any
    :ivar force_path_style: If true, use S3 path-style access instead of virtual hosted-style
     access. Default value is false. Type: boolean (or Expression with resultType boolean).
    :vartype force_path_style: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'access_key_id': {'key': 'typeProperties.accessKeyId', 'type': 'object'},
        'secret_access_key': {'key': 'typeProperties.secretAccessKey', 'type': 'SecretBase'},
        'service_url': {'key': 'typeProperties.serviceUrl', 'type': 'object'},
        'force_path_style': {'key': 'typeProperties.forcePathStyle', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        access_key_id: Optional[Any] = None,
        secret_access_key: Optional["SecretBase"] = None,
        service_url: Optional[Any] = None,
        force_path_style: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword access_key_id: The access key identifier of the Amazon S3 Compatible Identity and
         Access Management (IAM) user. Type: string (or Expression with resultType string).
        :paramtype access_key_id: any
        :keyword secret_access_key: The secret access key of the Amazon S3 Compatible Identity and
         Access Management (IAM) user.
        :paramtype secret_access_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword service_url: This value specifies the endpoint to access with the Amazon S3 Compatible
         Connector. This is an optional property; change it only if you want to try a different service
         endpoint or want to switch between https and http. Type: string (or Expression with resultType
         string).
        :paramtype service_url: any
        :keyword force_path_style: If true, use S3 path-style access instead of virtual hosted-style
         access. Default value is false. Type: boolean (or Expression with resultType boolean).
        :paramtype force_path_style: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(AmazonS3CompatibleLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AmazonS3Compatible'  # type: str
        self.access_key_id = access_key_id
        self.secret_access_key = secret_access_key
        self.service_url = service_url
        self.force_path_style = force_path_style
        self.encrypted_credential = encrypted_credential


class DatasetLocation(msrest.serialization.Model):
    """Dataset location.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AmazonS3CompatibleLocation, AmazonS3Location, AzureBlobFSLocation, AzureBlobStorageLocation, AzureDataLakeStoreLocation, AzureFileStorageLocation, FileServerLocation, FtpServerLocation, GoogleCloudStorageLocation, HdfsLocation, HttpServerLocation, OracleCloudStorageLocation, SftpLocation.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
    }

    _subtype_map = {
        'type': {'AmazonS3CompatibleLocation': 'AmazonS3CompatibleLocation', 'AmazonS3Location': 'AmazonS3Location', 'AzureBlobFSLocation': 'AzureBlobFSLocation', 'AzureBlobStorageLocation': 'AzureBlobStorageLocation', 'AzureDataLakeStoreLocation': 'AzureDataLakeStoreLocation', 'AzureFileStorageLocation': 'AzureFileStorageLocation', 'FileServerLocation': 'FileServerLocation', 'FtpServerLocation': 'FtpServerLocation', 'GoogleCloudStorageLocation': 'GoogleCloudStorageLocation', 'HdfsLocation': 'HdfsLocation', 'HttpServerLocation': 'HttpServerLocation', 'OracleCloudStorageLocation': 'OracleCloudStorageLocation', 'SftpLocation': 'SftpLocation'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        """
        super(DatasetLocation, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'DatasetLocation'  # type: str
        self.folder_path = folder_path
        self.file_name = file_name


class AmazonS3CompatibleLocation(DatasetLocation):
    """The location of Amazon S3 Compatible dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    :ivar bucket_name: Specify the bucketName of Amazon S3 Compatible. Type: string (or Expression
     with resultType string).
    :vartype bucket_name: any
    :ivar version: Specify the version of Amazon S3 Compatible. Type: string (or Expression with
     resultType string).
    :vartype version: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
        'bucket_name': {'key': 'bucketName', 'type': 'object'},
        'version': {'key': 'version', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        bucket_name: Optional[Any] = None,
        version: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        :keyword bucket_name: Specify the bucketName of Amazon S3 Compatible. Type: string (or
         Expression with resultType string).
        :paramtype bucket_name: any
        :keyword version: Specify the version of Amazon S3 Compatible. Type: string (or Expression with
         resultType string).
        :paramtype version: any
        """
        super(AmazonS3CompatibleLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'AmazonS3CompatibleLocation'  # type: str
        self.bucket_name = bucket_name
        self.version = version


class StoreReadSettings(msrest.serialization.Model):
    """Connector read setting.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AmazonS3CompatibleReadSettings, AmazonS3ReadSettings, AzureBlobFSReadSettings, AzureBlobStorageReadSettings, AzureDataLakeStoreReadSettings, AzureFileStorageReadSettings, FileServerReadSettings, FtpReadSettings, GoogleCloudStorageReadSettings, HdfsReadSettings, HttpReadSettings, OracleCloudStorageReadSettings, SftpReadSettings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
    }

    _subtype_map = {
        'type': {'AmazonS3CompatibleReadSettings': 'AmazonS3CompatibleReadSettings', 'AmazonS3ReadSettings': 'AmazonS3ReadSettings', 'AzureBlobFSReadSettings': 'AzureBlobFSReadSettings', 'AzureBlobStorageReadSettings': 'AzureBlobStorageReadSettings', 'AzureDataLakeStoreReadSettings': 'AzureDataLakeStoreReadSettings', 'AzureFileStorageReadSettings': 'AzureFileStorageReadSettings', 'FileServerReadSettings': 'FileServerReadSettings', 'FtpReadSettings': 'FtpReadSettings', 'GoogleCloudStorageReadSettings': 'GoogleCloudStorageReadSettings', 'HdfsReadSettings': 'HdfsReadSettings', 'HttpReadSettings': 'HttpReadSettings', 'OracleCloudStorageReadSettings': 'OracleCloudStorageReadSettings', 'SftpReadSettings': 'SftpReadSettings'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        """
        super(StoreReadSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'StoreReadSettings'  # type: str
        self.max_concurrent_connections = max_concurrent_connections
        self.disable_metrics_collection = disable_metrics_collection


class AmazonS3CompatibleReadSettings(StoreReadSettings):
    """Amazon S3 Compatible read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar wildcard_folder_path: Amazon S3 Compatible wildcardFolderPath. Type: string (or
     Expression with resultType string).
    :vartype wildcard_folder_path: any
    :ivar wildcard_file_name: Amazon S3 Compatible wildcardFileName. Type: string (or Expression
     with resultType string).
    :vartype wildcard_file_name: any
    :ivar prefix: The prefix filter for the S3 Compatible object name. Type: string (or Expression
     with resultType string).
    :vartype prefix: any
    :ivar file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :vartype file_list_path: any
    :ivar enable_partition_discovery: Indicates whether to enable partition discovery.
    :vartype enable_partition_discovery: bool
    :ivar partition_root_path: Specify the root path where partition discovery starts from. Type:
     string (or Expression with resultType string).
    :vartype partition_root_path: any
    :ivar delete_files_after_completion: Indicates whether the source files need to be deleted
     after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
    :vartype delete_files_after_completion: any
    :ivar modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :vartype modified_datetime_end: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'object'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'object'},
        'prefix': {'key': 'prefix', 'type': 'object'},
        'file_list_path': {'key': 'fileListPath', 'type': 'object'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'partition_root_path': {'key': 'partitionRootPath', 'type': 'object'},
        'delete_files_after_completion': {'key': 'deleteFilesAfterCompletion', 'type': 'object'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        wildcard_folder_path: Optional[Any] = None,
        wildcard_file_name: Optional[Any] = None,
        prefix: Optional[Any] = None,
        file_list_path: Optional[Any] = None,
        enable_partition_discovery: Optional[bool] = None,
        partition_root_path: Optional[Any] = None,
        delete_files_after_completion: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword wildcard_folder_path: Amazon S3 Compatible wildcardFolderPath. Type: string (or
         Expression with resultType string).
        :paramtype wildcard_folder_path: any
        :keyword wildcard_file_name: Amazon S3 Compatible wildcardFileName. Type: string (or Expression
         with resultType string).
        :paramtype wildcard_file_name: any
        :keyword prefix: The prefix filter for the S3 Compatible object name. Type: string (or
         Expression with resultType string).
        :paramtype prefix: any
        :keyword file_list_path: Point to a text file that lists each file (relative path to the path
         configured in the dataset) that you want to copy. Type: string (or Expression with resultType
         string).
        :paramtype file_list_path: any
        :keyword enable_partition_discovery: Indicates whether to enable partition discovery.
        :paramtype enable_partition_discovery: bool
        :keyword partition_root_path: Specify the root path where partition discovery starts from.
         Type: string (or Expression with resultType string).
        :paramtype partition_root_path: any
        :keyword delete_files_after_completion: Indicates whether the source files need to be deleted
         after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype delete_files_after_completion: any
        :keyword modified_datetime_start: The start of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        """
        super(AmazonS3CompatibleReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AmazonS3CompatibleReadSettings'  # type: str
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.prefix = prefix
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.partition_root_path = partition_root_path
        self.delete_files_after_completion = delete_files_after_completion
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class AmazonS3Dataset(Dataset):
    """A single Amazon Simple Storage Service (S3) object or a set of S3 objects.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar bucket_name: Required. The name of the Amazon S3 bucket. Type: string (or Expression with
     resultType string).
    :vartype bucket_name: any
    :ivar key: The key of the Amazon S3 object. Type: string (or Expression with resultType
     string).
    :vartype key: any
    :ivar prefix: The prefix filter for the S3 object name. Type: string (or Expression with
     resultType string).
    :vartype prefix: any
    :ivar version: The version for the S3 object. Type: string (or Expression with resultType
     string).
    :vartype version: any
    :ivar modified_datetime_start: The start of S3 object's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of S3 object's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_end: any
    :ivar format: The format of files.
    :vartype format: ~azure.mgmt.datafactory.models.DatasetStorageFormat
    :ivar compression: The data compression method used for the Amazon S3 object.
    :vartype compression: ~azure.mgmt.datafactory.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'bucket_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'bucket_name': {'key': 'typeProperties.bucketName', 'type': 'object'},
        'key': {'key': 'typeProperties.key', 'type': 'object'},
        'prefix': {'key': 'typeProperties.prefix', 'type': 'object'},
        'version': {'key': 'typeProperties.version', 'type': 'object'},
        'modified_datetime_start': {'key': 'typeProperties.modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'typeProperties.modifiedDatetimeEnd', 'type': 'object'},
        'format': {'key': 'typeProperties.format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        bucket_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        key: Optional[Any] = None,
        prefix: Optional[Any] = None,
        version: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword bucket_name: Required. The name of the Amazon S3 bucket. Type: string (or Expression
         with resultType string).
        :paramtype bucket_name: any
        :keyword key: The key of the Amazon S3 object. Type: string (or Expression with resultType
         string).
        :paramtype key: any
        :keyword prefix: The prefix filter for the S3 object name. Type: string (or Expression with
         resultType string).
        :paramtype prefix: any
        :keyword version: The version for the S3 object. Type: string (or Expression with resultType
         string).
        :paramtype version: any
        :keyword modified_datetime_start: The start of S3 object's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of S3 object's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        :keyword format: The format of files.
        :paramtype format: ~azure.mgmt.datafactory.models.DatasetStorageFormat
        :keyword compression: The data compression method used for the Amazon S3 object.
        :paramtype compression: ~azure.mgmt.datafactory.models.DatasetCompression
        """
        super(AmazonS3Dataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AmazonS3Object'  # type: str
        self.bucket_name = bucket_name
        self.key = key
        self.prefix = prefix
        self.version = version
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end
        self.format = format
        self.compression = compression


class AmazonS3LinkedService(LinkedService):
    """Linked service for Amazon S3.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar authentication_type: The authentication type of S3. Allowed value: AccessKey (default) or
     TemporarySecurityCredentials. Type: string (or Expression with resultType string).
    :vartype authentication_type: any
    :ivar access_key_id: The access key identifier of the Amazon S3 Identity and Access Management
     (IAM) user. Type: string (or Expression with resultType string).
    :vartype access_key_id: any
    :ivar secret_access_key: The secret access key of the Amazon S3 Identity and Access Management
     (IAM) user.
    :vartype secret_access_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar service_url: This value specifies the endpoint to access with the S3 Connector. This is
     an optional property; change it only if you want to try a different service endpoint or want to
     switch between https and http. Type: string (or Expression with resultType string).
    :vartype service_url: any
    :ivar session_token: The session token for the S3 temporary security credential.
    :vartype session_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'object'},
        'access_key_id': {'key': 'typeProperties.accessKeyId', 'type': 'object'},
        'secret_access_key': {'key': 'typeProperties.secretAccessKey', 'type': 'SecretBase'},
        'service_url': {'key': 'typeProperties.serviceUrl', 'type': 'object'},
        'session_token': {'key': 'typeProperties.sessionToken', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        authentication_type: Optional[Any] = None,
        access_key_id: Optional[Any] = None,
        secret_access_key: Optional["SecretBase"] = None,
        service_url: Optional[Any] = None,
        session_token: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword authentication_type: The authentication type of S3. Allowed value: AccessKey (default)
         or TemporarySecurityCredentials. Type: string (or Expression with resultType string).
        :paramtype authentication_type: any
        :keyword access_key_id: The access key identifier of the Amazon S3 Identity and Access
         Management (IAM) user. Type: string (or Expression with resultType string).
        :paramtype access_key_id: any
        :keyword secret_access_key: The secret access key of the Amazon S3 Identity and Access
         Management (IAM) user.
        :paramtype secret_access_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword service_url: This value specifies the endpoint to access with the S3 Connector. This
         is an optional property; change it only if you want to try a different service endpoint or want
         to switch between https and http. Type: string (or Expression with resultType string).
        :paramtype service_url: any
        :keyword session_token: The session token for the S3 temporary security credential.
        :paramtype session_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(AmazonS3LinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AmazonS3'  # type: str
        self.authentication_type = authentication_type
        self.access_key_id = access_key_id
        self.secret_access_key = secret_access_key
        self.service_url = service_url
        self.session_token = session_token
        self.encrypted_credential = encrypted_credential


class AmazonS3Location(DatasetLocation):
    """The location of amazon S3 dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    :ivar bucket_name: Specify the bucketName of amazon S3. Type: string (or Expression with
     resultType string).
    :vartype bucket_name: any
    :ivar version: Specify the version of amazon S3. Type: string (or Expression with resultType
     string).
    :vartype version: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
        'bucket_name': {'key': 'bucketName', 'type': 'object'},
        'version': {'key': 'version', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        bucket_name: Optional[Any] = None,
        version: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        :keyword bucket_name: Specify the bucketName of amazon S3. Type: string (or Expression with
         resultType string).
        :paramtype bucket_name: any
        :keyword version: Specify the version of amazon S3. Type: string (or Expression with resultType
         string).
        :paramtype version: any
        """
        super(AmazonS3Location, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'AmazonS3Location'  # type: str
        self.bucket_name = bucket_name
        self.version = version


class AmazonS3ReadSettings(StoreReadSettings):
    """Amazon S3 read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar wildcard_folder_path: AmazonS3 wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :vartype wildcard_folder_path: any
    :ivar wildcard_file_name: AmazonS3 wildcardFileName. Type: string (or Expression with
     resultType string).
    :vartype wildcard_file_name: any
    :ivar prefix: The prefix filter for the S3 object name. Type: string (or Expression with
     resultType string).
    :vartype prefix: any
    :ivar file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :vartype file_list_path: any
    :ivar enable_partition_discovery: Indicates whether to enable partition discovery.
    :vartype enable_partition_discovery: bool
    :ivar partition_root_path: Specify the root path where partition discovery starts from. Type:
     string (or Expression with resultType string).
    :vartype partition_root_path: any
    :ivar delete_files_after_completion: Indicates whether the source files need to be deleted
     after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
    :vartype delete_files_after_completion: any
    :ivar modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :vartype modified_datetime_end: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'object'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'object'},
        'prefix': {'key': 'prefix', 'type': 'object'},
        'file_list_path': {'key': 'fileListPath', 'type': 'object'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'partition_root_path': {'key': 'partitionRootPath', 'type': 'object'},
        'delete_files_after_completion': {'key': 'deleteFilesAfterCompletion', 'type': 'object'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        wildcard_folder_path: Optional[Any] = None,
        wildcard_file_name: Optional[Any] = None,
        prefix: Optional[Any] = None,
        file_list_path: Optional[Any] = None,
        enable_partition_discovery: Optional[bool] = None,
        partition_root_path: Optional[Any] = None,
        delete_files_after_completion: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword wildcard_folder_path: AmazonS3 wildcardFolderPath. Type: string (or Expression with
         resultType string).
        :paramtype wildcard_folder_path: any
        :keyword wildcard_file_name: AmazonS3 wildcardFileName. Type: string (or Expression with
         resultType string).
        :paramtype wildcard_file_name: any
        :keyword prefix: The prefix filter for the S3 object name. Type: string (or Expression with
         resultType string).
        :paramtype prefix: any
        :keyword file_list_path: Point to a text file that lists each file (relative path to the path
         configured in the dataset) that you want to copy. Type: string (or Expression with resultType
         string).
        :paramtype file_list_path: any
        :keyword enable_partition_discovery: Indicates whether to enable partition discovery.
        :paramtype enable_partition_discovery: bool
        :keyword partition_root_path: Specify the root path where partition discovery starts from.
         Type: string (or Expression with resultType string).
        :paramtype partition_root_path: any
        :keyword delete_files_after_completion: Indicates whether the source files need to be deleted
         after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype delete_files_after_completion: any
        :keyword modified_datetime_start: The start of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        """
        super(AmazonS3ReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AmazonS3ReadSettings'  # type: str
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.prefix = prefix
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.partition_root_path = partition_root_path
        self.delete_files_after_completion = delete_files_after_completion
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class ControlActivity(Activity):
    """Base class for all control activities like IfCondition, ForEach , Until.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AppendVariableActivity, ExecutePipelineActivity, FailActivity, FilterActivity, ForEachActivity, IfConditionActivity, SetVariableActivity, SwitchActivity, UntilActivity, ValidationActivity, WaitActivity, WebHookActivity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
    }

    _subtype_map = {
        'type': {'AppendVariable': 'AppendVariableActivity', 'ExecutePipeline': 'ExecutePipelineActivity', 'Fail': 'FailActivity', 'Filter': 'FilterActivity', 'ForEach': 'ForEachActivity', 'IfCondition': 'IfConditionActivity', 'SetVariable': 'SetVariableActivity', 'Switch': 'SwitchActivity', 'Until': 'UntilActivity', 'Validation': 'ValidationActivity', 'Wait': 'WaitActivity', 'WebHook': 'WebHookActivity'}
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        """
        super(ControlActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Container'  # type: str


class AppendVariableActivity(ControlActivity):
    """Append value for a Variable of type Array.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar variable_name: Name of the variable whose value needs to be appended to.
    :vartype variable_name: str
    :ivar value: Value to be appended. Could be a static value or Expression.
    :vartype value: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'variable_name': {'key': 'typeProperties.variableName', 'type': 'str'},
        'value': {'key': 'typeProperties.value', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        variable_name: Optional[str] = None,
        value: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword variable_name: Name of the variable whose value needs to be appended to.
        :paramtype variable_name: str
        :keyword value: Value to be appended. Could be a static value or Expression.
        :paramtype value: any
        """
        super(AppendVariableActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'AppendVariable'  # type: str
        self.variable_name = variable_name
        self.value = value


class AppFiguresLinkedService(LinkedService):
    """Linked service for AppFigures.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar user_name: Required. The username of the Appfigures source.
    :vartype user_name: any
    :ivar password: Required. The password of the AppFigures source.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar client_key: Required. The client key for the AppFigures source.
    :vartype client_key: ~azure.mgmt.datafactory.models.SecretBase
    """

    _validation = {
        'type': {'required': True},
        'user_name': {'required': True},
        'password': {'required': True},
        'client_key': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'client_key': {'key': 'typeProperties.clientKey', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        user_name: Any,
        password: "SecretBase",
        client_key: "SecretBase",
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword user_name: Required. The username of the Appfigures source.
        :paramtype user_name: any
        :keyword password: Required. The password of the AppFigures source.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword client_key: Required. The client key for the AppFigures source.
        :paramtype client_key: ~azure.mgmt.datafactory.models.SecretBase
        """
        super(AppFiguresLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AppFigures'  # type: str
        self.user_name = user_name
        self.password = password
        self.client_key = client_key


class ArmIdWrapper(msrest.serialization.Model):
    """A wrapper for an ARM resource id.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar id:
    :vartype id: str
    """

    _validation = {
        'id': {'readonly': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(ArmIdWrapper, self).__init__(**kwargs)
        self.id = None


class AsanaLinkedService(LinkedService):
    """Linked service for Asana.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar api_token: Required. The api token for the Asana source.
    :vartype api_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'api_token': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'api_token': {'key': 'typeProperties.apiToken', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        api_token: "SecretBase",
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword api_token: Required. The api token for the Asana source.
        :paramtype api_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(AsanaLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Asana'  # type: str
        self.api_token = api_token
        self.encrypted_credential = encrypted_credential


class AvroDataset(Dataset):
    """Avro dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar location: The location of the avro storage.
    :vartype location: ~azure.mgmt.datafactory.models.DatasetLocation
    :ivar avro_compression_codec: The data avroCompressionCodec. Type: string (or Expression with
     resultType string).
    :vartype avro_compression_codec: any
    :ivar avro_compression_level:
    :vartype avro_compression_level: int
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'avro_compression_level': {'maximum': 9, 'minimum': 1},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'avro_compression_codec': {'key': 'typeProperties.avroCompressionCodec', 'type': 'object'},
        'avro_compression_level': {'key': 'typeProperties.avroCompressionLevel', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        avro_compression_codec: Optional[Any] = None,
        avro_compression_level: Optional[int] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword location: The location of the avro storage.
        :paramtype location: ~azure.mgmt.datafactory.models.DatasetLocation
        :keyword avro_compression_codec: The data avroCompressionCodec. Type: string (or Expression
         with resultType string).
        :paramtype avro_compression_codec: any
        :keyword avro_compression_level:
        :paramtype avro_compression_level: int
        """
        super(AvroDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Avro'  # type: str
        self.location = location
        self.avro_compression_codec = avro_compression_codec
        self.avro_compression_level = avro_compression_level


class DatasetStorageFormat(msrest.serialization.Model):
    """The format definition of a storage.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AvroFormat, JsonFormat, OrcFormat, ParquetFormat, TextFormat.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage format.Constant filled by server.
    :vartype type: str
    :ivar serializer: Serializer. Type: string (or Expression with resultType string).
    :vartype serializer: any
    :ivar deserializer: Deserializer. Type: string (or Expression with resultType string).
    :vartype deserializer: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'serializer': {'key': 'serializer', 'type': 'object'},
        'deserializer': {'key': 'deserializer', 'type': 'object'},
    }

    _subtype_map = {
        'type': {'AvroFormat': 'AvroFormat', 'JsonFormat': 'JsonFormat', 'OrcFormat': 'OrcFormat', 'ParquetFormat': 'ParquetFormat', 'TextFormat': 'TextFormat'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        serializer: Optional[Any] = None,
        deserializer: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword serializer: Serializer. Type: string (or Expression with resultType string).
        :paramtype serializer: any
        :keyword deserializer: Deserializer. Type: string (or Expression with resultType string).
        :paramtype deserializer: any
        """
        super(DatasetStorageFormat, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'DatasetStorageFormat'  # type: str
        self.serializer = serializer
        self.deserializer = deserializer


class AvroFormat(DatasetStorageFormat):
    """The data stored in Avro format.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage format.Constant filled by server.
    :vartype type: str
    :ivar serializer: Serializer. Type: string (or Expression with resultType string).
    :vartype serializer: any
    :ivar deserializer: Deserializer. Type: string (or Expression with resultType string).
    :vartype deserializer: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'serializer': {'key': 'serializer', 'type': 'object'},
        'deserializer': {'key': 'deserializer', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        serializer: Optional[Any] = None,
        deserializer: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword serializer: Serializer. Type: string (or Expression with resultType string).
        :paramtype serializer: any
        :keyword deserializer: Deserializer. Type: string (or Expression with resultType string).
        :paramtype deserializer: any
        """
        super(AvroFormat, self).__init__(additional_properties=additional_properties, serializer=serializer, deserializer=deserializer, **kwargs)
        self.type = 'AvroFormat'  # type: str


class CopySink(msrest.serialization.Model):
    """A copy activity sink.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AvroSink, AzureBlobFSSink, AzureDataExplorerSink, AzureDataLakeStoreSink, AzureDatabricksDeltaLakeSink, AzureMySqlSink, AzurePostgreSqlSink, AzureQueueSink, AzureSearchIndexSink, AzureSqlSink, AzureTableSink, BinarySink, BlobSink, CommonDataServiceForAppsSink, CosmosDbMongoDbApiSink, CosmosDbSqlApiSink, DelimitedTextSink, DocumentDbCollectionSink, DynamicsCrmSink, DynamicsSink, FileSystemSink, InformixSink, JsonSink, MicrosoftAccessSink, MongoDbAtlasSink, MongoDbV2Sink, OdbcSink, OracleSink, OrcSink, ParquetSink, RestSink, SalesforceServiceCloudSink, SalesforceSink, SapCloudForCustomerSink, SnowflakeSink, SqlDWSink, SqlMISink, SqlServerSink, SqlSink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
    }

    _subtype_map = {
        'type': {'AvroSink': 'AvroSink', 'AzureBlobFSSink': 'AzureBlobFSSink', 'AzureDataExplorerSink': 'AzureDataExplorerSink', 'AzureDataLakeStoreSink': 'AzureDataLakeStoreSink', 'AzureDatabricksDeltaLakeSink': 'AzureDatabricksDeltaLakeSink', 'AzureMySqlSink': 'AzureMySqlSink', 'AzurePostgreSqlSink': 'AzurePostgreSqlSink', 'AzureQueueSink': 'AzureQueueSink', 'AzureSearchIndexSink': 'AzureSearchIndexSink', 'AzureSqlSink': 'AzureSqlSink', 'AzureTableSink': 'AzureTableSink', 'BinarySink': 'BinarySink', 'BlobSink': 'BlobSink', 'CommonDataServiceForAppsSink': 'CommonDataServiceForAppsSink', 'CosmosDbMongoDbApiSink': 'CosmosDbMongoDbApiSink', 'CosmosDbSqlApiSink': 'CosmosDbSqlApiSink', 'DelimitedTextSink': 'DelimitedTextSink', 'DocumentDbCollectionSink': 'DocumentDbCollectionSink', 'DynamicsCrmSink': 'DynamicsCrmSink', 'DynamicsSink': 'DynamicsSink', 'FileSystemSink': 'FileSystemSink', 'InformixSink': 'InformixSink', 'JsonSink': 'JsonSink', 'MicrosoftAccessSink': 'MicrosoftAccessSink', 'MongoDbAtlasSink': 'MongoDbAtlasSink', 'MongoDbV2Sink': 'MongoDbV2Sink', 'OdbcSink': 'OdbcSink', 'OracleSink': 'OracleSink', 'OrcSink': 'OrcSink', 'ParquetSink': 'ParquetSink', 'RestSink': 'RestSink', 'SalesforceServiceCloudSink': 'SalesforceServiceCloudSink', 'SalesforceSink': 'SalesforceSink', 'SapCloudForCustomerSink': 'SapCloudForCustomerSink', 'SnowflakeSink': 'SnowflakeSink', 'SqlDWSink': 'SqlDWSink', 'SqlMISink': 'SqlMISink', 'SqlServerSink': 'SqlServerSink', 'SqlSink': 'SqlSink'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        """
        super(CopySink, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'CopySink'  # type: str
        self.write_batch_size = write_batch_size
        self.write_batch_timeout = write_batch_timeout
        self.sink_retry_count = sink_retry_count
        self.sink_retry_wait = sink_retry_wait
        self.max_concurrent_connections = max_concurrent_connections
        self.disable_metrics_collection = disable_metrics_collection


class AvroSink(CopySink):
    """A copy activity Avro sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: Avro store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreWriteSettings
    :ivar format_settings: Avro format settings.
    :vartype format_settings: ~azure.mgmt.datafactory.models.AvroWriteSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreWriteSettings'},
        'format_settings': {'key': 'formatSettings', 'type': 'AvroWriteSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreWriteSettings"] = None,
        format_settings: Optional["AvroWriteSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: Avro store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreWriteSettings
        :keyword format_settings: Avro format settings.
        :paramtype format_settings: ~azure.mgmt.datafactory.models.AvroWriteSettings
        """
        super(AvroSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AvroSink'  # type: str
        self.store_settings = store_settings
        self.format_settings = format_settings


class AvroSource(CopySource):
    """A copy activity Avro source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: Avro store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: Avro store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(AvroSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AvroSource'  # type: str
        self.store_settings = store_settings
        self.additional_columns = additional_columns


class FormatWriteSettings(msrest.serialization.Model):
    """Format write settings.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AvroWriteSettings, DelimitedTextWriteSettings, JsonWriteSettings, OrcWriteSettings, ParquetWriteSettings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The write setting type.Constant filled by server.
    :vartype type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'AvroWriteSettings': 'AvroWriteSettings', 'DelimitedTextWriteSettings': 'DelimitedTextWriteSettings', 'JsonWriteSettings': 'JsonWriteSettings', 'OrcWriteSettings': 'OrcWriteSettings', 'ParquetWriteSettings': 'ParquetWriteSettings'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(FormatWriteSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'FormatWriteSettings'  # type: str


class AvroWriteSettings(FormatWriteSettings):
    """Avro write settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The write setting type.Constant filled by server.
    :vartype type: str
    :ivar record_name: Top level record name in write result, which is required in AVRO spec.
    :vartype record_name: str
    :ivar record_namespace: Record namespace in the write result.
    :vartype record_namespace: str
    :ivar max_rows_per_file: Limit the written file's row count to be smaller than or equal to the
     specified count. Type: integer (or Expression with resultType integer).
    :vartype max_rows_per_file: any
    :ivar file_name_prefix: Specifies the file name pattern
     :code:`<fileNamePrefix>`_:code:`<fileIndex>`.:code:`<fileExtension>` when copy from non-file
     based store without partitionOptions. Type: string (or Expression with resultType string).
    :vartype file_name_prefix: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'record_name': {'key': 'recordName', 'type': 'str'},
        'record_namespace': {'key': 'recordNamespace', 'type': 'str'},
        'max_rows_per_file': {'key': 'maxRowsPerFile', 'type': 'object'},
        'file_name_prefix': {'key': 'fileNamePrefix', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        record_name: Optional[str] = None,
        record_namespace: Optional[str] = None,
        max_rows_per_file: Optional[Any] = None,
        file_name_prefix: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword record_name: Top level record name in write result, which is required in AVRO spec.
        :paramtype record_name: str
        :keyword record_namespace: Record namespace in the write result.
        :paramtype record_namespace: str
        :keyword max_rows_per_file: Limit the written file's row count to be smaller than or equal to
         the specified count. Type: integer (or Expression with resultType integer).
        :paramtype max_rows_per_file: any
        :keyword file_name_prefix: Specifies the file name pattern
         :code:`<fileNamePrefix>`_:code:`<fileIndex>`.:code:`<fileExtension>` when copy from non-file
         based store without partitionOptions. Type: string (or Expression with resultType string).
        :paramtype file_name_prefix: any
        """
        super(AvroWriteSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'AvroWriteSettings'  # type: str
        self.record_name = record_name
        self.record_namespace = record_namespace
        self.max_rows_per_file = max_rows_per_file
        self.file_name_prefix = file_name_prefix


class CustomSetupBase(msrest.serialization.Model):
    """The base definition of the custom setup.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AzPowerShellSetup, CmdkeySetup, ComponentSetup, EnvironmentVariableSetup.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. The type of custom setup.Constant filled by server.
    :vartype type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'AzPowerShellSetup': 'AzPowerShellSetup', 'CmdkeySetup': 'CmdkeySetup', 'ComponentSetup': 'ComponentSetup', 'EnvironmentVariableSetup': 'EnvironmentVariableSetup'}
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(CustomSetupBase, self).__init__(**kwargs)
        self.type = None  # type: Optional[str]


class AzPowerShellSetup(CustomSetupBase):
    """The express custom setup of installing Azure PowerShell.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. The type of custom setup.Constant filled by server.
    :vartype type: str
    :ivar version: Required. The required version of Azure PowerShell to install.
    :vartype version: str
    """

    _validation = {
        'type': {'required': True},
        'version': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'version': {'key': 'typeProperties.version', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        version: str,
        **kwargs
    ):
        """
        :keyword version: Required. The required version of Azure PowerShell to install.
        :paramtype version: str
        """
        super(AzPowerShellSetup, self).__init__(**kwargs)
        self.type = 'AzPowerShellSetup'  # type: str
        self.version = version


class AzureBatchLinkedService(LinkedService):
    """Azure Batch linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar account_name: Required. The Azure Batch account name. Type: string (or Expression with
     resultType string).
    :vartype account_name: any
    :ivar access_key: The Azure Batch account access key.
    :vartype access_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar batch_uri: Required. The Azure Batch URI. Type: string (or Expression with resultType
     string).
    :vartype batch_uri: any
    :ivar pool_name: Required. The Azure Batch pool name. Type: string (or Expression with
     resultType string).
    :vartype pool_name: any
    :ivar linked_service_name: Required. The Azure Storage linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'type': {'required': True},
        'account_name': {'required': True},
        'batch_uri': {'required': True},
        'pool_name': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'account_name': {'key': 'typeProperties.accountName', 'type': 'object'},
        'access_key': {'key': 'typeProperties.accessKey', 'type': 'SecretBase'},
        'batch_uri': {'key': 'typeProperties.batchUri', 'type': 'object'},
        'pool_name': {'key': 'typeProperties.poolName', 'type': 'object'},
        'linked_service_name': {'key': 'typeProperties.linkedServiceName', 'type': 'LinkedServiceReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        account_name: Any,
        batch_uri: Any,
        pool_name: Any,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        access_key: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword account_name: Required. The Azure Batch account name. Type: string (or Expression with
         resultType string).
        :paramtype account_name: any
        :keyword access_key: The Azure Batch account access key.
        :paramtype access_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword batch_uri: Required. The Azure Batch URI. Type: string (or Expression with resultType
         string).
        :paramtype batch_uri: any
        :keyword pool_name: Required. The Azure Batch pool name. Type: string (or Expression with
         resultType string).
        :paramtype pool_name: any
        :keyword linked_service_name: Required. The Azure Storage linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(AzureBatchLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureBatch'  # type: str
        self.account_name = account_name
        self.access_key = access_key
        self.batch_uri = batch_uri
        self.pool_name = pool_name
        self.linked_service_name = linked_service_name
        self.encrypted_credential = encrypted_credential
        self.credential = credential


class AzureBlobDataset(Dataset):
    """The Azure Blob storage.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar folder_path: The path of the Azure Blob storage. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar table_root_location: The root of blob path. Type: string (or Expression with resultType
     string).
    :vartype table_root_location: any
    :ivar file_name: The name of the Azure Blob. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    :ivar modified_datetime_start: The start of Azure Blob's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of Azure Blob's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_end: any
    :ivar format: The format of the Azure Blob storage.
    :vartype format: ~azure.mgmt.datafactory.models.DatasetStorageFormat
    :ivar compression: The data compression method used for the blob storage.
    :vartype compression: ~azure.mgmt.datafactory.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'folder_path': {'key': 'typeProperties.folderPath', 'type': 'object'},
        'table_root_location': {'key': 'typeProperties.tableRootLocation', 'type': 'object'},
        'file_name': {'key': 'typeProperties.fileName', 'type': 'object'},
        'modified_datetime_start': {'key': 'typeProperties.modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'typeProperties.modifiedDatetimeEnd', 'type': 'object'},
        'format': {'key': 'typeProperties.format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        folder_path: Optional[Any] = None,
        table_root_location: Optional[Any] = None,
        file_name: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword folder_path: The path of the Azure Blob storage. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword table_root_location: The root of blob path. Type: string (or Expression with
         resultType string).
        :paramtype table_root_location: any
        :keyword file_name: The name of the Azure Blob. Type: string (or Expression with resultType
         string).
        :paramtype file_name: any
        :keyword modified_datetime_start: The start of Azure Blob's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of Azure Blob's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        :keyword format: The format of the Azure Blob storage.
        :paramtype format: ~azure.mgmt.datafactory.models.DatasetStorageFormat
        :keyword compression: The data compression method used for the blob storage.
        :paramtype compression: ~azure.mgmt.datafactory.models.DatasetCompression
        """
        super(AzureBlobDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureBlob'  # type: str
        self.folder_path = folder_path
        self.table_root_location = table_root_location
        self.file_name = file_name
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end
        self.format = format
        self.compression = compression


class AzureBlobFSDataset(Dataset):
    """The Azure Data Lake Storage Gen2 storage.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar folder_path: The path of the Azure Data Lake Storage Gen2 storage. Type: string (or
     Expression with resultType string).
    :vartype folder_path: any
    :ivar file_name: The name of the Azure Data Lake Storage Gen2. Type: string (or Expression with
     resultType string).
    :vartype file_name: any
    :ivar format: The format of the Azure Data Lake Storage Gen2 storage.
    :vartype format: ~azure.mgmt.datafactory.models.DatasetStorageFormat
    :ivar compression: The data compression method used for the blob storage.
    :vartype compression: ~azure.mgmt.datafactory.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'folder_path': {'key': 'typeProperties.folderPath', 'type': 'object'},
        'file_name': {'key': 'typeProperties.fileName', 'type': 'object'},
        'format': {'key': 'typeProperties.format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword folder_path: The path of the Azure Data Lake Storage Gen2 storage. Type: string (or
         Expression with resultType string).
        :paramtype folder_path: any
        :keyword file_name: The name of the Azure Data Lake Storage Gen2. Type: string (or Expression
         with resultType string).
        :paramtype file_name: any
        :keyword format: The format of the Azure Data Lake Storage Gen2 storage.
        :paramtype format: ~azure.mgmt.datafactory.models.DatasetStorageFormat
        :keyword compression: The data compression method used for the blob storage.
        :paramtype compression: ~azure.mgmt.datafactory.models.DatasetCompression
        """
        super(AzureBlobFSDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureBlobFSFile'  # type: str
        self.folder_path = folder_path
        self.file_name = file_name
        self.format = format
        self.compression = compression


class AzureBlobFSLinkedService(LinkedService):
    """Azure Data Lake Storage Gen2 linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar url: Required. Endpoint for the Azure Data Lake Storage Gen2 service. Type: string (or
     Expression with resultType string).
    :vartype url: any
    :ivar account_key: Account key for the Azure Data Lake Storage Gen2 service. Type: string (or
     Expression with resultType string).
    :vartype account_key: any
    :ivar service_principal_id: The ID of the application used to authenticate against the Azure
     Data Lake Storage Gen2 account. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: The Key of the application used to authenticate against the Azure
     Data Lake Storage Gen2 account.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar tenant: The name or ID of the tenant to which the service principal belongs. Type: string
     (or Expression with resultType string).
    :vartype tenant: any
    :ivar azure_cloud_type: Indicates the azure cloud type of the service principle auth. Allowed
     values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is the data
     factory regions cloud type. Type: string (or Expression with resultType string).
    :vartype azure_cloud_type: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    :ivar service_principal_credential_type: The service principal credential type to use in
     Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
     for certificate. Type: string (or Expression with resultType string).
    :vartype service_principal_credential_type: any
    :ivar service_principal_credential: The credential of the service principal object in Azure
     Active Directory. If servicePrincipalCredentialType is 'ServicePrincipalKey',
     servicePrincipalCredential can be SecureString or AzureKeyVaultSecretReference. If
     servicePrincipalCredentialType is 'ServicePrincipalCert', servicePrincipalCredential can only
     be AzureKeyVaultSecretReference.
    :vartype service_principal_credential: ~azure.mgmt.datafactory.models.SecretBase
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'url': {'key': 'typeProperties.url', 'type': 'object'},
        'account_key': {'key': 'typeProperties.accountKey', 'type': 'object'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'azure_cloud_type': {'key': 'typeProperties.azureCloudType', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
        'service_principal_credential_type': {'key': 'typeProperties.servicePrincipalCredentialType', 'type': 'object'},
        'service_principal_credential': {'key': 'typeProperties.servicePrincipalCredential', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        url: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        account_key: Optional[Any] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional[Any] = None,
        azure_cloud_type: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        credential: Optional["CredentialReference"] = None,
        service_principal_credential_type: Optional[Any] = None,
        service_principal_credential: Optional["SecretBase"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword url: Required. Endpoint for the Azure Data Lake Storage Gen2 service. Type: string (or
         Expression with resultType string).
        :paramtype url: any
        :keyword account_key: Account key for the Azure Data Lake Storage Gen2 service. Type: string
         (or Expression with resultType string).
        :paramtype account_key: any
        :keyword service_principal_id: The ID of the application used to authenticate against the Azure
         Data Lake Storage Gen2 account. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: The Key of the application used to authenticate against the
         Azure Data Lake Storage Gen2 account.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword tenant: The name or ID of the tenant to which the service principal belongs. Type:
         string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword azure_cloud_type: Indicates the azure cloud type of the service principle auth.
         Allowed values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is
         the data factory regions cloud type. Type: string (or Expression with resultType string).
        :paramtype azure_cloud_type: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        :keyword service_principal_credential_type: The service principal credential type to use in
         Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
         for certificate. Type: string (or Expression with resultType string).
        :paramtype service_principal_credential_type: any
        :keyword service_principal_credential: The credential of the service principal object in Azure
         Active Directory. If servicePrincipalCredentialType is 'ServicePrincipalKey',
         servicePrincipalCredential can be SecureString or AzureKeyVaultSecretReference. If
         servicePrincipalCredentialType is 'ServicePrincipalCert', servicePrincipalCredential can only
         be AzureKeyVaultSecretReference.
        :paramtype service_principal_credential: ~azure.mgmt.datafactory.models.SecretBase
        """
        super(AzureBlobFSLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureBlobFS'  # type: str
        self.url = url
        self.account_key = account_key
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.azure_cloud_type = azure_cloud_type
        self.encrypted_credential = encrypted_credential
        self.credential = credential
        self.service_principal_credential_type = service_principal_credential_type
        self.service_principal_credential = service_principal_credential


class AzureBlobFSLocation(DatasetLocation):
    """The location of azure blobFS dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    :ivar file_system: Specify the fileSystem of azure blobFS. Type: string (or Expression with
     resultType string).
    :vartype file_system: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
        'file_system': {'key': 'fileSystem', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        file_system: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        :keyword file_system: Specify the fileSystem of azure blobFS. Type: string (or Expression with
         resultType string).
        :paramtype file_system: any
        """
        super(AzureBlobFSLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'AzureBlobFSLocation'  # type: str
        self.file_system = file_system


class AzureBlobFSReadSettings(StoreReadSettings):
    """Azure blobFS read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar wildcard_folder_path: Azure blobFS wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :vartype wildcard_folder_path: any
    :ivar wildcard_file_name: Azure blobFS wildcardFileName. Type: string (or Expression with
     resultType string).
    :vartype wildcard_file_name: any
    :ivar file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :vartype file_list_path: any
    :ivar enable_partition_discovery: Indicates whether to enable partition discovery.
    :vartype enable_partition_discovery: bool
    :ivar partition_root_path: Specify the root path where partition discovery starts from. Type:
     string (or Expression with resultType string).
    :vartype partition_root_path: any
    :ivar delete_files_after_completion: Indicates whether the source files need to be deleted
     after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
    :vartype delete_files_after_completion: any
    :ivar modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :vartype modified_datetime_end: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'object'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'object'},
        'file_list_path': {'key': 'fileListPath', 'type': 'object'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'partition_root_path': {'key': 'partitionRootPath', 'type': 'object'},
        'delete_files_after_completion': {'key': 'deleteFilesAfterCompletion', 'type': 'object'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        wildcard_folder_path: Optional[Any] = None,
        wildcard_file_name: Optional[Any] = None,
        file_list_path: Optional[Any] = None,
        enable_partition_discovery: Optional[bool] = None,
        partition_root_path: Optional[Any] = None,
        delete_files_after_completion: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword wildcard_folder_path: Azure blobFS wildcardFolderPath. Type: string (or Expression
         with resultType string).
        :paramtype wildcard_folder_path: any
        :keyword wildcard_file_name: Azure blobFS wildcardFileName. Type: string (or Expression with
         resultType string).
        :paramtype wildcard_file_name: any
        :keyword file_list_path: Point to a text file that lists each file (relative path to the path
         configured in the dataset) that you want to copy. Type: string (or Expression with resultType
         string).
        :paramtype file_list_path: any
        :keyword enable_partition_discovery: Indicates whether to enable partition discovery.
        :paramtype enable_partition_discovery: bool
        :keyword partition_root_path: Specify the root path where partition discovery starts from.
         Type: string (or Expression with resultType string).
        :paramtype partition_root_path: any
        :keyword delete_files_after_completion: Indicates whether the source files need to be deleted
         after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype delete_files_after_completion: any
        :keyword modified_datetime_start: The start of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        """
        super(AzureBlobFSReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureBlobFSReadSettings'  # type: str
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.partition_root_path = partition_root_path
        self.delete_files_after_completion = delete_files_after_completion
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class AzureBlobFSSink(CopySink):
    """A copy activity Azure Data Lake Storage Gen2 sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar copy_behavior: The type of copy behavior for copy sink.
    :vartype copy_behavior: any
    :ivar metadata: Specify the custom metadata to be added to sink data. Type: array of objects
     (or Expression with resultType array of objects).
    :vartype metadata: list[~azure.mgmt.datafactory.models.MetadataItem]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'object'},
        'metadata': {'key': 'metadata', 'type': '[MetadataItem]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        copy_behavior: Optional[Any] = None,
        metadata: Optional[List["MetadataItem"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword copy_behavior: The type of copy behavior for copy sink.
        :paramtype copy_behavior: any
        :keyword metadata: Specify the custom metadata to be added to sink data. Type: array of objects
         (or Expression with resultType array of objects).
        :paramtype metadata: list[~azure.mgmt.datafactory.models.MetadataItem]
        """
        super(AzureBlobFSSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureBlobFSSink'  # type: str
        self.copy_behavior = copy_behavior
        self.metadata = metadata


class AzureBlobFSSource(CopySource):
    """A copy activity Azure BlobFS source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar treat_empty_as_null: Treat empty as null. Type: boolean (or Expression with resultType
     boolean).
    :vartype treat_empty_as_null: any
    :ivar skip_header_line_count: Number of header lines to skip from each blob. Type: integer (or
     Expression with resultType integer).
    :vartype skip_header_line_count: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'treat_empty_as_null': {'key': 'treatEmptyAsNull', 'type': 'object'},
        'skip_header_line_count': {'key': 'skipHeaderLineCount', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        treat_empty_as_null: Optional[Any] = None,
        skip_header_line_count: Optional[Any] = None,
        recursive: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword treat_empty_as_null: Treat empty as null. Type: boolean (or Expression with resultType
         boolean).
        :paramtype treat_empty_as_null: any
        :keyword skip_header_line_count: Number of header lines to skip from each blob. Type: integer
         (or Expression with resultType integer).
        :paramtype skip_header_line_count: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        """
        super(AzureBlobFSSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureBlobFSSource'  # type: str
        self.treat_empty_as_null = treat_empty_as_null
        self.skip_header_line_count = skip_header_line_count
        self.recursive = recursive


class StoreWriteSettings(msrest.serialization.Model):
    """Connector write settings.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AzureBlobFSWriteSettings, AzureBlobStorageWriteSettings, AzureDataLakeStoreWriteSettings, AzureFileStorageWriteSettings, FileServerWriteSettings, SftpWriteSettings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The write setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar copy_behavior: The type of copy behavior for copy sink.
    :vartype copy_behavior: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'object'},
    }

    _subtype_map = {
        'type': {'AzureBlobFSWriteSettings': 'AzureBlobFSWriteSettings', 'AzureBlobStorageWriteSettings': 'AzureBlobStorageWriteSettings', 'AzureDataLakeStoreWriteSettings': 'AzureDataLakeStoreWriteSettings', 'AzureFileStorageWriteSettings': 'AzureFileStorageWriteSettings', 'FileServerWriteSettings': 'FileServerWriteSettings', 'SftpWriteSettings': 'SftpWriteSettings'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        copy_behavior: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword copy_behavior: The type of copy behavior for copy sink.
        :paramtype copy_behavior: any
        """
        super(StoreWriteSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'StoreWriteSettings'  # type: str
        self.max_concurrent_connections = max_concurrent_connections
        self.disable_metrics_collection = disable_metrics_collection
        self.copy_behavior = copy_behavior


class AzureBlobFSWriteSettings(StoreWriteSettings):
    """Azure blobFS write settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The write setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar copy_behavior: The type of copy behavior for copy sink.
    :vartype copy_behavior: any
    :ivar block_size_in_mb: Indicates the block size(MB) when writing data to blob. Type: integer
     (or Expression with resultType integer).
    :vartype block_size_in_mb: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'object'},
        'block_size_in_mb': {'key': 'blockSizeInMB', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        copy_behavior: Optional[Any] = None,
        block_size_in_mb: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword copy_behavior: The type of copy behavior for copy sink.
        :paramtype copy_behavior: any
        :keyword block_size_in_mb: Indicates the block size(MB) when writing data to blob. Type:
         integer (or Expression with resultType integer).
        :paramtype block_size_in_mb: any
        """
        super(AzureBlobFSWriteSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, copy_behavior=copy_behavior, **kwargs)
        self.type = 'AzureBlobFSWriteSettings'  # type: str
        self.block_size_in_mb = block_size_in_mb


class AzureBlobStorageLinkedService(LinkedService):
    """The azure blob storage linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: The connection string. It is mutually exclusive with sasUri,
     serviceEndpoint property. Type: string, SecureString or AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar account_key: The Azure key vault secret reference of accountKey in connection string.
    :vartype account_key: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar sas_uri: SAS URI of the Azure Blob Storage resource. It is mutually exclusive with
     connectionString, serviceEndpoint property. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype sas_uri: any
    :ivar sas_token: The Azure key vault secret reference of sasToken in sas uri.
    :vartype sas_token: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar service_endpoint: Blob service endpoint of the Azure Blob Storage resource. It is
     mutually exclusive with connectionString, sasUri property.
    :vartype service_endpoint: str
    :ivar service_principal_id: The ID of the service principal used to authenticate against Azure
     SQL Data Warehouse. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: The key of the service principal used to authenticate against
     Azure SQL Data Warehouse.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar tenant: The name or ID of the tenant to which the service principal belongs. Type: string
     (or Expression with resultType string).
    :vartype tenant: any
    :ivar azure_cloud_type: Indicates the azure cloud type of the service principle auth. Allowed
     values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is the data
     factory regions cloud type. Type: string (or Expression with resultType string).
    :vartype azure_cloud_type: any
    :ivar account_kind: Specify the kind of your storage account. Allowed values are: Storage
     (general purpose v1), StorageV2 (general purpose v2), BlobStorage, or BlockBlobStorage. Type:
     string (or Expression with resultType string).
    :vartype account_kind: str
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: str
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'account_key': {'key': 'typeProperties.accountKey', 'type': 'AzureKeyVaultSecretReference'},
        'sas_uri': {'key': 'typeProperties.sasUri', 'type': 'object'},
        'sas_token': {'key': 'typeProperties.sasToken', 'type': 'AzureKeyVaultSecretReference'},
        'service_endpoint': {'key': 'typeProperties.serviceEndpoint', 'type': 'str'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'azure_cloud_type': {'key': 'typeProperties.azureCloudType', 'type': 'object'},
        'account_kind': {'key': 'typeProperties.accountKind', 'type': 'str'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'str'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        account_key: Optional["AzureKeyVaultSecretReference"] = None,
        sas_uri: Optional[Any] = None,
        sas_token: Optional["AzureKeyVaultSecretReference"] = None,
        service_endpoint: Optional[str] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional[Any] = None,
        azure_cloud_type: Optional[Any] = None,
        account_kind: Optional[str] = None,
        encrypted_credential: Optional[str] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: The connection string. It is mutually exclusive with sasUri,
         serviceEndpoint property. Type: string, SecureString or AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword account_key: The Azure key vault secret reference of accountKey in connection string.
        :paramtype account_key: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword sas_uri: SAS URI of the Azure Blob Storage resource. It is mutually exclusive with
         connectionString, serviceEndpoint property. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype sas_uri: any
        :keyword sas_token: The Azure key vault secret reference of sasToken in sas uri.
        :paramtype sas_token: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword service_endpoint: Blob service endpoint of the Azure Blob Storage resource. It is
         mutually exclusive with connectionString, sasUri property.
        :paramtype service_endpoint: str
        :keyword service_principal_id: The ID of the service principal used to authenticate against
         Azure SQL Data Warehouse. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: The key of the service principal used to authenticate against
         Azure SQL Data Warehouse.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword tenant: The name or ID of the tenant to which the service principal belongs. Type:
         string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword azure_cloud_type: Indicates the azure cloud type of the service principle auth.
         Allowed values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is
         the data factory regions cloud type. Type: string (or Expression with resultType string).
        :paramtype azure_cloud_type: any
        :keyword account_kind: Specify the kind of your storage account. Allowed values are: Storage
         (general purpose v1), StorageV2 (general purpose v2), BlobStorage, or BlockBlobStorage. Type:
         string (or Expression with resultType string).
        :paramtype account_kind: str
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: str
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(AzureBlobStorageLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureBlobStorage'  # type: str
        self.connection_string = connection_string
        self.account_key = account_key
        self.sas_uri = sas_uri
        self.sas_token = sas_token
        self.service_endpoint = service_endpoint
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.azure_cloud_type = azure_cloud_type
        self.account_kind = account_kind
        self.encrypted_credential = encrypted_credential
        self.credential = credential


class AzureBlobStorageLocation(DatasetLocation):
    """The location of azure blob dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    :ivar container: Specify the container of azure blob. Type: string (or Expression with
     resultType string).
    :vartype container: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
        'container': {'key': 'container', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        container: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        :keyword container: Specify the container of azure blob. Type: string (or Expression with
         resultType string).
        :paramtype container: any
        """
        super(AzureBlobStorageLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'AzureBlobStorageLocation'  # type: str
        self.container = container


class AzureBlobStorageReadSettings(StoreReadSettings):
    """Azure blob read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar wildcard_folder_path: Azure blob wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :vartype wildcard_folder_path: any
    :ivar wildcard_file_name: Azure blob wildcardFileName. Type: string (or Expression with
     resultType string).
    :vartype wildcard_file_name: any
    :ivar prefix: The prefix filter for the Azure Blob name. Type: string (or Expression with
     resultType string).
    :vartype prefix: any
    :ivar file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :vartype file_list_path: any
    :ivar enable_partition_discovery: Indicates whether to enable partition discovery.
    :vartype enable_partition_discovery: bool
    :ivar partition_root_path: Specify the root path where partition discovery starts from. Type:
     string (or Expression with resultType string).
    :vartype partition_root_path: any
    :ivar delete_files_after_completion: Indicates whether the source files need to be deleted
     after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
    :vartype delete_files_after_completion: any
    :ivar modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :vartype modified_datetime_end: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'object'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'object'},
        'prefix': {'key': 'prefix', 'type': 'object'},
        'file_list_path': {'key': 'fileListPath', 'type': 'object'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'partition_root_path': {'key': 'partitionRootPath', 'type': 'object'},
        'delete_files_after_completion': {'key': 'deleteFilesAfterCompletion', 'type': 'object'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        wildcard_folder_path: Optional[Any] = None,
        wildcard_file_name: Optional[Any] = None,
        prefix: Optional[Any] = None,
        file_list_path: Optional[Any] = None,
        enable_partition_discovery: Optional[bool] = None,
        partition_root_path: Optional[Any] = None,
        delete_files_after_completion: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword wildcard_folder_path: Azure blob wildcardFolderPath. Type: string (or Expression with
         resultType string).
        :paramtype wildcard_folder_path: any
        :keyword wildcard_file_name: Azure blob wildcardFileName. Type: string (or Expression with
         resultType string).
        :paramtype wildcard_file_name: any
        :keyword prefix: The prefix filter for the Azure Blob name. Type: string (or Expression with
         resultType string).
        :paramtype prefix: any
        :keyword file_list_path: Point to a text file that lists each file (relative path to the path
         configured in the dataset) that you want to copy. Type: string (or Expression with resultType
         string).
        :paramtype file_list_path: any
        :keyword enable_partition_discovery: Indicates whether to enable partition discovery.
        :paramtype enable_partition_discovery: bool
        :keyword partition_root_path: Specify the root path where partition discovery starts from.
         Type: string (or Expression with resultType string).
        :paramtype partition_root_path: any
        :keyword delete_files_after_completion: Indicates whether the source files need to be deleted
         after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype delete_files_after_completion: any
        :keyword modified_datetime_start: The start of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        """
        super(AzureBlobStorageReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureBlobStorageReadSettings'  # type: str
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.prefix = prefix
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.partition_root_path = partition_root_path
        self.delete_files_after_completion = delete_files_after_completion
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class AzureBlobStorageWriteSettings(StoreWriteSettings):
    """Azure blob write settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The write setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar copy_behavior: The type of copy behavior for copy sink.
    :vartype copy_behavior: any
    :ivar block_size_in_mb: Indicates the block size(MB) when writing data to blob. Type: integer
     (or Expression with resultType integer).
    :vartype block_size_in_mb: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'object'},
        'block_size_in_mb': {'key': 'blockSizeInMB', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        copy_behavior: Optional[Any] = None,
        block_size_in_mb: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword copy_behavior: The type of copy behavior for copy sink.
        :paramtype copy_behavior: any
        :keyword block_size_in_mb: Indicates the block size(MB) when writing data to blob. Type:
         integer (or Expression with resultType integer).
        :paramtype block_size_in_mb: any
        """
        super(AzureBlobStorageWriteSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, copy_behavior=copy_behavior, **kwargs)
        self.type = 'AzureBlobStorageWriteSettings'  # type: str
        self.block_size_in_mb = block_size_in_mb


class AzureDatabricksDeltaLakeDataset(Dataset):
    """Azure Databricks Delta Lake dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table: The name of delta table. Type: string (or Expression with resultType string).
    :vartype table: any
    :ivar database: The database name of delta table. Type: string (or Expression with resultType
     string).
    :vartype database: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'database': {'key': 'typeProperties.database', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table: Optional[Any] = None,
        database: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table: The name of delta table. Type: string (or Expression with resultType string).
        :paramtype table: any
        :keyword database: The database name of delta table. Type: string (or Expression with
         resultType string).
        :paramtype database: any
        """
        super(AzureDatabricksDeltaLakeDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureDatabricksDeltaLakeDataset'  # type: str
        self.table = table
        self.database = database


class ExportSettings(msrest.serialization.Model):
    """Export command settings.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AzureDatabricksDeltaLakeExportCommand, SnowflakeExportCopyCommand.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The export setting type.Constant filled by server.
    :vartype type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'AzureDatabricksDeltaLakeExportCommand': 'AzureDatabricksDeltaLakeExportCommand', 'SnowflakeExportCopyCommand': 'SnowflakeExportCopyCommand'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(ExportSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'ExportSettings'  # type: str


class AzureDatabricksDeltaLakeExportCommand(ExportSettings):
    """Azure Databricks Delta Lake export command settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The export setting type.Constant filled by server.
    :vartype type: str
    :ivar date_format: Specify the date format for the csv in Azure Databricks Delta Lake Copy.
     Type: string (or Expression with resultType string).
    :vartype date_format: any
    :ivar timestamp_format: Specify the timestamp format for the csv in Azure Databricks Delta Lake
     Copy. Type: string (or Expression with resultType string).
    :vartype timestamp_format: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'date_format': {'key': 'dateFormat', 'type': 'object'},
        'timestamp_format': {'key': 'timestampFormat', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        date_format: Optional[Any] = None,
        timestamp_format: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword date_format: Specify the date format for the csv in Azure Databricks Delta Lake Copy.
         Type: string (or Expression with resultType string).
        :paramtype date_format: any
        :keyword timestamp_format: Specify the timestamp format for the csv in Azure Databricks Delta
         Lake Copy. Type: string (or Expression with resultType string).
        :paramtype timestamp_format: any
        """
        super(AzureDatabricksDeltaLakeExportCommand, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'AzureDatabricksDeltaLakeExportCommand'  # type: str
        self.date_format = date_format
        self.timestamp_format = timestamp_format


class ImportSettings(msrest.serialization.Model):
    """Import command settings.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AzureDatabricksDeltaLakeImportCommand, SnowflakeImportCopyCommand.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The import setting type.Constant filled by server.
    :vartype type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'AzureDatabricksDeltaLakeImportCommand': 'AzureDatabricksDeltaLakeImportCommand', 'SnowflakeImportCopyCommand': 'SnowflakeImportCopyCommand'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(ImportSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'ImportSettings'  # type: str


class AzureDatabricksDeltaLakeImportCommand(ImportSettings):
    """Azure Databricks Delta Lake import command settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The import setting type.Constant filled by server.
    :vartype type: str
    :ivar date_format: Specify the date format for csv in Azure Databricks Delta Lake Copy. Type:
     string (or Expression with resultType string).
    :vartype date_format: any
    :ivar timestamp_format: Specify the timestamp format for csv in Azure Databricks Delta Lake
     Copy. Type: string (or Expression with resultType string).
    :vartype timestamp_format: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'date_format': {'key': 'dateFormat', 'type': 'object'},
        'timestamp_format': {'key': 'timestampFormat', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        date_format: Optional[Any] = None,
        timestamp_format: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword date_format: Specify the date format for csv in Azure Databricks Delta Lake Copy.
         Type: string (or Expression with resultType string).
        :paramtype date_format: any
        :keyword timestamp_format: Specify the timestamp format for csv in Azure Databricks Delta Lake
         Copy. Type: string (or Expression with resultType string).
        :paramtype timestamp_format: any
        """
        super(AzureDatabricksDeltaLakeImportCommand, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'AzureDatabricksDeltaLakeImportCommand'  # type: str
        self.date_format = date_format
        self.timestamp_format = timestamp_format


class AzureDatabricksDeltaLakeLinkedService(LinkedService):
    """Azure Databricks Delta Lake linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar domain: Required. :code:`<REGION>`.azuredatabricks.net, domain name of your Databricks
     deployment. Type: string (or Expression with resultType string).
    :vartype domain: any
    :ivar access_token: Access token for databricks REST API. Refer to
     https://docs.azuredatabricks.net/api/latest/authentication.html. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype access_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar cluster_id: The id of an existing interactive cluster that will be used for all runs of
     this job. Type: string (or Expression with resultType string).
    :vartype cluster_id: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    :ivar workspace_resource_id: Workspace resource id for databricks REST API. Type: string (or
     Expression with resultType string).
    :vartype workspace_resource_id: any
    """

    _validation = {
        'type': {'required': True},
        'domain': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'domain': {'key': 'typeProperties.domain', 'type': 'object'},
        'access_token': {'key': 'typeProperties.accessToken', 'type': 'SecretBase'},
        'cluster_id': {'key': 'typeProperties.clusterId', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
        'workspace_resource_id': {'key': 'typeProperties.workspaceResourceId', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        domain: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        access_token: Optional["SecretBase"] = None,
        cluster_id: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        credential: Optional["CredentialReference"] = None,
        workspace_resource_id: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword domain: Required. :code:`<REGION>`.azuredatabricks.net, domain name of your Databricks
         deployment. Type: string (or Expression with resultType string).
        :paramtype domain: any
        :keyword access_token: Access token for databricks REST API. Refer to
         https://docs.azuredatabricks.net/api/latest/authentication.html. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype access_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword cluster_id: The id of an existing interactive cluster that will be used for all runs
         of this job. Type: string (or Expression with resultType string).
        :paramtype cluster_id: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        :keyword workspace_resource_id: Workspace resource id for databricks REST API. Type: string (or
         Expression with resultType string).
        :paramtype workspace_resource_id: any
        """
        super(AzureDatabricksDeltaLakeLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureDatabricksDeltaLake'  # type: str
        self.domain = domain
        self.access_token = access_token
        self.cluster_id = cluster_id
        self.encrypted_credential = encrypted_credential
        self.credential = credential
        self.workspace_resource_id = workspace_resource_id


class AzureDatabricksDeltaLakeSink(CopySink):
    """A copy activity Azure Databricks Delta Lake sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :vartype pre_copy_script: any
    :ivar import_settings: Azure Databricks Delta Lake import settings.
    :vartype import_settings: ~azure.mgmt.datafactory.models.AzureDatabricksDeltaLakeImportCommand
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'object'},
        'import_settings': {'key': 'importSettings', 'type': 'AzureDatabricksDeltaLakeImportCommand'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        pre_copy_script: Optional[Any] = None,
        import_settings: Optional["AzureDatabricksDeltaLakeImportCommand"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
         string).
        :paramtype pre_copy_script: any
        :keyword import_settings: Azure Databricks Delta Lake import settings.
        :paramtype import_settings:
         ~azure.mgmt.datafactory.models.AzureDatabricksDeltaLakeImportCommand
        """
        super(AzureDatabricksDeltaLakeSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureDatabricksDeltaLakeSink'  # type: str
        self.pre_copy_script = pre_copy_script
        self.import_settings = import_settings


class AzureDatabricksDeltaLakeSource(CopySource):
    """A copy activity Azure Databricks Delta Lake source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: Azure Databricks Delta Lake Sql query. Type: string (or Expression with resultType
     string).
    :vartype query: any
    :ivar export_settings: Azure Databricks Delta Lake export settings.
    :vartype export_settings: ~azure.mgmt.datafactory.models.AzureDatabricksDeltaLakeExportCommand
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'export_settings': {'key': 'exportSettings', 'type': 'AzureDatabricksDeltaLakeExportCommand'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query: Optional[Any] = None,
        export_settings: Optional["AzureDatabricksDeltaLakeExportCommand"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: Azure Databricks Delta Lake Sql query. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        :keyword export_settings: Azure Databricks Delta Lake export settings.
        :paramtype export_settings:
         ~azure.mgmt.datafactory.models.AzureDatabricksDeltaLakeExportCommand
        """
        super(AzureDatabricksDeltaLakeSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureDatabricksDeltaLakeSource'  # type: str
        self.query = query
        self.export_settings = export_settings


class AzureDatabricksLinkedService(LinkedService):
    """Azure Databricks linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar domain: Required. :code:`<REGION>`.azuredatabricks.net, domain name of your Databricks
     deployment. Type: string (or Expression with resultType string).
    :vartype domain: any
    :ivar access_token: Access token for databricks REST API. Refer to
     https://docs.azuredatabricks.net/api/latest/authentication.html. Type: string (or Expression
     with resultType string).
    :vartype access_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar authentication: Required to specify MSI, if using Workspace resource id for databricks
     REST API. Type: string (or Expression with resultType string).
    :vartype authentication: any
    :ivar workspace_resource_id: Workspace resource id for databricks REST API. Type: string (or
     Expression with resultType string).
    :vartype workspace_resource_id: any
    :ivar existing_cluster_id: The id of an existing interactive cluster that will be used for all
     runs of this activity. Type: string (or Expression with resultType string).
    :vartype existing_cluster_id: any
    :ivar instance_pool_id: The id of an existing instance pool that will be used for all runs of
     this activity. Type: string (or Expression with resultType string).
    :vartype instance_pool_id: any
    :ivar new_cluster_version: If not using an existing interactive cluster, this specifies the
     Spark version of a new job cluster or instance pool nodes created for each run of this
     activity. Required if instancePoolId is specified. Type: string (or Expression with resultType
     string).
    :vartype new_cluster_version: any
    :ivar new_cluster_num_of_worker: If not using an existing interactive cluster, this specifies
     the number of worker nodes to use for the new job cluster or instance pool. For new job
     clusters, this a string-formatted Int32, like '1' means numOfWorker is 1 or '1:10' means
     auto-scale from 1 (min) to 10 (max). For instance pools, this is a string-formatted Int32, and
     can only specify a fixed number of worker nodes, such as '2'. Required if newClusterVersion is
     specified. Type: string (or Expression with resultType string).
    :vartype new_cluster_num_of_worker: any
    :ivar new_cluster_node_type: The node type of the new job cluster. This property is required if
     newClusterVersion is specified and instancePoolId is not specified. If instancePoolId is
     specified, this property is ignored. Type: string (or Expression with resultType string).
    :vartype new_cluster_node_type: any
    :ivar new_cluster_spark_conf: A set of optional, user-specified Spark configuration key-value
     pairs.
    :vartype new_cluster_spark_conf: dict[str, any]
    :ivar new_cluster_spark_env_vars: A set of optional, user-specified Spark environment variables
     key-value pairs.
    :vartype new_cluster_spark_env_vars: dict[str, any]
    :ivar new_cluster_custom_tags: Additional tags for cluster resources. This property is ignored
     in instance pool configurations.
    :vartype new_cluster_custom_tags: dict[str, any]
    :ivar new_cluster_log_destination: Specify a location to deliver Spark driver, worker, and
     event logs. Type: string (or Expression with resultType string).
    :vartype new_cluster_log_destination: any
    :ivar new_cluster_driver_node_type: The driver node type for the new job cluster. This property
     is ignored in instance pool configurations. Type: string (or Expression with resultType
     string).
    :vartype new_cluster_driver_node_type: any
    :ivar new_cluster_init_scripts: User-defined initialization scripts for the new cluster. Type:
     array of strings (or Expression with resultType array of strings).
    :vartype new_cluster_init_scripts: any
    :ivar new_cluster_enable_elastic_disk: Enable the elastic disk on the new cluster. This
     property is now ignored, and takes the default elastic disk behavior in Databricks (elastic
     disks are always enabled). Type: boolean (or Expression with resultType boolean).
    :vartype new_cluster_enable_elastic_disk: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar policy_id: The policy id for limiting the ability to configure clusters based on a user
     defined set of rules. Type: string (or Expression with resultType string).
    :vartype policy_id: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'type': {'required': True},
        'domain': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'domain': {'key': 'typeProperties.domain', 'type': 'object'},
        'access_token': {'key': 'typeProperties.accessToken', 'type': 'SecretBase'},
        'authentication': {'key': 'typeProperties.authentication', 'type': 'object'},
        'workspace_resource_id': {'key': 'typeProperties.workspaceResourceId', 'type': 'object'},
        'existing_cluster_id': {'key': 'typeProperties.existingClusterId', 'type': 'object'},
        'instance_pool_id': {'key': 'typeProperties.instancePoolId', 'type': 'object'},
        'new_cluster_version': {'key': 'typeProperties.newClusterVersion', 'type': 'object'},
        'new_cluster_num_of_worker': {'key': 'typeProperties.newClusterNumOfWorker', 'type': 'object'},
        'new_cluster_node_type': {'key': 'typeProperties.newClusterNodeType', 'type': 'object'},
        'new_cluster_spark_conf': {'key': 'typeProperties.newClusterSparkConf', 'type': '{object}'},
        'new_cluster_spark_env_vars': {'key': 'typeProperties.newClusterSparkEnvVars', 'type': '{object}'},
        'new_cluster_custom_tags': {'key': 'typeProperties.newClusterCustomTags', 'type': '{object}'},
        'new_cluster_log_destination': {'key': 'typeProperties.newClusterLogDestination', 'type': 'object'},
        'new_cluster_driver_node_type': {'key': 'typeProperties.newClusterDriverNodeType', 'type': 'object'},
        'new_cluster_init_scripts': {'key': 'typeProperties.newClusterInitScripts', 'type': 'object'},
        'new_cluster_enable_elastic_disk': {'key': 'typeProperties.newClusterEnableElasticDisk', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'policy_id': {'key': 'typeProperties.policyId', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        domain: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        access_token: Optional["SecretBase"] = None,
        authentication: Optional[Any] = None,
        workspace_resource_id: Optional[Any] = None,
        existing_cluster_id: Optional[Any] = None,
        instance_pool_id: Optional[Any] = None,
        new_cluster_version: Optional[Any] = None,
        new_cluster_num_of_worker: Optional[Any] = None,
        new_cluster_node_type: Optional[Any] = None,
        new_cluster_spark_conf: Optional[Dict[str, Any]] = None,
        new_cluster_spark_env_vars: Optional[Dict[str, Any]] = None,
        new_cluster_custom_tags: Optional[Dict[str, Any]] = None,
        new_cluster_log_destination: Optional[Any] = None,
        new_cluster_driver_node_type: Optional[Any] = None,
        new_cluster_init_scripts: Optional[Any] = None,
        new_cluster_enable_elastic_disk: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        policy_id: Optional[Any] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword domain: Required. :code:`<REGION>`.azuredatabricks.net, domain name of your Databricks
         deployment. Type: string (or Expression with resultType string).
        :paramtype domain: any
        :keyword access_token: Access token for databricks REST API. Refer to
         https://docs.azuredatabricks.net/api/latest/authentication.html. Type: string (or Expression
         with resultType string).
        :paramtype access_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword authentication: Required to specify MSI, if using Workspace resource id for databricks
         REST API. Type: string (or Expression with resultType string).
        :paramtype authentication: any
        :keyword workspace_resource_id: Workspace resource id for databricks REST API. Type: string (or
         Expression with resultType string).
        :paramtype workspace_resource_id: any
        :keyword existing_cluster_id: The id of an existing interactive cluster that will be used for
         all runs of this activity. Type: string (or Expression with resultType string).
        :paramtype existing_cluster_id: any
        :keyword instance_pool_id: The id of an existing instance pool that will be used for all runs
         of this activity. Type: string (or Expression with resultType string).
        :paramtype instance_pool_id: any
        :keyword new_cluster_version: If not using an existing interactive cluster, this specifies the
         Spark version of a new job cluster or instance pool nodes created for each run of this
         activity. Required if instancePoolId is specified. Type: string (or Expression with resultType
         string).
        :paramtype new_cluster_version: any
        :keyword new_cluster_num_of_worker: If not using an existing interactive cluster, this
         specifies the number of worker nodes to use for the new job cluster or instance pool. For new
         job clusters, this a string-formatted Int32, like '1' means numOfWorker is 1 or '1:10' means
         auto-scale from 1 (min) to 10 (max). For instance pools, this is a string-formatted Int32, and
         can only specify a fixed number of worker nodes, such as '2'. Required if newClusterVersion is
         specified. Type: string (or Expression with resultType string).
        :paramtype new_cluster_num_of_worker: any
        :keyword new_cluster_node_type: The node type of the new job cluster. This property is required
         if newClusterVersion is specified and instancePoolId is not specified. If instancePoolId is
         specified, this property is ignored. Type: string (or Expression with resultType string).
        :paramtype new_cluster_node_type: any
        :keyword new_cluster_spark_conf: A set of optional, user-specified Spark configuration
         key-value pairs.
        :paramtype new_cluster_spark_conf: dict[str, any]
        :keyword new_cluster_spark_env_vars: A set of optional, user-specified Spark environment
         variables key-value pairs.
        :paramtype new_cluster_spark_env_vars: dict[str, any]
        :keyword new_cluster_custom_tags: Additional tags for cluster resources. This property is
         ignored in instance pool configurations.
        :paramtype new_cluster_custom_tags: dict[str, any]
        :keyword new_cluster_log_destination: Specify a location to deliver Spark driver, worker, and
         event logs. Type: string (or Expression with resultType string).
        :paramtype new_cluster_log_destination: any
        :keyword new_cluster_driver_node_type: The driver node type for the new job cluster. This
         property is ignored in instance pool configurations. Type: string (or Expression with
         resultType string).
        :paramtype new_cluster_driver_node_type: any
        :keyword new_cluster_init_scripts: User-defined initialization scripts for the new cluster.
         Type: array of strings (or Expression with resultType array of strings).
        :paramtype new_cluster_init_scripts: any
        :keyword new_cluster_enable_elastic_disk: Enable the elastic disk on the new cluster. This
         property is now ignored, and takes the default elastic disk behavior in Databricks (elastic
         disks are always enabled). Type: boolean (or Expression with resultType boolean).
        :paramtype new_cluster_enable_elastic_disk: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword policy_id: The policy id for limiting the ability to configure clusters based on a
         user defined set of rules. Type: string (or Expression with resultType string).
        :paramtype policy_id: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(AzureDatabricksLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureDatabricks'  # type: str
        self.domain = domain
        self.access_token = access_token
        self.authentication = authentication
        self.workspace_resource_id = workspace_resource_id
        self.existing_cluster_id = existing_cluster_id
        self.instance_pool_id = instance_pool_id
        self.new_cluster_version = new_cluster_version
        self.new_cluster_num_of_worker = new_cluster_num_of_worker
        self.new_cluster_node_type = new_cluster_node_type
        self.new_cluster_spark_conf = new_cluster_spark_conf
        self.new_cluster_spark_env_vars = new_cluster_spark_env_vars
        self.new_cluster_custom_tags = new_cluster_custom_tags
        self.new_cluster_log_destination = new_cluster_log_destination
        self.new_cluster_driver_node_type = new_cluster_driver_node_type
        self.new_cluster_init_scripts = new_cluster_init_scripts
        self.new_cluster_enable_elastic_disk = new_cluster_enable_elastic_disk
        self.encrypted_credential = encrypted_credential
        self.policy_id = policy_id
        self.credential = credential


class ExecutionActivity(Activity):
    """Base class for all execution activities.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AzureDataExplorerCommandActivity, AzureFunctionActivity, AzureMLBatchExecutionActivity, AzureMLExecutePipelineActivity, AzureMLUpdateResourceActivity, CopyActivity, CustomActivity, DataLakeAnalyticsUSQLActivity, DatabricksNotebookActivity, DatabricksSparkJarActivity, DatabricksSparkPythonActivity, DeleteActivity, ExecuteDataFlowActivity, ExecuteSSISPackageActivity, GetMetadataActivity, HDInsightHiveActivity, HDInsightMapReduceActivity, HDInsightPigActivity, HDInsightSparkActivity, HDInsightStreamingActivity, LookupActivity, ScriptActivity, SqlServerStoredProcedureActivity, WebActivity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
    }

    _subtype_map = {
        'type': {'AzureDataExplorerCommand': 'AzureDataExplorerCommandActivity', 'AzureFunctionActivity': 'AzureFunctionActivity', 'AzureMLBatchExecution': 'AzureMLBatchExecutionActivity', 'AzureMLExecutePipeline': 'AzureMLExecutePipelineActivity', 'AzureMLUpdateResource': 'AzureMLUpdateResourceActivity', 'Copy': 'CopyActivity', 'Custom': 'CustomActivity', 'DataLakeAnalyticsU-SQL': 'DataLakeAnalyticsUSQLActivity', 'DatabricksNotebook': 'DatabricksNotebookActivity', 'DatabricksSparkJar': 'DatabricksSparkJarActivity', 'DatabricksSparkPython': 'DatabricksSparkPythonActivity', 'Delete': 'DeleteActivity', 'ExecuteDataFlow': 'ExecuteDataFlowActivity', 'ExecuteSSISPackage': 'ExecuteSSISPackageActivity', 'GetMetadata': 'GetMetadataActivity', 'HDInsightHive': 'HDInsightHiveActivity', 'HDInsightMapReduce': 'HDInsightMapReduceActivity', 'HDInsightPig': 'HDInsightPigActivity', 'HDInsightSpark': 'HDInsightSparkActivity', 'HDInsightStreaming': 'HDInsightStreamingActivity', 'Lookup': 'LookupActivity', 'Script': 'ScriptActivity', 'SqlServerStoredProcedure': 'SqlServerStoredProcedureActivity', 'WebActivity': 'WebActivity'}
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        """
        super(ExecutionActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Execution'  # type: str
        self.linked_service_name = linked_service_name
        self.policy = policy


class AzureDataExplorerCommandActivity(ExecutionActivity):
    """Azure Data Explorer command activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar command: Required. A control command, according to the Azure Data Explorer command
     syntax. Type: string (or Expression with resultType string).
    :vartype command: any
    :ivar command_timeout: Control command timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9]))..).
    :vartype command_timeout: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'command': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'command': {'key': 'typeProperties.command', 'type': 'object'},
        'command_timeout': {'key': 'typeProperties.commandTimeout', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        command: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        command_timeout: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword command: Required. A control command, according to the Azure Data Explorer command
         syntax. Type: string (or Expression with resultType string).
        :paramtype command: any
        :keyword command_timeout: Control command timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9]))..).
        :paramtype command_timeout: any
        """
        super(AzureDataExplorerCommandActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'AzureDataExplorerCommand'  # type: str
        self.command = command
        self.command_timeout = command_timeout


class AzureDataExplorerLinkedService(LinkedService):
    """Azure Data Explorer (Kusto) linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar endpoint: Required. The endpoint of Azure Data Explorer (the engine's endpoint). URL will
     be in the format https://:code:`<clusterName>`.:code:`<regionName>`.kusto.windows.net. Type:
     string (or Expression with resultType string).
    :vartype endpoint: any
    :ivar service_principal_id: The ID of the service principal used to authenticate against Azure
     Data Explorer. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: The key of the service principal used to authenticate against
     Kusto.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar database: Required. Database name for connection. Type: string (or Expression with
     resultType string).
    :vartype database: any
    :ivar tenant: The name or ID of the tenant to which the service principal belongs. Type: string
     (or Expression with resultType string).
    :vartype tenant: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'object'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'database': {'key': 'typeProperties.database', 'type': 'object'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        endpoint: Any,
        database: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional[Any] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword endpoint: Required. The endpoint of Azure Data Explorer (the engine's endpoint). URL
         will be in the format https://:code:`<clusterName>`.:code:`<regionName>`.kusto.windows.net.
         Type: string (or Expression with resultType string).
        :paramtype endpoint: any
        :keyword service_principal_id: The ID of the service principal used to authenticate against
         Azure Data Explorer. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: The key of the service principal used to authenticate against
         Kusto.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword database: Required. Database name for connection. Type: string (or Expression with
         resultType string).
        :paramtype database: any
        :keyword tenant: The name or ID of the tenant to which the service principal belongs. Type:
         string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(AzureDataExplorerLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureDataExplorer'  # type: str
        self.endpoint = endpoint
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.database = database
        self.tenant = tenant
        self.credential = credential


class AzureDataExplorerSink(CopySink):
    """A copy activity Azure Data Explorer sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar ingestion_mapping_name: A name of a pre-created csv mapping that was defined on the
     target Kusto table. Type: string.
    :vartype ingestion_mapping_name: any
    :ivar ingestion_mapping_as_json: An explicit column mapping description provided in a json
     format. Type: string.
    :vartype ingestion_mapping_as_json: any
    :ivar flush_immediately: If set to true, any aggregation will be skipped. Default is false.
     Type: boolean.
    :vartype flush_immediately: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'ingestion_mapping_name': {'key': 'ingestionMappingName', 'type': 'object'},
        'ingestion_mapping_as_json': {'key': 'ingestionMappingAsJson', 'type': 'object'},
        'flush_immediately': {'key': 'flushImmediately', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        ingestion_mapping_name: Optional[Any] = None,
        ingestion_mapping_as_json: Optional[Any] = None,
        flush_immediately: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword ingestion_mapping_name: A name of a pre-created csv mapping that was defined on the
         target Kusto table. Type: string.
        :paramtype ingestion_mapping_name: any
        :keyword ingestion_mapping_as_json: An explicit column mapping description provided in a json
         format. Type: string.
        :paramtype ingestion_mapping_as_json: any
        :keyword flush_immediately: If set to true, any aggregation will be skipped. Default is false.
         Type: boolean.
        :paramtype flush_immediately: any
        """
        super(AzureDataExplorerSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureDataExplorerSink'  # type: str
        self.ingestion_mapping_name = ingestion_mapping_name
        self.ingestion_mapping_as_json = ingestion_mapping_as_json
        self.flush_immediately = flush_immediately


class AzureDataExplorerSource(CopySource):
    """A copy activity Azure Data Explorer (Kusto) source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: Required. Database query. Should be a Kusto Query Language (KQL) query. Type:
     string (or Expression with resultType string).
    :vartype query: any
    :ivar no_truncation: The name of the Boolean option that controls whether truncation is applied
     to result-sets that go beyond a certain row-count limit.
    :vartype no_truncation: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9]))..
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
        'query': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'no_truncation': {'key': 'noTruncation', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        query: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        no_truncation: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: Required. Database query. Should be a Kusto Query Language (KQL) query. Type:
         string (or Expression with resultType string).
        :paramtype query: any
        :keyword no_truncation: The name of the Boolean option that controls whether truncation is
         applied to result-sets that go beyond a certain row-count limit.
        :paramtype no_truncation: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9]))..
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(AzureDataExplorerSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureDataExplorerSource'  # type: str
        self.query = query
        self.no_truncation = no_truncation
        self.query_timeout = query_timeout
        self.additional_columns = additional_columns


class AzureDataExplorerTableDataset(Dataset):
    """The Azure Data Explorer (Kusto) dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table: The table name of the Azure Data Explorer database. Type: string (or Expression
     with resultType string).
    :vartype table: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table: The table name of the Azure Data Explorer database. Type: string (or Expression
         with resultType string).
        :paramtype table: any
        """
        super(AzureDataExplorerTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureDataExplorerTable'  # type: str
        self.table = table


class AzureDataLakeAnalyticsLinkedService(LinkedService):
    """Azure Data Lake Analytics linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar account_name: Required. The Azure Data Lake Analytics account name. Type: string (or
     Expression with resultType string).
    :vartype account_name: any
    :ivar service_principal_id: The ID of the application used to authenticate against the Azure
     Data Lake Analytics account. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: The Key of the application used to authenticate against the Azure
     Data Lake Analytics account.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar tenant: Required. The name or ID of the tenant to which the service principal belongs.
     Type: string (or Expression with resultType string).
    :vartype tenant: any
    :ivar subscription_id: Data Lake Analytics account subscription ID (if different from Data
     Factory account). Type: string (or Expression with resultType string).
    :vartype subscription_id: any
    :ivar resource_group_name: Data Lake Analytics account resource group name (if different from
     Data Factory account). Type: string (or Expression with resultType string).
    :vartype resource_group_name: any
    :ivar data_lake_analytics_uri: Azure Data Lake Analytics URI Type: string (or Expression with
     resultType string).
    :vartype data_lake_analytics_uri: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'account_name': {'required': True},
        'tenant': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'account_name': {'key': 'typeProperties.accountName', 'type': 'object'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'subscription_id': {'key': 'typeProperties.subscriptionId', 'type': 'object'},
        'resource_group_name': {'key': 'typeProperties.resourceGroupName', 'type': 'object'},
        'data_lake_analytics_uri': {'key': 'typeProperties.dataLakeAnalyticsUri', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        account_name: Any,
        tenant: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["SecretBase"] = None,
        subscription_id: Optional[Any] = None,
        resource_group_name: Optional[Any] = None,
        data_lake_analytics_uri: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword account_name: Required. The Azure Data Lake Analytics account name. Type: string (or
         Expression with resultType string).
        :paramtype account_name: any
        :keyword service_principal_id: The ID of the application used to authenticate against the Azure
         Data Lake Analytics account. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: The Key of the application used to authenticate against the
         Azure Data Lake Analytics account.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword tenant: Required. The name or ID of the tenant to which the service principal belongs.
         Type: string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword subscription_id: Data Lake Analytics account subscription ID (if different from Data
         Factory account). Type: string (or Expression with resultType string).
        :paramtype subscription_id: any
        :keyword resource_group_name: Data Lake Analytics account resource group name (if different
         from Data Factory account). Type: string (or Expression with resultType string).
        :paramtype resource_group_name: any
        :keyword data_lake_analytics_uri: Azure Data Lake Analytics URI Type: string (or Expression
         with resultType string).
        :paramtype data_lake_analytics_uri: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(AzureDataLakeAnalyticsLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureDataLakeAnalytics'  # type: str
        self.account_name = account_name
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.subscription_id = subscription_id
        self.resource_group_name = resource_group_name
        self.data_lake_analytics_uri = data_lake_analytics_uri
        self.encrypted_credential = encrypted_credential


class AzureDataLakeStoreDataset(Dataset):
    """Azure Data Lake Store dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar folder_path: Path to the folder in the Azure Data Lake Store. Type: string (or Expression
     with resultType string).
    :vartype folder_path: any
    :ivar file_name: The name of the file in the Azure Data Lake Store. Type: string (or Expression
     with resultType string).
    :vartype file_name: any
    :ivar format: The format of the Data Lake Store.
    :vartype format: ~azure.mgmt.datafactory.models.DatasetStorageFormat
    :ivar compression: The data compression method used for the item(s) in the Azure Data Lake
     Store.
    :vartype compression: ~azure.mgmt.datafactory.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'folder_path': {'key': 'typeProperties.folderPath', 'type': 'object'},
        'file_name': {'key': 'typeProperties.fileName', 'type': 'object'},
        'format': {'key': 'typeProperties.format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword folder_path: Path to the folder in the Azure Data Lake Store. Type: string (or
         Expression with resultType string).
        :paramtype folder_path: any
        :keyword file_name: The name of the file in the Azure Data Lake Store. Type: string (or
         Expression with resultType string).
        :paramtype file_name: any
        :keyword format: The format of the Data Lake Store.
        :paramtype format: ~azure.mgmt.datafactory.models.DatasetStorageFormat
        :keyword compression: The data compression method used for the item(s) in the Azure Data Lake
         Store.
        :paramtype compression: ~azure.mgmt.datafactory.models.DatasetCompression
        """
        super(AzureDataLakeStoreDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureDataLakeStoreFile'  # type: str
        self.folder_path = folder_path
        self.file_name = file_name
        self.format = format
        self.compression = compression


class AzureDataLakeStoreLinkedService(LinkedService):
    """Azure Data Lake Store linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar data_lake_store_uri: Required. Data Lake Store service URI. Type: string (or Expression
     with resultType string).
    :vartype data_lake_store_uri: any
    :ivar service_principal_id: The ID of the application used to authenticate against the Azure
     Data Lake Store account. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: The Key of the application used to authenticate against the Azure
     Data Lake Store account.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar tenant: The name or ID of the tenant to which the service principal belongs. Type: string
     (or Expression with resultType string).
    :vartype tenant: any
    :ivar azure_cloud_type: Indicates the azure cloud type of the service principle auth. Allowed
     values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is the data
     factory regions cloud type. Type: string (or Expression with resultType string).
    :vartype azure_cloud_type: any
    :ivar account_name: Data Lake Store account name. Type: string (or Expression with resultType
     string).
    :vartype account_name: any
    :ivar subscription_id: Data Lake Store account subscription ID (if different from Data Factory
     account). Type: string (or Expression with resultType string).
    :vartype subscription_id: any
    :ivar resource_group_name: Data Lake Store account resource group name (if different from Data
     Factory account). Type: string (or Expression with resultType string).
    :vartype resource_group_name: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'type': {'required': True},
        'data_lake_store_uri': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'data_lake_store_uri': {'key': 'typeProperties.dataLakeStoreUri', 'type': 'object'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'azure_cloud_type': {'key': 'typeProperties.azureCloudType', 'type': 'object'},
        'account_name': {'key': 'typeProperties.accountName', 'type': 'object'},
        'subscription_id': {'key': 'typeProperties.subscriptionId', 'type': 'object'},
        'resource_group_name': {'key': 'typeProperties.resourceGroupName', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        data_lake_store_uri: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional[Any] = None,
        azure_cloud_type: Optional[Any] = None,
        account_name: Optional[Any] = None,
        subscription_id: Optional[Any] = None,
        resource_group_name: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword data_lake_store_uri: Required. Data Lake Store service URI. Type: string (or
         Expression with resultType string).
        :paramtype data_lake_store_uri: any
        :keyword service_principal_id: The ID of the application used to authenticate against the Azure
         Data Lake Store account. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: The Key of the application used to authenticate against the
         Azure Data Lake Store account.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword tenant: The name or ID of the tenant to which the service principal belongs. Type:
         string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword azure_cloud_type: Indicates the azure cloud type of the service principle auth.
         Allowed values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is
         the data factory regions cloud type. Type: string (or Expression with resultType string).
        :paramtype azure_cloud_type: any
        :keyword account_name: Data Lake Store account name. Type: string (or Expression with
         resultType string).
        :paramtype account_name: any
        :keyword subscription_id: Data Lake Store account subscription ID (if different from Data
         Factory account). Type: string (or Expression with resultType string).
        :paramtype subscription_id: any
        :keyword resource_group_name: Data Lake Store account resource group name (if different from
         Data Factory account). Type: string (or Expression with resultType string).
        :paramtype resource_group_name: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(AzureDataLakeStoreLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureDataLakeStore'  # type: str
        self.data_lake_store_uri = data_lake_store_uri
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.azure_cloud_type = azure_cloud_type
        self.account_name = account_name
        self.subscription_id = subscription_id
        self.resource_group_name = resource_group_name
        self.encrypted_credential = encrypted_credential
        self.credential = credential


class AzureDataLakeStoreLocation(DatasetLocation):
    """The location of azure data lake store dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        """
        super(AzureDataLakeStoreLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'AzureDataLakeStoreLocation'  # type: str


class AzureDataLakeStoreReadSettings(StoreReadSettings):
    """Azure data lake store read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar wildcard_folder_path: ADLS wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :vartype wildcard_folder_path: any
    :ivar wildcard_file_name: ADLS wildcardFileName. Type: string (or Expression with resultType
     string).
    :vartype wildcard_file_name: any
    :ivar file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :vartype file_list_path: any
    :ivar list_after: Lists files after the value (exclusive) based on file/folder names
     lexicographical order. Applies under the folderPath in data set, and filter files/sub-folders
     under the folderPath. Type: string (or Expression with resultType string).
    :vartype list_after: any
    :ivar list_before: Lists files before the value (inclusive) based on file/folder names
     lexicographical order. Applies under the folderPath in data set, and filter files/sub-folders
     under the folderPath. Type: string (or Expression with resultType string).
    :vartype list_before: any
    :ivar enable_partition_discovery: Indicates whether to enable partition discovery.
    :vartype enable_partition_discovery: bool
    :ivar partition_root_path: Specify the root path where partition discovery starts from. Type:
     string (or Expression with resultType string).
    :vartype partition_root_path: any
    :ivar delete_files_after_completion: Indicates whether the source files need to be deleted
     after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
    :vartype delete_files_after_completion: any
    :ivar modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :vartype modified_datetime_end: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'object'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'object'},
        'file_list_path': {'key': 'fileListPath', 'type': 'object'},
        'list_after': {'key': 'listAfter', 'type': 'object'},
        'list_before': {'key': 'listBefore', 'type': 'object'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'partition_root_path': {'key': 'partitionRootPath', 'type': 'object'},
        'delete_files_after_completion': {'key': 'deleteFilesAfterCompletion', 'type': 'object'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        wildcard_folder_path: Optional[Any] = None,
        wildcard_file_name: Optional[Any] = None,
        file_list_path: Optional[Any] = None,
        list_after: Optional[Any] = None,
        list_before: Optional[Any] = None,
        enable_partition_discovery: Optional[bool] = None,
        partition_root_path: Optional[Any] = None,
        delete_files_after_completion: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword wildcard_folder_path: ADLS wildcardFolderPath. Type: string (or Expression with
         resultType string).
        :paramtype wildcard_folder_path: any
        :keyword wildcard_file_name: ADLS wildcardFileName. Type: string (or Expression with resultType
         string).
        :paramtype wildcard_file_name: any
        :keyword file_list_path: Point to a text file that lists each file (relative path to the path
         configured in the dataset) that you want to copy. Type: string (or Expression with resultType
         string).
        :paramtype file_list_path: any
        :keyword list_after: Lists files after the value (exclusive) based on file/folder names
         lexicographical order. Applies under the folderPath in data set, and filter files/sub-folders
         under the folderPath. Type: string (or Expression with resultType string).
        :paramtype list_after: any
        :keyword list_before: Lists files before the value (inclusive) based on file/folder names
         lexicographical order. Applies under the folderPath in data set, and filter files/sub-folders
         under the folderPath. Type: string (or Expression with resultType string).
        :paramtype list_before: any
        :keyword enable_partition_discovery: Indicates whether to enable partition discovery.
        :paramtype enable_partition_discovery: bool
        :keyword partition_root_path: Specify the root path where partition discovery starts from.
         Type: string (or Expression with resultType string).
        :paramtype partition_root_path: any
        :keyword delete_files_after_completion: Indicates whether the source files need to be deleted
         after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype delete_files_after_completion: any
        :keyword modified_datetime_start: The start of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        """
        super(AzureDataLakeStoreReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureDataLakeStoreReadSettings'  # type: str
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.file_list_path = file_list_path
        self.list_after = list_after
        self.list_before = list_before
        self.enable_partition_discovery = enable_partition_discovery
        self.partition_root_path = partition_root_path
        self.delete_files_after_completion = delete_files_after_completion
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class AzureDataLakeStoreSink(CopySink):
    """A copy activity Azure Data Lake Store sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar copy_behavior: The type of copy behavior for copy sink.
    :vartype copy_behavior: any
    :ivar enable_adls_single_file_parallel: Single File Parallel.
    :vartype enable_adls_single_file_parallel: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'object'},
        'enable_adls_single_file_parallel': {'key': 'enableAdlsSingleFileParallel', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        copy_behavior: Optional[Any] = None,
        enable_adls_single_file_parallel: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword copy_behavior: The type of copy behavior for copy sink.
        :paramtype copy_behavior: any
        :keyword enable_adls_single_file_parallel: Single File Parallel.
        :paramtype enable_adls_single_file_parallel: any
        """
        super(AzureDataLakeStoreSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureDataLakeStoreSink'  # type: str
        self.copy_behavior = copy_behavior
        self.enable_adls_single_file_parallel = enable_adls_single_file_parallel


class AzureDataLakeStoreSource(CopySource):
    """A copy activity Azure Data Lake source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        """
        super(AzureDataLakeStoreSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureDataLakeStoreSource'  # type: str
        self.recursive = recursive


class AzureDataLakeStoreWriteSettings(StoreWriteSettings):
    """Azure data lake store write settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The write setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar copy_behavior: The type of copy behavior for copy sink.
    :vartype copy_behavior: any
    :ivar expiry_date_time: Specifies the expiry time of the written files. The time is applied to
     the UTC time zone in the format of "2018-12-01T05:00:00Z". Default value is NULL. Type: integer
     (or Expression with resultType integer).
    :vartype expiry_date_time: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'object'},
        'expiry_date_time': {'key': 'expiryDateTime', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        copy_behavior: Optional[Any] = None,
        expiry_date_time: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword copy_behavior: The type of copy behavior for copy sink.
        :paramtype copy_behavior: any
        :keyword expiry_date_time: Specifies the expiry time of the written files. The time is applied
         to the UTC time zone in the format of "2018-12-01T05:00:00Z". Default value is NULL. Type:
         integer (or Expression with resultType integer).
        :paramtype expiry_date_time: any
        """
        super(AzureDataLakeStoreWriteSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, copy_behavior=copy_behavior, **kwargs)
        self.type = 'AzureDataLakeStoreWriteSettings'  # type: str
        self.expiry_date_time = expiry_date_time


class AzureFileStorageLinkedService(LinkedService):
    """Azure File Storage linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Host name of the server. Type: string (or Expression with resultType string).
    :vartype host: any
    :ivar user_id: User ID to logon the server. Type: string (or Expression with resultType
     string).
    :vartype user_id: any
    :ivar password: Password to logon the server.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar connection_string: The connection string. It is mutually exclusive with sasUri property.
     Type: string, SecureString or AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar account_key: The Azure key vault secret reference of accountKey in connection string.
    :vartype account_key: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar sas_uri: SAS URI of the Azure File resource. It is mutually exclusive with
     connectionString property. Type: string, SecureString or AzureKeyVaultSecretReference.
    :vartype sas_uri: any
    :ivar sas_token: The Azure key vault secret reference of sasToken in sas uri.
    :vartype sas_token: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar file_share: The azure file share name. It is required when auth with accountKey/sasToken.
     Type: string (or Expression with resultType string).
    :vartype file_share: any
    :ivar snapshot: The azure file share snapshot version. Type: string (or Expression with
     resultType string).
    :vartype snapshot: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'user_id': {'key': 'typeProperties.userId', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'account_key': {'key': 'typeProperties.accountKey', 'type': 'AzureKeyVaultSecretReference'},
        'sas_uri': {'key': 'typeProperties.sasUri', 'type': 'object'},
        'sas_token': {'key': 'typeProperties.sasToken', 'type': 'AzureKeyVaultSecretReference'},
        'file_share': {'key': 'typeProperties.fileShare', 'type': 'object'},
        'snapshot': {'key': 'typeProperties.snapshot', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        host: Optional[Any] = None,
        user_id: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        connection_string: Optional[Any] = None,
        account_key: Optional["AzureKeyVaultSecretReference"] = None,
        sas_uri: Optional[Any] = None,
        sas_token: Optional["AzureKeyVaultSecretReference"] = None,
        file_share: Optional[Any] = None,
        snapshot: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Host name of the server. Type: string (or Expression with resultType string).
        :paramtype host: any
        :keyword user_id: User ID to logon the server. Type: string (or Expression with resultType
         string).
        :paramtype user_id: any
        :keyword password: Password to logon the server.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword connection_string: The connection string. It is mutually exclusive with sasUri
         property. Type: string, SecureString or AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword account_key: The Azure key vault secret reference of accountKey in connection string.
        :paramtype account_key: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword sas_uri: SAS URI of the Azure File resource. It is mutually exclusive with
         connectionString property. Type: string, SecureString or AzureKeyVaultSecretReference.
        :paramtype sas_uri: any
        :keyword sas_token: The Azure key vault secret reference of sasToken in sas uri.
        :paramtype sas_token: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword file_share: The azure file share name. It is required when auth with
         accountKey/sasToken. Type: string (or Expression with resultType string).
        :paramtype file_share: any
        :keyword snapshot: The azure file share snapshot version. Type: string (or Expression with
         resultType string).
        :paramtype snapshot: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(AzureFileStorageLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureFileStorage'  # type: str
        self.host = host
        self.user_id = user_id
        self.password = password
        self.connection_string = connection_string
        self.account_key = account_key
        self.sas_uri = sas_uri
        self.sas_token = sas_token
        self.file_share = file_share
        self.snapshot = snapshot
        self.encrypted_credential = encrypted_credential


class AzureFileStorageLocation(DatasetLocation):
    """The location of file server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        """
        super(AzureFileStorageLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'AzureFileStorageLocation'  # type: str


class AzureFileStorageReadSettings(StoreReadSettings):
    """Azure File Storage read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar wildcard_folder_path: Azure File Storage wildcardFolderPath. Type: string (or Expression
     with resultType string).
    :vartype wildcard_folder_path: any
    :ivar wildcard_file_name: Azure File Storage wildcardFileName. Type: string (or Expression with
     resultType string).
    :vartype wildcard_file_name: any
    :ivar prefix: The prefix filter for the Azure File name starting from root path. Type: string
     (or Expression with resultType string).
    :vartype prefix: any
    :ivar file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :vartype file_list_path: any
    :ivar enable_partition_discovery: Indicates whether to enable partition discovery.
    :vartype enable_partition_discovery: bool
    :ivar partition_root_path: Specify the root path where partition discovery starts from. Type:
     string (or Expression with resultType string).
    :vartype partition_root_path: any
    :ivar delete_files_after_completion: Indicates whether the source files need to be deleted
     after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
    :vartype delete_files_after_completion: any
    :ivar modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :vartype modified_datetime_end: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'object'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'object'},
        'prefix': {'key': 'prefix', 'type': 'object'},
        'file_list_path': {'key': 'fileListPath', 'type': 'object'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'partition_root_path': {'key': 'partitionRootPath', 'type': 'object'},
        'delete_files_after_completion': {'key': 'deleteFilesAfterCompletion', 'type': 'object'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        wildcard_folder_path: Optional[Any] = None,
        wildcard_file_name: Optional[Any] = None,
        prefix: Optional[Any] = None,
        file_list_path: Optional[Any] = None,
        enable_partition_discovery: Optional[bool] = None,
        partition_root_path: Optional[Any] = None,
        delete_files_after_completion: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword wildcard_folder_path: Azure File Storage wildcardFolderPath. Type: string (or
         Expression with resultType string).
        :paramtype wildcard_folder_path: any
        :keyword wildcard_file_name: Azure File Storage wildcardFileName. Type: string (or Expression
         with resultType string).
        :paramtype wildcard_file_name: any
        :keyword prefix: The prefix filter for the Azure File name starting from root path. Type:
         string (or Expression with resultType string).
        :paramtype prefix: any
        :keyword file_list_path: Point to a text file that lists each file (relative path to the path
         configured in the dataset) that you want to copy. Type: string (or Expression with resultType
         string).
        :paramtype file_list_path: any
        :keyword enable_partition_discovery: Indicates whether to enable partition discovery.
        :paramtype enable_partition_discovery: bool
        :keyword partition_root_path: Specify the root path where partition discovery starts from.
         Type: string (or Expression with resultType string).
        :paramtype partition_root_path: any
        :keyword delete_files_after_completion: Indicates whether the source files need to be deleted
         after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype delete_files_after_completion: any
        :keyword modified_datetime_start: The start of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        """
        super(AzureFileStorageReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureFileStorageReadSettings'  # type: str
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.prefix = prefix
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.partition_root_path = partition_root_path
        self.delete_files_after_completion = delete_files_after_completion
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class AzureFileStorageWriteSettings(StoreWriteSettings):
    """Azure File Storage write settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The write setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar copy_behavior: The type of copy behavior for copy sink.
    :vartype copy_behavior: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        copy_behavior: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword copy_behavior: The type of copy behavior for copy sink.
        :paramtype copy_behavior: any
        """
        super(AzureFileStorageWriteSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, copy_behavior=copy_behavior, **kwargs)
        self.type = 'AzureFileStorageWriteSettings'  # type: str


class AzureFunctionActivity(ExecutionActivity):
    """Azure Function activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar method: Required. Rest API method for target endpoint. Possible values include: "GET",
     "POST", "PUT", "DELETE", "OPTIONS", "HEAD", "TRACE".
    :vartype method: str or ~azure.mgmt.datafactory.models.AzureFunctionActivityMethod
    :ivar function_name: Required. Name of the Function that the Azure Function Activity will call.
     Type: string (or Expression with resultType string).
    :vartype function_name: any
    :ivar headers: Represents the headers that will be sent to the request. For example, to set the
     language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type":
     "application/json" }. Type: string (or Expression with resultType string).
    :vartype headers: any
    :ivar body: Represents the payload that will be sent to the endpoint. Required for POST/PUT
     method, not allowed for GET method Type: string (or Expression with resultType string).
    :vartype body: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'method': {'required': True},
        'function_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'method': {'key': 'typeProperties.method', 'type': 'str'},
        'function_name': {'key': 'typeProperties.functionName', 'type': 'object'},
        'headers': {'key': 'typeProperties.headers', 'type': 'object'},
        'body': {'key': 'typeProperties.body', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        method: Union[str, "AzureFunctionActivityMethod"],
        function_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        headers: Optional[Any] = None,
        body: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword method: Required. Rest API method for target endpoint. Possible values include: "GET",
         "POST", "PUT", "DELETE", "OPTIONS", "HEAD", "TRACE".
        :paramtype method: str or ~azure.mgmt.datafactory.models.AzureFunctionActivityMethod
        :keyword function_name: Required. Name of the Function that the Azure Function Activity will
         call. Type: string (or Expression with resultType string).
        :paramtype function_name: any
        :keyword headers: Represents the headers that will be sent to the request. For example, to set
         the language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type":
         "application/json" }. Type: string (or Expression with resultType string).
        :paramtype headers: any
        :keyword body: Represents the payload that will be sent to the endpoint. Required for POST/PUT
         method, not allowed for GET method Type: string (or Expression with resultType string).
        :paramtype body: any
        """
        super(AzureFunctionActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'AzureFunctionActivity'  # type: str
        self.method = method
        self.function_name = function_name
        self.headers = headers
        self.body = body


class AzureFunctionLinkedService(LinkedService):
    """Azure Function linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar function_app_url: Required. The endpoint of the Azure Function App. URL will be in the
     format https://:code:`<accountName>`.azurewebsites.net.
    :vartype function_app_url: any
    :ivar function_key: Function or Host key for Azure Function App.
    :vartype function_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    :ivar resource_id: Allowed token audiences for azure function.
    :vartype resource_id: any
    :ivar authentication: Type of authentication (Required to specify MSI) used to connect to
     AzureFunction. Type: string (or Expression with resultType string).
    :vartype authentication: any
    """

    _validation = {
        'type': {'required': True},
        'function_app_url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'function_app_url': {'key': 'typeProperties.functionAppUrl', 'type': 'object'},
        'function_key': {'key': 'typeProperties.functionKey', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
        'resource_id': {'key': 'typeProperties.resourceId', 'type': 'object'},
        'authentication': {'key': 'typeProperties.authentication', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        function_app_url: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        function_key: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        credential: Optional["CredentialReference"] = None,
        resource_id: Optional[Any] = None,
        authentication: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword function_app_url: Required. The endpoint of the Azure Function App. URL will be in the
         format https://:code:`<accountName>`.azurewebsites.net.
        :paramtype function_app_url: any
        :keyword function_key: Function or Host key for Azure Function App.
        :paramtype function_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        :keyword resource_id: Allowed token audiences for azure function.
        :paramtype resource_id: any
        :keyword authentication: Type of authentication (Required to specify MSI) used to connect to
         AzureFunction. Type: string (or Expression with resultType string).
        :paramtype authentication: any
        """
        super(AzureFunctionLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureFunction'  # type: str
        self.function_app_url = function_app_url
        self.function_key = function_key
        self.encrypted_credential = encrypted_credential
        self.credential = credential
        self.resource_id = resource_id
        self.authentication = authentication


class AzureKeyVaultLinkedService(LinkedService):
    """Azure Key Vault linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar base_url: Required. The base URL of the Azure Key Vault. e.g.
     https://myakv.vault.azure.net Type: string (or Expression with resultType string).
    :vartype base_url: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'type': {'required': True},
        'base_url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'base_url': {'key': 'typeProperties.baseUrl', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        base_url: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword base_url: Required. The base URL of the Azure Key Vault. e.g.
         https://myakv.vault.azure.net Type: string (or Expression with resultType string).
        :paramtype base_url: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(AzureKeyVaultLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureKeyVault'  # type: str
        self.base_url = base_url
        self.credential = credential


class SecretBase(msrest.serialization.Model):
    """The base definition of a secret type.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AzureKeyVaultSecretReference, SecureString.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of the secret.Constant filled by server.
    :vartype type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'AzureKeyVaultSecret': 'AzureKeyVaultSecretReference', 'SecureString': 'SecureString'}
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(SecretBase, self).__init__(**kwargs)
        self.type = None  # type: Optional[str]


class AzureKeyVaultSecretReference(SecretBase):
    """Azure Key Vault secret reference.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of the secret.Constant filled by server.
    :vartype type: str
    :ivar store: Required. The Azure Key Vault linked service reference.
    :vartype store: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar secret_name: Required. The name of the secret in Azure Key Vault. Type: string (or
     Expression with resultType string).
    :vartype secret_name: any
    :ivar secret_version: The version of the secret in Azure Key Vault. The default value is the
     latest version of the secret. Type: string (or Expression with resultType string).
    :vartype secret_version: any
    """

    _validation = {
        'type': {'required': True},
        'store': {'required': True},
        'secret_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'store': {'key': 'store', 'type': 'LinkedServiceReference'},
        'secret_name': {'key': 'secretName', 'type': 'object'},
        'secret_version': {'key': 'secretVersion', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        store: "LinkedServiceReference",
        secret_name: Any,
        secret_version: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword store: Required. The Azure Key Vault linked service reference.
        :paramtype store: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword secret_name: Required. The name of the secret in Azure Key Vault. Type: string (or
         Expression with resultType string).
        :paramtype secret_name: any
        :keyword secret_version: The version of the secret in Azure Key Vault. The default value is the
         latest version of the secret. Type: string (or Expression with resultType string).
        :paramtype secret_version: any
        """
        super(AzureKeyVaultSecretReference, self).__init__(**kwargs)
        self.type = 'AzureKeyVaultSecret'  # type: str
        self.store = store
        self.secret_name = secret_name
        self.secret_version = secret_version


class AzureMariaDBLinkedService(LinkedService):
    """Azure Database for MariaDB linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar pwd: The Azure key vault secret reference of password in connection string.
    :vartype pwd: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'pwd': {'key': 'typeProperties.pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: An ODBC connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword pwd: The Azure key vault secret reference of password in connection string.
        :paramtype pwd: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(AzureMariaDBLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureMariaDB'  # type: str
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class AzureMariaDBSource(TabularSource):
    """A copy activity Azure MariaDB source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(AzureMariaDBSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AzureMariaDBSource'  # type: str
        self.query = query


class AzureMariaDBTableDataset(Dataset):
    """Azure Database for MariaDB dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(AzureMariaDBTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureMariaDBTable'  # type: str
        self.table_name = table_name


class AzureMLBatchExecutionActivity(ExecutionActivity):
    """Azure ML Batch Execution activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar global_parameters: Key,Value pairs to be passed to the Azure ML Batch Execution Service
     endpoint. Keys must match the names of web service parameters defined in the published Azure ML
     web service. Values will be passed in the GlobalParameters property of the Azure ML batch
     execution request.
    :vartype global_parameters: dict[str, any]
    :ivar web_service_outputs: Key,Value pairs, mapping the names of Azure ML endpoint's Web
     Service Outputs to AzureMLWebServiceFile objects specifying the output Blob locations. This
     information will be passed in the WebServiceOutputs property of the Azure ML batch execution
     request.
    :vartype web_service_outputs: dict[str, ~azure.mgmt.datafactory.models.AzureMLWebServiceFile]
    :ivar web_service_inputs: Key,Value pairs, mapping the names of Azure ML endpoint's Web Service
     Inputs to AzureMLWebServiceFile objects specifying the input Blob locations.. This information
     will be passed in the WebServiceInputs property of the Azure ML batch execution request.
    :vartype web_service_inputs: dict[str, ~azure.mgmt.datafactory.models.AzureMLWebServiceFile]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'global_parameters': {'key': 'typeProperties.globalParameters', 'type': '{object}'},
        'web_service_outputs': {'key': 'typeProperties.webServiceOutputs', 'type': '{AzureMLWebServiceFile}'},
        'web_service_inputs': {'key': 'typeProperties.webServiceInputs', 'type': '{AzureMLWebServiceFile}'},
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        global_parameters: Optional[Dict[str, Any]] = None,
        web_service_outputs: Optional[Dict[str, "AzureMLWebServiceFile"]] = None,
        web_service_inputs: Optional[Dict[str, "AzureMLWebServiceFile"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword global_parameters: Key,Value pairs to be passed to the Azure ML Batch Execution
         Service endpoint. Keys must match the names of web service parameters defined in the published
         Azure ML web service. Values will be passed in the GlobalParameters property of the Azure ML
         batch execution request.
        :paramtype global_parameters: dict[str, any]
        :keyword web_service_outputs: Key,Value pairs, mapping the names of Azure ML endpoint's Web
         Service Outputs to AzureMLWebServiceFile objects specifying the output Blob locations. This
         information will be passed in the WebServiceOutputs property of the Azure ML batch execution
         request.
        :paramtype web_service_outputs: dict[str, ~azure.mgmt.datafactory.models.AzureMLWebServiceFile]
        :keyword web_service_inputs: Key,Value pairs, mapping the names of Azure ML endpoint's Web
         Service Inputs to AzureMLWebServiceFile objects specifying the input Blob locations.. This
         information will be passed in the WebServiceInputs property of the Azure ML batch execution
         request.
        :paramtype web_service_inputs: dict[str, ~azure.mgmt.datafactory.models.AzureMLWebServiceFile]
        """
        super(AzureMLBatchExecutionActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'AzureMLBatchExecution'  # type: str
        self.global_parameters = global_parameters
        self.web_service_outputs = web_service_outputs
        self.web_service_inputs = web_service_inputs


class AzureMLExecutePipelineActivity(ExecutionActivity):
    """Azure ML Execute Pipeline activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar ml_pipeline_id: ID of the published Azure ML pipeline. Type: string (or Expression with
     resultType string).
    :vartype ml_pipeline_id: any
    :ivar ml_pipeline_endpoint_id: ID of the published Azure ML pipeline endpoint. Type: string (or
     Expression with resultType string).
    :vartype ml_pipeline_endpoint_id: any
    :ivar version: Version of the published Azure ML pipeline endpoint. Type: string (or Expression
     with resultType string).
    :vartype version: any
    :ivar experiment_name: Run history experiment name of the pipeline run. This information will
     be passed in the ExperimentName property of the published pipeline execution request. Type:
     string (or Expression with resultType string).
    :vartype experiment_name: any
    :ivar ml_pipeline_parameters: Key,Value pairs to be passed to the published Azure ML pipeline
     endpoint. Keys must match the names of pipeline parameters defined in the published pipeline.
     Values will be passed in the ParameterAssignments property of the published pipeline execution
     request. Type: object with key value pairs (or Expression with resultType object).
    :vartype ml_pipeline_parameters: any
    :ivar data_path_assignments: Dictionary used for changing data path assignments without
     retraining. Values will be passed in the dataPathAssignments property of the published pipeline
     execution request. Type: object with key value pairs (or Expression with resultType object).
    :vartype data_path_assignments: any
    :ivar ml_parent_run_id: The parent Azure ML Service pipeline run id. This information will be
     passed in the ParentRunId property of the published pipeline execution request. Type: string
     (or Expression with resultType string).
    :vartype ml_parent_run_id: any
    :ivar continue_on_step_failure: Whether to continue execution of other steps in the PipelineRun
     if a step fails. This information will be passed in the continueOnStepFailure property of the
     published pipeline execution request. Type: boolean (or Expression with resultType boolean).
    :vartype continue_on_step_failure: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'ml_pipeline_id': {'key': 'typeProperties.mlPipelineId', 'type': 'object'},
        'ml_pipeline_endpoint_id': {'key': 'typeProperties.mlPipelineEndpointId', 'type': 'object'},
        'version': {'key': 'typeProperties.version', 'type': 'object'},
        'experiment_name': {'key': 'typeProperties.experimentName', 'type': 'object'},
        'ml_pipeline_parameters': {'key': 'typeProperties.mlPipelineParameters', 'type': 'object'},
        'data_path_assignments': {'key': 'typeProperties.dataPathAssignments', 'type': 'object'},
        'ml_parent_run_id': {'key': 'typeProperties.mlParentRunId', 'type': 'object'},
        'continue_on_step_failure': {'key': 'typeProperties.continueOnStepFailure', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        ml_pipeline_id: Optional[Any] = None,
        ml_pipeline_endpoint_id: Optional[Any] = None,
        version: Optional[Any] = None,
        experiment_name: Optional[Any] = None,
        ml_pipeline_parameters: Optional[Any] = None,
        data_path_assignments: Optional[Any] = None,
        ml_parent_run_id: Optional[Any] = None,
        continue_on_step_failure: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword ml_pipeline_id: ID of the published Azure ML pipeline. Type: string (or Expression
         with resultType string).
        :paramtype ml_pipeline_id: any
        :keyword ml_pipeline_endpoint_id: ID of the published Azure ML pipeline endpoint. Type: string
         (or Expression with resultType string).
        :paramtype ml_pipeline_endpoint_id: any
        :keyword version: Version of the published Azure ML pipeline endpoint. Type: string (or
         Expression with resultType string).
        :paramtype version: any
        :keyword experiment_name: Run history experiment name of the pipeline run. This information
         will be passed in the ExperimentName property of the published pipeline execution request.
         Type: string (or Expression with resultType string).
        :paramtype experiment_name: any
        :keyword ml_pipeline_parameters: Key,Value pairs to be passed to the published Azure ML
         pipeline endpoint. Keys must match the names of pipeline parameters defined in the published
         pipeline. Values will be passed in the ParameterAssignments property of the published pipeline
         execution request. Type: object with key value pairs (or Expression with resultType object).
        :paramtype ml_pipeline_parameters: any
        :keyword data_path_assignments: Dictionary used for changing data path assignments without
         retraining. Values will be passed in the dataPathAssignments property of the published pipeline
         execution request. Type: object with key value pairs (or Expression with resultType object).
        :paramtype data_path_assignments: any
        :keyword ml_parent_run_id: The parent Azure ML Service pipeline run id. This information will
         be passed in the ParentRunId property of the published pipeline execution request. Type: string
         (or Expression with resultType string).
        :paramtype ml_parent_run_id: any
        :keyword continue_on_step_failure: Whether to continue execution of other steps in the
         PipelineRun if a step fails. This information will be passed in the continueOnStepFailure
         property of the published pipeline execution request. Type: boolean (or Expression with
         resultType boolean).
        :paramtype continue_on_step_failure: any
        """
        super(AzureMLExecutePipelineActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'AzureMLExecutePipeline'  # type: str
        self.ml_pipeline_id = ml_pipeline_id
        self.ml_pipeline_endpoint_id = ml_pipeline_endpoint_id
        self.version = version
        self.experiment_name = experiment_name
        self.ml_pipeline_parameters = ml_pipeline_parameters
        self.data_path_assignments = data_path_assignments
        self.ml_parent_run_id = ml_parent_run_id
        self.continue_on_step_failure = continue_on_step_failure


class AzureMLLinkedService(LinkedService):
    """Azure ML Studio Web Service linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar ml_endpoint: Required. The Batch Execution REST URL for an Azure ML Studio Web Service
     endpoint. Type: string (or Expression with resultType string).
    :vartype ml_endpoint: any
    :ivar api_key: Required. The API key for accessing the Azure ML model endpoint.
    :vartype api_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar update_resource_endpoint: The Update Resource REST URL for an Azure ML Studio Web Service
     endpoint. Type: string (or Expression with resultType string).
    :vartype update_resource_endpoint: any
    :ivar service_principal_id: The ID of the service principal used to authenticate against the
     ARM-based updateResourceEndpoint of an Azure ML Studio web service. Type: string (or Expression
     with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: The key of the service principal used to authenticate against the
     ARM-based updateResourceEndpoint of an Azure ML Studio web service.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar tenant: The name or ID of the tenant to which the service principal belongs. Type: string
     (or Expression with resultType string).
    :vartype tenant: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar authentication: Type of authentication (Required to specify MSI) used to connect to
     AzureML. Type: string (or Expression with resultType string).
    :vartype authentication: any
    """

    _validation = {
        'type': {'required': True},
        'ml_endpoint': {'required': True},
        'api_key': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'ml_endpoint': {'key': 'typeProperties.mlEndpoint', 'type': 'object'},
        'api_key': {'key': 'typeProperties.apiKey', 'type': 'SecretBase'},
        'update_resource_endpoint': {'key': 'typeProperties.updateResourceEndpoint', 'type': 'object'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'authentication': {'key': 'typeProperties.authentication', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        ml_endpoint: Any,
        api_key: "SecretBase",
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        update_resource_endpoint: Optional[Any] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        authentication: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword ml_endpoint: Required. The Batch Execution REST URL for an Azure ML Studio Web Service
         endpoint. Type: string (or Expression with resultType string).
        :paramtype ml_endpoint: any
        :keyword api_key: Required. The API key for accessing the Azure ML model endpoint.
        :paramtype api_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword update_resource_endpoint: The Update Resource REST URL for an Azure ML Studio Web
         Service endpoint. Type: string (or Expression with resultType string).
        :paramtype update_resource_endpoint: any
        :keyword service_principal_id: The ID of the service principal used to authenticate against the
         ARM-based updateResourceEndpoint of an Azure ML Studio web service. Type: string (or Expression
         with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: The key of the service principal used to authenticate against
         the ARM-based updateResourceEndpoint of an Azure ML Studio web service.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword tenant: The name or ID of the tenant to which the service principal belongs. Type:
         string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword authentication: Type of authentication (Required to specify MSI) used to connect to
         AzureML. Type: string (or Expression with resultType string).
        :paramtype authentication: any
        """
        super(AzureMLLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureML'  # type: str
        self.ml_endpoint = ml_endpoint
        self.api_key = api_key
        self.update_resource_endpoint = update_resource_endpoint
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential
        self.authentication = authentication


class AzureMLServiceLinkedService(LinkedService):
    """Azure ML Service linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar subscription_id: Required. Azure ML Service workspace subscription ID. Type: string (or
     Expression with resultType string).
    :vartype subscription_id: any
    :ivar resource_group_name: Required. Azure ML Service workspace resource group name. Type:
     string (or Expression with resultType string).
    :vartype resource_group_name: any
    :ivar ml_workspace_name: Required. Azure ML Service workspace name. Type: string (or Expression
     with resultType string).
    :vartype ml_workspace_name: any
    :ivar service_principal_id: The ID of the service principal used to authenticate against the
     endpoint of a published Azure ML Service pipeline. Type: string (or Expression with resultType
     string).
    :vartype service_principal_id: any
    :ivar service_principal_key: The key of the service principal used to authenticate against the
     endpoint of a published Azure ML Service pipeline.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar tenant: The name or ID of the tenant to which the service principal belongs. Type: string
     (or Expression with resultType string).
    :vartype tenant: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'subscription_id': {'required': True},
        'resource_group_name': {'required': True},
        'ml_workspace_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'subscription_id': {'key': 'typeProperties.subscriptionId', 'type': 'object'},
        'resource_group_name': {'key': 'typeProperties.resourceGroupName', 'type': 'object'},
        'ml_workspace_name': {'key': 'typeProperties.mlWorkspaceName', 'type': 'object'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        subscription_id: Any,
        resource_group_name: Any,
        ml_workspace_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword subscription_id: Required. Azure ML Service workspace subscription ID. Type: string
         (or Expression with resultType string).
        :paramtype subscription_id: any
        :keyword resource_group_name: Required. Azure ML Service workspace resource group name. Type:
         string (or Expression with resultType string).
        :paramtype resource_group_name: any
        :keyword ml_workspace_name: Required. Azure ML Service workspace name. Type: string (or
         Expression with resultType string).
        :paramtype ml_workspace_name: any
        :keyword service_principal_id: The ID of the service principal used to authenticate against the
         endpoint of a published Azure ML Service pipeline. Type: string (or Expression with resultType
         string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: The key of the service principal used to authenticate against
         the endpoint of a published Azure ML Service pipeline.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword tenant: The name or ID of the tenant to which the service principal belongs. Type:
         string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(AzureMLServiceLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureMLService'  # type: str
        self.subscription_id = subscription_id
        self.resource_group_name = resource_group_name
        self.ml_workspace_name = ml_workspace_name
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.encrypted_credential = encrypted_credential


class AzureMLUpdateResourceActivity(ExecutionActivity):
    """Azure ML Update Resource management activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar trained_model_name: Required. Name of the Trained Model module in the Web Service
     experiment to be updated. Type: string (or Expression with resultType string).
    :vartype trained_model_name: any
    :ivar trained_model_linked_service_name: Required. Name of Azure Storage linked service holding
     the .ilearner file that will be uploaded by the update operation.
    :vartype trained_model_linked_service_name:
     ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar trained_model_file_path: Required. The relative file path in trainedModelLinkedService to
     represent the .ilearner file that will be uploaded by the update operation.  Type: string (or
     Expression with resultType string).
    :vartype trained_model_file_path: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'trained_model_name': {'required': True},
        'trained_model_linked_service_name': {'required': True},
        'trained_model_file_path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'trained_model_name': {'key': 'typeProperties.trainedModelName', 'type': 'object'},
        'trained_model_linked_service_name': {'key': 'typeProperties.trainedModelLinkedServiceName', 'type': 'LinkedServiceReference'},
        'trained_model_file_path': {'key': 'typeProperties.trainedModelFilePath', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        trained_model_name: Any,
        trained_model_linked_service_name: "LinkedServiceReference",
        trained_model_file_path: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword trained_model_name: Required. Name of the Trained Model module in the Web Service
         experiment to be updated. Type: string (or Expression with resultType string).
        :paramtype trained_model_name: any
        :keyword trained_model_linked_service_name: Required. Name of Azure Storage linked service
         holding the .ilearner file that will be uploaded by the update operation.
        :paramtype trained_model_linked_service_name:
         ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword trained_model_file_path: Required. The relative file path in trainedModelLinkedService
         to represent the .ilearner file that will be uploaded by the update operation.  Type: string
         (or Expression with resultType string).
        :paramtype trained_model_file_path: any
        """
        super(AzureMLUpdateResourceActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'AzureMLUpdateResource'  # type: str
        self.trained_model_name = trained_model_name
        self.trained_model_linked_service_name = trained_model_linked_service_name
        self.trained_model_file_path = trained_model_file_path


class AzureMLWebServiceFile(msrest.serialization.Model):
    """Azure ML WebService Input/Output file.

    All required parameters must be populated in order to send to Azure.

    :ivar file_path: Required. The relative file path, including container name, in the Azure Blob
     Storage specified by the LinkedService. Type: string (or Expression with resultType string).
    :vartype file_path: any
    :ivar linked_service_name: Required. Reference to an Azure Storage LinkedService, where Azure
     ML WebService Input/Output file located.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    """

    _validation = {
        'file_path': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'file_path': {'key': 'filePath', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
    }

    def __init__(
        self,
        *,
        file_path: Any,
        linked_service_name: "LinkedServiceReference",
        **kwargs
    ):
        """
        :keyword file_path: Required. The relative file path, including container name, in the Azure
         Blob Storage specified by the LinkedService. Type: string (or Expression with resultType
         string).
        :paramtype file_path: any
        :keyword linked_service_name: Required. Reference to an Azure Storage LinkedService, where
         Azure ML WebService Input/Output file located.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        """
        super(AzureMLWebServiceFile, self).__init__(**kwargs)
        self.file_path = file_path
        self.linked_service_name = linked_service_name


class AzureMySqlLinkedService(LinkedService):
    """Azure MySQL database linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar password: The Azure key vault secret reference of password in connection string.
    :vartype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword password: The Azure key vault secret reference of password in connection string.
        :paramtype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(AzureMySqlLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureMySql'  # type: str
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class AzureMySqlSink(CopySink):
    """A copy activity Azure MySql sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar pre_copy_script: A query to execute before starting the copy. Type: string (or Expression
     with resultType string).
    :vartype pre_copy_script: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        pre_copy_script: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword pre_copy_script: A query to execute before starting the copy. Type: string (or
         Expression with resultType string).
        :paramtype pre_copy_script: any
        """
        super(AzureMySqlSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureMySqlSink'  # type: str
        self.pre_copy_script = pre_copy_script


class AzureMySqlSource(TabularSource):
    """A copy activity Azure MySQL source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: Database query. Type: string (or Expression with resultType string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: Database query. Type: string (or Expression with resultType string).
        :paramtype query: any
        """
        super(AzureMySqlSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AzureMySqlSource'  # type: str
        self.query = query


class AzureMySqlTableDataset(Dataset):
    """The Azure MySQL database dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The Azure MySQL database table name. Type: string (or Expression with
     resultType string).
    :vartype table_name: any
    :ivar table: The name of Azure MySQL database table. Type: string (or Expression with
     resultType string).
    :vartype table: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The Azure MySQL database table name. Type: string (or Expression with
         resultType string).
        :paramtype table_name: any
        :keyword table: The name of Azure MySQL database table. Type: string (or Expression with
         resultType string).
        :paramtype table: any
        """
        super(AzureMySqlTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureMySqlTable'  # type: str
        self.table_name = table_name
        self.table = table


class AzurePostgreSqlLinkedService(LinkedService):
    """Azure PostgreSQL linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar password: The Azure key vault secret reference of password in connection string.
    :vartype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: An ODBC connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword password: The Azure key vault secret reference of password in connection string.
        :paramtype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(AzurePostgreSqlLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzurePostgreSql'  # type: str
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class AzurePostgreSqlSink(CopySink):
    """A copy activity Azure PostgreSQL sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar pre_copy_script: A query to execute before starting the copy. Type: string (or Expression
     with resultType string).
    :vartype pre_copy_script: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        pre_copy_script: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword pre_copy_script: A query to execute before starting the copy. Type: string (or
         Expression with resultType string).
        :paramtype pre_copy_script: any
        """
        super(AzurePostgreSqlSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzurePostgreSqlSink'  # type: str
        self.pre_copy_script = pre_copy_script


class AzurePostgreSqlSource(TabularSource):
    """A copy activity Azure PostgreSQL source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(AzurePostgreSqlSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AzurePostgreSqlSource'  # type: str
        self.query = query


class AzurePostgreSqlTableDataset(Dataset):
    """Azure PostgreSQL dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name of the Azure PostgreSQL database which includes both schema
     and table. Type: string (or Expression with resultType string).
    :vartype table_name: any
    :ivar table: The table name of the Azure PostgreSQL database. Type: string (or Expression with
     resultType string).
    :vartype table: any
    :ivar schema_type_properties_schema: The schema name of the Azure PostgreSQL database. Type:
     string (or Expression with resultType string).
    :vartype schema_type_properties_schema: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name of the Azure PostgreSQL database which includes both schema
         and table. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        :keyword table: The table name of the Azure PostgreSQL database. Type: string (or Expression
         with resultType string).
        :paramtype table: any
        :keyword schema_type_properties_schema: The schema name of the Azure PostgreSQL database. Type:
         string (or Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        """
        super(AzurePostgreSqlTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzurePostgreSqlTable'  # type: str
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class AzureQueueSink(CopySink):
    """A copy activity Azure Queue sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        """
        super(AzureQueueSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureQueueSink'  # type: str


class AzureSearchIndexDataset(Dataset):
    """The Azure Search Index.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar index_name: Required. The name of the Azure Search Index. Type: string (or Expression
     with resultType string).
    :vartype index_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'index_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'index_name': {'key': 'typeProperties.indexName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        index_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword index_name: Required. The name of the Azure Search Index. Type: string (or Expression
         with resultType string).
        :paramtype index_name: any
        """
        super(AzureSearchIndexDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureSearchIndex'  # type: str
        self.index_name = index_name


class AzureSearchIndexSink(CopySink):
    """A copy activity Azure Search Index sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar write_behavior: Specify the write behavior when upserting documents into Azure Search
     Index. Possible values include: "Merge", "Upload".
    :vartype write_behavior: str or
     ~azure.mgmt.datafactory.models.AzureSearchIndexWriteBehaviorType
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        write_behavior: Optional[Union[str, "AzureSearchIndexWriteBehaviorType"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword write_behavior: Specify the write behavior when upserting documents into Azure Search
         Index. Possible values include: "Merge", "Upload".
        :paramtype write_behavior: str or
         ~azure.mgmt.datafactory.models.AzureSearchIndexWriteBehaviorType
        """
        super(AzureSearchIndexSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureSearchIndexSink'  # type: str
        self.write_behavior = write_behavior


class AzureSearchLinkedService(LinkedService):
    """Linked service for Windows Azure Search Service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar url: Required. URL for Azure Search service. Type: string (or Expression with resultType
     string).
    :vartype url: any
    :ivar key: Admin Key for Azure Search service.
    :vartype key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'url': {'key': 'typeProperties.url', 'type': 'object'},
        'key': {'key': 'typeProperties.key', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        url: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        key: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword url: Required. URL for Azure Search service. Type: string (or Expression with
         resultType string).
        :paramtype url: any
        :keyword key: Admin Key for Azure Search service.
        :paramtype key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(AzureSearchLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureSearch'  # type: str
        self.url = url
        self.key = key
        self.encrypted_credential = encrypted_credential


class AzureSqlDatabaseLinkedService(LinkedService):
    """Microsoft Azure SQL Database linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar password: The Azure key vault secret reference of password in connection string.
    :vartype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar service_principal_id: The ID of the service principal used to authenticate against Azure
     SQL Database. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: The key of the service principal used to authenticate against
     Azure SQL Database.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar tenant: The name or ID of the tenant to which the service principal belongs. Type: string
     (or Expression with resultType string).
    :vartype tenant: any
    :ivar azure_cloud_type: Indicates the azure cloud type of the service principle auth. Allowed
     values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is the data
     factory regions cloud type. Type: string (or Expression with resultType string).
    :vartype azure_cloud_type: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar always_encrypted_settings: Sql always encrypted properties.
    :vartype always_encrypted_settings: ~azure.mgmt.datafactory.models.SqlAlwaysEncryptedProperties
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'azure_cloud_type': {'key': 'typeProperties.azureCloudType', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'always_encrypted_settings': {'key': 'typeProperties.alwaysEncryptedSettings', 'type': 'SqlAlwaysEncryptedProperties'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional[Any] = None,
        azure_cloud_type: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        always_encrypted_settings: Optional["SqlAlwaysEncryptedProperties"] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword password: The Azure key vault secret reference of password in connection string.
        :paramtype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword service_principal_id: The ID of the service principal used to authenticate against
         Azure SQL Database. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: The key of the service principal used to authenticate against
         Azure SQL Database.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword tenant: The name or ID of the tenant to which the service principal belongs. Type:
         string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword azure_cloud_type: Indicates the azure cloud type of the service principle auth.
         Allowed values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is
         the data factory regions cloud type. Type: string (or Expression with resultType string).
        :paramtype azure_cloud_type: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword always_encrypted_settings: Sql always encrypted properties.
        :paramtype always_encrypted_settings:
         ~azure.mgmt.datafactory.models.SqlAlwaysEncryptedProperties
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(AzureSqlDatabaseLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureSqlDatabase'  # type: str
        self.connection_string = connection_string
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.azure_cloud_type = azure_cloud_type
        self.encrypted_credential = encrypted_credential
        self.always_encrypted_settings = always_encrypted_settings
        self.credential = credential


class AzureSqlDWLinkedService(LinkedService):
    """Azure SQL Data Warehouse linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference. Type: string, SecureString or AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar password: The Azure key vault secret reference of password in connection string.
    :vartype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar service_principal_id: The ID of the service principal used to authenticate against Azure
     SQL Data Warehouse. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: The key of the service principal used to authenticate against
     Azure SQL Data Warehouse.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar tenant: The name or ID of the tenant to which the service principal belongs. Type: string
     (or Expression with resultType string).
    :vartype tenant: any
    :ivar azure_cloud_type: Indicates the azure cloud type of the service principle auth. Allowed
     values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is the data
     factory regions cloud type. Type: string (or Expression with resultType string).
    :vartype azure_cloud_type: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'azure_cloud_type': {'key': 'typeProperties.azureCloudType', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional[Any] = None,
        azure_cloud_type: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference. Type: string, SecureString or AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword password: The Azure key vault secret reference of password in connection string.
        :paramtype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword service_principal_id: The ID of the service principal used to authenticate against
         Azure SQL Data Warehouse. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: The key of the service principal used to authenticate against
         Azure SQL Data Warehouse.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword tenant: The name or ID of the tenant to which the service principal belongs. Type:
         string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword azure_cloud_type: Indicates the azure cloud type of the service principle auth.
         Allowed values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is
         the data factory regions cloud type. Type: string (or Expression with resultType string).
        :paramtype azure_cloud_type: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(AzureSqlDWLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureSqlDW'  # type: str
        self.connection_string = connection_string
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.azure_cloud_type = azure_cloud_type
        self.encrypted_credential = encrypted_credential
        self.credential = credential


class AzureSqlDWTableDataset(Dataset):
    """The Azure SQL Data Warehouse dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar schema_type_properties_schema: The schema name of the Azure SQL Data Warehouse. Type:
     string (or Expression with resultType string).
    :vartype schema_type_properties_schema: any
    :ivar table: The table name of the Azure SQL Data Warehouse. Type: string (or Expression with
     resultType string).
    :vartype table: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        table: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword schema_type_properties_schema: The schema name of the Azure SQL Data Warehouse. Type:
         string (or Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        :keyword table: The table name of the Azure SQL Data Warehouse. Type: string (or Expression
         with resultType string).
        :paramtype table: any
        """
        super(AzureSqlDWTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureSqlDWTable'  # type: str
        self.table_name = table_name
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class AzureSqlMILinkedService(LinkedService):
    """Azure SQL Managed Instance linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar password: The Azure key vault secret reference of password in connection string.
    :vartype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar service_principal_id: The ID of the service principal used to authenticate against Azure
     SQL Managed Instance. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: The key of the service principal used to authenticate against
     Azure SQL Managed Instance.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar tenant: The name or ID of the tenant to which the service principal belongs. Type: string
     (or Expression with resultType string).
    :vartype tenant: any
    :ivar azure_cloud_type: Indicates the azure cloud type of the service principle auth. Allowed
     values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is the data
     factory regions cloud type. Type: string (or Expression with resultType string).
    :vartype azure_cloud_type: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar always_encrypted_settings: Sql always encrypted properties.
    :vartype always_encrypted_settings: ~azure.mgmt.datafactory.models.SqlAlwaysEncryptedProperties
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'azure_cloud_type': {'key': 'typeProperties.azureCloudType', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'always_encrypted_settings': {'key': 'typeProperties.alwaysEncryptedSettings', 'type': 'SqlAlwaysEncryptedProperties'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional[Any] = None,
        azure_cloud_type: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        always_encrypted_settings: Optional["SqlAlwaysEncryptedProperties"] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword password: The Azure key vault secret reference of password in connection string.
        :paramtype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword service_principal_id: The ID of the service principal used to authenticate against
         Azure SQL Managed Instance. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: The key of the service principal used to authenticate against
         Azure SQL Managed Instance.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword tenant: The name or ID of the tenant to which the service principal belongs. Type:
         string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword azure_cloud_type: Indicates the azure cloud type of the service principle auth.
         Allowed values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is
         the data factory regions cloud type. Type: string (or Expression with resultType string).
        :paramtype azure_cloud_type: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword always_encrypted_settings: Sql always encrypted properties.
        :paramtype always_encrypted_settings:
         ~azure.mgmt.datafactory.models.SqlAlwaysEncryptedProperties
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(AzureSqlMILinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureSqlMI'  # type: str
        self.connection_string = connection_string
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.azure_cloud_type = azure_cloud_type
        self.encrypted_credential = encrypted_credential
        self.always_encrypted_settings = always_encrypted_settings
        self.credential = credential


class AzureSqlMITableDataset(Dataset):
    """The Azure SQL Managed Instance dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar schema_type_properties_schema: The schema name of the Azure SQL Managed Instance. Type:
     string (or Expression with resultType string).
    :vartype schema_type_properties_schema: any
    :ivar table: The table name of the Azure SQL Managed Instance dataset. Type: string (or
     Expression with resultType string).
    :vartype table: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        table: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword schema_type_properties_schema: The schema name of the Azure SQL Managed Instance.
         Type: string (or Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        :keyword table: The table name of the Azure SQL Managed Instance dataset. Type: string (or
         Expression with resultType string).
        :paramtype table: any
        """
        super(AzureSqlMITableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureSqlMITable'  # type: str
        self.table_name = table_name
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class AzureSqlSink(CopySink):
    """A copy activity Azure SQL sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar sql_writer_stored_procedure_name: SQL writer stored procedure name. Type: string (or
     Expression with resultType string).
    :vartype sql_writer_stored_procedure_name: any
    :ivar sql_writer_table_type: SQL writer table type. Type: string (or Expression with resultType
     string).
    :vartype sql_writer_table_type: any
    :ivar pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :vartype pre_copy_script: any
    :ivar stored_procedure_parameters: SQL stored procedure parameters.
    :vartype stored_procedure_parameters: dict[str,
     ~azure.mgmt.datafactory.models.StoredProcedureParameter]
    :ivar stored_procedure_table_type_parameter_name: The stored procedure parameter name of the
     table type. Type: string (or Expression with resultType string).
    :vartype stored_procedure_table_type_parameter_name: any
    :ivar table_option: The option to handle sink table, such as autoCreate. For now only
     'autoCreate' value is supported. Type: string (or Expression with resultType string).
    :vartype table_option: any
    :ivar sql_writer_use_table_lock: Whether to use table lock during bulk copy. Type: boolean (or
     Expression with resultType boolean).
    :vartype sql_writer_use_table_lock: any
    :ivar write_behavior: Write behavior when copying data into Azure SQL. Type:
     SqlWriteBehaviorEnum (or Expression with resultType SqlWriteBehaviorEnum).
    :vartype write_behavior: any
    :ivar upsert_settings: SQL upsert settings.
    :vartype upsert_settings: ~azure.mgmt.datafactory.models.SqlUpsertSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'sql_writer_stored_procedure_name': {'key': 'sqlWriterStoredProcedureName', 'type': 'object'},
        'sql_writer_table_type': {'key': 'sqlWriterTableType', 'type': 'object'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'object'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'stored_procedure_table_type_parameter_name': {'key': 'storedProcedureTableTypeParameterName', 'type': 'object'},
        'table_option': {'key': 'tableOption', 'type': 'object'},
        'sql_writer_use_table_lock': {'key': 'sqlWriterUseTableLock', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'object'},
        'upsert_settings': {'key': 'upsertSettings', 'type': 'SqlUpsertSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        sql_writer_stored_procedure_name: Optional[Any] = None,
        sql_writer_table_type: Optional[Any] = None,
        pre_copy_script: Optional[Any] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        stored_procedure_table_type_parameter_name: Optional[Any] = None,
        table_option: Optional[Any] = None,
        sql_writer_use_table_lock: Optional[Any] = None,
        write_behavior: Optional[Any] = None,
        upsert_settings: Optional["SqlUpsertSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword sql_writer_stored_procedure_name: SQL writer stored procedure name. Type: string (or
         Expression with resultType string).
        :paramtype sql_writer_stored_procedure_name: any
        :keyword sql_writer_table_type: SQL writer table type. Type: string (or Expression with
         resultType string).
        :paramtype sql_writer_table_type: any
        :keyword pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
         string).
        :paramtype pre_copy_script: any
        :keyword stored_procedure_parameters: SQL stored procedure parameters.
        :paramtype stored_procedure_parameters: dict[str,
         ~azure.mgmt.datafactory.models.StoredProcedureParameter]
        :keyword stored_procedure_table_type_parameter_name: The stored procedure parameter name of the
         table type. Type: string (or Expression with resultType string).
        :paramtype stored_procedure_table_type_parameter_name: any
        :keyword table_option: The option to handle sink table, such as autoCreate. For now only
         'autoCreate' value is supported. Type: string (or Expression with resultType string).
        :paramtype table_option: any
        :keyword sql_writer_use_table_lock: Whether to use table lock during bulk copy. Type: boolean
         (or Expression with resultType boolean).
        :paramtype sql_writer_use_table_lock: any
        :keyword write_behavior: Write behavior when copying data into Azure SQL. Type:
         SqlWriteBehaviorEnum (or Expression with resultType SqlWriteBehaviorEnum).
        :paramtype write_behavior: any
        :keyword upsert_settings: SQL upsert settings.
        :paramtype upsert_settings: ~azure.mgmt.datafactory.models.SqlUpsertSettings
        """
        super(AzureSqlSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureSqlSink'  # type: str
        self.sql_writer_stored_procedure_name = sql_writer_stored_procedure_name
        self.sql_writer_table_type = sql_writer_table_type
        self.pre_copy_script = pre_copy_script
        self.stored_procedure_parameters = stored_procedure_parameters
        self.stored_procedure_table_type_parameter_name = stored_procedure_table_type_parameter_name
        self.table_option = table_option
        self.sql_writer_use_table_lock = sql_writer_use_table_lock
        self.write_behavior = write_behavior
        self.upsert_settings = upsert_settings


class AzureSqlSource(TabularSource):
    """A copy activity Azure SQL source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar sql_reader_query: SQL reader query. Type: string (or Expression with resultType string).
    :vartype sql_reader_query: any
    :ivar sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Database source.
     This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression with
     resultType string).
    :vartype sql_reader_stored_procedure_name: any
    :ivar stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}".
    :vartype stored_procedure_parameters: dict[str,
     ~azure.mgmt.datafactory.models.StoredProcedureParameter]
    :ivar produce_additional_types: Which additional types to produce.
    :vartype produce_additional_types: any
    :ivar partition_option: The partition mechanism that will be used for Sql read in parallel.
     Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
    :vartype partition_option: any
    :ivar partition_settings: The settings that will be leveraged for Sql source partitioning.
    :vartype partition_settings: ~azure.mgmt.datafactory.models.SqlPartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'sql_reader_query': {'key': 'sqlReaderQuery', 'type': 'object'},
        'sql_reader_stored_procedure_name': {'key': 'sqlReaderStoredProcedureName', 'type': 'object'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'produce_additional_types': {'key': 'produceAdditionalTypes', 'type': 'object'},
        'partition_option': {'key': 'partitionOption', 'type': 'object'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'SqlPartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        sql_reader_query: Optional[Any] = None,
        sql_reader_stored_procedure_name: Optional[Any] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        produce_additional_types: Optional[Any] = None,
        partition_option: Optional[Any] = None,
        partition_settings: Optional["SqlPartitionSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword sql_reader_query: SQL reader query. Type: string (or Expression with resultType
         string).
        :paramtype sql_reader_query: any
        :keyword sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Database
         source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression
         with resultType string).
        :paramtype sql_reader_stored_procedure_name: any
        :keyword stored_procedure_parameters: Value and type setting for stored procedure parameters.
         Example: "{Parameter1: {value: "1", type: "int"}}".
        :paramtype stored_procedure_parameters: dict[str,
         ~azure.mgmt.datafactory.models.StoredProcedureParameter]
        :keyword produce_additional_types: Which additional types to produce.
        :paramtype produce_additional_types: any
        :keyword partition_option: The partition mechanism that will be used for Sql read in parallel.
         Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
        :paramtype partition_option: any
        :keyword partition_settings: The settings that will be leveraged for Sql source partitioning.
        :paramtype partition_settings: ~azure.mgmt.datafactory.models.SqlPartitionSettings
        """
        super(AzureSqlSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AzureSqlSource'  # type: str
        self.sql_reader_query = sql_reader_query
        self.sql_reader_stored_procedure_name = sql_reader_stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters
        self.produce_additional_types = produce_additional_types
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class AzureSqlTableDataset(Dataset):
    """The Azure SQL Server database dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar schema_type_properties_schema: The schema name of the Azure SQL database. Type: string
     (or Expression with resultType string).
    :vartype schema_type_properties_schema: any
    :ivar table: The table name of the Azure SQL database. Type: string (or Expression with
     resultType string).
    :vartype table: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        table: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword schema_type_properties_schema: The schema name of the Azure SQL database. Type: string
         (or Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        :keyword table: The table name of the Azure SQL database. Type: string (or Expression with
         resultType string).
        :paramtype table: any
        """
        super(AzureSqlTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureSqlTable'  # type: str
        self.table_name = table_name
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class AzureStorageLinkedService(LinkedService):
    """The storage account linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: The connection string. It is mutually exclusive with sasUri property.
     Type: string, SecureString or AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar account_key: The Azure key vault secret reference of accountKey in connection string.
    :vartype account_key: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar sas_uri: SAS URI of the Azure Storage resource. It is mutually exclusive with
     connectionString property. Type: string, SecureString or AzureKeyVaultSecretReference.
    :vartype sas_uri: any
    :ivar sas_token: The Azure key vault secret reference of sasToken in sas uri.
    :vartype sas_token: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'account_key': {'key': 'typeProperties.accountKey', 'type': 'AzureKeyVaultSecretReference'},
        'sas_uri': {'key': 'typeProperties.sasUri', 'type': 'object'},
        'sas_token': {'key': 'typeProperties.sasToken', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        account_key: Optional["AzureKeyVaultSecretReference"] = None,
        sas_uri: Optional[Any] = None,
        sas_token: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: The connection string. It is mutually exclusive with sasUri
         property. Type: string, SecureString or AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword account_key: The Azure key vault secret reference of accountKey in connection string.
        :paramtype account_key: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword sas_uri: SAS URI of the Azure Storage resource. It is mutually exclusive with
         connectionString property. Type: string, SecureString or AzureKeyVaultSecretReference.
        :paramtype sas_uri: any
        :keyword sas_token: The Azure key vault secret reference of sasToken in sas uri.
        :paramtype sas_token: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: str
        """
        super(AzureStorageLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureStorage'  # type: str
        self.connection_string = connection_string
        self.account_key = account_key
        self.sas_uri = sas_uri
        self.sas_token = sas_token
        self.encrypted_credential = encrypted_credential


class AzureTableDataset(Dataset):
    """The Azure Table storage dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: Required. The table name of the Azure Table storage. Type: string (or
     Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'table_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        table_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: Required. The table name of the Azure Table storage. Type: string (or
         Expression with resultType string).
        :paramtype table_name: any
        """
        super(AzureTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'AzureTable'  # type: str
        self.table_name = table_name


class AzureTableSink(CopySink):
    """A copy activity Azure Table sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar azure_table_default_partition_key_value: Azure Table default partition key value. Type:
     string (or Expression with resultType string).
    :vartype azure_table_default_partition_key_value: any
    :ivar azure_table_partition_key_name: Azure Table partition key name. Type: string (or
     Expression with resultType string).
    :vartype azure_table_partition_key_name: any
    :ivar azure_table_row_key_name: Azure Table row key name. Type: string (or Expression with
     resultType string).
    :vartype azure_table_row_key_name: any
    :ivar azure_table_insert_type: Azure Table insert type. Type: string (or Expression with
     resultType string).
    :vartype azure_table_insert_type: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'azure_table_default_partition_key_value': {'key': 'azureTableDefaultPartitionKeyValue', 'type': 'object'},
        'azure_table_partition_key_name': {'key': 'azureTablePartitionKeyName', 'type': 'object'},
        'azure_table_row_key_name': {'key': 'azureTableRowKeyName', 'type': 'object'},
        'azure_table_insert_type': {'key': 'azureTableInsertType', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        azure_table_default_partition_key_value: Optional[Any] = None,
        azure_table_partition_key_name: Optional[Any] = None,
        azure_table_row_key_name: Optional[Any] = None,
        azure_table_insert_type: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword azure_table_default_partition_key_value: Azure Table default partition key value.
         Type: string (or Expression with resultType string).
        :paramtype azure_table_default_partition_key_value: any
        :keyword azure_table_partition_key_name: Azure Table partition key name. Type: string (or
         Expression with resultType string).
        :paramtype azure_table_partition_key_name: any
        :keyword azure_table_row_key_name: Azure Table row key name. Type: string (or Expression with
         resultType string).
        :paramtype azure_table_row_key_name: any
        :keyword azure_table_insert_type: Azure Table insert type. Type: string (or Expression with
         resultType string).
        :paramtype azure_table_insert_type: any
        """
        super(AzureTableSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'AzureTableSink'  # type: str
        self.azure_table_default_partition_key_value = azure_table_default_partition_key_value
        self.azure_table_partition_key_name = azure_table_partition_key_name
        self.azure_table_row_key_name = azure_table_row_key_name
        self.azure_table_insert_type = azure_table_insert_type


class AzureTableSource(TabularSource):
    """A copy activity Azure Table source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar azure_table_source_query: Azure Table source query. Type: string (or Expression with
     resultType string).
    :vartype azure_table_source_query: any
    :ivar azure_table_source_ignore_table_not_found: Azure Table source ignore table not found.
     Type: boolean (or Expression with resultType boolean).
    :vartype azure_table_source_ignore_table_not_found: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'azure_table_source_query': {'key': 'azureTableSourceQuery', 'type': 'object'},
        'azure_table_source_ignore_table_not_found': {'key': 'azureTableSourceIgnoreTableNotFound', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        azure_table_source_query: Optional[Any] = None,
        azure_table_source_ignore_table_not_found: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword azure_table_source_query: Azure Table source query. Type: string (or Expression with
         resultType string).
        :paramtype azure_table_source_query: any
        :keyword azure_table_source_ignore_table_not_found: Azure Table source ignore table not found.
         Type: boolean (or Expression with resultType boolean).
        :paramtype azure_table_source_ignore_table_not_found: any
        """
        super(AzureTableSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'AzureTableSource'  # type: str
        self.azure_table_source_query = azure_table_source_query
        self.azure_table_source_ignore_table_not_found = azure_table_source_ignore_table_not_found


class AzureTableStorageLinkedService(LinkedService):
    """The azure table storage linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: The connection string. It is mutually exclusive with sasUri property.
     Type: string, SecureString or AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar account_key: The Azure key vault secret reference of accountKey in connection string.
    :vartype account_key: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar sas_uri: SAS URI of the Azure Storage resource. It is mutually exclusive with
     connectionString property. Type: string, SecureString or AzureKeyVaultSecretReference.
    :vartype sas_uri: any
    :ivar sas_token: The Azure key vault secret reference of sasToken in sas uri.
    :vartype sas_token: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'account_key': {'key': 'typeProperties.accountKey', 'type': 'AzureKeyVaultSecretReference'},
        'sas_uri': {'key': 'typeProperties.sasUri', 'type': 'object'},
        'sas_token': {'key': 'typeProperties.sasToken', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        account_key: Optional["AzureKeyVaultSecretReference"] = None,
        sas_uri: Optional[Any] = None,
        sas_token: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: The connection string. It is mutually exclusive with sasUri
         property. Type: string, SecureString or AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword account_key: The Azure key vault secret reference of accountKey in connection string.
        :paramtype account_key: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword sas_uri: SAS URI of the Azure Storage resource. It is mutually exclusive with
         connectionString property. Type: string, SecureString or AzureKeyVaultSecretReference.
        :paramtype sas_uri: any
        :keyword sas_token: The Azure key vault secret reference of sasToken in sas uri.
        :paramtype sas_token: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: str
        """
        super(AzureTableStorageLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'AzureTableStorage'  # type: str
        self.connection_string = connection_string
        self.account_key = account_key
        self.sas_uri = sas_uri
        self.sas_token = sas_token
        self.encrypted_credential = encrypted_credential


class BinaryDataset(Dataset):
    """Binary dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar location: The location of the Binary storage.
    :vartype location: ~azure.mgmt.datafactory.models.DatasetLocation
    :ivar compression: The data compression method used for the binary dataset.
    :vartype compression: ~azure.mgmt.datafactory.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword location: The location of the Binary storage.
        :paramtype location: ~azure.mgmt.datafactory.models.DatasetLocation
        :keyword compression: The data compression method used for the binary dataset.
        :paramtype compression: ~azure.mgmt.datafactory.models.DatasetCompression
        """
        super(BinaryDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Binary'  # type: str
        self.location = location
        self.compression = compression


class FormatReadSettings(msrest.serialization.Model):
    """Format read settings.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: BinaryReadSettings, DelimitedTextReadSettings, JsonReadSettings, XmlReadSettings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'BinaryReadSettings': 'BinaryReadSettings', 'DelimitedTextReadSettings': 'DelimitedTextReadSettings', 'JsonReadSettings': 'JsonReadSettings', 'XmlReadSettings': 'XmlReadSettings'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(FormatReadSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'FormatReadSettings'  # type: str


class BinaryReadSettings(FormatReadSettings):
    """Binary read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar compression_properties: Compression settings.
    :vartype compression_properties: ~azure.mgmt.datafactory.models.CompressionReadSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'compression_properties': {'key': 'compressionProperties', 'type': 'CompressionReadSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        compression_properties: Optional["CompressionReadSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword compression_properties: Compression settings.
        :paramtype compression_properties: ~azure.mgmt.datafactory.models.CompressionReadSettings
        """
        super(BinaryReadSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'BinaryReadSettings'  # type: str
        self.compression_properties = compression_properties


class BinarySink(CopySink):
    """A copy activity Binary sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: Binary store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreWriteSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreWriteSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreWriteSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: Binary store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreWriteSettings
        """
        super(BinarySink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'BinarySink'  # type: str
        self.store_settings = store_settings


class BinarySource(CopySource):
    """A copy activity Binary source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: Binary store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
    :ivar format_settings: Binary format settings.
    :vartype format_settings: ~azure.mgmt.datafactory.models.BinaryReadSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
        'format_settings': {'key': 'formatSettings', 'type': 'BinaryReadSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        format_settings: Optional["BinaryReadSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: Binary store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
        :keyword format_settings: Binary format settings.
        :paramtype format_settings: ~azure.mgmt.datafactory.models.BinaryReadSettings
        """
        super(BinarySource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'BinarySource'  # type: str
        self.store_settings = store_settings
        self.format_settings = format_settings


class Trigger(msrest.serialization.Model):
    """Azure data factory nested object which contains information about creating pipeline run.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: ChainingTrigger, MultiplePipelineTrigger, RerunTumblingWindowTrigger, TumblingWindowTrigger.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Trigger type.Constant filled by server.
    :vartype type: str
    :ivar description: Trigger description.
    :vartype description: str
    :ivar runtime_state: Indicates if trigger is running or not. Updated when Start/Stop APIs are
     called on the Trigger. Possible values include: "Started", "Stopped", "Disabled".
    :vartype runtime_state: str or ~azure.mgmt.datafactory.models.TriggerRuntimeState
    :ivar annotations: List of tags that can be used for describing the trigger.
    :vartype annotations: list[any]
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
    }

    _subtype_map = {
        'type': {'ChainingTrigger': 'ChainingTrigger', 'MultiplePipelineTrigger': 'MultiplePipelineTrigger', 'RerunTumblingWindowTrigger': 'RerunTumblingWindowTrigger', 'TumblingWindowTrigger': 'TumblingWindowTrigger'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Trigger description.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the trigger.
        :paramtype annotations: list[any]
        """
        super(Trigger, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'Trigger'  # type: str
        self.description = description
        self.runtime_state = None
        self.annotations = annotations


class MultiplePipelineTrigger(Trigger):
    """Base class for all triggers that support one to many model for trigger to pipeline.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: BlobEventsTrigger, BlobTrigger, CustomEventsTrigger, ScheduleTrigger.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Trigger type.Constant filled by server.
    :vartype type: str
    :ivar description: Trigger description.
    :vartype description: str
    :ivar runtime_state: Indicates if trigger is running or not. Updated when Start/Stop APIs are
     called on the Trigger. Possible values include: "Started", "Stopped", "Disabled".
    :vartype runtime_state: str or ~azure.mgmt.datafactory.models.TriggerRuntimeState
    :ivar annotations: List of tags that can be used for describing the trigger.
    :vartype annotations: list[any]
    :ivar pipelines: Pipelines that need to be started.
    :vartype pipelines: list[~azure.mgmt.datafactory.models.TriggerPipelineReference]
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'pipelines': {'key': 'pipelines', 'type': '[TriggerPipelineReference]'},
    }

    _subtype_map = {
        'type': {'BlobEventsTrigger': 'BlobEventsTrigger', 'BlobTrigger': 'BlobTrigger', 'CustomEventsTrigger': 'CustomEventsTrigger', 'ScheduleTrigger': 'ScheduleTrigger'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        pipelines: Optional[List["TriggerPipelineReference"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Trigger description.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the trigger.
        :paramtype annotations: list[any]
        :keyword pipelines: Pipelines that need to be started.
        :paramtype pipelines: list[~azure.mgmt.datafactory.models.TriggerPipelineReference]
        """
        super(MultiplePipelineTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, **kwargs)
        self.type = 'MultiplePipelineTrigger'  # type: str
        self.pipelines = pipelines


class BlobEventsTrigger(MultiplePipelineTrigger):
    """Trigger that runs every time a Blob event occurs.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Trigger type.Constant filled by server.
    :vartype type: str
    :ivar description: Trigger description.
    :vartype description: str
    :ivar runtime_state: Indicates if trigger is running or not. Updated when Start/Stop APIs are
     called on the Trigger. Possible values include: "Started", "Stopped", "Disabled".
    :vartype runtime_state: str or ~azure.mgmt.datafactory.models.TriggerRuntimeState
    :ivar annotations: List of tags that can be used for describing the trigger.
    :vartype annotations: list[any]
    :ivar pipelines: Pipelines that need to be started.
    :vartype pipelines: list[~azure.mgmt.datafactory.models.TriggerPipelineReference]
    :ivar blob_path_begins_with: The blob path must begin with the pattern provided for trigger to
     fire. For example, '/records/blobs/december/' will only fire the trigger for blobs in the
     december folder under the records container. At least one of these must be provided:
     blobPathBeginsWith, blobPathEndsWith.
    :vartype blob_path_begins_with: str
    :ivar blob_path_ends_with: The blob path must end with the pattern provided for trigger to
     fire. For example, 'december/boxes.csv' will only fire the trigger for blobs named boxes in a
     december folder. At least one of these must be provided: blobPathBeginsWith, blobPathEndsWith.
    :vartype blob_path_ends_with: str
    :ivar ignore_empty_blobs: If set to true, blobs with zero bytes will be ignored.
    :vartype ignore_empty_blobs: bool
    :ivar events: Required. The type of events that cause this trigger to fire.
    :vartype events: list[str or ~azure.mgmt.datafactory.models.BlobEventTypes]
    :ivar scope: Required. The ARM resource ID of the Storage Account.
    :vartype scope: str
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
        'events': {'required': True},
        'scope': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'pipelines': {'key': 'pipelines', 'type': '[TriggerPipelineReference]'},
        'blob_path_begins_with': {'key': 'typeProperties.blobPathBeginsWith', 'type': 'str'},
        'blob_path_ends_with': {'key': 'typeProperties.blobPathEndsWith', 'type': 'str'},
        'ignore_empty_blobs': {'key': 'typeProperties.ignoreEmptyBlobs', 'type': 'bool'},
        'events': {'key': 'typeProperties.events', 'type': '[str]'},
        'scope': {'key': 'typeProperties.scope', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        events: List[Union[str, "BlobEventTypes"]],
        scope: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        pipelines: Optional[List["TriggerPipelineReference"]] = None,
        blob_path_begins_with: Optional[str] = None,
        blob_path_ends_with: Optional[str] = None,
        ignore_empty_blobs: Optional[bool] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Trigger description.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the trigger.
        :paramtype annotations: list[any]
        :keyword pipelines: Pipelines that need to be started.
        :paramtype pipelines: list[~azure.mgmt.datafactory.models.TriggerPipelineReference]
        :keyword blob_path_begins_with: The blob path must begin with the pattern provided for trigger
         to fire. For example, '/records/blobs/december/' will only fire the trigger for blobs in the
         december folder under the records container. At least one of these must be provided:
         blobPathBeginsWith, blobPathEndsWith.
        :paramtype blob_path_begins_with: str
        :keyword blob_path_ends_with: The blob path must end with the pattern provided for trigger to
         fire. For example, 'december/boxes.csv' will only fire the trigger for blobs named boxes in a
         december folder. At least one of these must be provided: blobPathBeginsWith, blobPathEndsWith.
        :paramtype blob_path_ends_with: str
        :keyword ignore_empty_blobs: If set to true, blobs with zero bytes will be ignored.
        :paramtype ignore_empty_blobs: bool
        :keyword events: Required. The type of events that cause this trigger to fire.
        :paramtype events: list[str or ~azure.mgmt.datafactory.models.BlobEventTypes]
        :keyword scope: Required. The ARM resource ID of the Storage Account.
        :paramtype scope: str
        """
        super(BlobEventsTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, pipelines=pipelines, **kwargs)
        self.type = 'BlobEventsTrigger'  # type: str
        self.blob_path_begins_with = blob_path_begins_with
        self.blob_path_ends_with = blob_path_ends_with
        self.ignore_empty_blobs = ignore_empty_blobs
        self.events = events
        self.scope = scope


class BlobSink(CopySink):
    """A copy activity Azure Blob sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar blob_writer_overwrite_files: Blob writer overwrite files. Type: boolean (or Expression
     with resultType boolean).
    :vartype blob_writer_overwrite_files: any
    :ivar blob_writer_date_time_format: Blob writer date time format. Type: string (or Expression
     with resultType string).
    :vartype blob_writer_date_time_format: any
    :ivar blob_writer_add_header: Blob writer add header. Type: boolean (or Expression with
     resultType boolean).
    :vartype blob_writer_add_header: any
    :ivar copy_behavior: The type of copy behavior for copy sink.
    :vartype copy_behavior: any
    :ivar metadata: Specify the custom metadata to be added to sink data. Type: array of objects
     (or Expression with resultType array of objects).
    :vartype metadata: list[~azure.mgmt.datafactory.models.MetadataItem]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'blob_writer_overwrite_files': {'key': 'blobWriterOverwriteFiles', 'type': 'object'},
        'blob_writer_date_time_format': {'key': 'blobWriterDateTimeFormat', 'type': 'object'},
        'blob_writer_add_header': {'key': 'blobWriterAddHeader', 'type': 'object'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'object'},
        'metadata': {'key': 'metadata', 'type': '[MetadataItem]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        blob_writer_overwrite_files: Optional[Any] = None,
        blob_writer_date_time_format: Optional[Any] = None,
        blob_writer_add_header: Optional[Any] = None,
        copy_behavior: Optional[Any] = None,
        metadata: Optional[List["MetadataItem"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword blob_writer_overwrite_files: Blob writer overwrite files. Type: boolean (or Expression
         with resultType boolean).
        :paramtype blob_writer_overwrite_files: any
        :keyword blob_writer_date_time_format: Blob writer date time format. Type: string (or
         Expression with resultType string).
        :paramtype blob_writer_date_time_format: any
        :keyword blob_writer_add_header: Blob writer add header. Type: boolean (or Expression with
         resultType boolean).
        :paramtype blob_writer_add_header: any
        :keyword copy_behavior: The type of copy behavior for copy sink.
        :paramtype copy_behavior: any
        :keyword metadata: Specify the custom metadata to be added to sink data. Type: array of objects
         (or Expression with resultType array of objects).
        :paramtype metadata: list[~azure.mgmt.datafactory.models.MetadataItem]
        """
        super(BlobSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'BlobSink'  # type: str
        self.blob_writer_overwrite_files = blob_writer_overwrite_files
        self.blob_writer_date_time_format = blob_writer_date_time_format
        self.blob_writer_add_header = blob_writer_add_header
        self.copy_behavior = copy_behavior
        self.metadata = metadata


class BlobSource(CopySource):
    """A copy activity Azure Blob source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar treat_empty_as_null: Treat empty as null. Type: boolean (or Expression with resultType
     boolean).
    :vartype treat_empty_as_null: any
    :ivar skip_header_line_count: Number of header lines to skip from each blob. Type: integer (or
     Expression with resultType integer).
    :vartype skip_header_line_count: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'treat_empty_as_null': {'key': 'treatEmptyAsNull', 'type': 'object'},
        'skip_header_line_count': {'key': 'skipHeaderLineCount', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        treat_empty_as_null: Optional[Any] = None,
        skip_header_line_count: Optional[Any] = None,
        recursive: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword treat_empty_as_null: Treat empty as null. Type: boolean (or Expression with resultType
         boolean).
        :paramtype treat_empty_as_null: any
        :keyword skip_header_line_count: Number of header lines to skip from each blob. Type: integer
         (or Expression with resultType integer).
        :paramtype skip_header_line_count: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        """
        super(BlobSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'BlobSource'  # type: str
        self.treat_empty_as_null = treat_empty_as_null
        self.skip_header_line_count = skip_header_line_count
        self.recursive = recursive


class BlobTrigger(MultiplePipelineTrigger):
    """Trigger that runs every time the selected Blob container changes.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Trigger type.Constant filled by server.
    :vartype type: str
    :ivar description: Trigger description.
    :vartype description: str
    :ivar runtime_state: Indicates if trigger is running or not. Updated when Start/Stop APIs are
     called on the Trigger. Possible values include: "Started", "Stopped", "Disabled".
    :vartype runtime_state: str or ~azure.mgmt.datafactory.models.TriggerRuntimeState
    :ivar annotations: List of tags that can be used for describing the trigger.
    :vartype annotations: list[any]
    :ivar pipelines: Pipelines that need to be started.
    :vartype pipelines: list[~azure.mgmt.datafactory.models.TriggerPipelineReference]
    :ivar folder_path: Required. The path of the container/folder that will trigger the pipeline.
    :vartype folder_path: str
    :ivar max_concurrency: Required. The max number of parallel files to handle when it is
     triggered.
    :vartype max_concurrency: int
    :ivar linked_service: Required. The Azure Storage linked service reference.
    :vartype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
        'folder_path': {'required': True},
        'max_concurrency': {'required': True},
        'linked_service': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'pipelines': {'key': 'pipelines', 'type': '[TriggerPipelineReference]'},
        'folder_path': {'key': 'typeProperties.folderPath', 'type': 'str'},
        'max_concurrency': {'key': 'typeProperties.maxConcurrency', 'type': 'int'},
        'linked_service': {'key': 'typeProperties.linkedService', 'type': 'LinkedServiceReference'},
    }

    def __init__(
        self,
        *,
        folder_path: str,
        max_concurrency: int,
        linked_service: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        pipelines: Optional[List["TriggerPipelineReference"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Trigger description.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the trigger.
        :paramtype annotations: list[any]
        :keyword pipelines: Pipelines that need to be started.
        :paramtype pipelines: list[~azure.mgmt.datafactory.models.TriggerPipelineReference]
        :keyword folder_path: Required. The path of the container/folder that will trigger the
         pipeline.
        :paramtype folder_path: str
        :keyword max_concurrency: Required. The max number of parallel files to handle when it is
         triggered.
        :paramtype max_concurrency: int
        :keyword linked_service: Required. The Azure Storage linked service reference.
        :paramtype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        """
        super(BlobTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, pipelines=pipelines, **kwargs)
        self.type = 'BlobTrigger'  # type: str
        self.folder_path = folder_path
        self.max_concurrency = max_concurrency
        self.linked_service = linked_service


class CassandraLinkedService(LinkedService):
    """Linked service for Cassandra data source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. Host name for connection. Type: string (or Expression with resultType
     string).
    :vartype host: any
    :ivar authentication_type: AuthenticationType to be used for connection. Type: string (or
     Expression with resultType string).
    :vartype authentication_type: any
    :ivar port: The port for the connection. Type: integer (or Expression with resultType integer).
    :vartype port: any
    :ivar username: Username for authentication. Type: string (or Expression with resultType
     string).
    :vartype username: any
    :ivar password: Password for authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        authentication_type: Optional[Any] = None,
        port: Optional[Any] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. Host name for connection. Type: string (or Expression with resultType
         string).
        :paramtype host: any
        :keyword authentication_type: AuthenticationType to be used for connection. Type: string (or
         Expression with resultType string).
        :paramtype authentication_type: any
        :keyword port: The port for the connection. Type: integer (or Expression with resultType
         integer).
        :paramtype port: any
        :keyword username: Username for authentication. Type: string (or Expression with resultType
         string).
        :paramtype username: any
        :keyword password: Password for authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(CassandraLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Cassandra'  # type: str
        self.host = host
        self.authentication_type = authentication_type
        self.port = port
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class CassandraSource(TabularSource):
    """A copy activity source for a Cassandra database.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: Database query. Should be a SQL-92 query expression or Cassandra Query Language
     (CQL) command. Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar consistency_level: The consistency level specifies how many Cassandra servers must
     respond to a read request before returning data to the client application. Cassandra checks the
     specified number of Cassandra servers for data to satisfy the read request. Must be one of
     cassandraSourceReadConsistencyLevels. The default value is 'ONE'. It is case-insensitive.
     Possible values include: "ALL", "EACH_QUORUM", "QUORUM", "LOCAL_QUORUM", "ONE", "TWO", "THREE",
     "LOCAL_ONE", "SERIAL", "LOCAL_SERIAL".
    :vartype consistency_level: str or
     ~azure.mgmt.datafactory.models.CassandraSourceReadConsistencyLevels
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'consistency_level': {'key': 'consistencyLevel', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        consistency_level: Optional[Union[str, "CassandraSourceReadConsistencyLevels"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: Database query. Should be a SQL-92 query expression or Cassandra Query Language
         (CQL) command. Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword consistency_level: The consistency level specifies how many Cassandra servers must
         respond to a read request before returning data to the client application. Cassandra checks the
         specified number of Cassandra servers for data to satisfy the read request. Must be one of
         cassandraSourceReadConsistencyLevels. The default value is 'ONE'. It is case-insensitive.
         Possible values include: "ALL", "EACH_QUORUM", "QUORUM", "LOCAL_QUORUM", "ONE", "TWO", "THREE",
         "LOCAL_ONE", "SERIAL", "LOCAL_SERIAL".
        :paramtype consistency_level: str or
         ~azure.mgmt.datafactory.models.CassandraSourceReadConsistencyLevels
        """
        super(CassandraSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'CassandraSource'  # type: str
        self.query = query
        self.consistency_level = consistency_level


class CassandraTableDataset(Dataset):
    """The Cassandra database dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name of the Cassandra database. Type: string (or Expression with
     resultType string).
    :vartype table_name: any
    :ivar keyspace: The keyspace of the Cassandra database. Type: string (or Expression with
     resultType string).
    :vartype keyspace: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'keyspace': {'key': 'typeProperties.keyspace', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        keyspace: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name of the Cassandra database. Type: string (or Expression with
         resultType string).
        :paramtype table_name: any
        :keyword keyspace: The keyspace of the Cassandra database. Type: string (or Expression with
         resultType string).
        :paramtype keyspace: any
        """
        super(CassandraTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'CassandraTable'  # type: str
        self.table_name = table_name
        self.keyspace = keyspace


class ChainingTrigger(Trigger):
    """Trigger that allows the referenced pipeline to depend on other pipeline runs based on runDimension Name/Value pairs. Upstream pipelines should declare the same runDimension Name and their runs should have the values for those runDimensions. The referenced pipeline run would be triggered if the values for the runDimension match for all upstream pipeline runs.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Trigger type.Constant filled by server.
    :vartype type: str
    :ivar description: Trigger description.
    :vartype description: str
    :ivar runtime_state: Indicates if trigger is running or not. Updated when Start/Stop APIs are
     called on the Trigger. Possible values include: "Started", "Stopped", "Disabled".
    :vartype runtime_state: str or ~azure.mgmt.datafactory.models.TriggerRuntimeState
    :ivar annotations: List of tags that can be used for describing the trigger.
    :vartype annotations: list[any]
    :ivar pipeline: Required. Pipeline for which runs are created when all upstream pipelines
     complete successfully.
    :vartype pipeline: ~azure.mgmt.datafactory.models.TriggerPipelineReference
    :ivar depends_on: Required. Upstream Pipelines.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.PipelineReference]
    :ivar run_dimension: Required. Run Dimension property that needs to be emitted by upstream
     pipelines.
    :vartype run_dimension: str
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
        'pipeline': {'required': True},
        'depends_on': {'required': True},
        'run_dimension': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'pipeline': {'key': 'pipeline', 'type': 'TriggerPipelineReference'},
        'depends_on': {'key': 'typeProperties.dependsOn', 'type': '[PipelineReference]'},
        'run_dimension': {'key': 'typeProperties.runDimension', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        pipeline: "TriggerPipelineReference",
        depends_on: List["PipelineReference"],
        run_dimension: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Trigger description.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the trigger.
        :paramtype annotations: list[any]
        :keyword pipeline: Required. Pipeline for which runs are created when all upstream pipelines
         complete successfully.
        :paramtype pipeline: ~azure.mgmt.datafactory.models.TriggerPipelineReference
        :keyword depends_on: Required. Upstream Pipelines.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.PipelineReference]
        :keyword run_dimension: Required. Run Dimension property that needs to be emitted by upstream
         pipelines.
        :paramtype run_dimension: str
        """
        super(ChainingTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, **kwargs)
        self.type = 'ChainingTrigger'  # type: str
        self.pipeline = pipeline
        self.depends_on = depends_on
        self.run_dimension = run_dimension


class CloudError(msrest.serialization.Model):
    """The object that defines the structure of an Azure Data Factory error response.

    All required parameters must be populated in order to send to Azure.

    :ivar code: Required. Error code.
    :vartype code: str
    :ivar message: Required. Error message.
    :vartype message: str
    :ivar target: Property name/path in request associated with error.
    :vartype target: str
    :ivar details: Array with additional error details.
    :vartype details: list[~azure.mgmt.datafactory.models.CloudError]
    """

    _validation = {
        'code': {'required': True},
        'message': {'required': True},
    }

    _attribute_map = {
        'code': {'key': 'error.code', 'type': 'str'},
        'message': {'key': 'error.message', 'type': 'str'},
        'target': {'key': 'error.target', 'type': 'str'},
        'details': {'key': 'error.details', 'type': '[CloudError]'},
    }

    def __init__(
        self,
        *,
        code: str,
        message: str,
        target: Optional[str] = None,
        details: Optional[List["CloudError"]] = None,
        **kwargs
    ):
        """
        :keyword code: Required. Error code.
        :paramtype code: str
        :keyword message: Required. Error message.
        :paramtype message: str
        :keyword target: Property name/path in request associated with error.
        :paramtype target: str
        :keyword details: Array with additional error details.
        :paramtype details: list[~azure.mgmt.datafactory.models.CloudError]
        """
        super(CloudError, self).__init__(**kwargs)
        self.code = code
        self.message = message
        self.target = target
        self.details = details


class CmdkeySetup(CustomSetupBase):
    """The custom setup of running cmdkey commands.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. The type of custom setup.Constant filled by server.
    :vartype type: str
    :ivar target_name: Required. The server name of data source access.
    :vartype target_name: any
    :ivar user_name: Required. The user name of data source access.
    :vartype user_name: any
    :ivar password: Required. The password of data source access.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    """

    _validation = {
        'type': {'required': True},
        'target_name': {'required': True},
        'user_name': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'target_name': {'key': 'typeProperties.targetName', 'type': 'object'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        target_name: Any,
        user_name: Any,
        password: "SecretBase",
        **kwargs
    ):
        """
        :keyword target_name: Required. The server name of data source access.
        :paramtype target_name: any
        :keyword user_name: Required. The user name of data source access.
        :paramtype user_name: any
        :keyword password: Required. The password of data source access.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        """
        super(CmdkeySetup, self).__init__(**kwargs)
        self.type = 'CmdkeySetup'  # type: str
        self.target_name = target_name
        self.user_name = user_name
        self.password = password


class CMKIdentityDefinition(msrest.serialization.Model):
    """Managed Identity used for CMK.

    :ivar user_assigned_identity: The resource id of the user assigned identity to authenticate to
     customer's key vault.
    :vartype user_assigned_identity: str
    """

    _attribute_map = {
        'user_assigned_identity': {'key': 'userAssignedIdentity', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        user_assigned_identity: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword user_assigned_identity: The resource id of the user assigned identity to authenticate
         to customer's key vault.
        :paramtype user_assigned_identity: str
        """
        super(CMKIdentityDefinition, self).__init__(**kwargs)
        self.user_assigned_identity = user_assigned_identity


class CommonDataServiceForAppsEntityDataset(Dataset):
    """The Common Data Service for Apps entity dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar entity_name: The logical name of the entity. Type: string (or Expression with resultType
     string).
    :vartype entity_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'entity_name': {'key': 'typeProperties.entityName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        entity_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword entity_name: The logical name of the entity. Type: string (or Expression with
         resultType string).
        :paramtype entity_name: any
        """
        super(CommonDataServiceForAppsEntityDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'CommonDataServiceForAppsEntity'  # type: str
        self.entity_name = entity_name


class CommonDataServiceForAppsLinkedService(LinkedService):
    """Common Data Service for Apps linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar deployment_type: Required. The deployment type of the Common Data Service for Apps
     instance. 'Online' for Common Data Service for Apps Online and 'OnPremisesWithIfd' for Common
     Data Service for Apps on-premises with Ifd. Type: string (or Expression with resultType
     string).
    :vartype deployment_type: any
    :ivar host_name: The host name of the on-premises Common Data Service for Apps server. The
     property is required for on-prem and not allowed for online. Type: string (or Expression with
     resultType string).
    :vartype host_name: any
    :ivar port: The port of on-premises Common Data Service for Apps server. The property is
     required for on-prem and not allowed for online. Default is 443. Type: integer (or Expression
     with resultType integer), minimum: 0.
    :vartype port: any
    :ivar service_uri: The URL to the Microsoft Common Data Service for Apps server. The property
     is required for on-line and not allowed for on-prem. Type: string (or Expression with
     resultType string).
    :vartype service_uri: any
    :ivar organization_name: The organization name of the Common Data Service for Apps instance.
     The property is required for on-prem and required for online when there are more than one
     Common Data Service for Apps instances associated with the user. Type: string (or Expression
     with resultType string).
    :vartype organization_name: any
    :ivar authentication_type: Required. The authentication type to connect to Common Data Service
     for Apps server. 'Office365' for online scenario, 'Ifd' for on-premises with Ifd scenario.
     'AADServicePrincipal' for Server-To-Server authentication in online scenario. Type: string (or
     Expression with resultType string).
    :vartype authentication_type: any
    :ivar username: User name to access the Common Data Service for Apps instance. Type: string (or
     Expression with resultType string).
    :vartype username: any
    :ivar password: Password to access the Common Data Service for Apps instance.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar service_principal_id: The client ID of the application in Azure Active Directory used for
     Server-To-Server authentication. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_credential_type: The service principal credential type to use in
     Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
     for certificate. Type: string (or Expression with resultType string).
    :vartype service_principal_credential_type: any
    :ivar service_principal_credential: The credential of the service principal object in Azure
     Active Directory. If servicePrincipalCredentialType is 'ServicePrincipalKey',
     servicePrincipalCredential can be SecureString or AzureKeyVaultSecretReference. If
     servicePrincipalCredentialType is 'ServicePrincipalCert', servicePrincipalCredential can only
     be AzureKeyVaultSecretReference.
    :vartype service_principal_credential: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'deployment_type': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'deployment_type': {'key': 'typeProperties.deploymentType', 'type': 'object'},
        'host_name': {'key': 'typeProperties.hostName', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'service_uri': {'key': 'typeProperties.serviceUri', 'type': 'object'},
        'organization_name': {'key': 'typeProperties.organizationName', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_credential_type': {'key': 'typeProperties.servicePrincipalCredentialType', 'type': 'object'},
        'service_principal_credential': {'key': 'typeProperties.servicePrincipalCredential', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        deployment_type: Any,
        authentication_type: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        host_name: Optional[Any] = None,
        port: Optional[Any] = None,
        service_uri: Optional[Any] = None,
        organization_name: Optional[Any] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_credential_type: Optional[Any] = None,
        service_principal_credential: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword deployment_type: Required. The deployment type of the Common Data Service for Apps
         instance. 'Online' for Common Data Service for Apps Online and 'OnPremisesWithIfd' for Common
         Data Service for Apps on-premises with Ifd. Type: string (or Expression with resultType
         string).
        :paramtype deployment_type: any
        :keyword host_name: The host name of the on-premises Common Data Service for Apps server. The
         property is required for on-prem and not allowed for online. Type: string (or Expression with
         resultType string).
        :paramtype host_name: any
        :keyword port: The port of on-premises Common Data Service for Apps server. The property is
         required for on-prem and not allowed for online. Default is 443. Type: integer (or Expression
         with resultType integer), minimum: 0.
        :paramtype port: any
        :keyword service_uri: The URL to the Microsoft Common Data Service for Apps server. The
         property is required for on-line and not allowed for on-prem. Type: string (or Expression with
         resultType string).
        :paramtype service_uri: any
        :keyword organization_name: The organization name of the Common Data Service for Apps instance.
         The property is required for on-prem and required for online when there are more than one
         Common Data Service for Apps instances associated with the user. Type: string (or Expression
         with resultType string).
        :paramtype organization_name: any
        :keyword authentication_type: Required. The authentication type to connect to Common Data
         Service for Apps server. 'Office365' for online scenario, 'Ifd' for on-premises with Ifd
         scenario. 'AADServicePrincipal' for Server-To-Server authentication in online scenario. Type:
         string (or Expression with resultType string).
        :paramtype authentication_type: any
        :keyword username: User name to access the Common Data Service for Apps instance. Type: string
         (or Expression with resultType string).
        :paramtype username: any
        :keyword password: Password to access the Common Data Service for Apps instance.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword service_principal_id: The client ID of the application in Azure Active Directory used
         for Server-To-Server authentication. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_credential_type: The service principal credential type to use in
         Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
         for certificate. Type: string (or Expression with resultType string).
        :paramtype service_principal_credential_type: any
        :keyword service_principal_credential: The credential of the service principal object in Azure
         Active Directory. If servicePrincipalCredentialType is 'ServicePrincipalKey',
         servicePrincipalCredential can be SecureString or AzureKeyVaultSecretReference. If
         servicePrincipalCredentialType is 'ServicePrincipalCert', servicePrincipalCredential can only
         be AzureKeyVaultSecretReference.
        :paramtype service_principal_credential: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(CommonDataServiceForAppsLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'CommonDataServiceForApps'  # type: str
        self.deployment_type = deployment_type
        self.host_name = host_name
        self.port = port
        self.service_uri = service_uri
        self.organization_name = organization_name
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_credential_type = service_principal_credential_type
        self.service_principal_credential = service_principal_credential
        self.encrypted_credential = encrypted_credential


class CommonDataServiceForAppsSink(CopySink):
    """A copy activity Common Data Service for Apps sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar write_behavior: Required. The write behavior for the operation. Possible values include:
     "Upsert".
    :vartype write_behavior: str or ~azure.mgmt.datafactory.models.DynamicsSinkWriteBehavior
    :ivar ignore_null_values: The flag indicating whether to ignore null values from input dataset
     (except key fields) during write operation. Default is false. Type: boolean (or Expression with
     resultType boolean).
    :vartype ignore_null_values: any
    :ivar alternate_key_name: The logical name of the alternate key which will be used when
     upserting records. Type: string (or Expression with resultType string).
    :vartype alternate_key_name: any
    """

    _validation = {
        'type': {'required': True},
        'write_behavior': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
        'ignore_null_values': {'key': 'ignoreNullValues', 'type': 'object'},
        'alternate_key_name': {'key': 'alternateKeyName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        write_behavior: Union[str, "DynamicsSinkWriteBehavior"],
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        ignore_null_values: Optional[Any] = None,
        alternate_key_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword write_behavior: Required. The write behavior for the operation. Possible values
         include: "Upsert".
        :paramtype write_behavior: str or ~azure.mgmt.datafactory.models.DynamicsSinkWriteBehavior
        :keyword ignore_null_values: The flag indicating whether to ignore null values from input
         dataset (except key fields) during write operation. Default is false. Type: boolean (or
         Expression with resultType boolean).
        :paramtype ignore_null_values: any
        :keyword alternate_key_name: The logical name of the alternate key which will be used when
         upserting records. Type: string (or Expression with resultType string).
        :paramtype alternate_key_name: any
        """
        super(CommonDataServiceForAppsSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'CommonDataServiceForAppsSink'  # type: str
        self.write_behavior = write_behavior
        self.ignore_null_values = ignore_null_values
        self.alternate_key_name = alternate_key_name


class CommonDataServiceForAppsSource(CopySource):
    """A copy activity Common Data Service for Apps source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: FetchXML is a proprietary query language that is used in Microsoft Common Data
     Service for Apps (online & on-premises). Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: FetchXML is a proprietary query language that is used in Microsoft Common Data
         Service for Apps (online & on-premises). Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(CommonDataServiceForAppsSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'CommonDataServiceForAppsSource'  # type: str
        self.query = query
        self.additional_columns = additional_columns


class ComponentSetup(CustomSetupBase):
    """The custom setup of installing 3rd party components.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. The type of custom setup.Constant filled by server.
    :vartype type: str
    :ivar component_name: Required. The name of the 3rd party component.
    :vartype component_name: str
    :ivar license_key: The license key to activate the component.
    :vartype license_key: ~azure.mgmt.datafactory.models.SecretBase
    """

    _validation = {
        'type': {'required': True},
        'component_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'component_name': {'key': 'typeProperties.componentName', 'type': 'str'},
        'license_key': {'key': 'typeProperties.licenseKey', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        component_name: str,
        license_key: Optional["SecretBase"] = None,
        **kwargs
    ):
        """
        :keyword component_name: Required. The name of the 3rd party component.
        :paramtype component_name: str
        :keyword license_key: The license key to activate the component.
        :paramtype license_key: ~azure.mgmt.datafactory.models.SecretBase
        """
        super(ComponentSetup, self).__init__(**kwargs)
        self.type = 'ComponentSetup'  # type: str
        self.component_name = component_name
        self.license_key = license_key


class CompressionReadSettings(msrest.serialization.Model):
    """Compression read settings.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: TarGZipReadSettings, TarReadSettings, ZipDeflateReadSettings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The Compression setting type.Constant filled by server.
    :vartype type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'TarGZipReadSettings': 'TarGZipReadSettings', 'TarReadSettings': 'TarReadSettings', 'ZipDeflateReadSettings': 'ZipDeflateReadSettings'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(CompressionReadSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'CompressionReadSettings'  # type: str


class ConcurLinkedService(LinkedService):
    """Concur Service linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_properties: Properties used to connect to Concur. It is mutually exclusive
     with any other properties in the linked service. Type: object.
    :vartype connection_properties: any
    :ivar client_id: Required. Application client_id supplied by Concur App Management.
    :vartype client_id: any
    :ivar username: Required. The user name that you use to access Concur Service.
    :vartype username: any
    :ivar password: The password corresponding to the user name that you provided in the username
     field.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'client_id': {'required': True},
        'username': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_properties': {'key': 'typeProperties.connectionProperties', 'type': 'object'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        client_id: Any,
        username: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_properties: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_properties: Properties used to connect to Concur. It is mutually exclusive
         with any other properties in the linked service. Type: object.
        :paramtype connection_properties: any
        :keyword client_id: Required. Application client_id supplied by Concur App Management.
        :paramtype client_id: any
        :keyword username: Required. The user name that you use to access Concur Service.
        :paramtype username: any
        :keyword password: The password corresponding to the user name that you provided in the
         username field.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true.
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true.
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(ConcurLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Concur'  # type: str
        self.connection_properties = connection_properties
        self.client_id = client_id
        self.username = username
        self.password = password
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ConcurObjectDataset(Dataset):
    """Concur Service dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(ConcurObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ConcurObject'  # type: str
        self.table_name = table_name


class ConcurSource(TabularSource):
    """A copy activity Concur Service source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(ConcurSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'ConcurSource'  # type: str
        self.query = query


class ConnectionStateProperties(msrest.serialization.Model):
    """The connection state of a managed private endpoint.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar actions_required: The actions required on the managed private endpoint.
    :vartype actions_required: str
    :ivar description: The managed private endpoint description.
    :vartype description: str
    :ivar status: The approval status.
    :vartype status: str
    """

    _validation = {
        'actions_required': {'readonly': True},
        'description': {'readonly': True},
        'status': {'readonly': True},
    }

    _attribute_map = {
        'actions_required': {'key': 'actionsRequired', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(ConnectionStateProperties, self).__init__(**kwargs)
        self.actions_required = None
        self.description = None
        self.status = None


class CopyActivity(ExecutionActivity):
    """Copy activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar inputs: List of inputs for the activity.
    :vartype inputs: list[~azure.mgmt.datafactory.models.DatasetReference]
    :ivar outputs: List of outputs for the activity.
    :vartype outputs: list[~azure.mgmt.datafactory.models.DatasetReference]
    :ivar source: Required. Copy activity source.
    :vartype source: ~azure.mgmt.datafactory.models.CopySource
    :ivar sink: Required. Copy activity sink.
    :vartype sink: ~azure.mgmt.datafactory.models.CopySink
    :ivar translator: Copy activity translator. If not specified, tabular translator is used.
    :vartype translator: any
    :ivar enable_staging: Specifies whether to copy data via an interim staging. Default value is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype enable_staging: any
    :ivar staging_settings: Specifies interim staging settings when EnableStaging is true.
    :vartype staging_settings: ~azure.mgmt.datafactory.models.StagingSettings
    :ivar parallel_copies: Maximum number of concurrent sessions opened on the source or sink to
     avoid overloading the data store. Type: integer (or Expression with resultType integer),
     minimum: 0.
    :vartype parallel_copies: any
    :ivar data_integration_units: Maximum number of data integration units that can be used to
     perform this data movement. Type: integer (or Expression with resultType integer), minimum: 0.
    :vartype data_integration_units: any
    :ivar enable_skip_incompatible_row: Whether to skip incompatible row. Default value is false.
     Type: boolean (or Expression with resultType boolean).
    :vartype enable_skip_incompatible_row: any
    :ivar redirect_incompatible_row_settings: Redirect incompatible row settings when
     EnableSkipIncompatibleRow is true.
    :vartype redirect_incompatible_row_settings:
     ~azure.mgmt.datafactory.models.RedirectIncompatibleRowSettings
    :ivar log_storage_settings: (Deprecated. Please use LogSettings) Log storage settings customer
     need to provide when enabling session log.
    :vartype log_storage_settings: ~azure.mgmt.datafactory.models.LogStorageSettings
    :ivar log_settings: Log settings customer needs provide when enabling log.
    :vartype log_settings: ~azure.mgmt.datafactory.models.LogSettings
    :ivar preserve_rules: Preserve Rules.
    :vartype preserve_rules: list[any]
    :ivar preserve: Preserve rules.
    :vartype preserve: list[any]
    :ivar validate_data_consistency: Whether to enable Data Consistency validation. Type: boolean
     (or Expression with resultType boolean).
    :vartype validate_data_consistency: any
    :ivar skip_error_file: Specify the fault tolerance for data consistency.
    :vartype skip_error_file: ~azure.mgmt.datafactory.models.SkipErrorFile
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'source': {'required': True},
        'sink': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'inputs': {'key': 'inputs', 'type': '[DatasetReference]'},
        'outputs': {'key': 'outputs', 'type': '[DatasetReference]'},
        'source': {'key': 'typeProperties.source', 'type': 'CopySource'},
        'sink': {'key': 'typeProperties.sink', 'type': 'CopySink'},
        'translator': {'key': 'typeProperties.translator', 'type': 'object'},
        'enable_staging': {'key': 'typeProperties.enableStaging', 'type': 'object'},
        'staging_settings': {'key': 'typeProperties.stagingSettings', 'type': 'StagingSettings'},
        'parallel_copies': {'key': 'typeProperties.parallelCopies', 'type': 'object'},
        'data_integration_units': {'key': 'typeProperties.dataIntegrationUnits', 'type': 'object'},
        'enable_skip_incompatible_row': {'key': 'typeProperties.enableSkipIncompatibleRow', 'type': 'object'},
        'redirect_incompatible_row_settings': {'key': 'typeProperties.redirectIncompatibleRowSettings', 'type': 'RedirectIncompatibleRowSettings'},
        'log_storage_settings': {'key': 'typeProperties.logStorageSettings', 'type': 'LogStorageSettings'},
        'log_settings': {'key': 'typeProperties.logSettings', 'type': 'LogSettings'},
        'preserve_rules': {'key': 'typeProperties.preserveRules', 'type': '[object]'},
        'preserve': {'key': 'typeProperties.preserve', 'type': '[object]'},
        'validate_data_consistency': {'key': 'typeProperties.validateDataConsistency', 'type': 'object'},
        'skip_error_file': {'key': 'typeProperties.skipErrorFile', 'type': 'SkipErrorFile'},
    }

    def __init__(
        self,
        *,
        name: str,
        source: "CopySource",
        sink: "CopySink",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        inputs: Optional[List["DatasetReference"]] = None,
        outputs: Optional[List["DatasetReference"]] = None,
        translator: Optional[Any] = None,
        enable_staging: Optional[Any] = None,
        staging_settings: Optional["StagingSettings"] = None,
        parallel_copies: Optional[Any] = None,
        data_integration_units: Optional[Any] = None,
        enable_skip_incompatible_row: Optional[Any] = None,
        redirect_incompatible_row_settings: Optional["RedirectIncompatibleRowSettings"] = None,
        log_storage_settings: Optional["LogStorageSettings"] = None,
        log_settings: Optional["LogSettings"] = None,
        preserve_rules: Optional[List[Any]] = None,
        preserve: Optional[List[Any]] = None,
        validate_data_consistency: Optional[Any] = None,
        skip_error_file: Optional["SkipErrorFile"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword inputs: List of inputs for the activity.
        :paramtype inputs: list[~azure.mgmt.datafactory.models.DatasetReference]
        :keyword outputs: List of outputs for the activity.
        :paramtype outputs: list[~azure.mgmt.datafactory.models.DatasetReference]
        :keyword source: Required. Copy activity source.
        :paramtype source: ~azure.mgmt.datafactory.models.CopySource
        :keyword sink: Required. Copy activity sink.
        :paramtype sink: ~azure.mgmt.datafactory.models.CopySink
        :keyword translator: Copy activity translator. If not specified, tabular translator is used.
        :paramtype translator: any
        :keyword enable_staging: Specifies whether to copy data via an interim staging. Default value
         is false. Type: boolean (or Expression with resultType boolean).
        :paramtype enable_staging: any
        :keyword staging_settings: Specifies interim staging settings when EnableStaging is true.
        :paramtype staging_settings: ~azure.mgmt.datafactory.models.StagingSettings
        :keyword parallel_copies: Maximum number of concurrent sessions opened on the source or sink to
         avoid overloading the data store. Type: integer (or Expression with resultType integer),
         minimum: 0.
        :paramtype parallel_copies: any
        :keyword data_integration_units: Maximum number of data integration units that can be used to
         perform this data movement. Type: integer (or Expression with resultType integer), minimum: 0.
        :paramtype data_integration_units: any
        :keyword enable_skip_incompatible_row: Whether to skip incompatible row. Default value is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype enable_skip_incompatible_row: any
        :keyword redirect_incompatible_row_settings: Redirect incompatible row settings when
         EnableSkipIncompatibleRow is true.
        :paramtype redirect_incompatible_row_settings:
         ~azure.mgmt.datafactory.models.RedirectIncompatibleRowSettings
        :keyword log_storage_settings: (Deprecated. Please use LogSettings) Log storage settings
         customer need to provide when enabling session log.
        :paramtype log_storage_settings: ~azure.mgmt.datafactory.models.LogStorageSettings
        :keyword log_settings: Log settings customer needs provide when enabling log.
        :paramtype log_settings: ~azure.mgmt.datafactory.models.LogSettings
        :keyword preserve_rules: Preserve Rules.
        :paramtype preserve_rules: list[any]
        :keyword preserve: Preserve rules.
        :paramtype preserve: list[any]
        :keyword validate_data_consistency: Whether to enable Data Consistency validation. Type:
         boolean (or Expression with resultType boolean).
        :paramtype validate_data_consistency: any
        :keyword skip_error_file: Specify the fault tolerance for data consistency.
        :paramtype skip_error_file: ~azure.mgmt.datafactory.models.SkipErrorFile
        """
        super(CopyActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'Copy'  # type: str
        self.inputs = inputs
        self.outputs = outputs
        self.source = source
        self.sink = sink
        self.translator = translator
        self.enable_staging = enable_staging
        self.staging_settings = staging_settings
        self.parallel_copies = parallel_copies
        self.data_integration_units = data_integration_units
        self.enable_skip_incompatible_row = enable_skip_incompatible_row
        self.redirect_incompatible_row_settings = redirect_incompatible_row_settings
        self.log_storage_settings = log_storage_settings
        self.log_settings = log_settings
        self.preserve_rules = preserve_rules
        self.preserve = preserve
        self.validate_data_consistency = validate_data_consistency
        self.skip_error_file = skip_error_file


class CopyActivityLogSettings(msrest.serialization.Model):
    """Settings for copy activity log.

    :ivar log_level: Gets or sets the log level, support: Info, Warning. Type: string (or
     Expression with resultType string).
    :vartype log_level: any
    :ivar enable_reliable_logging: Specifies whether to enable reliable logging. Type: boolean (or
     Expression with resultType boolean).
    :vartype enable_reliable_logging: any
    """

    _attribute_map = {
        'log_level': {'key': 'logLevel', 'type': 'object'},
        'enable_reliable_logging': {'key': 'enableReliableLogging', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        log_level: Optional[Any] = None,
        enable_reliable_logging: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword log_level: Gets or sets the log level, support: Info, Warning. Type: string (or
         Expression with resultType string).
        :paramtype log_level: any
        :keyword enable_reliable_logging: Specifies whether to enable reliable logging. Type: boolean
         (or Expression with resultType boolean).
        :paramtype enable_reliable_logging: any
        """
        super(CopyActivityLogSettings, self).__init__(**kwargs)
        self.log_level = log_level
        self.enable_reliable_logging = enable_reliable_logging


class CopyTranslator(msrest.serialization.Model):
    """A copy activity translator.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: TabularTranslator.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy translator type.Constant filled by server.
    :vartype type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'TabularTranslator': 'TabularTranslator'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(CopyTranslator, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'CopyTranslator'  # type: str


class CosmosDbLinkedService(LinkedService):
    """Microsoft Azure Cosmos Database (CosmosDB) linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar account_endpoint: The endpoint of the Azure CosmosDB account. Type: string (or Expression
     with resultType string).
    :vartype account_endpoint: any
    :ivar database: The name of the database. Type: string (or Expression with resultType string).
    :vartype database: any
    :ivar account_key: The account key of the Azure CosmosDB account. Type: SecureString or
     AzureKeyVaultSecretReference.
    :vartype account_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar service_principal_id: The client ID of the application in Azure Active Directory used for
     Server-To-Server authentication. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_credential_type: The service principal credential type to use in
     Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
     for certificate. Type: string (or Expression with resultType string). Possible values include:
     "ServicePrincipalKey", "ServicePrincipalCert".
    :vartype service_principal_credential_type: str or
     ~azure.mgmt.datafactory.models.CosmosDbServicePrincipalCredentialType
    :ivar service_principal_credential: The credential of the service principal object in Azure
     Active Directory. If servicePrincipalCredentialType is 'ServicePrincipalKey',
     servicePrincipalCredential can be SecureString or AzureKeyVaultSecretReference. If
     servicePrincipalCredentialType is 'ServicePrincipalCert', servicePrincipalCredential can only
     be AzureKeyVaultSecretReference.
    :vartype service_principal_credential: ~azure.mgmt.datafactory.models.SecretBase
    :ivar tenant: The name or ID of the tenant to which the service principal belongs. Type: string
     (or Expression with resultType string).
    :vartype tenant: any
    :ivar azure_cloud_type: Indicates the azure cloud type of the service principle auth. Allowed
     values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is the data
     factory regions cloud type. Type: string (or Expression with resultType string).
    :vartype azure_cloud_type: any
    :ivar connection_mode: The connection mode used to access CosmosDB account. Type: string (or
     Expression with resultType string). Possible values include: "Gateway", "Direct".
    :vartype connection_mode: str or ~azure.mgmt.datafactory.models.CosmosDbConnectionMode
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'account_endpoint': {'key': 'typeProperties.accountEndpoint', 'type': 'object'},
        'database': {'key': 'typeProperties.database', 'type': 'object'},
        'account_key': {'key': 'typeProperties.accountKey', 'type': 'SecretBase'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_credential_type': {'key': 'typeProperties.servicePrincipalCredentialType', 'type': 'str'},
        'service_principal_credential': {'key': 'typeProperties.servicePrincipalCredential', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'azure_cloud_type': {'key': 'typeProperties.azureCloudType', 'type': 'object'},
        'connection_mode': {'key': 'typeProperties.connectionMode', 'type': 'str'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        account_endpoint: Optional[Any] = None,
        database: Optional[Any] = None,
        account_key: Optional["SecretBase"] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_credential_type: Optional[Union[str, "CosmosDbServicePrincipalCredentialType"]] = None,
        service_principal_credential: Optional["SecretBase"] = None,
        tenant: Optional[Any] = None,
        azure_cloud_type: Optional[Any] = None,
        connection_mode: Optional[Union[str, "CosmosDbConnectionMode"]] = None,
        encrypted_credential: Optional[Any] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: The connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword account_endpoint: The endpoint of the Azure CosmosDB account. Type: string (or
         Expression with resultType string).
        :paramtype account_endpoint: any
        :keyword database: The name of the database. Type: string (or Expression with resultType
         string).
        :paramtype database: any
        :keyword account_key: The account key of the Azure CosmosDB account. Type: SecureString or
         AzureKeyVaultSecretReference.
        :paramtype account_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword service_principal_id: The client ID of the application in Azure Active Directory used
         for Server-To-Server authentication. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_credential_type: The service principal credential type to use in
         Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
         for certificate. Type: string (or Expression with resultType string). Possible values include:
         "ServicePrincipalKey", "ServicePrincipalCert".
        :paramtype service_principal_credential_type: str or
         ~azure.mgmt.datafactory.models.CosmosDbServicePrincipalCredentialType
        :keyword service_principal_credential: The credential of the service principal object in Azure
         Active Directory. If servicePrincipalCredentialType is 'ServicePrincipalKey',
         servicePrincipalCredential can be SecureString or AzureKeyVaultSecretReference. If
         servicePrincipalCredentialType is 'ServicePrincipalCert', servicePrincipalCredential can only
         be AzureKeyVaultSecretReference.
        :paramtype service_principal_credential: ~azure.mgmt.datafactory.models.SecretBase
        :keyword tenant: The name or ID of the tenant to which the service principal belongs. Type:
         string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword azure_cloud_type: Indicates the azure cloud type of the service principle auth.
         Allowed values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is
         the data factory regions cloud type. Type: string (or Expression with resultType string).
        :paramtype azure_cloud_type: any
        :keyword connection_mode: The connection mode used to access CosmosDB account. Type: string (or
         Expression with resultType string). Possible values include: "Gateway", "Direct".
        :paramtype connection_mode: str or ~azure.mgmt.datafactory.models.CosmosDbConnectionMode
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(CosmosDbLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'CosmosDb'  # type: str
        self.connection_string = connection_string
        self.account_endpoint = account_endpoint
        self.database = database
        self.account_key = account_key
        self.service_principal_id = service_principal_id
        self.service_principal_credential_type = service_principal_credential_type
        self.service_principal_credential = service_principal_credential
        self.tenant = tenant
        self.azure_cloud_type = azure_cloud_type
        self.connection_mode = connection_mode
        self.encrypted_credential = encrypted_credential
        self.credential = credential


class CosmosDbMongoDbApiCollectionDataset(Dataset):
    """The CosmosDB (MongoDB API) database dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar collection: Required. The collection name of the CosmosDB (MongoDB API) database. Type:
     string (or Expression with resultType string).
    :vartype collection: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'collection': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'collection': {'key': 'typeProperties.collection', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        collection: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword collection: Required. The collection name of the CosmosDB (MongoDB API) database.
         Type: string (or Expression with resultType string).
        :paramtype collection: any
        """
        super(CosmosDbMongoDbApiCollectionDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'CosmosDbMongoDbApiCollection'  # type: str
        self.collection = collection


class CosmosDbMongoDbApiLinkedService(LinkedService):
    """Linked service for CosmosDB (MongoDB API) data source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar is_server_version_above32: Whether the CosmosDB (MongoDB API) server version is higher
     than 3.2. The default value is false. Type: boolean (or Expression with resultType boolean).
    :vartype is_server_version_above32: any
    :ivar connection_string: Required. The CosmosDB (MongoDB API) connection string. Type: string,
     SecureString or AzureKeyVaultSecretReference. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar database: Required. The name of the CosmosDB (MongoDB API) database that you want to
     access. Type: string (or Expression with resultType string).
    :vartype database: any
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'is_server_version_above32': {'key': 'typeProperties.isServerVersionAbove32', 'type': 'object'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'database': {'key': 'typeProperties.database', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        database: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        is_server_version_above32: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword is_server_version_above32: Whether the CosmosDB (MongoDB API) server version is higher
         than 3.2. The default value is false. Type: boolean (or Expression with resultType boolean).
        :paramtype is_server_version_above32: any
        :keyword connection_string: Required. The CosmosDB (MongoDB API) connection string. Type:
         string, SecureString or AzureKeyVaultSecretReference. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword database: Required. The name of the CosmosDB (MongoDB API) database that you want to
         access. Type: string (or Expression with resultType string).
        :paramtype database: any
        """
        super(CosmosDbMongoDbApiLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'CosmosDbMongoDbApi'  # type: str
        self.is_server_version_above32 = is_server_version_above32
        self.connection_string = connection_string
        self.database = database


class CosmosDbMongoDbApiSink(CopySink):
    """A copy activity sink for a CosmosDB (MongoDB API) database.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar write_behavior: Specifies whether the document with same key to be overwritten (upsert)
     rather than throw exception (insert). The default value is "insert". Type: string (or
     Expression with resultType string). Type: string (or Expression with resultType string).
    :vartype write_behavior: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        write_behavior: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword write_behavior: Specifies whether the document with same key to be overwritten
         (upsert) rather than throw exception (insert). The default value is "insert". Type: string (or
         Expression with resultType string). Type: string (or Expression with resultType string).
        :paramtype write_behavior: any
        """
        super(CosmosDbMongoDbApiSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'CosmosDbMongoDbApiSink'  # type: str
        self.write_behavior = write_behavior


class CosmosDbMongoDbApiSource(CopySource):
    """A copy activity source for a CosmosDB (MongoDB API) database.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar filter: Specifies selection filter using query operators. To return all documents in a
     collection, omit this parameter or pass an empty document ({}). Type: string (or Expression
     with resultType string).
    :vartype filter: any
    :ivar cursor_methods: Cursor methods for Mongodb query.
    :vartype cursor_methods: ~azure.mgmt.datafactory.models.MongoDbCursorMethodsProperties
    :ivar batch_size: Specifies the number of documents to return in each batch of the response
     from MongoDB instance. In most cases, modifying the batch size will not affect the user or the
     application. This property's main purpose is to avoid hit the limitation of response size.
     Type: integer (or Expression with resultType integer).
    :vartype batch_size: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'filter': {'key': 'filter', 'type': 'object'},
        'cursor_methods': {'key': 'cursorMethods', 'type': 'MongoDbCursorMethodsProperties'},
        'batch_size': {'key': 'batchSize', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        filter: Optional[Any] = None,
        cursor_methods: Optional["MongoDbCursorMethodsProperties"] = None,
        batch_size: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword filter: Specifies selection filter using query operators. To return all documents in a
         collection, omit this parameter or pass an empty document ({}). Type: string (or Expression
         with resultType string).
        :paramtype filter: any
        :keyword cursor_methods: Cursor methods for Mongodb query.
        :paramtype cursor_methods: ~azure.mgmt.datafactory.models.MongoDbCursorMethodsProperties
        :keyword batch_size: Specifies the number of documents to return in each batch of the response
         from MongoDB instance. In most cases, modifying the batch size will not affect the user or the
         application. This property's main purpose is to avoid hit the limitation of response size.
         Type: integer (or Expression with resultType integer).
        :paramtype batch_size: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(CosmosDbMongoDbApiSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'CosmosDbMongoDbApiSource'  # type: str
        self.filter = filter
        self.cursor_methods = cursor_methods
        self.batch_size = batch_size
        self.query_timeout = query_timeout
        self.additional_columns = additional_columns


class CosmosDbSqlApiCollectionDataset(Dataset):
    """Microsoft Azure CosmosDB (SQL API) Collection dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar collection_name: Required. CosmosDB (SQL API) collection name. Type: string (or
     Expression with resultType string).
    :vartype collection_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'collection_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'collection_name': {'key': 'typeProperties.collectionName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        collection_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword collection_name: Required. CosmosDB (SQL API) collection name. Type: string (or
         Expression with resultType string).
        :paramtype collection_name: any
        """
        super(CosmosDbSqlApiCollectionDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'CosmosDbSqlApiCollection'  # type: str
        self.collection_name = collection_name


class CosmosDbSqlApiSink(CopySink):
    """A copy activity Azure CosmosDB (SQL API) Collection sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar write_behavior: Describes how to write data to Azure Cosmos DB. Type: string (or
     Expression with resultType string). Allowed values: insert and upsert.
    :vartype write_behavior: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        write_behavior: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword write_behavior: Describes how to write data to Azure Cosmos DB. Type: string (or
         Expression with resultType string). Allowed values: insert and upsert.
        :paramtype write_behavior: any
        """
        super(CosmosDbSqlApiSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'CosmosDbSqlApiSink'  # type: str
        self.write_behavior = write_behavior


class CosmosDbSqlApiSource(CopySource):
    """A copy activity Azure CosmosDB (SQL API) Collection source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: SQL API query. Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar page_size: Page size of the result. Type: integer (or Expression with resultType
     integer).
    :vartype page_size: any
    :ivar preferred_regions: Preferred regions. Type: array of strings (or Expression with
     resultType array of strings).
    :vartype preferred_regions: any
    :ivar detect_datetime: Whether detect primitive values as datetime values. Type: boolean (or
     Expression with resultType boolean).
    :vartype detect_datetime: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'page_size': {'key': 'pageSize', 'type': 'object'},
        'preferred_regions': {'key': 'preferredRegions', 'type': 'object'},
        'detect_datetime': {'key': 'detectDatetime', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query: Optional[Any] = None,
        page_size: Optional[Any] = None,
        preferred_regions: Optional[Any] = None,
        detect_datetime: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: SQL API query. Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword page_size: Page size of the result. Type: integer (or Expression with resultType
         integer).
        :paramtype page_size: any
        :keyword preferred_regions: Preferred regions. Type: array of strings (or Expression with
         resultType array of strings).
        :paramtype preferred_regions: any
        :keyword detect_datetime: Whether detect primitive values as datetime values. Type: boolean (or
         Expression with resultType boolean).
        :paramtype detect_datetime: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(CosmosDbSqlApiSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'CosmosDbSqlApiSource'  # type: str
        self.query = query
        self.page_size = page_size
        self.preferred_regions = preferred_regions
        self.detect_datetime = detect_datetime
        self.additional_columns = additional_columns


class CouchbaseLinkedService(LinkedService):
    """Couchbase server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar cred_string: The Azure key vault secret reference of credString in connection string.
    :vartype cred_string: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'cred_string': {'key': 'typeProperties.credString', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        cred_string: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: An ODBC connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword cred_string: The Azure key vault secret reference of credString in connection string.
        :paramtype cred_string: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(CouchbaseLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Couchbase'  # type: str
        self.connection_string = connection_string
        self.cred_string = cred_string
        self.encrypted_credential = encrypted_credential


class CouchbaseSource(TabularSource):
    """A copy activity Couchbase server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(CouchbaseSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'CouchbaseSource'  # type: str
        self.query = query


class CouchbaseTableDataset(Dataset):
    """Couchbase server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(CouchbaseTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'CouchbaseTable'  # type: str
        self.table_name = table_name


class CreateDataFlowDebugSessionRequest(msrest.serialization.Model):
    """Request body structure for creating data flow debug session.

    :ivar compute_type: Compute type of the cluster. The value will be overwritten by the same
     setting in integration runtime if provided.
    :vartype compute_type: str
    :ivar core_count: Core count of the cluster. The value will be overwritten by the same setting
     in integration runtime if provided.
    :vartype core_count: int
    :ivar time_to_live: Time to live setting of the cluster in minutes.
    :vartype time_to_live: int
    :ivar integration_runtime: Set to use integration runtime setting for data flow debug session.
    :vartype integration_runtime: ~azure.mgmt.datafactory.models.IntegrationRuntimeDebugResource
    """

    _attribute_map = {
        'compute_type': {'key': 'computeType', 'type': 'str'},
        'core_count': {'key': 'coreCount', 'type': 'int'},
        'time_to_live': {'key': 'timeToLive', 'type': 'int'},
        'integration_runtime': {'key': 'integrationRuntime', 'type': 'IntegrationRuntimeDebugResource'},
    }

    def __init__(
        self,
        *,
        compute_type: Optional[str] = None,
        core_count: Optional[int] = None,
        time_to_live: Optional[int] = None,
        integration_runtime: Optional["IntegrationRuntimeDebugResource"] = None,
        **kwargs
    ):
        """
        :keyword compute_type: Compute type of the cluster. The value will be overwritten by the same
         setting in integration runtime if provided.
        :paramtype compute_type: str
        :keyword core_count: Core count of the cluster. The value will be overwritten by the same
         setting in integration runtime if provided.
        :paramtype core_count: int
        :keyword time_to_live: Time to live setting of the cluster in minutes.
        :paramtype time_to_live: int
        :keyword integration_runtime: Set to use integration runtime setting for data flow debug
         session.
        :paramtype integration_runtime: ~azure.mgmt.datafactory.models.IntegrationRuntimeDebugResource
        """
        super(CreateDataFlowDebugSessionRequest, self).__init__(**kwargs)
        self.compute_type = compute_type
        self.core_count = core_count
        self.time_to_live = time_to_live
        self.integration_runtime = integration_runtime


class CreateDataFlowDebugSessionResponse(msrest.serialization.Model):
    """Response body structure for creating data flow debug session.

    :ivar status: The state of the debug session.
    :vartype status: str
    :ivar session_id: The ID of data flow debug session.
    :vartype session_id: str
    """

    _attribute_map = {
        'status': {'key': 'status', 'type': 'str'},
        'session_id': {'key': 'sessionId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        status: Optional[str] = None,
        session_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword status: The state of the debug session.
        :paramtype status: str
        :keyword session_id: The ID of data flow debug session.
        :paramtype session_id: str
        """
        super(CreateDataFlowDebugSessionResponse, self).__init__(**kwargs)
        self.status = status
        self.session_id = session_id


class CreateLinkedIntegrationRuntimeRequest(msrest.serialization.Model):
    """The linked integration runtime information.

    :ivar name: The name of the linked integration runtime.
    :vartype name: str
    :ivar subscription_id: The ID of the subscription that the linked integration runtime belongs
     to.
    :vartype subscription_id: str
    :ivar data_factory_name: The name of the data factory that the linked integration runtime
     belongs to.
    :vartype data_factory_name: str
    :ivar data_factory_location: The location of the data factory that the linked integration
     runtime belongs to.
    :vartype data_factory_location: str
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'subscription_id': {'key': 'subscriptionId', 'type': 'str'},
        'data_factory_name': {'key': 'dataFactoryName', 'type': 'str'},
        'data_factory_location': {'key': 'dataFactoryLocation', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        subscription_id: Optional[str] = None,
        data_factory_name: Optional[str] = None,
        data_factory_location: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword name: The name of the linked integration runtime.
        :paramtype name: str
        :keyword subscription_id: The ID of the subscription that the linked integration runtime
         belongs to.
        :paramtype subscription_id: str
        :keyword data_factory_name: The name of the data factory that the linked integration runtime
         belongs to.
        :paramtype data_factory_name: str
        :keyword data_factory_location: The location of the data factory that the linked integration
         runtime belongs to.
        :paramtype data_factory_location: str
        """
        super(CreateLinkedIntegrationRuntimeRequest, self).__init__(**kwargs)
        self.name = name
        self.subscription_id = subscription_id
        self.data_factory_name = data_factory_name
        self.data_factory_location = data_factory_location


class CreateRunResponse(msrest.serialization.Model):
    """Response body with a run identifier.

    All required parameters must be populated in order to send to Azure.

    :ivar run_id: Required. Identifier of a run.
    :vartype run_id: str
    """

    _validation = {
        'run_id': {'required': True},
    }

    _attribute_map = {
        'run_id': {'key': 'runId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        run_id: str,
        **kwargs
    ):
        """
        :keyword run_id: Required. Identifier of a run.
        :paramtype run_id: str
        """
        super(CreateRunResponse, self).__init__(**kwargs)
        self.run_id = run_id


class Credential(msrest.serialization.Model):
    """The Azure Data Factory nested object which contains the information and credential which can be used to connect with related store or compute resource.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: ManagedIdentityCredential, ServicePrincipalCredential.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of credential.Constant filled by server.
    :vartype type: str
    :ivar description: Credential description.
    :vartype description: str
    :ivar annotations: List of tags that can be used for describing the Credential.
    :vartype annotations: list[any]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
    }

    _subtype_map = {
        'type': {'ManagedIdentity': 'ManagedIdentityCredential', 'ServicePrincipal': 'ServicePrincipalCredential'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Credential description.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the Credential.
        :paramtype annotations: list[any]
        """
        super(Credential, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'Credential'  # type: str
        self.description = description
        self.annotations = annotations


class CredentialReference(msrest.serialization.Model):
    """Credential reference type.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Credential reference type. Possible values include:
     "CredentialReference".
    :vartype type: str or ~azure.mgmt.datafactory.models.CredentialReferenceType
    :ivar reference_name: Required. Reference credential name.
    :vartype reference_name: str
    """

    _validation = {
        'type': {'required': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        type: Union[str, "CredentialReferenceType"],
        reference_name: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword type: Required. Credential reference type. Possible values include:
         "CredentialReference".
        :paramtype type: str or ~azure.mgmt.datafactory.models.CredentialReferenceType
        :keyword reference_name: Required. Reference credential name.
        :paramtype reference_name: str
        """
        super(CredentialReference, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = type
        self.reference_name = reference_name


class SubResource(msrest.serialization.Model):
    """Azure Data Factory nested resource, which belongs to a factory.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(SubResource, self).__init__(**kwargs)
        self.id = None
        self.name = None
        self.type = None
        self.etag = None


class CredentialResource(SubResource):
    """Credential resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :ivar properties: Required. Properties of credentials.
    :vartype properties: ~azure.mgmt.datafactory.models.Credential
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'Credential'},
    }

    def __init__(
        self,
        *,
        properties: "Credential",
        **kwargs
    ):
        """
        :keyword properties: Required. Properties of credentials.
        :paramtype properties: ~azure.mgmt.datafactory.models.Credential
        """
        super(CredentialResource, self).__init__(**kwargs)
        self.properties = properties


class CustomActivity(ExecutionActivity):
    """Custom activity type.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar command: Required. Command for custom activity Type: string (or Expression with
     resultType string).
    :vartype command: any
    :ivar resource_linked_service: Resource linked service reference.
    :vartype resource_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar folder_path: Folder path for resource files Type: string (or Expression with resultType
     string).
    :vartype folder_path: any
    :ivar reference_objects: Reference objects.
    :vartype reference_objects: ~azure.mgmt.datafactory.models.CustomActivityReferenceObject
    :ivar extended_properties: User defined property bag. There is no restriction on the keys or
     values that can be used. The user specified custom activity has the full responsibility to
     consume and interpret the content defined.
    :vartype extended_properties: dict[str, any]
    :ivar retention_time_in_days: The retention time for the files submitted for custom activity.
     Type: double (or Expression with resultType double).
    :vartype retention_time_in_days: any
    :ivar auto_user_specification: Elevation level and scope for the user, default is nonadmin
     task. Type: string (or Expression with resultType double).
    :vartype auto_user_specification: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'command': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'command': {'key': 'typeProperties.command', 'type': 'object'},
        'resource_linked_service': {'key': 'typeProperties.resourceLinkedService', 'type': 'LinkedServiceReference'},
        'folder_path': {'key': 'typeProperties.folderPath', 'type': 'object'},
        'reference_objects': {'key': 'typeProperties.referenceObjects', 'type': 'CustomActivityReferenceObject'},
        'extended_properties': {'key': 'typeProperties.extendedProperties', 'type': '{object}'},
        'retention_time_in_days': {'key': 'typeProperties.retentionTimeInDays', 'type': 'object'},
        'auto_user_specification': {'key': 'typeProperties.autoUserSpecification', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        command: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        resource_linked_service: Optional["LinkedServiceReference"] = None,
        folder_path: Optional[Any] = None,
        reference_objects: Optional["CustomActivityReferenceObject"] = None,
        extended_properties: Optional[Dict[str, Any]] = None,
        retention_time_in_days: Optional[Any] = None,
        auto_user_specification: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword command: Required. Command for custom activity Type: string (or Expression with
         resultType string).
        :paramtype command: any
        :keyword resource_linked_service: Resource linked service reference.
        :paramtype resource_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword folder_path: Folder path for resource files Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword reference_objects: Reference objects.
        :paramtype reference_objects: ~azure.mgmt.datafactory.models.CustomActivityReferenceObject
        :keyword extended_properties: User defined property bag. There is no restriction on the keys or
         values that can be used. The user specified custom activity has the full responsibility to
         consume and interpret the content defined.
        :paramtype extended_properties: dict[str, any]
        :keyword retention_time_in_days: The retention time for the files submitted for custom
         activity. Type: double (or Expression with resultType double).
        :paramtype retention_time_in_days: any
        :keyword auto_user_specification: Elevation level and scope for the user, default is nonadmin
         task. Type: string (or Expression with resultType double).
        :paramtype auto_user_specification: any
        """
        super(CustomActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'Custom'  # type: str
        self.command = command
        self.resource_linked_service = resource_linked_service
        self.folder_path = folder_path
        self.reference_objects = reference_objects
        self.extended_properties = extended_properties
        self.retention_time_in_days = retention_time_in_days
        self.auto_user_specification = auto_user_specification


class CustomActivityReferenceObject(msrest.serialization.Model):
    """Reference objects for custom activity.

    :ivar linked_services: Linked service references.
    :vartype linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceReference]
    :ivar datasets: Dataset references.
    :vartype datasets: list[~azure.mgmt.datafactory.models.DatasetReference]
    """

    _attribute_map = {
        'linked_services': {'key': 'linkedServices', 'type': '[LinkedServiceReference]'},
        'datasets': {'key': 'datasets', 'type': '[DatasetReference]'},
    }

    def __init__(
        self,
        *,
        linked_services: Optional[List["LinkedServiceReference"]] = None,
        datasets: Optional[List["DatasetReference"]] = None,
        **kwargs
    ):
        """
        :keyword linked_services: Linked service references.
        :paramtype linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceReference]
        :keyword datasets: Dataset references.
        :paramtype datasets: list[~azure.mgmt.datafactory.models.DatasetReference]
        """
        super(CustomActivityReferenceObject, self).__init__(**kwargs)
        self.linked_services = linked_services
        self.datasets = datasets


class CustomDataset(Dataset):
    """The custom dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar type_properties: Custom dataset properties.
    :vartype type_properties: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'type_properties': {'key': 'typeProperties', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        type_properties: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword type_properties: Custom dataset properties.
        :paramtype type_properties: any
        """
        super(CustomDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'CustomDataset'  # type: str
        self.type_properties = type_properties


class CustomDataSourceLinkedService(LinkedService):
    """Custom linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar type_properties: Required. Custom linked service properties.
    :vartype type_properties: any
    """

    _validation = {
        'type': {'required': True},
        'type_properties': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'type_properties': {'key': 'typeProperties', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        type_properties: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword type_properties: Required. Custom linked service properties.
        :paramtype type_properties: any
        """
        super(CustomDataSourceLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'CustomDataSource'  # type: str
        self.type_properties = type_properties


class CustomEventsTrigger(MultiplePipelineTrigger):
    """Trigger that runs every time a custom event is received.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Trigger type.Constant filled by server.
    :vartype type: str
    :ivar description: Trigger description.
    :vartype description: str
    :ivar runtime_state: Indicates if trigger is running or not. Updated when Start/Stop APIs are
     called on the Trigger. Possible values include: "Started", "Stopped", "Disabled".
    :vartype runtime_state: str or ~azure.mgmt.datafactory.models.TriggerRuntimeState
    :ivar annotations: List of tags that can be used for describing the trigger.
    :vartype annotations: list[any]
    :ivar pipelines: Pipelines that need to be started.
    :vartype pipelines: list[~azure.mgmt.datafactory.models.TriggerPipelineReference]
    :ivar subject_begins_with: The event subject must begin with the pattern provided for trigger
     to fire. At least one of these must be provided: subjectBeginsWith, subjectEndsWith.
    :vartype subject_begins_with: str
    :ivar subject_ends_with: The event subject must end with the pattern provided for trigger to
     fire. At least one of these must be provided: subjectBeginsWith, subjectEndsWith.
    :vartype subject_ends_with: str
    :ivar events: Required. The list of event types that cause this trigger to fire.
    :vartype events: list[any]
    :ivar scope: Required. The ARM resource ID of the Azure Event Grid Topic.
    :vartype scope: str
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
        'events': {'required': True},
        'scope': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'pipelines': {'key': 'pipelines', 'type': '[TriggerPipelineReference]'},
        'subject_begins_with': {'key': 'typeProperties.subjectBeginsWith', 'type': 'str'},
        'subject_ends_with': {'key': 'typeProperties.subjectEndsWith', 'type': 'str'},
        'events': {'key': 'typeProperties.events', 'type': '[object]'},
        'scope': {'key': 'typeProperties.scope', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        events: List[Any],
        scope: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        pipelines: Optional[List["TriggerPipelineReference"]] = None,
        subject_begins_with: Optional[str] = None,
        subject_ends_with: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Trigger description.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the trigger.
        :paramtype annotations: list[any]
        :keyword pipelines: Pipelines that need to be started.
        :paramtype pipelines: list[~azure.mgmt.datafactory.models.TriggerPipelineReference]
        :keyword subject_begins_with: The event subject must begin with the pattern provided for
         trigger to fire. At least one of these must be provided: subjectBeginsWith, subjectEndsWith.
        :paramtype subject_begins_with: str
        :keyword subject_ends_with: The event subject must end with the pattern provided for trigger to
         fire. At least one of these must be provided: subjectBeginsWith, subjectEndsWith.
        :paramtype subject_ends_with: str
        :keyword events: Required. The list of event types that cause this trigger to fire.
        :paramtype events: list[any]
        :keyword scope: Required. The ARM resource ID of the Azure Event Grid Topic.
        :paramtype scope: str
        """
        super(CustomEventsTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, pipelines=pipelines, **kwargs)
        self.type = 'CustomEventsTrigger'  # type: str
        self.subject_begins_with = subject_begins_with
        self.subject_ends_with = subject_ends_with
        self.events = events
        self.scope = scope


class DatabricksNotebookActivity(ExecutionActivity):
    """DatabricksNotebook activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar notebook_path: Required. The absolute path of the notebook to be run in the Databricks
     Workspace. This path must begin with a slash. Type: string (or Expression with resultType
     string).
    :vartype notebook_path: any
    :ivar base_parameters: Base parameters to be used for each run of this job.If the notebook
     takes a parameter that is not specified, the default value from the notebook will be used.
    :vartype base_parameters: dict[str, any]
    :ivar libraries: A list of libraries to be installed on the cluster that will execute the job.
    :vartype libraries: list[dict[str, any]]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'notebook_path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'notebook_path': {'key': 'typeProperties.notebookPath', 'type': 'object'},
        'base_parameters': {'key': 'typeProperties.baseParameters', 'type': '{object}'},
        'libraries': {'key': 'typeProperties.libraries', 'type': '[{object}]'},
    }

    def __init__(
        self,
        *,
        name: str,
        notebook_path: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        base_parameters: Optional[Dict[str, Any]] = None,
        libraries: Optional[List[Dict[str, Any]]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword notebook_path: Required. The absolute path of the notebook to be run in the Databricks
         Workspace. This path must begin with a slash. Type: string (or Expression with resultType
         string).
        :paramtype notebook_path: any
        :keyword base_parameters: Base parameters to be used for each run of this job.If the notebook
         takes a parameter that is not specified, the default value from the notebook will be used.
        :paramtype base_parameters: dict[str, any]
        :keyword libraries: A list of libraries to be installed on the cluster that will execute the
         job.
        :paramtype libraries: list[dict[str, any]]
        """
        super(DatabricksNotebookActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'DatabricksNotebook'  # type: str
        self.notebook_path = notebook_path
        self.base_parameters = base_parameters
        self.libraries = libraries


class DatabricksSparkJarActivity(ExecutionActivity):
    """DatabricksSparkJar activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar main_class_name: Required. The full name of the class containing the main method to be
     executed. This class must be contained in a JAR provided as a library. Type: string (or
     Expression with resultType string).
    :vartype main_class_name: any
    :ivar parameters: Parameters that will be passed to the main method.
    :vartype parameters: list[any]
    :ivar libraries: A list of libraries to be installed on the cluster that will execute the job.
    :vartype libraries: list[dict[str, any]]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'main_class_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'main_class_name': {'key': 'typeProperties.mainClassName', 'type': 'object'},
        'parameters': {'key': 'typeProperties.parameters', 'type': '[object]'},
        'libraries': {'key': 'typeProperties.libraries', 'type': '[{object}]'},
    }

    def __init__(
        self,
        *,
        name: str,
        main_class_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        parameters: Optional[List[Any]] = None,
        libraries: Optional[List[Dict[str, Any]]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword main_class_name: Required. The full name of the class containing the main method to be
         executed. This class must be contained in a JAR provided as a library. Type: string (or
         Expression with resultType string).
        :paramtype main_class_name: any
        :keyword parameters: Parameters that will be passed to the main method.
        :paramtype parameters: list[any]
        :keyword libraries: A list of libraries to be installed on the cluster that will execute the
         job.
        :paramtype libraries: list[dict[str, any]]
        """
        super(DatabricksSparkJarActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'DatabricksSparkJar'  # type: str
        self.main_class_name = main_class_name
        self.parameters = parameters
        self.libraries = libraries


class DatabricksSparkPythonActivity(ExecutionActivity):
    """DatabricksSparkPython activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar python_file: Required. The URI of the Python file to be executed. DBFS paths are
     supported. Type: string (or Expression with resultType string).
    :vartype python_file: any
    :ivar parameters: Command line parameters that will be passed to the Python file.
    :vartype parameters: list[any]
    :ivar libraries: A list of libraries to be installed on the cluster that will execute the job.
    :vartype libraries: list[dict[str, any]]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'python_file': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'python_file': {'key': 'typeProperties.pythonFile', 'type': 'object'},
        'parameters': {'key': 'typeProperties.parameters', 'type': '[object]'},
        'libraries': {'key': 'typeProperties.libraries', 'type': '[{object}]'},
    }

    def __init__(
        self,
        *,
        name: str,
        python_file: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        parameters: Optional[List[Any]] = None,
        libraries: Optional[List[Dict[str, Any]]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword python_file: Required. The URI of the Python file to be executed. DBFS paths are
         supported. Type: string (or Expression with resultType string).
        :paramtype python_file: any
        :keyword parameters: Command line parameters that will be passed to the Python file.
        :paramtype parameters: list[any]
        :keyword libraries: A list of libraries to be installed on the cluster that will execute the
         job.
        :paramtype libraries: list[dict[str, any]]
        """
        super(DatabricksSparkPythonActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'DatabricksSparkPython'  # type: str
        self.python_file = python_file
        self.parameters = parameters
        self.libraries = libraries


class DataFlow(msrest.serialization.Model):
    """Azure Data Factory nested object which contains a flow with data movements and transformations.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: Flowlet, MappingDataFlow, WranglingDataFlow.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of data flow.Constant filled by server.
    :vartype type: str
    :ivar description: The description of the data flow.
    :vartype description: str
    :ivar annotations: List of tags that can be used for describing the data flow.
    :vartype annotations: list[any]
    :ivar folder: The folder that this data flow is in. If not specified, Data flow will appear at
     the root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DataFlowFolder
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DataFlowFolder'},
    }

    _subtype_map = {
        'type': {'Flowlet': 'Flowlet', 'MappingDataFlow': 'MappingDataFlow', 'WranglingDataFlow': 'WranglingDataFlow'}
    }

    def __init__(
        self,
        *,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DataFlowFolder"] = None,
        **kwargs
    ):
        """
        :keyword description: The description of the data flow.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the data flow.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this data flow is in. If not specified, Data flow will appear
         at the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DataFlowFolder
        """
        super(DataFlow, self).__init__(**kwargs)
        self.type = None  # type: Optional[str]
        self.description = description
        self.annotations = annotations
        self.folder = folder


class DataFlowDebugCommandPayload(msrest.serialization.Model):
    """Structure of command payload.

    All required parameters must be populated in order to send to Azure.

    :ivar stream_name: Required. The stream name which is used for preview.
    :vartype stream_name: str
    :ivar row_limits: Row limits for preview response.
    :vartype row_limits: int
    :ivar columns: Array of column names.
    :vartype columns: list[str]
    :ivar expression: The expression which is used for preview.
    :vartype expression: str
    """

    _validation = {
        'stream_name': {'required': True},
    }

    _attribute_map = {
        'stream_name': {'key': 'streamName', 'type': 'str'},
        'row_limits': {'key': 'rowLimits', 'type': 'int'},
        'columns': {'key': 'columns', 'type': '[str]'},
        'expression': {'key': 'expression', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        stream_name: str,
        row_limits: Optional[int] = None,
        columns: Optional[List[str]] = None,
        expression: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword stream_name: Required. The stream name which is used for preview.
        :paramtype stream_name: str
        :keyword row_limits: Row limits for preview response.
        :paramtype row_limits: int
        :keyword columns: Array of column names.
        :paramtype columns: list[str]
        :keyword expression: The expression which is used for preview.
        :paramtype expression: str
        """
        super(DataFlowDebugCommandPayload, self).__init__(**kwargs)
        self.stream_name = stream_name
        self.row_limits = row_limits
        self.columns = columns
        self.expression = expression


class DataFlowDebugCommandRequest(msrest.serialization.Model):
    """Request body structure for data flow debug command.

    :ivar session_id: The ID of data flow debug session.
    :vartype session_id: str
    :ivar command: The command type. Possible values include: "executePreviewQuery",
     "executeStatisticsQuery", "executeExpressionQuery".
    :vartype command: str or ~azure.mgmt.datafactory.models.DataFlowDebugCommandType
    :ivar command_payload: The command payload object.
    :vartype command_payload: ~azure.mgmt.datafactory.models.DataFlowDebugCommandPayload
    """

    _attribute_map = {
        'session_id': {'key': 'sessionId', 'type': 'str'},
        'command': {'key': 'command', 'type': 'str'},
        'command_payload': {'key': 'commandPayload', 'type': 'DataFlowDebugCommandPayload'},
    }

    def __init__(
        self,
        *,
        session_id: Optional[str] = None,
        command: Optional[Union[str, "DataFlowDebugCommandType"]] = None,
        command_payload: Optional["DataFlowDebugCommandPayload"] = None,
        **kwargs
    ):
        """
        :keyword session_id: The ID of data flow debug session.
        :paramtype session_id: str
        :keyword command: The command type. Possible values include: "executePreviewQuery",
         "executeStatisticsQuery", "executeExpressionQuery".
        :paramtype command: str or ~azure.mgmt.datafactory.models.DataFlowDebugCommandType
        :keyword command_payload: The command payload object.
        :paramtype command_payload: ~azure.mgmt.datafactory.models.DataFlowDebugCommandPayload
        """
        super(DataFlowDebugCommandRequest, self).__init__(**kwargs)
        self.session_id = session_id
        self.command = command
        self.command_payload = command_payload


class DataFlowDebugCommandResponse(msrest.serialization.Model):
    """Response body structure of data flow result for data preview, statistics or expression preview.

    :ivar status: The run status of data preview, statistics or expression preview.
    :vartype status: str
    :ivar data: The result data of data preview, statistics or expression preview.
    :vartype data: str
    """

    _attribute_map = {
        'status': {'key': 'status', 'type': 'str'},
        'data': {'key': 'data', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        status: Optional[str] = None,
        data: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword status: The run status of data preview, statistics or expression preview.
        :paramtype status: str
        :keyword data: The result data of data preview, statistics or expression preview.
        :paramtype data: str
        """
        super(DataFlowDebugCommandResponse, self).__init__(**kwargs)
        self.status = status
        self.data = data


class DataFlowDebugPackage(msrest.serialization.Model):
    """Request body structure for starting data flow debug session.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar session_id: The ID of data flow debug session.
    :vartype session_id: str
    :ivar data_flow: Data flow instance.
    :vartype data_flow: ~azure.mgmt.datafactory.models.DataFlowDebugResource
    :ivar data_flows: List of Data flows.
    :vartype data_flows: list[~azure.mgmt.datafactory.models.DataFlowDebugResource]
    :ivar datasets: List of datasets.
    :vartype datasets: list[~azure.mgmt.datafactory.models.DatasetDebugResource]
    :ivar linked_services: List of linked services.
    :vartype linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceDebugResource]
    :ivar staging: Staging info for debug session.
    :vartype staging: ~azure.mgmt.datafactory.models.DataFlowStagingInfo
    :ivar debug_settings: Data flow debug settings.
    :vartype debug_settings: ~azure.mgmt.datafactory.models.DataFlowDebugPackageDebugSettings
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'session_id': {'key': 'sessionId', 'type': 'str'},
        'data_flow': {'key': 'dataFlow', 'type': 'DataFlowDebugResource'},
        'data_flows': {'key': 'dataFlows', 'type': '[DataFlowDebugResource]'},
        'datasets': {'key': 'datasets', 'type': '[DatasetDebugResource]'},
        'linked_services': {'key': 'linkedServices', 'type': '[LinkedServiceDebugResource]'},
        'staging': {'key': 'staging', 'type': 'DataFlowStagingInfo'},
        'debug_settings': {'key': 'debugSettings', 'type': 'DataFlowDebugPackageDebugSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        session_id: Optional[str] = None,
        data_flow: Optional["DataFlowDebugResource"] = None,
        data_flows: Optional[List["DataFlowDebugResource"]] = None,
        datasets: Optional[List["DatasetDebugResource"]] = None,
        linked_services: Optional[List["LinkedServiceDebugResource"]] = None,
        staging: Optional["DataFlowStagingInfo"] = None,
        debug_settings: Optional["DataFlowDebugPackageDebugSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword session_id: The ID of data flow debug session.
        :paramtype session_id: str
        :keyword data_flow: Data flow instance.
        :paramtype data_flow: ~azure.mgmt.datafactory.models.DataFlowDebugResource
        :keyword data_flows: List of Data flows.
        :paramtype data_flows: list[~azure.mgmt.datafactory.models.DataFlowDebugResource]
        :keyword datasets: List of datasets.
        :paramtype datasets: list[~azure.mgmt.datafactory.models.DatasetDebugResource]
        :keyword linked_services: List of linked services.
        :paramtype linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceDebugResource]
        :keyword staging: Staging info for debug session.
        :paramtype staging: ~azure.mgmt.datafactory.models.DataFlowStagingInfo
        :keyword debug_settings: Data flow debug settings.
        :paramtype debug_settings: ~azure.mgmt.datafactory.models.DataFlowDebugPackageDebugSettings
        """
        super(DataFlowDebugPackage, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.session_id = session_id
        self.data_flow = data_flow
        self.data_flows = data_flows
        self.datasets = datasets
        self.linked_services = linked_services
        self.staging = staging
        self.debug_settings = debug_settings


class DataFlowDebugPackageDebugSettings(msrest.serialization.Model):
    """Data flow debug settings.

    :ivar source_settings: Source setting for data flow debug.
    :vartype source_settings: list[~azure.mgmt.datafactory.models.DataFlowSourceSetting]
    :ivar parameters: Data flow parameters.
    :vartype parameters: dict[str, any]
    :ivar dataset_parameters: Parameters for dataset.
    :vartype dataset_parameters: any
    """

    _attribute_map = {
        'source_settings': {'key': 'sourceSettings', 'type': '[DataFlowSourceSetting]'},
        'parameters': {'key': 'parameters', 'type': '{object}'},
        'dataset_parameters': {'key': 'datasetParameters', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        source_settings: Optional[List["DataFlowSourceSetting"]] = None,
        parameters: Optional[Dict[str, Any]] = None,
        dataset_parameters: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword source_settings: Source setting for data flow debug.
        :paramtype source_settings: list[~azure.mgmt.datafactory.models.DataFlowSourceSetting]
        :keyword parameters: Data flow parameters.
        :paramtype parameters: dict[str, any]
        :keyword dataset_parameters: Parameters for dataset.
        :paramtype dataset_parameters: any
        """
        super(DataFlowDebugPackageDebugSettings, self).__init__(**kwargs)
        self.source_settings = source_settings
        self.parameters = parameters
        self.dataset_parameters = dataset_parameters


class SubResourceDebugResource(msrest.serialization.Model):
    """Azure Data Factory nested debug resource.

    :ivar name: The resource name.
    :vartype name: str
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword name: The resource name.
        :paramtype name: str
        """
        super(SubResourceDebugResource, self).__init__(**kwargs)
        self.name = name


class DataFlowDebugResource(SubResourceDebugResource):
    """Data flow debug resource.

    All required parameters must be populated in order to send to Azure.

    :ivar name: The resource name.
    :vartype name: str
    :ivar properties: Required. Data flow properties.
    :vartype properties: ~azure.mgmt.datafactory.models.DataFlow
    """

    _validation = {
        'properties': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'DataFlow'},
    }

    def __init__(
        self,
        *,
        properties: "DataFlow",
        name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword name: The resource name.
        :paramtype name: str
        :keyword properties: Required. Data flow properties.
        :paramtype properties: ~azure.mgmt.datafactory.models.DataFlow
        """
        super(DataFlowDebugResource, self).__init__(name=name, **kwargs)
        self.properties = properties


class DataFlowDebugSessionInfo(msrest.serialization.Model):
    """Data flow debug session info.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar data_flow_name: The name of the data flow.
    :vartype data_flow_name: str
    :ivar compute_type: Compute type of the cluster.
    :vartype compute_type: str
    :ivar core_count: Core count of the cluster.
    :vartype core_count: int
    :ivar node_count: Node count of the cluster. (deprecated property).
    :vartype node_count: int
    :ivar integration_runtime_name: Attached integration runtime name of data flow debug session.
    :vartype integration_runtime_name: str
    :ivar session_id: The ID of data flow debug session.
    :vartype session_id: str
    :ivar start_time: Start time of data flow debug session.
    :vartype start_time: str
    :ivar time_to_live_in_minutes: Compute type of the cluster.
    :vartype time_to_live_in_minutes: int
    :ivar last_activity_time: Last activity time of data flow debug session.
    :vartype last_activity_time: str
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'data_flow_name': {'key': 'dataFlowName', 'type': 'str'},
        'compute_type': {'key': 'computeType', 'type': 'str'},
        'core_count': {'key': 'coreCount', 'type': 'int'},
        'node_count': {'key': 'nodeCount', 'type': 'int'},
        'integration_runtime_name': {'key': 'integrationRuntimeName', 'type': 'str'},
        'session_id': {'key': 'sessionId', 'type': 'str'},
        'start_time': {'key': 'startTime', 'type': 'str'},
        'time_to_live_in_minutes': {'key': 'timeToLiveInMinutes', 'type': 'int'},
        'last_activity_time': {'key': 'lastActivityTime', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        data_flow_name: Optional[str] = None,
        compute_type: Optional[str] = None,
        core_count: Optional[int] = None,
        node_count: Optional[int] = None,
        integration_runtime_name: Optional[str] = None,
        session_id: Optional[str] = None,
        start_time: Optional[str] = None,
        time_to_live_in_minutes: Optional[int] = None,
        last_activity_time: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword data_flow_name: The name of the data flow.
        :paramtype data_flow_name: str
        :keyword compute_type: Compute type of the cluster.
        :paramtype compute_type: str
        :keyword core_count: Core count of the cluster.
        :paramtype core_count: int
        :keyword node_count: Node count of the cluster. (deprecated property).
        :paramtype node_count: int
        :keyword integration_runtime_name: Attached integration runtime name of data flow debug
         session.
        :paramtype integration_runtime_name: str
        :keyword session_id: The ID of data flow debug session.
        :paramtype session_id: str
        :keyword start_time: Start time of data flow debug session.
        :paramtype start_time: str
        :keyword time_to_live_in_minutes: Compute type of the cluster.
        :paramtype time_to_live_in_minutes: int
        :keyword last_activity_time: Last activity time of data flow debug session.
        :paramtype last_activity_time: str
        """
        super(DataFlowDebugSessionInfo, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.data_flow_name = data_flow_name
        self.compute_type = compute_type
        self.core_count = core_count
        self.node_count = node_count
        self.integration_runtime_name = integration_runtime_name
        self.session_id = session_id
        self.start_time = start_time
        self.time_to_live_in_minutes = time_to_live_in_minutes
        self.last_activity_time = last_activity_time


class DataFlowFolder(msrest.serialization.Model):
    """The folder that this data flow is in. If not specified, Data flow will appear at the root level.

    :ivar name: The name of the folder that this data flow is in.
    :vartype name: str
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword name: The name of the folder that this data flow is in.
        :paramtype name: str
        """
        super(DataFlowFolder, self).__init__(**kwargs)
        self.name = name


class DataFlowListResponse(msrest.serialization.Model):
    """A list of data flow resources.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of data flows.
    :vartype value: list[~azure.mgmt.datafactory.models.DataFlowResource]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[DataFlowResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["DataFlowResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of data flows.
        :paramtype value: list[~azure.mgmt.datafactory.models.DataFlowResource]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(DataFlowListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class DataFlowReference(msrest.serialization.Model):
    """Data flow reference type.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Data flow reference type. Possible values include: "DataFlowReference".
    :vartype type: str or ~azure.mgmt.datafactory.models.DataFlowReferenceType
    :ivar reference_name: Required. Reference data flow name.
    :vartype reference_name: str
    :ivar dataset_parameters: Reference data flow parameters from dataset.
    :vartype dataset_parameters: any
    :ivar parameters: Data flow parameters.
    :vartype parameters: dict[str, any]
    """

    _validation = {
        'type': {'required': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
        'dataset_parameters': {'key': 'datasetParameters', 'type': 'object'},
        'parameters': {'key': 'parameters', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        type: Union[str, "DataFlowReferenceType"],
        reference_name: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        dataset_parameters: Optional[Any] = None,
        parameters: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword type: Required. Data flow reference type. Possible values include:
         "DataFlowReference".
        :paramtype type: str or ~azure.mgmt.datafactory.models.DataFlowReferenceType
        :keyword reference_name: Required. Reference data flow name.
        :paramtype reference_name: str
        :keyword dataset_parameters: Reference data flow parameters from dataset.
        :paramtype dataset_parameters: any
        :keyword parameters: Data flow parameters.
        :paramtype parameters: dict[str, any]
        """
        super(DataFlowReference, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = type
        self.reference_name = reference_name
        self.dataset_parameters = dataset_parameters
        self.parameters = parameters


class DataFlowResource(SubResource):
    """Data flow resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :ivar properties: Required. Data flow properties.
    :vartype properties: ~azure.mgmt.datafactory.models.DataFlow
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'DataFlow'},
    }

    def __init__(
        self,
        *,
        properties: "DataFlow",
        **kwargs
    ):
        """
        :keyword properties: Required. Data flow properties.
        :paramtype properties: ~azure.mgmt.datafactory.models.DataFlow
        """
        super(DataFlowResource, self).__init__(**kwargs)
        self.properties = properties


class Transformation(msrest.serialization.Model):
    """A data flow transformation.

    All required parameters must be populated in order to send to Azure.

    :ivar name: Required. Transformation name.
    :vartype name: str
    :ivar description: Transformation description.
    :vartype description: str
    :ivar dataset: Dataset reference.
    :vartype dataset: ~azure.mgmt.datafactory.models.DatasetReference
    :ivar linked_service: Linked service reference.
    :vartype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar flowlet: Flowlet Reference.
    :vartype flowlet: ~azure.mgmt.datafactory.models.DataFlowReference
    """

    _validation = {
        'name': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'dataset': {'key': 'dataset', 'type': 'DatasetReference'},
        'linked_service': {'key': 'linkedService', 'type': 'LinkedServiceReference'},
        'flowlet': {'key': 'flowlet', 'type': 'DataFlowReference'},
    }

    def __init__(
        self,
        *,
        name: str,
        description: Optional[str] = None,
        dataset: Optional["DatasetReference"] = None,
        linked_service: Optional["LinkedServiceReference"] = None,
        flowlet: Optional["DataFlowReference"] = None,
        **kwargs
    ):
        """
        :keyword name: Required. Transformation name.
        :paramtype name: str
        :keyword description: Transformation description.
        :paramtype description: str
        :keyword dataset: Dataset reference.
        :paramtype dataset: ~azure.mgmt.datafactory.models.DatasetReference
        :keyword linked_service: Linked service reference.
        :paramtype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword flowlet: Flowlet Reference.
        :paramtype flowlet: ~azure.mgmt.datafactory.models.DataFlowReference
        """
        super(Transformation, self).__init__(**kwargs)
        self.name = name
        self.description = description
        self.dataset = dataset
        self.linked_service = linked_service
        self.flowlet = flowlet


class DataFlowSink(Transformation):
    """Transformation for data flow sink.

    All required parameters must be populated in order to send to Azure.

    :ivar name: Required. Transformation name.
    :vartype name: str
    :ivar description: Transformation description.
    :vartype description: str
    :ivar dataset: Dataset reference.
    :vartype dataset: ~azure.mgmt.datafactory.models.DatasetReference
    :ivar linked_service: Linked service reference.
    :vartype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar flowlet: Flowlet Reference.
    :vartype flowlet: ~azure.mgmt.datafactory.models.DataFlowReference
    :ivar schema_linked_service: Schema linked service reference.
    :vartype schema_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    """

    _validation = {
        'name': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'dataset': {'key': 'dataset', 'type': 'DatasetReference'},
        'linked_service': {'key': 'linkedService', 'type': 'LinkedServiceReference'},
        'flowlet': {'key': 'flowlet', 'type': 'DataFlowReference'},
        'schema_linked_service': {'key': 'schemaLinkedService', 'type': 'LinkedServiceReference'},
    }

    def __init__(
        self,
        *,
        name: str,
        description: Optional[str] = None,
        dataset: Optional["DatasetReference"] = None,
        linked_service: Optional["LinkedServiceReference"] = None,
        flowlet: Optional["DataFlowReference"] = None,
        schema_linked_service: Optional["LinkedServiceReference"] = None,
        **kwargs
    ):
        """
        :keyword name: Required. Transformation name.
        :paramtype name: str
        :keyword description: Transformation description.
        :paramtype description: str
        :keyword dataset: Dataset reference.
        :paramtype dataset: ~azure.mgmt.datafactory.models.DatasetReference
        :keyword linked_service: Linked service reference.
        :paramtype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword flowlet: Flowlet Reference.
        :paramtype flowlet: ~azure.mgmt.datafactory.models.DataFlowReference
        :keyword schema_linked_service: Schema linked service reference.
        :paramtype schema_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        """
        super(DataFlowSink, self).__init__(name=name, description=description, dataset=dataset, linked_service=linked_service, flowlet=flowlet, **kwargs)
        self.schema_linked_service = schema_linked_service


class DataFlowSource(Transformation):
    """Transformation for data flow source.

    All required parameters must be populated in order to send to Azure.

    :ivar name: Required. Transformation name.
    :vartype name: str
    :ivar description: Transformation description.
    :vartype description: str
    :ivar dataset: Dataset reference.
    :vartype dataset: ~azure.mgmt.datafactory.models.DatasetReference
    :ivar linked_service: Linked service reference.
    :vartype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar flowlet: Flowlet Reference.
    :vartype flowlet: ~azure.mgmt.datafactory.models.DataFlowReference
    :ivar schema_linked_service: Schema linked service reference.
    :vartype schema_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    """

    _validation = {
        'name': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'dataset': {'key': 'dataset', 'type': 'DatasetReference'},
        'linked_service': {'key': 'linkedService', 'type': 'LinkedServiceReference'},
        'flowlet': {'key': 'flowlet', 'type': 'DataFlowReference'},
        'schema_linked_service': {'key': 'schemaLinkedService', 'type': 'LinkedServiceReference'},
    }

    def __init__(
        self,
        *,
        name: str,
        description: Optional[str] = None,
        dataset: Optional["DatasetReference"] = None,
        linked_service: Optional["LinkedServiceReference"] = None,
        flowlet: Optional["DataFlowReference"] = None,
        schema_linked_service: Optional["LinkedServiceReference"] = None,
        **kwargs
    ):
        """
        :keyword name: Required. Transformation name.
        :paramtype name: str
        :keyword description: Transformation description.
        :paramtype description: str
        :keyword dataset: Dataset reference.
        :paramtype dataset: ~azure.mgmt.datafactory.models.DatasetReference
        :keyword linked_service: Linked service reference.
        :paramtype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword flowlet: Flowlet Reference.
        :paramtype flowlet: ~azure.mgmt.datafactory.models.DataFlowReference
        :keyword schema_linked_service: Schema linked service reference.
        :paramtype schema_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        """
        super(DataFlowSource, self).__init__(name=name, description=description, dataset=dataset, linked_service=linked_service, flowlet=flowlet, **kwargs)
        self.schema_linked_service = schema_linked_service


class DataFlowSourceSetting(msrest.serialization.Model):
    """Definition of data flow source setting for debug.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar source_name: The data flow source name.
    :vartype source_name: str
    :ivar row_limit: Defines the row limit of data flow source in debug.
    :vartype row_limit: int
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'source_name': {'key': 'sourceName', 'type': 'str'},
        'row_limit': {'key': 'rowLimit', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_name: Optional[str] = None,
        row_limit: Optional[int] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_name: The data flow source name.
        :paramtype source_name: str
        :keyword row_limit: Defines the row limit of data flow source in debug.
        :paramtype row_limit: int
        """
        super(DataFlowSourceSetting, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.source_name = source_name
        self.row_limit = row_limit


class DataFlowStagingInfo(msrest.serialization.Model):
    """Staging info for execute data flow activity.

    :ivar linked_service: Staging linked service reference.
    :vartype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar folder_path: Folder path for staging blob. Type: string (or Expression with resultType
     string).
    :vartype folder_path: any
    """

    _attribute_map = {
        'linked_service': {'key': 'linkedService', 'type': 'LinkedServiceReference'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service: Optional["LinkedServiceReference"] = None,
        folder_path: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword linked_service: Staging linked service reference.
        :paramtype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword folder_path: Folder path for staging blob. Type: string (or Expression with resultType
         string).
        :paramtype folder_path: any
        """
        super(DataFlowStagingInfo, self).__init__(**kwargs)
        self.linked_service = linked_service
        self.folder_path = folder_path


class DataLakeAnalyticsUSQLActivity(ExecutionActivity):
    """Data Lake Analytics U-SQL activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar script_path: Required. Case-sensitive path to folder that contains the U-SQL script.
     Type: string (or Expression with resultType string).
    :vartype script_path: any
    :ivar script_linked_service: Required. Script linked service reference.
    :vartype script_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar degree_of_parallelism: The maximum number of nodes simultaneously used to run the job.
     Default value is 1. Type: integer (or Expression with resultType integer), minimum: 1.
    :vartype degree_of_parallelism: any
    :ivar priority: Determines which jobs out of all that are queued should be selected to run
     first. The lower the number, the higher the priority. Default value is 1000. Type: integer (or
     Expression with resultType integer), minimum: 1.
    :vartype priority: any
    :ivar parameters: Parameters for U-SQL job request.
    :vartype parameters: dict[str, any]
    :ivar runtime_version: Runtime version of the U-SQL engine to use. Type: string (or Expression
     with resultType string).
    :vartype runtime_version: any
    :ivar compilation_mode: Compilation mode of U-SQL. Must be one of these values : Semantic, Full
     and SingleBox. Type: string (or Expression with resultType string).
    :vartype compilation_mode: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'script_path': {'required': True},
        'script_linked_service': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'script_path': {'key': 'typeProperties.scriptPath', 'type': 'object'},
        'script_linked_service': {'key': 'typeProperties.scriptLinkedService', 'type': 'LinkedServiceReference'},
        'degree_of_parallelism': {'key': 'typeProperties.degreeOfParallelism', 'type': 'object'},
        'priority': {'key': 'typeProperties.priority', 'type': 'object'},
        'parameters': {'key': 'typeProperties.parameters', 'type': '{object}'},
        'runtime_version': {'key': 'typeProperties.runtimeVersion', 'type': 'object'},
        'compilation_mode': {'key': 'typeProperties.compilationMode', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        script_path: Any,
        script_linked_service: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        degree_of_parallelism: Optional[Any] = None,
        priority: Optional[Any] = None,
        parameters: Optional[Dict[str, Any]] = None,
        runtime_version: Optional[Any] = None,
        compilation_mode: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword script_path: Required. Case-sensitive path to folder that contains the U-SQL script.
         Type: string (or Expression with resultType string).
        :paramtype script_path: any
        :keyword script_linked_service: Required. Script linked service reference.
        :paramtype script_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword degree_of_parallelism: The maximum number of nodes simultaneously used to run the job.
         Default value is 1. Type: integer (or Expression with resultType integer), minimum: 1.
        :paramtype degree_of_parallelism: any
        :keyword priority: Determines which jobs out of all that are queued should be selected to run
         first. The lower the number, the higher the priority. Default value is 1000. Type: integer (or
         Expression with resultType integer), minimum: 1.
        :paramtype priority: any
        :keyword parameters: Parameters for U-SQL job request.
        :paramtype parameters: dict[str, any]
        :keyword runtime_version: Runtime version of the U-SQL engine to use. Type: string (or
         Expression with resultType string).
        :paramtype runtime_version: any
        :keyword compilation_mode: Compilation mode of U-SQL. Must be one of these values : Semantic,
         Full and SingleBox. Type: string (or Expression with resultType string).
        :paramtype compilation_mode: any
        """
        super(DataLakeAnalyticsUSQLActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'DataLakeAnalyticsU-SQL'  # type: str
        self.script_path = script_path
        self.script_linked_service = script_linked_service
        self.degree_of_parallelism = degree_of_parallelism
        self.priority = priority
        self.parameters = parameters
        self.runtime_version = runtime_version
        self.compilation_mode = compilation_mode


class DatasetCompression(msrest.serialization.Model):
    """The compression method used on a dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset compression. Type: string (or Expression with resultType
     string).
    :vartype type: any
    :ivar level: The dataset compression level. Type: string (or Expression with resultType
     string).
    :vartype level: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'object'},
        'level': {'key': 'level', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        type: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        level: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword type: Required. Type of dataset compression. Type: string (or Expression with
         resultType string).
        :paramtype type: any
        :keyword level: The dataset compression level. Type: string (or Expression with resultType
         string).
        :paramtype level: any
        """
        super(DatasetCompression, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = type
        self.level = level


class DatasetDataElement(msrest.serialization.Model):
    """Columns that define the structure of the dataset.

    :ivar name: Name of the column. Type: string (or Expression with resultType string).
    :vartype name: any
    :ivar type: Type of the column. Type: string (or Expression with resultType string).
    :vartype type: any
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'object'},
        'type': {'key': 'type', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: Optional[Any] = None,
        type: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword name: Name of the column. Type: string (or Expression with resultType string).
        :paramtype name: any
        :keyword type: Type of the column. Type: string (or Expression with resultType string).
        :paramtype type: any
        """
        super(DatasetDataElement, self).__init__(**kwargs)
        self.name = name
        self.type = type


class DatasetDebugResource(SubResourceDebugResource):
    """Dataset debug resource.

    All required parameters must be populated in order to send to Azure.

    :ivar name: The resource name.
    :vartype name: str
    :ivar properties: Required. Dataset properties.
    :vartype properties: ~azure.mgmt.datafactory.models.Dataset
    """

    _validation = {
        'properties': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'Dataset'},
    }

    def __init__(
        self,
        *,
        properties: "Dataset",
        name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword name: The resource name.
        :paramtype name: str
        :keyword properties: Required. Dataset properties.
        :paramtype properties: ~azure.mgmt.datafactory.models.Dataset
        """
        super(DatasetDebugResource, self).__init__(name=name, **kwargs)
        self.properties = properties


class DatasetFolder(msrest.serialization.Model):
    """The folder that this Dataset is in. If not specified, Dataset will appear at the root level.

    :ivar name: The name of the folder that this Dataset is in.
    :vartype name: str
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword name: The name of the folder that this Dataset is in.
        :paramtype name: str
        """
        super(DatasetFolder, self).__init__(**kwargs)
        self.name = name


class DatasetListResponse(msrest.serialization.Model):
    """A list of dataset resources.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of datasets.
    :vartype value: list[~azure.mgmt.datafactory.models.DatasetResource]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[DatasetResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["DatasetResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of datasets.
        :paramtype value: list[~azure.mgmt.datafactory.models.DatasetResource]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(DatasetListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class DatasetReference(msrest.serialization.Model):
    """Dataset reference type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Dataset reference type. Has constant value: "DatasetReference".
    :vartype type: str
    :ivar reference_name: Required. Reference dataset name.
    :vartype reference_name: str
    :ivar parameters: Arguments for dataset.
    :vartype parameters: dict[str, any]
    """

    _validation = {
        'type': {'required': True, 'constant': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{object}'},
    }

    type = "DatasetReference"

    def __init__(
        self,
        *,
        reference_name: str,
        parameters: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword reference_name: Required. Reference dataset name.
        :paramtype reference_name: str
        :keyword parameters: Arguments for dataset.
        :paramtype parameters: dict[str, any]
        """
        super(DatasetReference, self).__init__(**kwargs)
        self.reference_name = reference_name
        self.parameters = parameters


class DatasetResource(SubResource):
    """Dataset resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :ivar properties: Required. Dataset properties.
    :vartype properties: ~azure.mgmt.datafactory.models.Dataset
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'Dataset'},
    }

    def __init__(
        self,
        *,
        properties: "Dataset",
        **kwargs
    ):
        """
        :keyword properties: Required. Dataset properties.
        :paramtype properties: ~azure.mgmt.datafactory.models.Dataset
        """
        super(DatasetResource, self).__init__(**kwargs)
        self.properties = properties


class DatasetSchemaDataElement(msrest.serialization.Model):
    """Columns that define the physical type schema of the dataset.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Name of the schema column. Type: string (or Expression with resultType string).
    :vartype name: any
    :ivar type: Type of the schema column. Type: string (or Expression with resultType string).
    :vartype type: any
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'object'},
        'type': {'key': 'type', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        name: Optional[Any] = None,
        type: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Name of the schema column. Type: string (or Expression with resultType string).
        :paramtype name: any
        :keyword type: Type of the schema column. Type: string (or Expression with resultType string).
        :paramtype type: any
        """
        super(DatasetSchemaDataElement, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.name = name
        self.type = type


class DataworldLinkedService(LinkedService):
    """Linked service for Dataworld.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar api_token: Required. The api token for the Dataworld source.
    :vartype api_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'api_token': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'api_token': {'key': 'typeProperties.apiToken', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        api_token: "SecretBase",
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword api_token: Required. The api token for the Dataworld source.
        :paramtype api_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(DataworldLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Dataworld'  # type: str
        self.api_token = api_token
        self.encrypted_credential = encrypted_credential


class Db2LinkedService(LinkedService):
    """Linked service for DB2 data source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: The connection string. It is mutually exclusive with server, database,
     authenticationType, userName, packageCollection and certificateCommonName property. Type:
     string, SecureString or AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar server: Server name for connection. It is mutually exclusive with connectionString
     property. Type: string (or Expression with resultType string).
    :vartype server: any
    :ivar database: Database name for connection. It is mutually exclusive with connectionString
     property. Type: string (or Expression with resultType string).
    :vartype database: any
    :ivar authentication_type: AuthenticationType to be used for connection. It is mutually
     exclusive with connectionString property. Possible values include: "Basic".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.Db2AuthenticationType
    :ivar username: Username for authentication. It is mutually exclusive with connectionString
     property. Type: string (or Expression with resultType string).
    :vartype username: any
    :ivar password: Password for authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar package_collection: Under where packages are created when querying database. It is
     mutually exclusive with connectionString property. Type: string (or Expression with resultType
     string).
    :vartype package_collection: any
    :ivar certificate_common_name: Certificate Common Name when TLS is enabled. It is mutually
     exclusive with connectionString property. Type: string (or Expression with resultType string).
    :vartype certificate_common_name: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. It is mutually exclusive with
     connectionString property. Type: string (or Expression with resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'server': {'key': 'typeProperties.server', 'type': 'object'},
        'database': {'key': 'typeProperties.database', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'package_collection': {'key': 'typeProperties.packageCollection', 'type': 'object'},
        'certificate_common_name': {'key': 'typeProperties.certificateCommonName', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        server: Optional[Any] = None,
        database: Optional[Any] = None,
        authentication_type: Optional[Union[str, "Db2AuthenticationType"]] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        package_collection: Optional[Any] = None,
        certificate_common_name: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: The connection string. It is mutually exclusive with server,
         database, authenticationType, userName, packageCollection and certificateCommonName property.
         Type: string, SecureString or AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword server: Server name for connection. It is mutually exclusive with connectionString
         property. Type: string (or Expression with resultType string).
        :paramtype server: any
        :keyword database: Database name for connection. It is mutually exclusive with connectionString
         property. Type: string (or Expression with resultType string).
        :paramtype database: any
        :keyword authentication_type: AuthenticationType to be used for connection. It is mutually
         exclusive with connectionString property. Possible values include: "Basic".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.Db2AuthenticationType
        :keyword username: Username for authentication. It is mutually exclusive with connectionString
         property. Type: string (or Expression with resultType string).
        :paramtype username: any
        :keyword password: Password for authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword package_collection: Under where packages are created when querying database. It is
         mutually exclusive with connectionString property. Type: string (or Expression with resultType
         string).
        :paramtype package_collection: any
        :keyword certificate_common_name: Certificate Common Name when TLS is enabled. It is mutually
         exclusive with connectionString property. Type: string (or Expression with resultType string).
        :paramtype certificate_common_name: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. It is mutually exclusive with
         connectionString property. Type: string (or Expression with resultType string).
        :paramtype encrypted_credential: any
        """
        super(Db2LinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Db2'  # type: str
        self.connection_string = connection_string
        self.server = server
        self.database = database
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.package_collection = package_collection
        self.certificate_common_name = certificate_common_name
        self.encrypted_credential = encrypted_credential


class Db2Source(TabularSource):
    """A copy activity source for Db2 databases.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: Database query. Type: string (or Expression with resultType string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: Database query. Type: string (or Expression with resultType string).
        :paramtype query: any
        """
        super(Db2Source, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'Db2Source'  # type: str
        self.query = query


class Db2TableDataset(Dataset):
    """The Db2 table dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar schema_type_properties_schema: The Db2 schema name. Type: string (or Expression with
     resultType string).
    :vartype schema_type_properties_schema: any
    :ivar table: The Db2 table name. Type: string (or Expression with resultType string).
    :vartype table: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        table: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword schema_type_properties_schema: The Db2 schema name. Type: string (or Expression with
         resultType string).
        :paramtype schema_type_properties_schema: any
        :keyword table: The Db2 table name. Type: string (or Expression with resultType string).
        :paramtype table: any
        """
        super(Db2TableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Db2Table'  # type: str
        self.table_name = table_name
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class DeleteActivity(ExecutionActivity):
    """Delete activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar recursive: If true, files or sub-folders under current folder path will be deleted
     recursively. Default is false. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar max_concurrent_connections: The max concurrent connections to connect data source at the
     same time.
    :vartype max_concurrent_connections: int
    :ivar enable_logging: Whether to record detailed logs of delete-activity execution. Default
     value is false. Type: boolean (or Expression with resultType boolean).
    :vartype enable_logging: any
    :ivar log_storage_settings: Log storage settings customer need to provide when enableLogging is
     true.
    :vartype log_storage_settings: ~azure.mgmt.datafactory.models.LogStorageSettings
    :ivar dataset: Required. Delete activity dataset reference.
    :vartype dataset: ~azure.mgmt.datafactory.models.DatasetReference
    :ivar store_settings: Delete activity store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'max_concurrent_connections': {'minimum': 1},
        'dataset': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'recursive': {'key': 'typeProperties.recursive', 'type': 'object'},
        'max_concurrent_connections': {'key': 'typeProperties.maxConcurrentConnections', 'type': 'int'},
        'enable_logging': {'key': 'typeProperties.enableLogging', 'type': 'object'},
        'log_storage_settings': {'key': 'typeProperties.logStorageSettings', 'type': 'LogStorageSettings'},
        'dataset': {'key': 'typeProperties.dataset', 'type': 'DatasetReference'},
        'store_settings': {'key': 'typeProperties.storeSettings', 'type': 'StoreReadSettings'},
    }

    def __init__(
        self,
        *,
        name: str,
        dataset: "DatasetReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        recursive: Optional[Any] = None,
        max_concurrent_connections: Optional[int] = None,
        enable_logging: Optional[Any] = None,
        log_storage_settings: Optional["LogStorageSettings"] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword recursive: If true, files or sub-folders under current folder path will be deleted
         recursively. Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword max_concurrent_connections: The max concurrent connections to connect data source at
         the same time.
        :paramtype max_concurrent_connections: int
        :keyword enable_logging: Whether to record detailed logs of delete-activity execution. Default
         value is false. Type: boolean (or Expression with resultType boolean).
        :paramtype enable_logging: any
        :keyword log_storage_settings: Log storage settings customer need to provide when enableLogging
         is true.
        :paramtype log_storage_settings: ~azure.mgmt.datafactory.models.LogStorageSettings
        :keyword dataset: Required. Delete activity dataset reference.
        :paramtype dataset: ~azure.mgmt.datafactory.models.DatasetReference
        :keyword store_settings: Delete activity store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
        """
        super(DeleteActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'Delete'  # type: str
        self.recursive = recursive
        self.max_concurrent_connections = max_concurrent_connections
        self.enable_logging = enable_logging
        self.log_storage_settings = log_storage_settings
        self.dataset = dataset
        self.store_settings = store_settings


class DeleteDataFlowDebugSessionRequest(msrest.serialization.Model):
    """Request body structure for deleting data flow debug session.

    :ivar session_id: The ID of data flow debug session.
    :vartype session_id: str
    """

    _attribute_map = {
        'session_id': {'key': 'sessionId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        session_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword session_id: The ID of data flow debug session.
        :paramtype session_id: str
        """
        super(DeleteDataFlowDebugSessionRequest, self).__init__(**kwargs)
        self.session_id = session_id


class DelimitedTextDataset(Dataset):
    """Delimited text dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar location: The location of the delimited text storage.
    :vartype location: ~azure.mgmt.datafactory.models.DatasetLocation
    :ivar column_delimiter: The column delimiter. Type: string (or Expression with resultType
     string).
    :vartype column_delimiter: any
    :ivar row_delimiter: The row delimiter. Type: string (or Expression with resultType string).
    :vartype row_delimiter: any
    :ivar encoding_name: The code page name of the preferred encoding. If miss, the default value
     is UTF-8, unless BOM denotes another Unicode encoding. Refer to the name column of the table in
     the following link to set supported values:
     https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
     resultType string).
    :vartype encoding_name: any
    :ivar compression_codec: The data compressionCodec. Type: string (or Expression with resultType
     string).
    :vartype compression_codec: any
    :ivar compression_level: The data compression method used for DelimitedText.
    :vartype compression_level: any
    :ivar quote_char: The quote character. Type: string (or Expression with resultType string).
    :vartype quote_char: any
    :ivar escape_char: The escape character. Type: string (or Expression with resultType string).
    :vartype escape_char: any
    :ivar first_row_as_header: When used as input, treat the first row of data as headers. When
     used as output,write the headers into the output as the first row of data. The default value is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype first_row_as_header: any
    :ivar null_value: The null value string. Type: string (or Expression with resultType string).
    :vartype null_value: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'column_delimiter': {'key': 'typeProperties.columnDelimiter', 'type': 'object'},
        'row_delimiter': {'key': 'typeProperties.rowDelimiter', 'type': 'object'},
        'encoding_name': {'key': 'typeProperties.encodingName', 'type': 'object'},
        'compression_codec': {'key': 'typeProperties.compressionCodec', 'type': 'object'},
        'compression_level': {'key': 'typeProperties.compressionLevel', 'type': 'object'},
        'quote_char': {'key': 'typeProperties.quoteChar', 'type': 'object'},
        'escape_char': {'key': 'typeProperties.escapeChar', 'type': 'object'},
        'first_row_as_header': {'key': 'typeProperties.firstRowAsHeader', 'type': 'object'},
        'null_value': {'key': 'typeProperties.nullValue', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        column_delimiter: Optional[Any] = None,
        row_delimiter: Optional[Any] = None,
        encoding_name: Optional[Any] = None,
        compression_codec: Optional[Any] = None,
        compression_level: Optional[Any] = None,
        quote_char: Optional[Any] = None,
        escape_char: Optional[Any] = None,
        first_row_as_header: Optional[Any] = None,
        null_value: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword location: The location of the delimited text storage.
        :paramtype location: ~azure.mgmt.datafactory.models.DatasetLocation
        :keyword column_delimiter: The column delimiter. Type: string (or Expression with resultType
         string).
        :paramtype column_delimiter: any
        :keyword row_delimiter: The row delimiter. Type: string (or Expression with resultType string).
        :paramtype row_delimiter: any
        :keyword encoding_name: The code page name of the preferred encoding. If miss, the default
         value is UTF-8, unless BOM denotes another Unicode encoding. Refer to the name column of the
         table in the following link to set supported values:
         https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
         resultType string).
        :paramtype encoding_name: any
        :keyword compression_codec: The data compressionCodec. Type: string (or Expression with
         resultType string).
        :paramtype compression_codec: any
        :keyword compression_level: The data compression method used for DelimitedText.
        :paramtype compression_level: any
        :keyword quote_char: The quote character. Type: string (or Expression with resultType string).
        :paramtype quote_char: any
        :keyword escape_char: The escape character. Type: string (or Expression with resultType
         string).
        :paramtype escape_char: any
        :keyword first_row_as_header: When used as input, treat the first row of data as headers. When
         used as output,write the headers into the output as the first row of data. The default value is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype first_row_as_header: any
        :keyword null_value: The null value string. Type: string (or Expression with resultType
         string).
        :paramtype null_value: any
        """
        super(DelimitedTextDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'DelimitedText'  # type: str
        self.location = location
        self.column_delimiter = column_delimiter
        self.row_delimiter = row_delimiter
        self.encoding_name = encoding_name
        self.compression_codec = compression_codec
        self.compression_level = compression_level
        self.quote_char = quote_char
        self.escape_char = escape_char
        self.first_row_as_header = first_row_as_header
        self.null_value = null_value


class DelimitedTextReadSettings(FormatReadSettings):
    """Delimited text read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar skip_line_count: Indicates the number of non-empty rows to skip when reading data from
     input files. Type: integer (or Expression with resultType integer).
    :vartype skip_line_count: any
    :ivar compression_properties: Compression settings.
    :vartype compression_properties: ~azure.mgmt.datafactory.models.CompressionReadSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'skip_line_count': {'key': 'skipLineCount', 'type': 'object'},
        'compression_properties': {'key': 'compressionProperties', 'type': 'CompressionReadSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        skip_line_count: Optional[Any] = None,
        compression_properties: Optional["CompressionReadSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword skip_line_count: Indicates the number of non-empty rows to skip when reading data from
         input files. Type: integer (or Expression with resultType integer).
        :paramtype skip_line_count: any
        :keyword compression_properties: Compression settings.
        :paramtype compression_properties: ~azure.mgmt.datafactory.models.CompressionReadSettings
        """
        super(DelimitedTextReadSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'DelimitedTextReadSettings'  # type: str
        self.skip_line_count = skip_line_count
        self.compression_properties = compression_properties


class DelimitedTextSink(CopySink):
    """A copy activity DelimitedText sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: DelimitedText store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreWriteSettings
    :ivar format_settings: DelimitedText format settings.
    :vartype format_settings: ~azure.mgmt.datafactory.models.DelimitedTextWriteSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreWriteSettings'},
        'format_settings': {'key': 'formatSettings', 'type': 'DelimitedTextWriteSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreWriteSettings"] = None,
        format_settings: Optional["DelimitedTextWriteSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: DelimitedText store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreWriteSettings
        :keyword format_settings: DelimitedText format settings.
        :paramtype format_settings: ~azure.mgmt.datafactory.models.DelimitedTextWriteSettings
        """
        super(DelimitedTextSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'DelimitedTextSink'  # type: str
        self.store_settings = store_settings
        self.format_settings = format_settings


class DelimitedTextSource(CopySource):
    """A copy activity DelimitedText source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: DelimitedText store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
    :ivar format_settings: DelimitedText format settings.
    :vartype format_settings: ~azure.mgmt.datafactory.models.DelimitedTextReadSettings
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
        'format_settings': {'key': 'formatSettings', 'type': 'DelimitedTextReadSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        format_settings: Optional["DelimitedTextReadSettings"] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: DelimitedText store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
        :keyword format_settings: DelimitedText format settings.
        :paramtype format_settings: ~azure.mgmt.datafactory.models.DelimitedTextReadSettings
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(DelimitedTextSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'DelimitedTextSource'  # type: str
        self.store_settings = store_settings
        self.format_settings = format_settings
        self.additional_columns = additional_columns


class DelimitedTextWriteSettings(FormatWriteSettings):
    """Delimited text write settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The write setting type.Constant filled by server.
    :vartype type: str
    :ivar quote_all_text: Indicates whether string values should always be enclosed with quotes.
     Type: boolean (or Expression with resultType boolean).
    :vartype quote_all_text: any
    :ivar file_extension: Required. The file extension used to create the files. Type: string (or
     Expression with resultType string).
    :vartype file_extension: any
    :ivar max_rows_per_file: Limit the written file's row count to be smaller than or equal to the
     specified count. Type: integer (or Expression with resultType integer).
    :vartype max_rows_per_file: any
    :ivar file_name_prefix: Specifies the file name pattern
     :code:`<fileNamePrefix>`_:code:`<fileIndex>`.:code:`<fileExtension>` when copy from non-file
     based store without partitionOptions. Type: string (or Expression with resultType string).
    :vartype file_name_prefix: any
    """

    _validation = {
        'type': {'required': True},
        'file_extension': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'quote_all_text': {'key': 'quoteAllText', 'type': 'object'},
        'file_extension': {'key': 'fileExtension', 'type': 'object'},
        'max_rows_per_file': {'key': 'maxRowsPerFile', 'type': 'object'},
        'file_name_prefix': {'key': 'fileNamePrefix', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        file_extension: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        quote_all_text: Optional[Any] = None,
        max_rows_per_file: Optional[Any] = None,
        file_name_prefix: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword quote_all_text: Indicates whether string values should always be enclosed with quotes.
         Type: boolean (or Expression with resultType boolean).
        :paramtype quote_all_text: any
        :keyword file_extension: Required. The file extension used to create the files. Type: string
         (or Expression with resultType string).
        :paramtype file_extension: any
        :keyword max_rows_per_file: Limit the written file's row count to be smaller than or equal to
         the specified count. Type: integer (or Expression with resultType integer).
        :paramtype max_rows_per_file: any
        :keyword file_name_prefix: Specifies the file name pattern
         :code:`<fileNamePrefix>`_:code:`<fileIndex>`.:code:`<fileExtension>` when copy from non-file
         based store without partitionOptions. Type: string (or Expression with resultType string).
        :paramtype file_name_prefix: any
        """
        super(DelimitedTextWriteSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'DelimitedTextWriteSettings'  # type: str
        self.quote_all_text = quote_all_text
        self.file_extension = file_extension
        self.max_rows_per_file = max_rows_per_file
        self.file_name_prefix = file_name_prefix


class DependencyReference(msrest.serialization.Model):
    """Referenced dependency.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: SelfDependencyTumblingWindowTriggerReference, TriggerDependencyReference.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. The type of dependency reference.Constant filled by server.
    :vartype type: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'SelfDependencyTumblingWindowTriggerReference': 'SelfDependencyTumblingWindowTriggerReference', 'TriggerDependencyReference': 'TriggerDependencyReference'}
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(DependencyReference, self).__init__(**kwargs)
        self.type = None  # type: Optional[str]


class DistcpSettings(msrest.serialization.Model):
    """Distcp settings.

    All required parameters must be populated in order to send to Azure.

    :ivar resource_manager_endpoint: Required. Specifies the Yarn ResourceManager endpoint. Type:
     string (or Expression with resultType string).
    :vartype resource_manager_endpoint: any
    :ivar temp_script_path: Required. Specifies an existing folder path which will be used to store
     temp Distcp command script. The script file is generated by ADF and will be removed after Copy
     job finished. Type: string (or Expression with resultType string).
    :vartype temp_script_path: any
    :ivar distcp_options: Specifies the Distcp options. Type: string (or Expression with resultType
     string).
    :vartype distcp_options: any
    """

    _validation = {
        'resource_manager_endpoint': {'required': True},
        'temp_script_path': {'required': True},
    }

    _attribute_map = {
        'resource_manager_endpoint': {'key': 'resourceManagerEndpoint', 'type': 'object'},
        'temp_script_path': {'key': 'tempScriptPath', 'type': 'object'},
        'distcp_options': {'key': 'distcpOptions', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        resource_manager_endpoint: Any,
        temp_script_path: Any,
        distcp_options: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword resource_manager_endpoint: Required. Specifies the Yarn ResourceManager endpoint.
         Type: string (or Expression with resultType string).
        :paramtype resource_manager_endpoint: any
        :keyword temp_script_path: Required. Specifies an existing folder path which will be used to
         store temp Distcp command script. The script file is generated by ADF and will be removed after
         Copy job finished. Type: string (or Expression with resultType string).
        :paramtype temp_script_path: any
        :keyword distcp_options: Specifies the Distcp options. Type: string (or Expression with
         resultType string).
        :paramtype distcp_options: any
        """
        super(DistcpSettings, self).__init__(**kwargs)
        self.resource_manager_endpoint = resource_manager_endpoint
        self.temp_script_path = temp_script_path
        self.distcp_options = distcp_options


class DocumentDbCollectionDataset(Dataset):
    """Microsoft Azure Document Database Collection dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar collection_name: Required. Document Database collection name. Type: string (or Expression
     with resultType string).
    :vartype collection_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'collection_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'collection_name': {'key': 'typeProperties.collectionName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        collection_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword collection_name: Required. Document Database collection name. Type: string (or
         Expression with resultType string).
        :paramtype collection_name: any
        """
        super(DocumentDbCollectionDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'DocumentDbCollection'  # type: str
        self.collection_name = collection_name


class DocumentDbCollectionSink(CopySink):
    """A copy activity Document Database Collection sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar nesting_separator: Nested properties separator. Default is . (dot). Type: string (or
     Expression with resultType string).
    :vartype nesting_separator: any
    :ivar write_behavior: Describes how to write data to Azure Cosmos DB. Type: string (or
     Expression with resultType string). Allowed values: insert and upsert.
    :vartype write_behavior: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'nesting_separator': {'key': 'nestingSeparator', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        nesting_separator: Optional[Any] = None,
        write_behavior: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword nesting_separator: Nested properties separator. Default is . (dot). Type: string (or
         Expression with resultType string).
        :paramtype nesting_separator: any
        :keyword write_behavior: Describes how to write data to Azure Cosmos DB. Type: string (or
         Expression with resultType string). Allowed values: insert and upsert.
        :paramtype write_behavior: any
        """
        super(DocumentDbCollectionSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'DocumentDbCollectionSink'  # type: str
        self.nesting_separator = nesting_separator
        self.write_behavior = write_behavior


class DocumentDbCollectionSource(CopySource):
    """A copy activity Document Database Collection source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: Documents query. Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar nesting_separator: Nested properties separator. Type: string (or Expression with
     resultType string).
    :vartype nesting_separator: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'nesting_separator': {'key': 'nestingSeparator', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query: Optional[Any] = None,
        nesting_separator: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: Documents query. Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword nesting_separator: Nested properties separator. Type: string (or Expression with
         resultType string).
        :paramtype nesting_separator: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(DocumentDbCollectionSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'DocumentDbCollectionSource'  # type: str
        self.query = query
        self.nesting_separator = nesting_separator
        self.query_timeout = query_timeout
        self.additional_columns = additional_columns


class DrillLinkedService(LinkedService):
    """Drill server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar pwd: The Azure key vault secret reference of password in connection string.
    :vartype pwd: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'pwd': {'key': 'typeProperties.pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: An ODBC connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword pwd: The Azure key vault secret reference of password in connection string.
        :paramtype pwd: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(DrillLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Drill'  # type: str
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class DrillSource(TabularSource):
    """A copy activity Drill server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(DrillSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'DrillSource'  # type: str
        self.query = query


class DrillTableDataset(Dataset):
    """Drill server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar table: The table name of the Drill. Type: string (or Expression with resultType string).
    :vartype table: any
    :ivar schema_type_properties_schema: The schema name of the Drill. Type: string (or Expression
     with resultType string).
    :vartype schema_type_properties_schema: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword table: The table name of the Drill. Type: string (or Expression with resultType
         string).
        :paramtype table: any
        :keyword schema_type_properties_schema: The schema name of the Drill. Type: string (or
         Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        """
        super(DrillTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'DrillTable'  # type: str
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class DWCopyCommandDefaultValue(msrest.serialization.Model):
    """Default value.

    :ivar column_name: Column name. Type: object (or Expression with resultType string).
    :vartype column_name: any
    :ivar default_value: The default value of the column. Type: object (or Expression with
     resultType string).
    :vartype default_value: any
    """

    _attribute_map = {
        'column_name': {'key': 'columnName', 'type': 'object'},
        'default_value': {'key': 'defaultValue', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        column_name: Optional[Any] = None,
        default_value: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword column_name: Column name. Type: object (or Expression with resultType string).
        :paramtype column_name: any
        :keyword default_value: The default value of the column. Type: object (or Expression with
         resultType string).
        :paramtype default_value: any
        """
        super(DWCopyCommandDefaultValue, self).__init__(**kwargs)
        self.column_name = column_name
        self.default_value = default_value


class DWCopyCommandSettings(msrest.serialization.Model):
    """DW Copy Command settings.

    :ivar default_values: Specifies the default values for each target column in SQL DW. The
     default values in the property overwrite the DEFAULT constraint set in the DB, and identity
     column cannot have a default value. Type: array of objects (or Expression with resultType array
     of objects).
    :vartype default_values: list[~azure.mgmt.datafactory.models.DWCopyCommandDefaultValue]
    :ivar additional_options: Additional options directly passed to SQL DW in Copy Command. Type:
     key value pairs (value should be string type) (or Expression with resultType object). Example:
     "additionalOptions": { "MAXERRORS": "1000", "DATEFORMAT": "'ymd'" }.
    :vartype additional_options: dict[str, str]
    """

    _attribute_map = {
        'default_values': {'key': 'defaultValues', 'type': '[DWCopyCommandDefaultValue]'},
        'additional_options': {'key': 'additionalOptions', 'type': '{str}'},
    }

    def __init__(
        self,
        *,
        default_values: Optional[List["DWCopyCommandDefaultValue"]] = None,
        additional_options: Optional[Dict[str, str]] = None,
        **kwargs
    ):
        """
        :keyword default_values: Specifies the default values for each target column in SQL DW. The
         default values in the property overwrite the DEFAULT constraint set in the DB, and identity
         column cannot have a default value. Type: array of objects (or Expression with resultType array
         of objects).
        :paramtype default_values: list[~azure.mgmt.datafactory.models.DWCopyCommandDefaultValue]
        :keyword additional_options: Additional options directly passed to SQL DW in Copy Command.
         Type: key value pairs (value should be string type) (or Expression with resultType object).
         Example: "additionalOptions": { "MAXERRORS": "1000", "DATEFORMAT": "'ymd'" }.
        :paramtype additional_options: dict[str, str]
        """
        super(DWCopyCommandSettings, self).__init__(**kwargs)
        self.default_values = default_values
        self.additional_options = additional_options


class DynamicsAXLinkedService(LinkedService):
    """Dynamics AX linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar url: Required. The Dynamics AX (or Dynamics 365 Finance and Operations) instance OData
     endpoint.
    :vartype url: any
    :ivar service_principal_id: Required. Specify the application's client ID. Type: string (or
     Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: Required. Specify the application's key. Mark this field as a
     SecureString to store it securely in Data Factory, or reference a secret stored in Azure Key
     Vault. Type: string (or Expression with resultType string).
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar tenant: Required. Specify the tenant information (domain name or tenant ID) under which
     your application resides. Retrieve it by hovering the mouse in the top-right corner of the
     Azure portal. Type: string (or Expression with resultType string).
    :vartype tenant: any
    :ivar aad_resource_id: Required. Specify the resource you are requesting authorization. Type:
     string (or Expression with resultType string).
    :vartype aad_resource_id: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
        'service_principal_id': {'required': True},
        'service_principal_key': {'required': True},
        'tenant': {'required': True},
        'aad_resource_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'url': {'key': 'typeProperties.url', 'type': 'object'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'aad_resource_id': {'key': 'typeProperties.aadResourceId', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        url: Any,
        service_principal_id: Any,
        service_principal_key: "SecretBase",
        tenant: Any,
        aad_resource_id: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword url: Required. The Dynamics AX (or Dynamics 365 Finance and Operations) instance OData
         endpoint.
        :paramtype url: any
        :keyword service_principal_id: Required. Specify the application's client ID. Type: string (or
         Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: Required. Specify the application's key. Mark this field as a
         SecureString to store it securely in Data Factory, or reference a secret stored in Azure Key
         Vault. Type: string (or Expression with resultType string).
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword tenant: Required. Specify the tenant information (domain name or tenant ID) under
         which your application resides. Retrieve it by hovering the mouse in the top-right corner of
         the Azure portal. Type: string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword aad_resource_id: Required. Specify the resource you are requesting authorization.
         Type: string (or Expression with resultType string).
        :paramtype aad_resource_id: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(DynamicsAXLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'DynamicsAX'  # type: str
        self.url = url
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.aad_resource_id = aad_resource_id
        self.encrypted_credential = encrypted_credential


class DynamicsAXResourceDataset(Dataset):
    """The path of the Dynamics AX OData entity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar path: Required. The path of the Dynamics AX OData entity. Type: string (or Expression
     with resultType string).
    :vartype path: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'path': {'key': 'typeProperties.path', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        path: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword path: Required. The path of the Dynamics AX OData entity. Type: string (or Expression
         with resultType string).
        :paramtype path: any
        """
        super(DynamicsAXResourceDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'DynamicsAXResource'  # type: str
        self.path = path


class DynamicsAXSource(TabularSource):
    """A copy activity Dynamics AX source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    :ivar http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the timeout
     to get a response, not the timeout to read response data. Default value: 00:05:00. Type: string
     (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype http_request_timeout: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'http_request_timeout': {'key': 'httpRequestTimeout', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        http_request_timeout: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        :keyword http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the
         timeout to get a response, not the timeout to read response data. Default value: 00:05:00.
         Type: string (or Expression with resultType string), pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype http_request_timeout: any
        """
        super(DynamicsAXSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'DynamicsAXSource'  # type: str
        self.query = query
        self.http_request_timeout = http_request_timeout


class DynamicsCrmEntityDataset(Dataset):
    """The Dynamics CRM entity dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar entity_name: The logical name of the entity. Type: string (or Expression with resultType
     string).
    :vartype entity_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'entity_name': {'key': 'typeProperties.entityName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        entity_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword entity_name: The logical name of the entity. Type: string (or Expression with
         resultType string).
        :paramtype entity_name: any
        """
        super(DynamicsCrmEntityDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'DynamicsCrmEntity'  # type: str
        self.entity_name = entity_name


class DynamicsCrmLinkedService(LinkedService):
    """Dynamics CRM linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar deployment_type: Required. The deployment type of the Dynamics CRM instance. 'Online' for
     Dynamics CRM Online and 'OnPremisesWithIfd' for Dynamics CRM on-premises with Ifd. Type: string
     (or Expression with resultType string).
    :vartype deployment_type: any
    :ivar host_name: The host name of the on-premises Dynamics CRM server. The property is required
     for on-prem and not allowed for online. Type: string (or Expression with resultType string).
    :vartype host_name: any
    :ivar port: The port of on-premises Dynamics CRM server. The property is required for on-prem
     and not allowed for online. Default is 443. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype port: any
    :ivar service_uri: The URL to the Microsoft Dynamics CRM server. The property is required for
     on-line and not allowed for on-prem. Type: string (or Expression with resultType string).
    :vartype service_uri: any
    :ivar organization_name: The organization name of the Dynamics CRM instance. The property is
     required for on-prem and required for online when there are more than one Dynamics CRM
     instances associated with the user. Type: string (or Expression with resultType string).
    :vartype organization_name: any
    :ivar authentication_type: Required. The authentication type to connect to Dynamics CRM server.
     'Office365' for online scenario, 'Ifd' for on-premises with Ifd scenario, 'AADServicePrincipal'
     for Server-To-Server authentication in online scenario. Type: string (or Expression with
     resultType string).
    :vartype authentication_type: any
    :ivar username: User name to access the Dynamics CRM instance. Type: string (or Expression with
     resultType string).
    :vartype username: any
    :ivar password: Password to access the Dynamics CRM instance.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar service_principal_id: The client ID of the application in Azure Active Directory used for
     Server-To-Server authentication. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_credential_type: The service principal credential type to use in
     Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
     for certificate. Type: string (or Expression with resultType string).
    :vartype service_principal_credential_type: any
    :ivar service_principal_credential: The credential of the service principal object in Azure
     Active Directory. If servicePrincipalCredentialType is 'ServicePrincipalKey',
     servicePrincipalCredential can be SecureString or AzureKeyVaultSecretReference. If
     servicePrincipalCredentialType is 'ServicePrincipalCert', servicePrincipalCredential can only
     be AzureKeyVaultSecretReference.
    :vartype service_principal_credential: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'deployment_type': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'deployment_type': {'key': 'typeProperties.deploymentType', 'type': 'object'},
        'host_name': {'key': 'typeProperties.hostName', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'service_uri': {'key': 'typeProperties.serviceUri', 'type': 'object'},
        'organization_name': {'key': 'typeProperties.organizationName', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_credential_type': {'key': 'typeProperties.servicePrincipalCredentialType', 'type': 'object'},
        'service_principal_credential': {'key': 'typeProperties.servicePrincipalCredential', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        deployment_type: Any,
        authentication_type: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        host_name: Optional[Any] = None,
        port: Optional[Any] = None,
        service_uri: Optional[Any] = None,
        organization_name: Optional[Any] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_credential_type: Optional[Any] = None,
        service_principal_credential: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword deployment_type: Required. The deployment type of the Dynamics CRM instance. 'Online'
         for Dynamics CRM Online and 'OnPremisesWithIfd' for Dynamics CRM on-premises with Ifd. Type:
         string (or Expression with resultType string).
        :paramtype deployment_type: any
        :keyword host_name: The host name of the on-premises Dynamics CRM server. The property is
         required for on-prem and not allowed for online. Type: string (or Expression with resultType
         string).
        :paramtype host_name: any
        :keyword port: The port of on-premises Dynamics CRM server. The property is required for
         on-prem and not allowed for online. Default is 443. Type: integer (or Expression with
         resultType integer), minimum: 0.
        :paramtype port: any
        :keyword service_uri: The URL to the Microsoft Dynamics CRM server. The property is required
         for on-line and not allowed for on-prem. Type: string (or Expression with resultType string).
        :paramtype service_uri: any
        :keyword organization_name: The organization name of the Dynamics CRM instance. The property is
         required for on-prem and required for online when there are more than one Dynamics CRM
         instances associated with the user. Type: string (or Expression with resultType string).
        :paramtype organization_name: any
        :keyword authentication_type: Required. The authentication type to connect to Dynamics CRM
         server. 'Office365' for online scenario, 'Ifd' for on-premises with Ifd scenario,
         'AADServicePrincipal' for Server-To-Server authentication in online scenario. Type: string (or
         Expression with resultType string).
        :paramtype authentication_type: any
        :keyword username: User name to access the Dynamics CRM instance. Type: string (or Expression
         with resultType string).
        :paramtype username: any
        :keyword password: Password to access the Dynamics CRM instance.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword service_principal_id: The client ID of the application in Azure Active Directory used
         for Server-To-Server authentication. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_credential_type: The service principal credential type to use in
         Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
         for certificate. Type: string (or Expression with resultType string).
        :paramtype service_principal_credential_type: any
        :keyword service_principal_credential: The credential of the service principal object in Azure
         Active Directory. If servicePrincipalCredentialType is 'ServicePrincipalKey',
         servicePrincipalCredential can be SecureString or AzureKeyVaultSecretReference. If
         servicePrincipalCredentialType is 'ServicePrincipalCert', servicePrincipalCredential can only
         be AzureKeyVaultSecretReference.
        :paramtype service_principal_credential: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(DynamicsCrmLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'DynamicsCrm'  # type: str
        self.deployment_type = deployment_type
        self.host_name = host_name
        self.port = port
        self.service_uri = service_uri
        self.organization_name = organization_name
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_credential_type = service_principal_credential_type
        self.service_principal_credential = service_principal_credential
        self.encrypted_credential = encrypted_credential


class DynamicsCrmSink(CopySink):
    """A copy activity Dynamics CRM sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar write_behavior: Required. The write behavior for the operation. Possible values include:
     "Upsert".
    :vartype write_behavior: str or ~azure.mgmt.datafactory.models.DynamicsSinkWriteBehavior
    :ivar ignore_null_values: The flag indicating whether to ignore null values from input dataset
     (except key fields) during write operation. Default is false. Type: boolean (or Expression with
     resultType boolean).
    :vartype ignore_null_values: any
    :ivar alternate_key_name: The logical name of the alternate key which will be used when
     upserting records. Type: string (or Expression with resultType string).
    :vartype alternate_key_name: any
    """

    _validation = {
        'type': {'required': True},
        'write_behavior': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
        'ignore_null_values': {'key': 'ignoreNullValues', 'type': 'object'},
        'alternate_key_name': {'key': 'alternateKeyName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        write_behavior: Union[str, "DynamicsSinkWriteBehavior"],
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        ignore_null_values: Optional[Any] = None,
        alternate_key_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword write_behavior: Required. The write behavior for the operation. Possible values
         include: "Upsert".
        :paramtype write_behavior: str or ~azure.mgmt.datafactory.models.DynamicsSinkWriteBehavior
        :keyword ignore_null_values: The flag indicating whether to ignore null values from input
         dataset (except key fields) during write operation. Default is false. Type: boolean (or
         Expression with resultType boolean).
        :paramtype ignore_null_values: any
        :keyword alternate_key_name: The logical name of the alternate key which will be used when
         upserting records. Type: string (or Expression with resultType string).
        :paramtype alternate_key_name: any
        """
        super(DynamicsCrmSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'DynamicsCrmSink'  # type: str
        self.write_behavior = write_behavior
        self.ignore_null_values = ignore_null_values
        self.alternate_key_name = alternate_key_name


class DynamicsCrmSource(CopySource):
    """A copy activity Dynamics CRM source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: FetchXML is a proprietary query language that is used in Microsoft Dynamics CRM
     (online & on-premises). Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: FetchXML is a proprietary query language that is used in Microsoft Dynamics CRM
         (online & on-premises). Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(DynamicsCrmSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'DynamicsCrmSource'  # type: str
        self.query = query
        self.additional_columns = additional_columns


class DynamicsEntityDataset(Dataset):
    """The Dynamics entity dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar entity_name: The logical name of the entity. Type: string (or Expression with resultType
     string).
    :vartype entity_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'entity_name': {'key': 'typeProperties.entityName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        entity_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword entity_name: The logical name of the entity. Type: string (or Expression with
         resultType string).
        :paramtype entity_name: any
        """
        super(DynamicsEntityDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'DynamicsEntity'  # type: str
        self.entity_name = entity_name


class DynamicsLinkedService(LinkedService):
    """Dynamics linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar deployment_type: Required. The deployment type of the Dynamics instance. 'Online' for
     Dynamics Online and 'OnPremisesWithIfd' for Dynamics on-premises with Ifd. Type: string (or
     Expression with resultType string).
    :vartype deployment_type: any
    :ivar host_name: The host name of the on-premises Dynamics server. The property is required for
     on-prem and not allowed for online. Type: string (or Expression with resultType string).
    :vartype host_name: any
    :ivar port: The port of on-premises Dynamics server. The property is required for on-prem and
     not allowed for online. Default is 443. Type: integer (or Expression with resultType integer),
     minimum: 0.
    :vartype port: any
    :ivar service_uri: The URL to the Microsoft Dynamics server. The property is required for
     on-line and not allowed for on-prem. Type: string (or Expression with resultType string).
    :vartype service_uri: any
    :ivar organization_name: The organization name of the Dynamics instance. The property is
     required for on-prem and required for online when there are more than one Dynamics instances
     associated with the user. Type: string (or Expression with resultType string).
    :vartype organization_name: any
    :ivar authentication_type: Required. The authentication type to connect to Dynamics server.
     'Office365' for online scenario, 'Ifd' for on-premises with Ifd scenario, 'AADServicePrincipal'
     for Server-To-Server authentication in online scenario. Type: string (or Expression with
     resultType string).
    :vartype authentication_type: any
    :ivar username: User name to access the Dynamics instance. Type: string (or Expression with
     resultType string).
    :vartype username: any
    :ivar password: Password to access the Dynamics instance.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar service_principal_id: The client ID of the application in Azure Active Directory used for
     Server-To-Server authentication. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_credential_type: The service principal credential type to use in
     Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
     for certificate. Type: string (or Expression with resultType string).
    :vartype service_principal_credential_type: any
    :ivar service_principal_credential: The credential of the service principal object in Azure
     Active Directory. If servicePrincipalCredentialType is 'ServicePrincipalKey',
     servicePrincipalCredential can be SecureString or AzureKeyVaultSecretReference. If
     servicePrincipalCredentialType is 'ServicePrincipalCert', servicePrincipalCredential can only
     be AzureKeyVaultSecretReference.
    :vartype service_principal_credential: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'type': {'required': True},
        'deployment_type': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'deployment_type': {'key': 'typeProperties.deploymentType', 'type': 'object'},
        'host_name': {'key': 'typeProperties.hostName', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'service_uri': {'key': 'typeProperties.serviceUri', 'type': 'object'},
        'organization_name': {'key': 'typeProperties.organizationName', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_credential_type': {'key': 'typeProperties.servicePrincipalCredentialType', 'type': 'object'},
        'service_principal_credential': {'key': 'typeProperties.servicePrincipalCredential', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        deployment_type: Any,
        authentication_type: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        host_name: Optional[Any] = None,
        port: Optional[Any] = None,
        service_uri: Optional[Any] = None,
        organization_name: Optional[Any] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_credential_type: Optional[Any] = None,
        service_principal_credential: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword deployment_type: Required. The deployment type of the Dynamics instance. 'Online' for
         Dynamics Online and 'OnPremisesWithIfd' for Dynamics on-premises with Ifd. Type: string (or
         Expression with resultType string).
        :paramtype deployment_type: any
        :keyword host_name: The host name of the on-premises Dynamics server. The property is required
         for on-prem and not allowed for online. Type: string (or Expression with resultType string).
        :paramtype host_name: any
        :keyword port: The port of on-premises Dynamics server. The property is required for on-prem
         and not allowed for online. Default is 443. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype port: any
        :keyword service_uri: The URL to the Microsoft Dynamics server. The property is required for
         on-line and not allowed for on-prem. Type: string (or Expression with resultType string).
        :paramtype service_uri: any
        :keyword organization_name: The organization name of the Dynamics instance. The property is
         required for on-prem and required for online when there are more than one Dynamics instances
         associated with the user. Type: string (or Expression with resultType string).
        :paramtype organization_name: any
        :keyword authentication_type: Required. The authentication type to connect to Dynamics server.
         'Office365' for online scenario, 'Ifd' for on-premises with Ifd scenario, 'AADServicePrincipal'
         for Server-To-Server authentication in online scenario. Type: string (or Expression with
         resultType string).
        :paramtype authentication_type: any
        :keyword username: User name to access the Dynamics instance. Type: string (or Expression with
         resultType string).
        :paramtype username: any
        :keyword password: Password to access the Dynamics instance.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword service_principal_id: The client ID of the application in Azure Active Directory used
         for Server-To-Server authentication. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_credential_type: The service principal credential type to use in
         Server-To-Server authentication. 'ServicePrincipalKey' for key/secret, 'ServicePrincipalCert'
         for certificate. Type: string (or Expression with resultType string).
        :paramtype service_principal_credential_type: any
        :keyword service_principal_credential: The credential of the service principal object in Azure
         Active Directory. If servicePrincipalCredentialType is 'ServicePrincipalKey',
         servicePrincipalCredential can be SecureString or AzureKeyVaultSecretReference. If
         servicePrincipalCredentialType is 'ServicePrincipalCert', servicePrincipalCredential can only
         be AzureKeyVaultSecretReference.
        :paramtype service_principal_credential: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(DynamicsLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Dynamics'  # type: str
        self.deployment_type = deployment_type
        self.host_name = host_name
        self.port = port
        self.service_uri = service_uri
        self.organization_name = organization_name
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.service_principal_id = service_principal_id
        self.service_principal_credential_type = service_principal_credential_type
        self.service_principal_credential = service_principal_credential
        self.encrypted_credential = encrypted_credential
        self.credential = credential


class DynamicsSink(CopySink):
    """A copy activity Dynamics sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar write_behavior: Required. The write behavior for the operation. Possible values include:
     "Upsert".
    :vartype write_behavior: str or ~azure.mgmt.datafactory.models.DynamicsSinkWriteBehavior
    :ivar ignore_null_values: The flag indicating whether ignore null values from input dataset
     (except key fields) during write operation. Default is false. Type: boolean (or Expression with
     resultType boolean).
    :vartype ignore_null_values: any
    :ivar alternate_key_name: The logical name of the alternate key which will be used when
     upserting records. Type: string (or Expression with resultType string).
    :vartype alternate_key_name: any
    """

    _validation = {
        'type': {'required': True},
        'write_behavior': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
        'ignore_null_values': {'key': 'ignoreNullValues', 'type': 'object'},
        'alternate_key_name': {'key': 'alternateKeyName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        write_behavior: Union[str, "DynamicsSinkWriteBehavior"],
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        ignore_null_values: Optional[Any] = None,
        alternate_key_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword write_behavior: Required. The write behavior for the operation. Possible values
         include: "Upsert".
        :paramtype write_behavior: str or ~azure.mgmt.datafactory.models.DynamicsSinkWriteBehavior
        :keyword ignore_null_values: The flag indicating whether ignore null values from input dataset
         (except key fields) during write operation. Default is false. Type: boolean (or Expression with
         resultType boolean).
        :paramtype ignore_null_values: any
        :keyword alternate_key_name: The logical name of the alternate key which will be used when
         upserting records. Type: string (or Expression with resultType string).
        :paramtype alternate_key_name: any
        """
        super(DynamicsSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'DynamicsSink'  # type: str
        self.write_behavior = write_behavior
        self.ignore_null_values = ignore_null_values
        self.alternate_key_name = alternate_key_name


class DynamicsSource(CopySource):
    """A copy activity Dynamics source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: FetchXML is a proprietary query language that is used in Microsoft Dynamics
     (online & on-premises). Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: FetchXML is a proprietary query language that is used in Microsoft Dynamics
         (online & on-premises). Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(DynamicsSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'DynamicsSource'  # type: str
        self.query = query
        self.additional_columns = additional_columns


class EloquaLinkedService(LinkedService):
    """Eloqua server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar endpoint: Required. The endpoint of the Eloqua server. (i.e. eloqua.example.com).
    :vartype endpoint: any
    :ivar username: Required. The site name and user name of your Eloqua account in the form:
     sitename/username. (i.e. Eloqua/Alice).
    :vartype username: any
    :ivar password: The password corresponding to the user name.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
        'username': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        endpoint: Any,
        username: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        password: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword endpoint: Required. The endpoint of the Eloqua server. (i.e. eloqua.example.com).
        :paramtype endpoint: any
        :keyword username: Required. The site name and user name of your Eloqua account in the form:
         sitename/username. (i.e. Eloqua/Alice).
        :paramtype username: any
        :keyword password: The password corresponding to the user name.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true.
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true.
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(EloquaLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Eloqua'  # type: str
        self.endpoint = endpoint
        self.username = username
        self.password = password
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class EloquaObjectDataset(Dataset):
    """Eloqua server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(EloquaObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'EloquaObject'  # type: str
        self.table_name = table_name


class EloquaSource(TabularSource):
    """A copy activity Eloqua server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(EloquaSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'EloquaSource'  # type: str
        self.query = query


class EncryptionConfiguration(msrest.serialization.Model):
    """Definition of CMK for the factory.

    All required parameters must be populated in order to send to Azure.

    :ivar key_name: Required. The name of the key in Azure Key Vault to use as Customer Managed
     Key.
    :vartype key_name: str
    :ivar vault_base_url: Required. The url of the Azure Key Vault used for CMK.
    :vartype vault_base_url: str
    :ivar key_version: The version of the key used for CMK. If not provided, latest version will be
     used.
    :vartype key_version: str
    :ivar identity: User assigned identity to use to authenticate to customer's key vault. If not
     provided Managed Service Identity will be used.
    :vartype identity: ~azure.mgmt.datafactory.models.CMKIdentityDefinition
    """

    _validation = {
        'key_name': {'required': True},
        'vault_base_url': {'required': True},
    }

    _attribute_map = {
        'key_name': {'key': 'keyName', 'type': 'str'},
        'vault_base_url': {'key': 'vaultBaseUrl', 'type': 'str'},
        'key_version': {'key': 'keyVersion', 'type': 'str'},
        'identity': {'key': 'identity', 'type': 'CMKIdentityDefinition'},
    }

    def __init__(
        self,
        *,
        key_name: str,
        vault_base_url: str,
        key_version: Optional[str] = None,
        identity: Optional["CMKIdentityDefinition"] = None,
        **kwargs
    ):
        """
        :keyword key_name: Required. The name of the key in Azure Key Vault to use as Customer Managed
         Key.
        :paramtype key_name: str
        :keyword vault_base_url: Required. The url of the Azure Key Vault used for CMK.
        :paramtype vault_base_url: str
        :keyword key_version: The version of the key used for CMK. If not provided, latest version will
         be used.
        :paramtype key_version: str
        :keyword identity: User assigned identity to use to authenticate to customer's key vault. If
         not provided Managed Service Identity will be used.
        :paramtype identity: ~azure.mgmt.datafactory.models.CMKIdentityDefinition
        """
        super(EncryptionConfiguration, self).__init__(**kwargs)
        self.key_name = key_name
        self.vault_base_url = vault_base_url
        self.key_version = key_version
        self.identity = identity


class EntityReference(msrest.serialization.Model):
    """The entity reference.

    :ivar type: The type of this referenced entity. Possible values include:
     "IntegrationRuntimeReference", "LinkedServiceReference".
    :vartype type: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeEntityReferenceType
    :ivar reference_name: The name of this referenced entity.
    :vartype reference_name: str
    """

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        type: Optional[Union[str, "IntegrationRuntimeEntityReferenceType"]] = None,
        reference_name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword type: The type of this referenced entity. Possible values include:
         "IntegrationRuntimeReference", "LinkedServiceReference".
        :paramtype type: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeEntityReferenceType
        :keyword reference_name: The name of this referenced entity.
        :paramtype reference_name: str
        """
        super(EntityReference, self).__init__(**kwargs)
        self.type = type
        self.reference_name = reference_name


class EnvironmentVariableSetup(CustomSetupBase):
    """The custom setup of setting environment variable.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. The type of custom setup.Constant filled by server.
    :vartype type: str
    :ivar variable_name: Required. The name of the environment variable.
    :vartype variable_name: str
    :ivar variable_value: Required. The value of the environment variable.
    :vartype variable_value: str
    """

    _validation = {
        'type': {'required': True},
        'variable_name': {'required': True},
        'variable_value': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'variable_name': {'key': 'typeProperties.variableName', 'type': 'str'},
        'variable_value': {'key': 'typeProperties.variableValue', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        variable_name: str,
        variable_value: str,
        **kwargs
    ):
        """
        :keyword variable_name: Required. The name of the environment variable.
        :paramtype variable_name: str
        :keyword variable_value: Required. The value of the environment variable.
        :paramtype variable_value: str
        """
        super(EnvironmentVariableSetup, self).__init__(**kwargs)
        self.type = 'EnvironmentVariableSetup'  # type: str
        self.variable_name = variable_name
        self.variable_value = variable_value


class ExcelDataset(Dataset):
    """Excel dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar location: The location of the excel storage.
    :vartype location: ~azure.mgmt.datafactory.models.DatasetLocation
    :ivar sheet_name: The sheet name of excel file. Type: string (or Expression with resultType
     string).
    :vartype sheet_name: any
    :ivar sheet_index: The sheet index of excel file and default value is 0. Type: integer (or
     Expression with resultType integer).
    :vartype sheet_index: any
    :ivar range: The partial data of one sheet. Type: string (or Expression with resultType
     string).
    :vartype range: any
    :ivar first_row_as_header: When used as input, treat the first row of data as headers. When
     used as output,write the headers into the output as the first row of data. The default value is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype first_row_as_header: any
    :ivar compression: The data compression method used for the json dataset.
    :vartype compression: ~azure.mgmt.datafactory.models.DatasetCompression
    :ivar null_value: The null value string. Type: string (or Expression with resultType string).
    :vartype null_value: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'sheet_name': {'key': 'typeProperties.sheetName', 'type': 'object'},
        'sheet_index': {'key': 'typeProperties.sheetIndex', 'type': 'object'},
        'range': {'key': 'typeProperties.range', 'type': 'object'},
        'first_row_as_header': {'key': 'typeProperties.firstRowAsHeader', 'type': 'object'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
        'null_value': {'key': 'typeProperties.nullValue', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        sheet_name: Optional[Any] = None,
        sheet_index: Optional[Any] = None,
        range: Optional[Any] = None,
        first_row_as_header: Optional[Any] = None,
        compression: Optional["DatasetCompression"] = None,
        null_value: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword location: The location of the excel storage.
        :paramtype location: ~azure.mgmt.datafactory.models.DatasetLocation
        :keyword sheet_name: The sheet name of excel file. Type: string (or Expression with resultType
         string).
        :paramtype sheet_name: any
        :keyword sheet_index: The sheet index of excel file and default value is 0. Type: integer (or
         Expression with resultType integer).
        :paramtype sheet_index: any
        :keyword range: The partial data of one sheet. Type: string (or Expression with resultType
         string).
        :paramtype range: any
        :keyword first_row_as_header: When used as input, treat the first row of data as headers. When
         used as output,write the headers into the output as the first row of data. The default value is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype first_row_as_header: any
        :keyword compression: The data compression method used for the json dataset.
        :paramtype compression: ~azure.mgmt.datafactory.models.DatasetCompression
        :keyword null_value: The null value string. Type: string (or Expression with resultType
         string).
        :paramtype null_value: any
        """
        super(ExcelDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Excel'  # type: str
        self.location = location
        self.sheet_name = sheet_name
        self.sheet_index = sheet_index
        self.range = range
        self.first_row_as_header = first_row_as_header
        self.compression = compression
        self.null_value = null_value


class ExcelSource(CopySource):
    """A copy activity excel source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: Excel store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: Excel store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(ExcelSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'ExcelSource'  # type: str
        self.store_settings = store_settings
        self.additional_columns = additional_columns


class ExecuteDataFlowActivity(ExecutionActivity):
    """Execute data flow activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar data_flow: Required. Data flow reference.
    :vartype data_flow: ~azure.mgmt.datafactory.models.DataFlowReference
    :ivar staging: Staging info for execute data flow activity.
    :vartype staging: ~azure.mgmt.datafactory.models.DataFlowStagingInfo
    :ivar integration_runtime: The integration runtime reference.
    :vartype integration_runtime: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar compute: Compute properties for data flow activity.
    :vartype compute: ~azure.mgmt.datafactory.models.ExecuteDataFlowActivityTypePropertiesCompute
    :ivar trace_level: Trace level setting used for data flow monitoring output. Supported values
     are: 'coarse', 'fine', and 'none'. Type: string (or Expression with resultType string).
    :vartype trace_level: any
    :ivar continue_on_error: Continue on error setting used for data flow execution. Enables
     processing to continue if a sink fails. Type: boolean (or Expression with resultType boolean).
    :vartype continue_on_error: any
    :ivar run_concurrently: Concurrent run setting used for data flow execution. Allows sinks with
     the same save order to be processed concurrently. Type: boolean (or Expression with resultType
     boolean).
    :vartype run_concurrently: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'data_flow': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'data_flow': {'key': 'typeProperties.dataFlow', 'type': 'DataFlowReference'},
        'staging': {'key': 'typeProperties.staging', 'type': 'DataFlowStagingInfo'},
        'integration_runtime': {'key': 'typeProperties.integrationRuntime', 'type': 'IntegrationRuntimeReference'},
        'compute': {'key': 'typeProperties.compute', 'type': 'ExecuteDataFlowActivityTypePropertiesCompute'},
        'trace_level': {'key': 'typeProperties.traceLevel', 'type': 'object'},
        'continue_on_error': {'key': 'typeProperties.continueOnError', 'type': 'object'},
        'run_concurrently': {'key': 'typeProperties.runConcurrently', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        data_flow: "DataFlowReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        staging: Optional["DataFlowStagingInfo"] = None,
        integration_runtime: Optional["IntegrationRuntimeReference"] = None,
        compute: Optional["ExecuteDataFlowActivityTypePropertiesCompute"] = None,
        trace_level: Optional[Any] = None,
        continue_on_error: Optional[Any] = None,
        run_concurrently: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword data_flow: Required. Data flow reference.
        :paramtype data_flow: ~azure.mgmt.datafactory.models.DataFlowReference
        :keyword staging: Staging info for execute data flow activity.
        :paramtype staging: ~azure.mgmt.datafactory.models.DataFlowStagingInfo
        :keyword integration_runtime: The integration runtime reference.
        :paramtype integration_runtime: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword compute: Compute properties for data flow activity.
        :paramtype compute: ~azure.mgmt.datafactory.models.ExecuteDataFlowActivityTypePropertiesCompute
        :keyword trace_level: Trace level setting used for data flow monitoring output. Supported
         values are: 'coarse', 'fine', and 'none'. Type: string (or Expression with resultType string).
        :paramtype trace_level: any
        :keyword continue_on_error: Continue on error setting used for data flow execution. Enables
         processing to continue if a sink fails. Type: boolean (or Expression with resultType boolean).
        :paramtype continue_on_error: any
        :keyword run_concurrently: Concurrent run setting used for data flow execution. Allows sinks
         with the same save order to be processed concurrently. Type: boolean (or Expression with
         resultType boolean).
        :paramtype run_concurrently: any
        """
        super(ExecuteDataFlowActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'ExecuteDataFlow'  # type: str
        self.data_flow = data_flow
        self.staging = staging
        self.integration_runtime = integration_runtime
        self.compute = compute
        self.trace_level = trace_level
        self.continue_on_error = continue_on_error
        self.run_concurrently = run_concurrently


class ExecuteDataFlowActivityTypeProperties(msrest.serialization.Model):
    """Execute data flow activity properties.

    All required parameters must be populated in order to send to Azure.

    :ivar data_flow: Required. Data flow reference.
    :vartype data_flow: ~azure.mgmt.datafactory.models.DataFlowReference
    :ivar staging: Staging info for execute data flow activity.
    :vartype staging: ~azure.mgmt.datafactory.models.DataFlowStagingInfo
    :ivar integration_runtime: The integration runtime reference.
    :vartype integration_runtime: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar compute: Compute properties for data flow activity.
    :vartype compute: ~azure.mgmt.datafactory.models.ExecuteDataFlowActivityTypePropertiesCompute
    :ivar trace_level: Trace level setting used for data flow monitoring output. Supported values
     are: 'coarse', 'fine', and 'none'. Type: string (or Expression with resultType string).
    :vartype trace_level: any
    :ivar continue_on_error: Continue on error setting used for data flow execution. Enables
     processing to continue if a sink fails. Type: boolean (or Expression with resultType boolean).
    :vartype continue_on_error: any
    :ivar run_concurrently: Concurrent run setting used for data flow execution. Allows sinks with
     the same save order to be processed concurrently. Type: boolean (or Expression with resultType
     boolean).
    :vartype run_concurrently: any
    """

    _validation = {
        'data_flow': {'required': True},
    }

    _attribute_map = {
        'data_flow': {'key': 'dataFlow', 'type': 'DataFlowReference'},
        'staging': {'key': 'staging', 'type': 'DataFlowStagingInfo'},
        'integration_runtime': {'key': 'integrationRuntime', 'type': 'IntegrationRuntimeReference'},
        'compute': {'key': 'compute', 'type': 'ExecuteDataFlowActivityTypePropertiesCompute'},
        'trace_level': {'key': 'traceLevel', 'type': 'object'},
        'continue_on_error': {'key': 'continueOnError', 'type': 'object'},
        'run_concurrently': {'key': 'runConcurrently', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        data_flow: "DataFlowReference",
        staging: Optional["DataFlowStagingInfo"] = None,
        integration_runtime: Optional["IntegrationRuntimeReference"] = None,
        compute: Optional["ExecuteDataFlowActivityTypePropertiesCompute"] = None,
        trace_level: Optional[Any] = None,
        continue_on_error: Optional[Any] = None,
        run_concurrently: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword data_flow: Required. Data flow reference.
        :paramtype data_flow: ~azure.mgmt.datafactory.models.DataFlowReference
        :keyword staging: Staging info for execute data flow activity.
        :paramtype staging: ~azure.mgmt.datafactory.models.DataFlowStagingInfo
        :keyword integration_runtime: The integration runtime reference.
        :paramtype integration_runtime: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword compute: Compute properties for data flow activity.
        :paramtype compute: ~azure.mgmt.datafactory.models.ExecuteDataFlowActivityTypePropertiesCompute
        :keyword trace_level: Trace level setting used for data flow monitoring output. Supported
         values are: 'coarse', 'fine', and 'none'. Type: string (or Expression with resultType string).
        :paramtype trace_level: any
        :keyword continue_on_error: Continue on error setting used for data flow execution. Enables
         processing to continue if a sink fails. Type: boolean (or Expression with resultType boolean).
        :paramtype continue_on_error: any
        :keyword run_concurrently: Concurrent run setting used for data flow execution. Allows sinks
         with the same save order to be processed concurrently. Type: boolean (or Expression with
         resultType boolean).
        :paramtype run_concurrently: any
        """
        super(ExecuteDataFlowActivityTypeProperties, self).__init__(**kwargs)
        self.data_flow = data_flow
        self.staging = staging
        self.integration_runtime = integration_runtime
        self.compute = compute
        self.trace_level = trace_level
        self.continue_on_error = continue_on_error
        self.run_concurrently = run_concurrently


class ExecuteDataFlowActivityTypePropertiesCompute(msrest.serialization.Model):
    """Compute properties for data flow activity.

    :ivar compute_type: Compute type of the cluster which will execute data flow job. Possible
     values include: 'General', 'MemoryOptimized', 'ComputeOptimized'. Type: string (or Expression
     with resultType string).
    :vartype compute_type: any
    :ivar core_count: Core count of the cluster which will execute data flow job. Supported values
     are: 8, 16, 32, 48, 80, 144 and 272. Type: integer (or Expression with resultType integer).
    :vartype core_count: any
    """

    _attribute_map = {
        'compute_type': {'key': 'computeType', 'type': 'object'},
        'core_count': {'key': 'coreCount', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        compute_type: Optional[Any] = None,
        core_count: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword compute_type: Compute type of the cluster which will execute data flow job. Possible
         values include: 'General', 'MemoryOptimized', 'ComputeOptimized'. Type: string (or Expression
         with resultType string).
        :paramtype compute_type: any
        :keyword core_count: Core count of the cluster which will execute data flow job. Supported
         values are: 8, 16, 32, 48, 80, 144 and 272. Type: integer (or Expression with resultType
         integer).
        :paramtype core_count: any
        """
        super(ExecuteDataFlowActivityTypePropertiesCompute, self).__init__(**kwargs)
        self.compute_type = compute_type
        self.core_count = core_count


class ExecutePipelineActivity(ControlActivity):
    """Execute pipeline activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar policy: Execute pipeline activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ExecutePipelineActivityPolicy
    :ivar pipeline: Required. Pipeline reference.
    :vartype pipeline: ~azure.mgmt.datafactory.models.PipelineReference
    :ivar parameters: Pipeline parameters.
    :vartype parameters: dict[str, any]
    :ivar wait_on_completion: Defines whether activity execution will wait for the dependent
     pipeline execution to finish. Default is false.
    :vartype wait_on_completion: bool
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'pipeline': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'policy': {'key': 'policy', 'type': 'ExecutePipelineActivityPolicy'},
        'pipeline': {'key': 'typeProperties.pipeline', 'type': 'PipelineReference'},
        'parameters': {'key': 'typeProperties.parameters', 'type': '{object}'},
        'wait_on_completion': {'key': 'typeProperties.waitOnCompletion', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        name: str,
        pipeline: "PipelineReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        policy: Optional["ExecutePipelineActivityPolicy"] = None,
        parameters: Optional[Dict[str, Any]] = None,
        wait_on_completion: Optional[bool] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword policy: Execute pipeline activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ExecutePipelineActivityPolicy
        :keyword pipeline: Required. Pipeline reference.
        :paramtype pipeline: ~azure.mgmt.datafactory.models.PipelineReference
        :keyword parameters: Pipeline parameters.
        :paramtype parameters: dict[str, any]
        :keyword wait_on_completion: Defines whether activity execution will wait for the dependent
         pipeline execution to finish. Default is false.
        :paramtype wait_on_completion: bool
        """
        super(ExecutePipelineActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'ExecutePipeline'  # type: str
        self.policy = policy
        self.pipeline = pipeline
        self.parameters = parameters
        self.wait_on_completion = wait_on_completion


class ExecutePipelineActivityPolicy(msrest.serialization.Model):
    """Execution policy for an execute pipeline activity.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar secure_input: When set to true, Input from activity is considered as secure and will not
     be logged to monitoring.
    :vartype secure_input: bool
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'secure_input': {'key': 'secureInput', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        secure_input: Optional[bool] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword secure_input: When set to true, Input from activity is considered as secure and will
         not be logged to monitoring.
        :paramtype secure_input: bool
        """
        super(ExecutePipelineActivityPolicy, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.secure_input = secure_input


class ExecutePowerQueryActivityTypeProperties(ExecuteDataFlowActivityTypeProperties):
    """Execute power query data flow activity properties.

    All required parameters must be populated in order to send to Azure.

    :ivar data_flow: Required. Data flow reference.
    :vartype data_flow: ~azure.mgmt.datafactory.models.DataFlowReference
    :ivar staging: Staging info for execute data flow activity.
    :vartype staging: ~azure.mgmt.datafactory.models.DataFlowStagingInfo
    :ivar integration_runtime: The integration runtime reference.
    :vartype integration_runtime: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar compute: Compute properties for data flow activity.
    :vartype compute: ~azure.mgmt.datafactory.models.ExecuteDataFlowActivityTypePropertiesCompute
    :ivar trace_level: Trace level setting used for data flow monitoring output. Supported values
     are: 'coarse', 'fine', and 'none'. Type: string (or Expression with resultType string).
    :vartype trace_level: any
    :ivar continue_on_error: Continue on error setting used for data flow execution. Enables
     processing to continue if a sink fails. Type: boolean (or Expression with resultType boolean).
    :vartype continue_on_error: any
    :ivar run_concurrently: Concurrent run setting used for data flow execution. Allows sinks with
     the same save order to be processed concurrently. Type: boolean (or Expression with resultType
     boolean).
    :vartype run_concurrently: any
    :ivar sinks: (Deprecated. Please use Queries). List of Power Query activity sinks mapped to a
     queryName.
    :vartype sinks: dict[str, ~azure.mgmt.datafactory.models.PowerQuerySink]
    :ivar queries: List of mapping for Power Query mashup query to sink dataset(s).
    :vartype queries: list[~azure.mgmt.datafactory.models.PowerQuerySinkMapping]
    """

    _validation = {
        'data_flow': {'required': True},
    }

    _attribute_map = {
        'data_flow': {'key': 'dataFlow', 'type': 'DataFlowReference'},
        'staging': {'key': 'staging', 'type': 'DataFlowStagingInfo'},
        'integration_runtime': {'key': 'integrationRuntime', 'type': 'IntegrationRuntimeReference'},
        'compute': {'key': 'compute', 'type': 'ExecuteDataFlowActivityTypePropertiesCompute'},
        'trace_level': {'key': 'traceLevel', 'type': 'object'},
        'continue_on_error': {'key': 'continueOnError', 'type': 'object'},
        'run_concurrently': {'key': 'runConcurrently', 'type': 'object'},
        'sinks': {'key': 'sinks', 'type': '{PowerQuerySink}'},
        'queries': {'key': 'queries', 'type': '[PowerQuerySinkMapping]'},
    }

    def __init__(
        self,
        *,
        data_flow: "DataFlowReference",
        staging: Optional["DataFlowStagingInfo"] = None,
        integration_runtime: Optional["IntegrationRuntimeReference"] = None,
        compute: Optional["ExecuteDataFlowActivityTypePropertiesCompute"] = None,
        trace_level: Optional[Any] = None,
        continue_on_error: Optional[Any] = None,
        run_concurrently: Optional[Any] = None,
        sinks: Optional[Dict[str, "PowerQuerySink"]] = None,
        queries: Optional[List["PowerQuerySinkMapping"]] = None,
        **kwargs
    ):
        """
        :keyword data_flow: Required. Data flow reference.
        :paramtype data_flow: ~azure.mgmt.datafactory.models.DataFlowReference
        :keyword staging: Staging info for execute data flow activity.
        :paramtype staging: ~azure.mgmt.datafactory.models.DataFlowStagingInfo
        :keyword integration_runtime: The integration runtime reference.
        :paramtype integration_runtime: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword compute: Compute properties for data flow activity.
        :paramtype compute: ~azure.mgmt.datafactory.models.ExecuteDataFlowActivityTypePropertiesCompute
        :keyword trace_level: Trace level setting used for data flow monitoring output. Supported
         values are: 'coarse', 'fine', and 'none'. Type: string (or Expression with resultType string).
        :paramtype trace_level: any
        :keyword continue_on_error: Continue on error setting used for data flow execution. Enables
         processing to continue if a sink fails. Type: boolean (or Expression with resultType boolean).
        :paramtype continue_on_error: any
        :keyword run_concurrently: Concurrent run setting used for data flow execution. Allows sinks
         with the same save order to be processed concurrently. Type: boolean (or Expression with
         resultType boolean).
        :paramtype run_concurrently: any
        :keyword sinks: (Deprecated. Please use Queries). List of Power Query activity sinks mapped to
         a queryName.
        :paramtype sinks: dict[str, ~azure.mgmt.datafactory.models.PowerQuerySink]
        :keyword queries: List of mapping for Power Query mashup query to sink dataset(s).
        :paramtype queries: list[~azure.mgmt.datafactory.models.PowerQuerySinkMapping]
        """
        super(ExecutePowerQueryActivityTypeProperties, self).__init__(data_flow=data_flow, staging=staging, integration_runtime=integration_runtime, compute=compute, trace_level=trace_level, continue_on_error=continue_on_error, run_concurrently=run_concurrently, **kwargs)
        self.sinks = sinks
        self.queries = queries


class ExecuteSSISPackageActivity(ExecutionActivity):
    """Execute SSIS package activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar package_location: Required. SSIS package location.
    :vartype package_location: ~azure.mgmt.datafactory.models.SSISPackageLocation
    :ivar runtime: Specifies the runtime to execute SSIS package. The value should be "x86" or
     "x64". Type: string (or Expression with resultType string).
    :vartype runtime: any
    :ivar logging_level: The logging level of SSIS package execution. Type: string (or Expression
     with resultType string).
    :vartype logging_level: any
    :ivar environment_path: The environment path to execute the SSIS package. Type: string (or
     Expression with resultType string).
    :vartype environment_path: any
    :ivar execution_credential: The package execution credential.
    :vartype execution_credential: ~azure.mgmt.datafactory.models.SSISExecutionCredential
    :ivar connect_via: Required. The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar project_parameters: The project level parameters to execute the SSIS package.
    :vartype project_parameters: dict[str, ~azure.mgmt.datafactory.models.SSISExecutionParameter]
    :ivar package_parameters: The package level parameters to execute the SSIS package.
    :vartype package_parameters: dict[str, ~azure.mgmt.datafactory.models.SSISExecutionParameter]
    :ivar project_connection_managers: The project level connection managers to execute the SSIS
     package.
    :vartype project_connection_managers: dict[str, dict[str,
     ~azure.mgmt.datafactory.models.SSISExecutionParameter]]
    :ivar package_connection_managers: The package level connection managers to execute the SSIS
     package.
    :vartype package_connection_managers: dict[str, dict[str,
     ~azure.mgmt.datafactory.models.SSISExecutionParameter]]
    :ivar property_overrides: The property overrides to execute the SSIS package.
    :vartype property_overrides: dict[str, ~azure.mgmt.datafactory.models.SSISPropertyOverride]
    :ivar log_location: SSIS package execution log location.
    :vartype log_location: ~azure.mgmt.datafactory.models.SSISLogLocation
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'package_location': {'required': True},
        'connect_via': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'package_location': {'key': 'typeProperties.packageLocation', 'type': 'SSISPackageLocation'},
        'runtime': {'key': 'typeProperties.runtime', 'type': 'object'},
        'logging_level': {'key': 'typeProperties.loggingLevel', 'type': 'object'},
        'environment_path': {'key': 'typeProperties.environmentPath', 'type': 'object'},
        'execution_credential': {'key': 'typeProperties.executionCredential', 'type': 'SSISExecutionCredential'},
        'connect_via': {'key': 'typeProperties.connectVia', 'type': 'IntegrationRuntimeReference'},
        'project_parameters': {'key': 'typeProperties.projectParameters', 'type': '{SSISExecutionParameter}'},
        'package_parameters': {'key': 'typeProperties.packageParameters', 'type': '{SSISExecutionParameter}'},
        'project_connection_managers': {'key': 'typeProperties.projectConnectionManagers', 'type': '{{SSISExecutionParameter}}'},
        'package_connection_managers': {'key': 'typeProperties.packageConnectionManagers', 'type': '{{SSISExecutionParameter}}'},
        'property_overrides': {'key': 'typeProperties.propertyOverrides', 'type': '{SSISPropertyOverride}'},
        'log_location': {'key': 'typeProperties.logLocation', 'type': 'SSISLogLocation'},
    }

    def __init__(
        self,
        *,
        name: str,
        package_location: "SSISPackageLocation",
        connect_via: "IntegrationRuntimeReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        runtime: Optional[Any] = None,
        logging_level: Optional[Any] = None,
        environment_path: Optional[Any] = None,
        execution_credential: Optional["SSISExecutionCredential"] = None,
        project_parameters: Optional[Dict[str, "SSISExecutionParameter"]] = None,
        package_parameters: Optional[Dict[str, "SSISExecutionParameter"]] = None,
        project_connection_managers: Optional[Dict[str, Dict[str, "SSISExecutionParameter"]]] = None,
        package_connection_managers: Optional[Dict[str, Dict[str, "SSISExecutionParameter"]]] = None,
        property_overrides: Optional[Dict[str, "SSISPropertyOverride"]] = None,
        log_location: Optional["SSISLogLocation"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword package_location: Required. SSIS package location.
        :paramtype package_location: ~azure.mgmt.datafactory.models.SSISPackageLocation
        :keyword runtime: Specifies the runtime to execute SSIS package. The value should be "x86" or
         "x64". Type: string (or Expression with resultType string).
        :paramtype runtime: any
        :keyword logging_level: The logging level of SSIS package execution. Type: string (or
         Expression with resultType string).
        :paramtype logging_level: any
        :keyword environment_path: The environment path to execute the SSIS package. Type: string (or
         Expression with resultType string).
        :paramtype environment_path: any
        :keyword execution_credential: The package execution credential.
        :paramtype execution_credential: ~azure.mgmt.datafactory.models.SSISExecutionCredential
        :keyword connect_via: Required. The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword project_parameters: The project level parameters to execute the SSIS package.
        :paramtype project_parameters: dict[str, ~azure.mgmt.datafactory.models.SSISExecutionParameter]
        :keyword package_parameters: The package level parameters to execute the SSIS package.
        :paramtype package_parameters: dict[str, ~azure.mgmt.datafactory.models.SSISExecutionParameter]
        :keyword project_connection_managers: The project level connection managers to execute the SSIS
         package.
        :paramtype project_connection_managers: dict[str, dict[str,
         ~azure.mgmt.datafactory.models.SSISExecutionParameter]]
        :keyword package_connection_managers: The package level connection managers to execute the SSIS
         package.
        :paramtype package_connection_managers: dict[str, dict[str,
         ~azure.mgmt.datafactory.models.SSISExecutionParameter]]
        :keyword property_overrides: The property overrides to execute the SSIS package.
        :paramtype property_overrides: dict[str, ~azure.mgmt.datafactory.models.SSISPropertyOverride]
        :keyword log_location: SSIS package execution log location.
        :paramtype log_location: ~azure.mgmt.datafactory.models.SSISLogLocation
        """
        super(ExecuteSSISPackageActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'ExecuteSSISPackage'  # type: str
        self.package_location = package_location
        self.runtime = runtime
        self.logging_level = logging_level
        self.environment_path = environment_path
        self.execution_credential = execution_credential
        self.connect_via = connect_via
        self.project_parameters = project_parameters
        self.package_parameters = package_parameters
        self.project_connection_managers = project_connection_managers
        self.package_connection_managers = package_connection_managers
        self.property_overrides = property_overrides
        self.log_location = log_location


class ExecuteWranglingDataflowActivity(Activity):
    """Execute power query activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar data_flow: Required. Data flow reference.
    :vartype data_flow: ~azure.mgmt.datafactory.models.DataFlowReference
    :ivar staging: Staging info for execute data flow activity.
    :vartype staging: ~azure.mgmt.datafactory.models.DataFlowStagingInfo
    :ivar integration_runtime: The integration runtime reference.
    :vartype integration_runtime: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar compute: Compute properties for data flow activity.
    :vartype compute: ~azure.mgmt.datafactory.models.ExecuteDataFlowActivityTypePropertiesCompute
    :ivar trace_level: Trace level setting used for data flow monitoring output. Supported values
     are: 'coarse', 'fine', and 'none'. Type: string (or Expression with resultType string).
    :vartype trace_level: any
    :ivar continue_on_error: Continue on error setting used for data flow execution. Enables
     processing to continue if a sink fails. Type: boolean (or Expression with resultType boolean).
    :vartype continue_on_error: any
    :ivar run_concurrently: Concurrent run setting used for data flow execution. Allows sinks with
     the same save order to be processed concurrently. Type: boolean (or Expression with resultType
     boolean).
    :vartype run_concurrently: any
    :ivar sinks: (Deprecated. Please use Queries). List of Power Query activity sinks mapped to a
     queryName.
    :vartype sinks: dict[str, ~azure.mgmt.datafactory.models.PowerQuerySink]
    :ivar queries: List of mapping for Power Query mashup query to sink dataset(s).
    :vartype queries: list[~azure.mgmt.datafactory.models.PowerQuerySinkMapping]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'data_flow': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'data_flow': {'key': 'typeProperties.dataFlow', 'type': 'DataFlowReference'},
        'staging': {'key': 'typeProperties.staging', 'type': 'DataFlowStagingInfo'},
        'integration_runtime': {'key': 'typeProperties.integrationRuntime', 'type': 'IntegrationRuntimeReference'},
        'compute': {'key': 'typeProperties.compute', 'type': 'ExecuteDataFlowActivityTypePropertiesCompute'},
        'trace_level': {'key': 'typeProperties.traceLevel', 'type': 'object'},
        'continue_on_error': {'key': 'typeProperties.continueOnError', 'type': 'object'},
        'run_concurrently': {'key': 'typeProperties.runConcurrently', 'type': 'object'},
        'sinks': {'key': 'typeProperties.sinks', 'type': '{PowerQuerySink}'},
        'queries': {'key': 'typeProperties.queries', 'type': '[PowerQuerySinkMapping]'},
    }

    def __init__(
        self,
        *,
        name: str,
        data_flow: "DataFlowReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        policy: Optional["ActivityPolicy"] = None,
        staging: Optional["DataFlowStagingInfo"] = None,
        integration_runtime: Optional["IntegrationRuntimeReference"] = None,
        compute: Optional["ExecuteDataFlowActivityTypePropertiesCompute"] = None,
        trace_level: Optional[Any] = None,
        continue_on_error: Optional[Any] = None,
        run_concurrently: Optional[Any] = None,
        sinks: Optional[Dict[str, "PowerQuerySink"]] = None,
        queries: Optional[List["PowerQuerySinkMapping"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword data_flow: Required. Data flow reference.
        :paramtype data_flow: ~azure.mgmt.datafactory.models.DataFlowReference
        :keyword staging: Staging info for execute data flow activity.
        :paramtype staging: ~azure.mgmt.datafactory.models.DataFlowStagingInfo
        :keyword integration_runtime: The integration runtime reference.
        :paramtype integration_runtime: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword compute: Compute properties for data flow activity.
        :paramtype compute: ~azure.mgmt.datafactory.models.ExecuteDataFlowActivityTypePropertiesCompute
        :keyword trace_level: Trace level setting used for data flow monitoring output. Supported
         values are: 'coarse', 'fine', and 'none'. Type: string (or Expression with resultType string).
        :paramtype trace_level: any
        :keyword continue_on_error: Continue on error setting used for data flow execution. Enables
         processing to continue if a sink fails. Type: boolean (or Expression with resultType boolean).
        :paramtype continue_on_error: any
        :keyword run_concurrently: Concurrent run setting used for data flow execution. Allows sinks
         with the same save order to be processed concurrently. Type: boolean (or Expression with
         resultType boolean).
        :paramtype run_concurrently: any
        :keyword sinks: (Deprecated. Please use Queries). List of Power Query activity sinks mapped to
         a queryName.
        :paramtype sinks: dict[str, ~azure.mgmt.datafactory.models.PowerQuerySink]
        :keyword queries: List of mapping for Power Query mashup query to sink dataset(s).
        :paramtype queries: list[~azure.mgmt.datafactory.models.PowerQuerySinkMapping]
        """
        super(ExecuteWranglingDataflowActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'ExecuteWranglingDataflow'  # type: str
        self.policy = policy
        self.data_flow = data_flow
        self.staging = staging
        self.integration_runtime = integration_runtime
        self.compute = compute
        self.trace_level = trace_level
        self.continue_on_error = continue_on_error
        self.run_concurrently = run_concurrently
        self.sinks = sinks
        self.queries = queries


class ExposureControlBatchRequest(msrest.serialization.Model):
    """A list of exposure control features.

    All required parameters must be populated in order to send to Azure.

    :ivar exposure_control_requests: Required. List of exposure control features.
    :vartype exposure_control_requests: list[~azure.mgmt.datafactory.models.ExposureControlRequest]
    """

    _validation = {
        'exposure_control_requests': {'required': True},
    }

    _attribute_map = {
        'exposure_control_requests': {'key': 'exposureControlRequests', 'type': '[ExposureControlRequest]'},
    }

    def __init__(
        self,
        *,
        exposure_control_requests: List["ExposureControlRequest"],
        **kwargs
    ):
        """
        :keyword exposure_control_requests: Required. List of exposure control features.
        :paramtype exposure_control_requests:
         list[~azure.mgmt.datafactory.models.ExposureControlRequest]
        """
        super(ExposureControlBatchRequest, self).__init__(**kwargs)
        self.exposure_control_requests = exposure_control_requests


class ExposureControlBatchResponse(msrest.serialization.Model):
    """A list of exposure control feature values.

    All required parameters must be populated in order to send to Azure.

    :ivar exposure_control_responses: Required. List of exposure control feature values.
    :vartype exposure_control_responses:
     list[~azure.mgmt.datafactory.models.ExposureControlResponse]
    """

    _validation = {
        'exposure_control_responses': {'required': True},
    }

    _attribute_map = {
        'exposure_control_responses': {'key': 'exposureControlResponses', 'type': '[ExposureControlResponse]'},
    }

    def __init__(
        self,
        *,
        exposure_control_responses: List["ExposureControlResponse"],
        **kwargs
    ):
        """
        :keyword exposure_control_responses: Required. List of exposure control feature values.
        :paramtype exposure_control_responses:
         list[~azure.mgmt.datafactory.models.ExposureControlResponse]
        """
        super(ExposureControlBatchResponse, self).__init__(**kwargs)
        self.exposure_control_responses = exposure_control_responses


class ExposureControlRequest(msrest.serialization.Model):
    """The exposure control request.

    :ivar feature_name: The feature name.
    :vartype feature_name: str
    :ivar feature_type: The feature type.
    :vartype feature_type: str
    """

    _attribute_map = {
        'feature_name': {'key': 'featureName', 'type': 'str'},
        'feature_type': {'key': 'featureType', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        feature_name: Optional[str] = None,
        feature_type: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword feature_name: The feature name.
        :paramtype feature_name: str
        :keyword feature_type: The feature type.
        :paramtype feature_type: str
        """
        super(ExposureControlRequest, self).__init__(**kwargs)
        self.feature_name = feature_name
        self.feature_type = feature_type


class ExposureControlResponse(msrest.serialization.Model):
    """The exposure control response.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar feature_name: The feature name.
    :vartype feature_name: str
    :ivar value: The feature value.
    :vartype value: str
    """

    _validation = {
        'feature_name': {'readonly': True},
        'value': {'readonly': True},
    }

    _attribute_map = {
        'feature_name': {'key': 'featureName', 'type': 'str'},
        'value': {'key': 'value', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(ExposureControlResponse, self).__init__(**kwargs)
        self.feature_name = None
        self.value = None


class Expression(msrest.serialization.Model):
    """Azure Data Factory expression definition.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Expression type. Has constant value: "Expression".
    :vartype type: str
    :ivar value: Required. Expression value.
    :vartype value: str
    """

    _validation = {
        'type': {'required': True, 'constant': True},
        'value': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'value': {'key': 'value', 'type': 'str'},
    }

    type = "Expression"

    def __init__(
        self,
        *,
        value: str,
        **kwargs
    ):
        """
        :keyword value: Required. Expression value.
        :paramtype value: str
        """
        super(Expression, self).__init__(**kwargs)
        self.value = value


class Resource(msrest.serialization.Model):
    """Azure Data Factory top-level resource.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar location: The resource location.
    :vartype location: str
    :ivar tags: A set of tags. The resource tags.
    :vartype tags: dict[str, str]
    :ivar e_tag: Etag identifies change in the resource.
    :vartype e_tag: str
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'e_tag': {'readonly': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'location': {'key': 'location', 'type': 'str'},
        'tags': {'key': 'tags', 'type': '{str}'},
        'e_tag': {'key': 'eTag', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        location: Optional[str] = None,
        tags: Optional[Dict[str, str]] = None,
        **kwargs
    ):
        """
        :keyword location: The resource location.
        :paramtype location: str
        :keyword tags: A set of tags. The resource tags.
        :paramtype tags: dict[str, str]
        """
        super(Resource, self).__init__(**kwargs)
        self.id = None
        self.name = None
        self.type = None
        self.location = location
        self.tags = tags
        self.e_tag = None


class Factory(Resource):
    """Factory resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar location: The resource location.
    :vartype location: str
    :ivar tags: A set of tags. The resource tags.
    :vartype tags: dict[str, str]
    :ivar e_tag: Etag identifies change in the resource.
    :vartype e_tag: str
    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar identity: Managed service identity of the factory.
    :vartype identity: ~azure.mgmt.datafactory.models.FactoryIdentity
    :ivar provisioning_state: Factory provisioning state, example Succeeded.
    :vartype provisioning_state: str
    :ivar create_time: Time the factory was created in ISO8601 format.
    :vartype create_time: ~datetime.datetime
    :ivar version: Version of the factory.
    :vartype version: str
    :ivar repo_configuration: Git repo information of the factory.
    :vartype repo_configuration: ~azure.mgmt.datafactory.models.FactoryRepoConfiguration
    :ivar global_parameters: List of parameters for factory.
    :vartype global_parameters: dict[str,
     ~azure.mgmt.datafactory.models.GlobalParameterSpecification]
    :ivar encryption: Properties to enable Customer Managed Key for the factory.
    :vartype encryption: ~azure.mgmt.datafactory.models.EncryptionConfiguration
    :ivar public_network_access: Whether or not public network access is allowed for the data
     factory. Possible values include: "Enabled", "Disabled".
    :vartype public_network_access: str or ~azure.mgmt.datafactory.models.PublicNetworkAccess
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'e_tag': {'readonly': True},
        'provisioning_state': {'readonly': True},
        'create_time': {'readonly': True},
        'version': {'readonly': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'location': {'key': 'location', 'type': 'str'},
        'tags': {'key': 'tags', 'type': '{str}'},
        'e_tag': {'key': 'eTag', 'type': 'str'},
        'additional_properties': {'key': '', 'type': '{object}'},
        'identity': {'key': 'identity', 'type': 'FactoryIdentity'},
        'provisioning_state': {'key': 'properties.provisioningState', 'type': 'str'},
        'create_time': {'key': 'properties.createTime', 'type': 'iso-8601'},
        'version': {'key': 'properties.version', 'type': 'str'},
        'repo_configuration': {'key': 'properties.repoConfiguration', 'type': 'FactoryRepoConfiguration'},
        'global_parameters': {'key': 'properties.globalParameters', 'type': '{GlobalParameterSpecification}'},
        'encryption': {'key': 'properties.encryption', 'type': 'EncryptionConfiguration'},
        'public_network_access': {'key': 'properties.publicNetworkAccess', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        location: Optional[str] = None,
        tags: Optional[Dict[str, str]] = None,
        additional_properties: Optional[Dict[str, Any]] = None,
        identity: Optional["FactoryIdentity"] = None,
        repo_configuration: Optional["FactoryRepoConfiguration"] = None,
        global_parameters: Optional[Dict[str, "GlobalParameterSpecification"]] = None,
        encryption: Optional["EncryptionConfiguration"] = None,
        public_network_access: Optional[Union[str, "PublicNetworkAccess"]] = None,
        **kwargs
    ):
        """
        :keyword location: The resource location.
        :paramtype location: str
        :keyword tags: A set of tags. The resource tags.
        :paramtype tags: dict[str, str]
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword identity: Managed service identity of the factory.
        :paramtype identity: ~azure.mgmt.datafactory.models.FactoryIdentity
        :keyword repo_configuration: Git repo information of the factory.
        :paramtype repo_configuration: ~azure.mgmt.datafactory.models.FactoryRepoConfiguration
        :keyword global_parameters: List of parameters for factory.
        :paramtype global_parameters: dict[str,
         ~azure.mgmt.datafactory.models.GlobalParameterSpecification]
        :keyword encryption: Properties to enable Customer Managed Key for the factory.
        :paramtype encryption: ~azure.mgmt.datafactory.models.EncryptionConfiguration
        :keyword public_network_access: Whether or not public network access is allowed for the data
         factory. Possible values include: "Enabled", "Disabled".
        :paramtype public_network_access: str or ~azure.mgmt.datafactory.models.PublicNetworkAccess
        """
        super(Factory, self).__init__(location=location, tags=tags, **kwargs)
        self.additional_properties = additional_properties
        self.identity = identity
        self.provisioning_state = None
        self.create_time = None
        self.version = None
        self.repo_configuration = repo_configuration
        self.global_parameters = global_parameters
        self.encryption = encryption
        self.public_network_access = public_network_access


class FactoryRepoConfiguration(msrest.serialization.Model):
    """Factory's git repo information.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: FactoryGitHubConfiguration, FactoryVSTSConfiguration.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of repo configuration.Constant filled by server.
    :vartype type: str
    :ivar account_name: Required. Account name.
    :vartype account_name: str
    :ivar repository_name: Required. Repository name.
    :vartype repository_name: str
    :ivar collaboration_branch: Required. Collaboration branch.
    :vartype collaboration_branch: str
    :ivar root_folder: Required. Root folder.
    :vartype root_folder: str
    :ivar last_commit_id: Last commit id.
    :vartype last_commit_id: str
    """

    _validation = {
        'type': {'required': True},
        'account_name': {'required': True},
        'repository_name': {'required': True},
        'collaboration_branch': {'required': True},
        'root_folder': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'account_name': {'key': 'accountName', 'type': 'str'},
        'repository_name': {'key': 'repositoryName', 'type': 'str'},
        'collaboration_branch': {'key': 'collaborationBranch', 'type': 'str'},
        'root_folder': {'key': 'rootFolder', 'type': 'str'},
        'last_commit_id': {'key': 'lastCommitId', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'FactoryGitHubConfiguration': 'FactoryGitHubConfiguration', 'FactoryVSTSConfiguration': 'FactoryVSTSConfiguration'}
    }

    def __init__(
        self,
        *,
        account_name: str,
        repository_name: str,
        collaboration_branch: str,
        root_folder: str,
        last_commit_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword account_name: Required. Account name.
        :paramtype account_name: str
        :keyword repository_name: Required. Repository name.
        :paramtype repository_name: str
        :keyword collaboration_branch: Required. Collaboration branch.
        :paramtype collaboration_branch: str
        :keyword root_folder: Required. Root folder.
        :paramtype root_folder: str
        :keyword last_commit_id: Last commit id.
        :paramtype last_commit_id: str
        """
        super(FactoryRepoConfiguration, self).__init__(**kwargs)
        self.type = None  # type: Optional[str]
        self.account_name = account_name
        self.repository_name = repository_name
        self.collaboration_branch = collaboration_branch
        self.root_folder = root_folder
        self.last_commit_id = last_commit_id


class FactoryGitHubConfiguration(FactoryRepoConfiguration):
    """Factory's GitHub repo information.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of repo configuration.Constant filled by server.
    :vartype type: str
    :ivar account_name: Required. Account name.
    :vartype account_name: str
    :ivar repository_name: Required. Repository name.
    :vartype repository_name: str
    :ivar collaboration_branch: Required. Collaboration branch.
    :vartype collaboration_branch: str
    :ivar root_folder: Required. Root folder.
    :vartype root_folder: str
    :ivar last_commit_id: Last commit id.
    :vartype last_commit_id: str
    :ivar host_name: GitHub Enterprise host name. For example: https://github.mydomain.com.
    :vartype host_name: str
    :ivar client_id: GitHub bring your own app client id.
    :vartype client_id: str
    :ivar client_secret: GitHub bring your own app client secret information.
    :vartype client_secret: ~azure.mgmt.datafactory.models.GitHubClientSecret
    """

    _validation = {
        'type': {'required': True},
        'account_name': {'required': True},
        'repository_name': {'required': True},
        'collaboration_branch': {'required': True},
        'root_folder': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'account_name': {'key': 'accountName', 'type': 'str'},
        'repository_name': {'key': 'repositoryName', 'type': 'str'},
        'collaboration_branch': {'key': 'collaborationBranch', 'type': 'str'},
        'root_folder': {'key': 'rootFolder', 'type': 'str'},
        'last_commit_id': {'key': 'lastCommitId', 'type': 'str'},
        'host_name': {'key': 'hostName', 'type': 'str'},
        'client_id': {'key': 'clientId', 'type': 'str'},
        'client_secret': {'key': 'clientSecret', 'type': 'GitHubClientSecret'},
    }

    def __init__(
        self,
        *,
        account_name: str,
        repository_name: str,
        collaboration_branch: str,
        root_folder: str,
        last_commit_id: Optional[str] = None,
        host_name: Optional[str] = None,
        client_id: Optional[str] = None,
        client_secret: Optional["GitHubClientSecret"] = None,
        **kwargs
    ):
        """
        :keyword account_name: Required. Account name.
        :paramtype account_name: str
        :keyword repository_name: Required. Repository name.
        :paramtype repository_name: str
        :keyword collaboration_branch: Required. Collaboration branch.
        :paramtype collaboration_branch: str
        :keyword root_folder: Required. Root folder.
        :paramtype root_folder: str
        :keyword last_commit_id: Last commit id.
        :paramtype last_commit_id: str
        :keyword host_name: GitHub Enterprise host name. For example: https://github.mydomain.com.
        :paramtype host_name: str
        :keyword client_id: GitHub bring your own app client id.
        :paramtype client_id: str
        :keyword client_secret: GitHub bring your own app client secret information.
        :paramtype client_secret: ~azure.mgmt.datafactory.models.GitHubClientSecret
        """
        super(FactoryGitHubConfiguration, self).__init__(account_name=account_name, repository_name=repository_name, collaboration_branch=collaboration_branch, root_folder=root_folder, last_commit_id=last_commit_id, **kwargs)
        self.type = 'FactoryGitHubConfiguration'  # type: str
        self.host_name = host_name
        self.client_id = client_id
        self.client_secret = client_secret


class FactoryIdentity(msrest.serialization.Model):
    """Identity properties of the factory resource.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. The identity type. Possible values include: "SystemAssigned",
     "UserAssigned", "SystemAssigned,UserAssigned".
    :vartype type: str or ~azure.mgmt.datafactory.models.FactoryIdentityType
    :ivar principal_id: The principal id of the identity.
    :vartype principal_id: str
    :ivar tenant_id: The client tenant id of the identity.
    :vartype tenant_id: str
    :ivar user_assigned_identities: List of user assigned identities for the factory.
    :vartype user_assigned_identities: dict[str, any]
    """

    _validation = {
        'type': {'required': True},
        'principal_id': {'readonly': True},
        'tenant_id': {'readonly': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'principal_id': {'key': 'principalId', 'type': 'str'},
        'tenant_id': {'key': 'tenantId', 'type': 'str'},
        'user_assigned_identities': {'key': 'userAssignedIdentities', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        type: Union[str, "FactoryIdentityType"],
        user_assigned_identities: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword type: Required. The identity type. Possible values include: "SystemAssigned",
         "UserAssigned", "SystemAssigned,UserAssigned".
        :paramtype type: str or ~azure.mgmt.datafactory.models.FactoryIdentityType
        :keyword user_assigned_identities: List of user assigned identities for the factory.
        :paramtype user_assigned_identities: dict[str, any]
        """
        super(FactoryIdentity, self).__init__(**kwargs)
        self.type = type
        self.principal_id = None
        self.tenant_id = None
        self.user_assigned_identities = user_assigned_identities


class FactoryListResponse(msrest.serialization.Model):
    """A list of factory resources.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of factories.
    :vartype value: list[~azure.mgmt.datafactory.models.Factory]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[Factory]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["Factory"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of factories.
        :paramtype value: list[~azure.mgmt.datafactory.models.Factory]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(FactoryListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class FactoryRepoUpdate(msrest.serialization.Model):
    """Factory's git repo information.

    :ivar factory_resource_id: The factory resource id.
    :vartype factory_resource_id: str
    :ivar repo_configuration: Git repo information of the factory.
    :vartype repo_configuration: ~azure.mgmt.datafactory.models.FactoryRepoConfiguration
    """

    _attribute_map = {
        'factory_resource_id': {'key': 'factoryResourceId', 'type': 'str'},
        'repo_configuration': {'key': 'repoConfiguration', 'type': 'FactoryRepoConfiguration'},
    }

    def __init__(
        self,
        *,
        factory_resource_id: Optional[str] = None,
        repo_configuration: Optional["FactoryRepoConfiguration"] = None,
        **kwargs
    ):
        """
        :keyword factory_resource_id: The factory resource id.
        :paramtype factory_resource_id: str
        :keyword repo_configuration: Git repo information of the factory.
        :paramtype repo_configuration: ~azure.mgmt.datafactory.models.FactoryRepoConfiguration
        """
        super(FactoryRepoUpdate, self).__init__(**kwargs)
        self.factory_resource_id = factory_resource_id
        self.repo_configuration = repo_configuration


class FactoryUpdateParameters(msrest.serialization.Model):
    """Parameters for updating a factory resource.

    :ivar tags: A set of tags. The resource tags.
    :vartype tags: dict[str, str]
    :ivar identity: Managed service identity of the factory.
    :vartype identity: ~azure.mgmt.datafactory.models.FactoryIdentity
    :ivar public_network_access: Whether or not public network access is allowed for the data
     factory. Possible values include: "Enabled", "Disabled".
    :vartype public_network_access: str or ~azure.mgmt.datafactory.models.PublicNetworkAccess
    """

    _attribute_map = {
        'tags': {'key': 'tags', 'type': '{str}'},
        'identity': {'key': 'identity', 'type': 'FactoryIdentity'},
        'public_network_access': {'key': 'properties.publicNetworkAccess', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        tags: Optional[Dict[str, str]] = None,
        identity: Optional["FactoryIdentity"] = None,
        public_network_access: Optional[Union[str, "PublicNetworkAccess"]] = None,
        **kwargs
    ):
        """
        :keyword tags: A set of tags. The resource tags.
        :paramtype tags: dict[str, str]
        :keyword identity: Managed service identity of the factory.
        :paramtype identity: ~azure.mgmt.datafactory.models.FactoryIdentity
        :keyword public_network_access: Whether or not public network access is allowed for the data
         factory. Possible values include: "Enabled", "Disabled".
        :paramtype public_network_access: str or ~azure.mgmt.datafactory.models.PublicNetworkAccess
        """
        super(FactoryUpdateParameters, self).__init__(**kwargs)
        self.tags = tags
        self.identity = identity
        self.public_network_access = public_network_access


class FactoryVSTSConfiguration(FactoryRepoConfiguration):
    """Factory's VSTS repo information.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of repo configuration.Constant filled by server.
    :vartype type: str
    :ivar account_name: Required. Account name.
    :vartype account_name: str
    :ivar repository_name: Required. Repository name.
    :vartype repository_name: str
    :ivar collaboration_branch: Required. Collaboration branch.
    :vartype collaboration_branch: str
    :ivar root_folder: Required. Root folder.
    :vartype root_folder: str
    :ivar last_commit_id: Last commit id.
    :vartype last_commit_id: str
    :ivar project_name: Required. VSTS project name.
    :vartype project_name: str
    :ivar tenant_id: VSTS tenant id.
    :vartype tenant_id: str
    """

    _validation = {
        'type': {'required': True},
        'account_name': {'required': True},
        'repository_name': {'required': True},
        'collaboration_branch': {'required': True},
        'root_folder': {'required': True},
        'project_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'account_name': {'key': 'accountName', 'type': 'str'},
        'repository_name': {'key': 'repositoryName', 'type': 'str'},
        'collaboration_branch': {'key': 'collaborationBranch', 'type': 'str'},
        'root_folder': {'key': 'rootFolder', 'type': 'str'},
        'last_commit_id': {'key': 'lastCommitId', 'type': 'str'},
        'project_name': {'key': 'projectName', 'type': 'str'},
        'tenant_id': {'key': 'tenantId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        account_name: str,
        repository_name: str,
        collaboration_branch: str,
        root_folder: str,
        project_name: str,
        last_commit_id: Optional[str] = None,
        tenant_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword account_name: Required. Account name.
        :paramtype account_name: str
        :keyword repository_name: Required. Repository name.
        :paramtype repository_name: str
        :keyword collaboration_branch: Required. Collaboration branch.
        :paramtype collaboration_branch: str
        :keyword root_folder: Required. Root folder.
        :paramtype root_folder: str
        :keyword last_commit_id: Last commit id.
        :paramtype last_commit_id: str
        :keyword project_name: Required. VSTS project name.
        :paramtype project_name: str
        :keyword tenant_id: VSTS tenant id.
        :paramtype tenant_id: str
        """
        super(FactoryVSTSConfiguration, self).__init__(account_name=account_name, repository_name=repository_name, collaboration_branch=collaboration_branch, root_folder=root_folder, last_commit_id=last_commit_id, **kwargs)
        self.type = 'FactoryVSTSConfiguration'  # type: str
        self.project_name = project_name
        self.tenant_id = tenant_id


class FailActivity(ControlActivity):
    """This activity will fail within its own scope and output a custom error message and error code. The error message and code can provided either as a string literal or as an expression that can be evaluated to a string at runtime. The activity scope can be the whole pipeline or a control activity (e.g. foreach, switch, until), if the fail activity is contained in it.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar message: Required. The error message that surfaced in the Fail activity. It can be
     dynamic content that's evaluated to a non empty/blank string at runtime. Type: string (or
     Expression with resultType string).
    :vartype message: any
    :ivar error_code: Required. The error code that categorizes the error type of the Fail
     activity. It can be dynamic content that's evaluated to a non empty/blank string at runtime.
     Type: string (or Expression with resultType string).
    :vartype error_code: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'message': {'required': True},
        'error_code': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'message': {'key': 'typeProperties.message', 'type': 'object'},
        'error_code': {'key': 'typeProperties.errorCode', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        message: Any,
        error_code: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword message: Required. The error message that surfaced in the Fail activity. It can be
         dynamic content that's evaluated to a non empty/blank string at runtime. Type: string (or
         Expression with resultType string).
        :paramtype message: any
        :keyword error_code: Required. The error code that categorizes the error type of the Fail
         activity. It can be dynamic content that's evaluated to a non empty/blank string at runtime.
         Type: string (or Expression with resultType string).
        :paramtype error_code: any
        """
        super(FailActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Fail'  # type: str
        self.message = message
        self.error_code = error_code


class FileServerLinkedService(LinkedService):
    """File system linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. Host name of the server. Type: string (or Expression with resultType
     string).
    :vartype host: any
    :ivar user_id: User ID to logon the server. Type: string (or Expression with resultType
     string).
    :vartype user_id: any
    :ivar password: Password to logon the server.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'user_id': {'key': 'typeProperties.userId', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        user_id: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. Host name of the server. Type: string (or Expression with resultType
         string).
        :paramtype host: any
        :keyword user_id: User ID to logon the server. Type: string (or Expression with resultType
         string).
        :paramtype user_id: any
        :keyword password: Password to logon the server.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(FileServerLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'FileServer'  # type: str
        self.host = host
        self.user_id = user_id
        self.password = password
        self.encrypted_credential = encrypted_credential


class FileServerLocation(DatasetLocation):
    """The location of file server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        """
        super(FileServerLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'FileServerLocation'  # type: str


class FileServerReadSettings(StoreReadSettings):
    """File server read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar wildcard_folder_path: FileServer wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :vartype wildcard_folder_path: any
    :ivar wildcard_file_name: FileServer wildcardFileName. Type: string (or Expression with
     resultType string).
    :vartype wildcard_file_name: any
    :ivar file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :vartype file_list_path: any
    :ivar enable_partition_discovery: Indicates whether to enable partition discovery.
    :vartype enable_partition_discovery: bool
    :ivar partition_root_path: Specify the root path where partition discovery starts from. Type:
     string (or Expression with resultType string).
    :vartype partition_root_path: any
    :ivar delete_files_after_completion: Indicates whether the source files need to be deleted
     after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
    :vartype delete_files_after_completion: any
    :ivar modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :vartype modified_datetime_end: any
    :ivar file_filter: Specify a filter to be used to select a subset of files in the folderPath
     rather than all files. Type: string (or Expression with resultType string).
    :vartype file_filter: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'object'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'object'},
        'file_list_path': {'key': 'fileListPath', 'type': 'object'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'partition_root_path': {'key': 'partitionRootPath', 'type': 'object'},
        'delete_files_after_completion': {'key': 'deleteFilesAfterCompletion', 'type': 'object'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'object'},
        'file_filter': {'key': 'fileFilter', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        wildcard_folder_path: Optional[Any] = None,
        wildcard_file_name: Optional[Any] = None,
        file_list_path: Optional[Any] = None,
        enable_partition_discovery: Optional[bool] = None,
        partition_root_path: Optional[Any] = None,
        delete_files_after_completion: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        file_filter: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword wildcard_folder_path: FileServer wildcardFolderPath. Type: string (or Expression with
         resultType string).
        :paramtype wildcard_folder_path: any
        :keyword wildcard_file_name: FileServer wildcardFileName. Type: string (or Expression with
         resultType string).
        :paramtype wildcard_file_name: any
        :keyword file_list_path: Point to a text file that lists each file (relative path to the path
         configured in the dataset) that you want to copy. Type: string (or Expression with resultType
         string).
        :paramtype file_list_path: any
        :keyword enable_partition_discovery: Indicates whether to enable partition discovery.
        :paramtype enable_partition_discovery: bool
        :keyword partition_root_path: Specify the root path where partition discovery starts from.
         Type: string (or Expression with resultType string).
        :paramtype partition_root_path: any
        :keyword delete_files_after_completion: Indicates whether the source files need to be deleted
         after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype delete_files_after_completion: any
        :keyword modified_datetime_start: The start of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        :keyword file_filter: Specify a filter to be used to select a subset of files in the folderPath
         rather than all files. Type: string (or Expression with resultType string).
        :paramtype file_filter: any
        """
        super(FileServerReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'FileServerReadSettings'  # type: str
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.partition_root_path = partition_root_path
        self.delete_files_after_completion = delete_files_after_completion
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end
        self.file_filter = file_filter


class FileServerWriteSettings(StoreWriteSettings):
    """File server write settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The write setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar copy_behavior: The type of copy behavior for copy sink.
    :vartype copy_behavior: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        copy_behavior: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword copy_behavior: The type of copy behavior for copy sink.
        :paramtype copy_behavior: any
        """
        super(FileServerWriteSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, copy_behavior=copy_behavior, **kwargs)
        self.type = 'FileServerWriteSettings'  # type: str


class FileShareDataset(Dataset):
    """An on-premises file system dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar folder_path: The path of the on-premises file system. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: The name of the on-premises file system. Type: string (or Expression with
     resultType string).
    :vartype file_name: any
    :ivar modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :vartype modified_datetime_end: any
    :ivar format: The format of the files.
    :vartype format: ~azure.mgmt.datafactory.models.DatasetStorageFormat
    :ivar file_filter: Specify a filter to be used to select a subset of files in the folderPath
     rather than all files. Type: string (or Expression with resultType string).
    :vartype file_filter: any
    :ivar compression: The data compression method used for the file system.
    :vartype compression: ~azure.mgmt.datafactory.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'folder_path': {'key': 'typeProperties.folderPath', 'type': 'object'},
        'file_name': {'key': 'typeProperties.fileName', 'type': 'object'},
        'modified_datetime_start': {'key': 'typeProperties.modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'typeProperties.modifiedDatetimeEnd', 'type': 'object'},
        'format': {'key': 'typeProperties.format', 'type': 'DatasetStorageFormat'},
        'file_filter': {'key': 'typeProperties.fileFilter', 'type': 'object'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        format: Optional["DatasetStorageFormat"] = None,
        file_filter: Optional[Any] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword folder_path: The path of the on-premises file system. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: The name of the on-premises file system. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        :keyword modified_datetime_start: The start of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        :keyword format: The format of the files.
        :paramtype format: ~azure.mgmt.datafactory.models.DatasetStorageFormat
        :keyword file_filter: Specify a filter to be used to select a subset of files in the folderPath
         rather than all files. Type: string (or Expression with resultType string).
        :paramtype file_filter: any
        :keyword compression: The data compression method used for the file system.
        :paramtype compression: ~azure.mgmt.datafactory.models.DatasetCompression
        """
        super(FileShareDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'FileShare'  # type: str
        self.folder_path = folder_path
        self.file_name = file_name
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end
        self.format = format
        self.file_filter = file_filter
        self.compression = compression


class FileSystemSink(CopySink):
    """A copy activity file system sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar copy_behavior: The type of copy behavior for copy sink.
    :vartype copy_behavior: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        copy_behavior: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword copy_behavior: The type of copy behavior for copy sink.
        :paramtype copy_behavior: any
        """
        super(FileSystemSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'FileSystemSink'  # type: str
        self.copy_behavior = copy_behavior


class FileSystemSource(CopySource):
    """A copy activity file system source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(FileSystemSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'FileSystemSource'  # type: str
        self.recursive = recursive
        self.additional_columns = additional_columns


class FilterActivity(ControlActivity):
    """Filter and return results from input array based on the conditions.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar items: Required. Input array on which filter should be applied.
    :vartype items: ~azure.mgmt.datafactory.models.Expression
    :ivar condition: Required. Condition to be used for filtering the input.
    :vartype condition: ~azure.mgmt.datafactory.models.Expression
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'items': {'required': True},
        'condition': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'items': {'key': 'typeProperties.items', 'type': 'Expression'},
        'condition': {'key': 'typeProperties.condition', 'type': 'Expression'},
    }

    def __init__(
        self,
        *,
        name: str,
        items: "Expression",
        condition: "Expression",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword items: Required. Input array on which filter should be applied.
        :paramtype items: ~azure.mgmt.datafactory.models.Expression
        :keyword condition: Required. Condition to be used for filtering the input.
        :paramtype condition: ~azure.mgmt.datafactory.models.Expression
        """
        super(FilterActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Filter'  # type: str
        self.items = items
        self.condition = condition


class Flowlet(DataFlow):
    """Data flow flowlet.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of data flow.Constant filled by server.
    :vartype type: str
    :ivar description: The description of the data flow.
    :vartype description: str
    :ivar annotations: List of tags that can be used for describing the data flow.
    :vartype annotations: list[any]
    :ivar folder: The folder that this data flow is in. If not specified, Data flow will appear at
     the root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DataFlowFolder
    :ivar sources: List of sources in Flowlet.
    :vartype sources: list[~azure.mgmt.datafactory.models.DataFlowSource]
    :ivar sinks: List of sinks in Flowlet.
    :vartype sinks: list[~azure.mgmt.datafactory.models.DataFlowSink]
    :ivar transformations: List of transformations in Flowlet.
    :vartype transformations: list[~azure.mgmt.datafactory.models.Transformation]
    :ivar script: Flowlet script.
    :vartype script: str
    :ivar script_lines: Flowlet script lines.
    :vartype script_lines: list[str]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DataFlowFolder'},
        'sources': {'key': 'typeProperties.sources', 'type': '[DataFlowSource]'},
        'sinks': {'key': 'typeProperties.sinks', 'type': '[DataFlowSink]'},
        'transformations': {'key': 'typeProperties.transformations', 'type': '[Transformation]'},
        'script': {'key': 'typeProperties.script', 'type': 'str'},
        'script_lines': {'key': 'typeProperties.scriptLines', 'type': '[str]'},
    }

    def __init__(
        self,
        *,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DataFlowFolder"] = None,
        sources: Optional[List["DataFlowSource"]] = None,
        sinks: Optional[List["DataFlowSink"]] = None,
        transformations: Optional[List["Transformation"]] = None,
        script: Optional[str] = None,
        script_lines: Optional[List[str]] = None,
        **kwargs
    ):
        """
        :keyword description: The description of the data flow.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the data flow.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this data flow is in. If not specified, Data flow will appear
         at the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DataFlowFolder
        :keyword sources: List of sources in Flowlet.
        :paramtype sources: list[~azure.mgmt.datafactory.models.DataFlowSource]
        :keyword sinks: List of sinks in Flowlet.
        :paramtype sinks: list[~azure.mgmt.datafactory.models.DataFlowSink]
        :keyword transformations: List of transformations in Flowlet.
        :paramtype transformations: list[~azure.mgmt.datafactory.models.Transformation]
        :keyword script: Flowlet script.
        :paramtype script: str
        :keyword script_lines: Flowlet script lines.
        :paramtype script_lines: list[str]
        """
        super(Flowlet, self).__init__(description=description, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Flowlet'  # type: str
        self.sources = sources
        self.sinks = sinks
        self.transformations = transformations
        self.script = script
        self.script_lines = script_lines


class ForEachActivity(ControlActivity):
    """This activity is used for iterating over a collection and execute given activities.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar is_sequential: Should the loop be executed in sequence or in parallel (max 50).
    :vartype is_sequential: bool
    :ivar batch_count: Batch count to be used for controlling the number of parallel execution
     (when isSequential is set to false).
    :vartype batch_count: int
    :ivar items: Required. Collection to iterate.
    :vartype items: ~azure.mgmt.datafactory.models.Expression
    :ivar activities: Required. List of activities to execute .
    :vartype activities: list[~azure.mgmt.datafactory.models.Activity]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'batch_count': {'maximum': 50},
        'items': {'required': True},
        'activities': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'is_sequential': {'key': 'typeProperties.isSequential', 'type': 'bool'},
        'batch_count': {'key': 'typeProperties.batchCount', 'type': 'int'},
        'items': {'key': 'typeProperties.items', 'type': 'Expression'},
        'activities': {'key': 'typeProperties.activities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        name: str,
        items: "Expression",
        activities: List["Activity"],
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        is_sequential: Optional[bool] = None,
        batch_count: Optional[int] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword is_sequential: Should the loop be executed in sequence or in parallel (max 50).
        :paramtype is_sequential: bool
        :keyword batch_count: Batch count to be used for controlling the number of parallel execution
         (when isSequential is set to false).
        :paramtype batch_count: int
        :keyword items: Required. Collection to iterate.
        :paramtype items: ~azure.mgmt.datafactory.models.Expression
        :keyword activities: Required. List of activities to execute .
        :paramtype activities: list[~azure.mgmt.datafactory.models.Activity]
        """
        super(ForEachActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'ForEach'  # type: str
        self.is_sequential = is_sequential
        self.batch_count = batch_count
        self.items = items
        self.activities = activities


class FtpReadSettings(StoreReadSettings):
    """Ftp read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar wildcard_folder_path: Ftp wildcardFolderPath. Type: string (or Expression with resultType
     string).
    :vartype wildcard_folder_path: any
    :ivar wildcard_file_name: Ftp wildcardFileName. Type: string (or Expression with resultType
     string).
    :vartype wildcard_file_name: any
    :ivar enable_partition_discovery: Indicates whether to enable partition discovery.
    :vartype enable_partition_discovery: bool
    :ivar partition_root_path: Specify the root path where partition discovery starts from. Type:
     string (or Expression with resultType string).
    :vartype partition_root_path: any
    :ivar delete_files_after_completion: Indicates whether the source files need to be deleted
     after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
    :vartype delete_files_after_completion: any
    :ivar file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :vartype file_list_path: any
    :ivar use_binary_transfer: Specify whether to use binary transfer mode for FTP stores.
    :vartype use_binary_transfer: bool
    :ivar disable_chunking: If true, disable parallel reading within each file. Default is false.
     Type: boolean (or Expression with resultType boolean).
    :vartype disable_chunking: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'object'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'object'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'partition_root_path': {'key': 'partitionRootPath', 'type': 'object'},
        'delete_files_after_completion': {'key': 'deleteFilesAfterCompletion', 'type': 'object'},
        'file_list_path': {'key': 'fileListPath', 'type': 'object'},
        'use_binary_transfer': {'key': 'useBinaryTransfer', 'type': 'bool'},
        'disable_chunking': {'key': 'disableChunking', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        wildcard_folder_path: Optional[Any] = None,
        wildcard_file_name: Optional[Any] = None,
        enable_partition_discovery: Optional[bool] = None,
        partition_root_path: Optional[Any] = None,
        delete_files_after_completion: Optional[Any] = None,
        file_list_path: Optional[Any] = None,
        use_binary_transfer: Optional[bool] = None,
        disable_chunking: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword wildcard_folder_path: Ftp wildcardFolderPath. Type: string (or Expression with
         resultType string).
        :paramtype wildcard_folder_path: any
        :keyword wildcard_file_name: Ftp wildcardFileName. Type: string (or Expression with resultType
         string).
        :paramtype wildcard_file_name: any
        :keyword enable_partition_discovery: Indicates whether to enable partition discovery.
        :paramtype enable_partition_discovery: bool
        :keyword partition_root_path: Specify the root path where partition discovery starts from.
         Type: string (or Expression with resultType string).
        :paramtype partition_root_path: any
        :keyword delete_files_after_completion: Indicates whether the source files need to be deleted
         after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype delete_files_after_completion: any
        :keyword file_list_path: Point to a text file that lists each file (relative path to the path
         configured in the dataset) that you want to copy. Type: string (or Expression with resultType
         string).
        :paramtype file_list_path: any
        :keyword use_binary_transfer: Specify whether to use binary transfer mode for FTP stores.
        :paramtype use_binary_transfer: bool
        :keyword disable_chunking: If true, disable parallel reading within each file. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_chunking: any
        """
        super(FtpReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'FtpReadSettings'  # type: str
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.enable_partition_discovery = enable_partition_discovery
        self.partition_root_path = partition_root_path
        self.delete_files_after_completion = delete_files_after_completion
        self.file_list_path = file_list_path
        self.use_binary_transfer = use_binary_transfer
        self.disable_chunking = disable_chunking


class FtpServerLinkedService(LinkedService):
    """A FTP server Linked Service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. Host name of the FTP server. Type: string (or Expression with resultType
     string).
    :vartype host: any
    :ivar port: The TCP port number that the FTP server uses to listen for client connections.
     Default value is 21. Type: integer (or Expression with resultType integer), minimum: 0.
    :vartype port: any
    :ivar authentication_type: The authentication type to be used to connect to the FTP server.
     Possible values include: "Basic", "Anonymous".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.FtpAuthenticationType
    :ivar user_name: Username to logon the FTP server. Type: string (or Expression with resultType
     string).
    :vartype user_name: any
    :ivar password: Password to logon the FTP server.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar enable_ssl: If true, connect to the FTP server over SSL/TLS channel. Default value is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype enable_ssl: any
    :ivar enable_server_certificate_validation: If true, validate the FTP server SSL certificate
     when connect over SSL/TLS channel. Default value is true. Type: boolean (or Expression with
     resultType boolean).
    :vartype enable_server_certificate_validation: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'object'},
        'enable_server_certificate_validation': {'key': 'typeProperties.enableServerCertificateValidation', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        port: Optional[Any] = None,
        authentication_type: Optional[Union[str, "FtpAuthenticationType"]] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        enable_ssl: Optional[Any] = None,
        enable_server_certificate_validation: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. Host name of the FTP server. Type: string (or Expression with
         resultType string).
        :paramtype host: any
        :keyword port: The TCP port number that the FTP server uses to listen for client connections.
         Default value is 21. Type: integer (or Expression with resultType integer), minimum: 0.
        :paramtype port: any
        :keyword authentication_type: The authentication type to be used to connect to the FTP server.
         Possible values include: "Basic", "Anonymous".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.FtpAuthenticationType
        :keyword user_name: Username to logon the FTP server. Type: string (or Expression with
         resultType string).
        :paramtype user_name: any
        :keyword password: Password to logon the FTP server.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword enable_ssl: If true, connect to the FTP server over SSL/TLS channel. Default value is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype enable_ssl: any
        :keyword enable_server_certificate_validation: If true, validate the FTP server SSL certificate
         when connect over SSL/TLS channel. Default value is true. Type: boolean (or Expression with
         resultType boolean).
        :paramtype enable_server_certificate_validation: any
        """
        super(FtpServerLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'FtpServer'  # type: str
        self.host = host
        self.port = port
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential
        self.enable_ssl = enable_ssl
        self.enable_server_certificate_validation = enable_server_certificate_validation


class FtpServerLocation(DatasetLocation):
    """The location of ftp server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        """
        super(FtpServerLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'FtpServerLocation'  # type: str


class GetDataFactoryOperationStatusResponse(msrest.serialization.Model):
    """Response body structure for get data factory operation status.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar status: Status of the operation.
    :vartype status: str
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'status': {'key': 'status', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        status: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword status: Status of the operation.
        :paramtype status: str
        """
        super(GetDataFactoryOperationStatusResponse, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.status = status


class GetMetadataActivity(ExecutionActivity):
    """Activity to get metadata of dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar dataset: Required. GetMetadata activity dataset reference.
    :vartype dataset: ~azure.mgmt.datafactory.models.DatasetReference
    :ivar field_list: Fields of metadata to get from dataset.
    :vartype field_list: list[any]
    :ivar store_settings: GetMetadata activity store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
    :ivar format_settings: GetMetadata activity format settings.
    :vartype format_settings: ~azure.mgmt.datafactory.models.FormatReadSettings
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'dataset': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'dataset': {'key': 'typeProperties.dataset', 'type': 'DatasetReference'},
        'field_list': {'key': 'typeProperties.fieldList', 'type': '[object]'},
        'store_settings': {'key': 'typeProperties.storeSettings', 'type': 'StoreReadSettings'},
        'format_settings': {'key': 'typeProperties.formatSettings', 'type': 'FormatReadSettings'},
    }

    def __init__(
        self,
        *,
        name: str,
        dataset: "DatasetReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        field_list: Optional[List[Any]] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        format_settings: Optional["FormatReadSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword dataset: Required. GetMetadata activity dataset reference.
        :paramtype dataset: ~azure.mgmt.datafactory.models.DatasetReference
        :keyword field_list: Fields of metadata to get from dataset.
        :paramtype field_list: list[any]
        :keyword store_settings: GetMetadata activity store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
        :keyword format_settings: GetMetadata activity format settings.
        :paramtype format_settings: ~azure.mgmt.datafactory.models.FormatReadSettings
        """
        super(GetMetadataActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'GetMetadata'  # type: str
        self.dataset = dataset
        self.field_list = field_list
        self.store_settings = store_settings
        self.format_settings = format_settings


class GetSsisObjectMetadataRequest(msrest.serialization.Model):
    """The request payload of get SSIS object metadata.

    :ivar metadata_path: Metadata path.
    :vartype metadata_path: str
    """

    _attribute_map = {
        'metadata_path': {'key': 'metadataPath', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        metadata_path: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword metadata_path: Metadata path.
        :paramtype metadata_path: str
        """
        super(GetSsisObjectMetadataRequest, self).__init__(**kwargs)
        self.metadata_path = metadata_path


class GitHubAccessTokenRequest(msrest.serialization.Model):
    """Get GitHub access token request definition.

    All required parameters must be populated in order to send to Azure.

    :ivar git_hub_access_code: Required. GitHub access code.
    :vartype git_hub_access_code: str
    :ivar git_hub_client_id: GitHub application client ID.
    :vartype git_hub_client_id: str
    :ivar git_hub_client_secret: GitHub bring your own app client secret information.
    :vartype git_hub_client_secret: ~azure.mgmt.datafactory.models.GitHubClientSecret
    :ivar git_hub_access_token_base_url: Required. GitHub access token base URL.
    :vartype git_hub_access_token_base_url: str
    """

    _validation = {
        'git_hub_access_code': {'required': True},
        'git_hub_access_token_base_url': {'required': True},
    }

    _attribute_map = {
        'git_hub_access_code': {'key': 'gitHubAccessCode', 'type': 'str'},
        'git_hub_client_id': {'key': 'gitHubClientId', 'type': 'str'},
        'git_hub_client_secret': {'key': 'gitHubClientSecret', 'type': 'GitHubClientSecret'},
        'git_hub_access_token_base_url': {'key': 'gitHubAccessTokenBaseUrl', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        git_hub_access_code: str,
        git_hub_access_token_base_url: str,
        git_hub_client_id: Optional[str] = None,
        git_hub_client_secret: Optional["GitHubClientSecret"] = None,
        **kwargs
    ):
        """
        :keyword git_hub_access_code: Required. GitHub access code.
        :paramtype git_hub_access_code: str
        :keyword git_hub_client_id: GitHub application client ID.
        :paramtype git_hub_client_id: str
        :keyword git_hub_client_secret: GitHub bring your own app client secret information.
        :paramtype git_hub_client_secret: ~azure.mgmt.datafactory.models.GitHubClientSecret
        :keyword git_hub_access_token_base_url: Required. GitHub access token base URL.
        :paramtype git_hub_access_token_base_url: str
        """
        super(GitHubAccessTokenRequest, self).__init__(**kwargs)
        self.git_hub_access_code = git_hub_access_code
        self.git_hub_client_id = git_hub_client_id
        self.git_hub_client_secret = git_hub_client_secret
        self.git_hub_access_token_base_url = git_hub_access_token_base_url


class GitHubAccessTokenResponse(msrest.serialization.Model):
    """Get GitHub access token response definition.

    :ivar git_hub_access_token: GitHub access token.
    :vartype git_hub_access_token: str
    """

    _attribute_map = {
        'git_hub_access_token': {'key': 'gitHubAccessToken', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        git_hub_access_token: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword git_hub_access_token: GitHub access token.
        :paramtype git_hub_access_token: str
        """
        super(GitHubAccessTokenResponse, self).__init__(**kwargs)
        self.git_hub_access_token = git_hub_access_token


class GitHubClientSecret(msrest.serialization.Model):
    """Client secret information for factory's bring your own app repository configuration.

    :ivar byoa_secret_akv_url: Bring your own app client secret AKV URL.
    :vartype byoa_secret_akv_url: str
    :ivar byoa_secret_name: Bring your own app client secret name in AKV.
    :vartype byoa_secret_name: str
    """

    _attribute_map = {
        'byoa_secret_akv_url': {'key': 'byoaSecretAkvUrl', 'type': 'str'},
        'byoa_secret_name': {'key': 'byoaSecretName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        byoa_secret_akv_url: Optional[str] = None,
        byoa_secret_name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword byoa_secret_akv_url: Bring your own app client secret AKV URL.
        :paramtype byoa_secret_akv_url: str
        :keyword byoa_secret_name: Bring your own app client secret name in AKV.
        :paramtype byoa_secret_name: str
        """
        super(GitHubClientSecret, self).__init__(**kwargs)
        self.byoa_secret_akv_url = byoa_secret_akv_url
        self.byoa_secret_name = byoa_secret_name


class GlobalParameterSpecification(msrest.serialization.Model):
    """Definition of a single parameter for an entity.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Global Parameter type. Possible values include: "Object", "String",
     "Int", "Float", "Bool", "Array".
    :vartype type: str or ~azure.mgmt.datafactory.models.GlobalParameterType
    :ivar value: Required. Value of parameter.
    :vartype value: any
    """

    _validation = {
        'type': {'required': True},
        'value': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'value': {'key': 'value', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        type: Union[str, "GlobalParameterType"],
        value: Any,
        **kwargs
    ):
        """
        :keyword type: Required. Global Parameter type. Possible values include: "Object", "String",
         "Int", "Float", "Bool", "Array".
        :paramtype type: str or ~azure.mgmt.datafactory.models.GlobalParameterType
        :keyword value: Required. Value of parameter.
        :paramtype value: any
        """
        super(GlobalParameterSpecification, self).__init__(**kwargs)
        self.type = type
        self.value = value


class GoogleAdWordsLinkedService(LinkedService):
    """Google AdWords service linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_properties: Properties used to connect to GoogleAds. It is mutually exclusive
     with any other properties in the linked service. Type: object.
    :vartype connection_properties: any
    :ivar client_customer_id: The Client customer ID of the AdWords account that you want to fetch
     report data for.
    :vartype client_customer_id: any
    :ivar developer_token: The developer token associated with the manager account that you use to
     grant access to the AdWords API.
    :vartype developer_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar authentication_type: The OAuth 2.0 authentication mechanism used for authentication.
     ServiceAuthentication can only be used on self-hosted IR. Possible values include:
     "ServiceAuthentication", "UserAuthentication".
    :vartype authentication_type: str or
     ~azure.mgmt.datafactory.models.GoogleAdWordsAuthenticationType
    :ivar refresh_token: The refresh token obtained from Google for authorizing access to AdWords
     for UserAuthentication.
    :vartype refresh_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar client_id: The client id of the google application used to acquire the refresh token.
     Type: string (or Expression with resultType string).
    :vartype client_id: any
    :ivar client_secret: The client secret of the google application used to acquire the refresh
     token.
    :vartype client_secret: ~azure.mgmt.datafactory.models.SecretBase
    :ivar email: The service account email ID that is used for ServiceAuthentication and can only
     be used on self-hosted IR.
    :vartype email: any
    :ivar key_file_path: The full path to the .p12 key file that is used to authenticate the
     service account email address and can only be used on self-hosted IR.
    :vartype key_file_path: any
    :ivar trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :vartype trusted_cert_path: any
    :ivar use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :vartype use_system_trust_store: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_properties': {'key': 'typeProperties.connectionProperties', 'type': 'object'},
        'client_customer_id': {'key': 'typeProperties.clientCustomerID', 'type': 'object'},
        'developer_token': {'key': 'typeProperties.developerToken', 'type': 'SecretBase'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'refresh_token': {'key': 'typeProperties.refreshToken', 'type': 'SecretBase'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'object'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'email': {'key': 'typeProperties.email', 'type': 'object'},
        'key_file_path': {'key': 'typeProperties.keyFilePath', 'type': 'object'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'object'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_properties: Optional[Any] = None,
        client_customer_id: Optional[Any] = None,
        developer_token: Optional["SecretBase"] = None,
        authentication_type: Optional[Union[str, "GoogleAdWordsAuthenticationType"]] = None,
        refresh_token: Optional["SecretBase"] = None,
        client_id: Optional[Any] = None,
        client_secret: Optional["SecretBase"] = None,
        email: Optional[Any] = None,
        key_file_path: Optional[Any] = None,
        trusted_cert_path: Optional[Any] = None,
        use_system_trust_store: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_properties: Properties used to connect to GoogleAds. It is mutually
         exclusive with any other properties in the linked service. Type: object.
        :paramtype connection_properties: any
        :keyword client_customer_id: The Client customer ID of the AdWords account that you want to
         fetch report data for.
        :paramtype client_customer_id: any
        :keyword developer_token: The developer token associated with the manager account that you use
         to grant access to the AdWords API.
        :paramtype developer_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword authentication_type: The OAuth 2.0 authentication mechanism used for authentication.
         ServiceAuthentication can only be used on self-hosted IR. Possible values include:
         "ServiceAuthentication", "UserAuthentication".
        :paramtype authentication_type: str or
         ~azure.mgmt.datafactory.models.GoogleAdWordsAuthenticationType
        :keyword refresh_token: The refresh token obtained from Google for authorizing access to
         AdWords for UserAuthentication.
        :paramtype refresh_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword client_id: The client id of the google application used to acquire the refresh token.
         Type: string (or Expression with resultType string).
        :paramtype client_id: any
        :keyword client_secret: The client secret of the google application used to acquire the refresh
         token.
        :paramtype client_secret: ~azure.mgmt.datafactory.models.SecretBase
        :keyword email: The service account email ID that is used for ServiceAuthentication and can
         only be used on self-hosted IR.
        :paramtype email: any
        :keyword key_file_path: The full path to the .p12 key file that is used to authenticate the
         service account email address and can only be used on self-hosted IR.
        :paramtype key_file_path: any
        :keyword trusted_cert_path: The full path of the .pem file containing trusted CA certificates
         for verifying the server when connecting over SSL. This property can only be set when using SSL
         on self-hosted IR. The default value is the cacerts.pem file installed with the IR.
        :paramtype trusted_cert_path: any
        :keyword use_system_trust_store: Specifies whether to use a CA certificate from the system
         trust store or from a specified PEM file. The default value is false.
        :paramtype use_system_trust_store: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(GoogleAdWordsLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'GoogleAdWords'  # type: str
        self.connection_properties = connection_properties
        self.client_customer_id = client_customer_id
        self.developer_token = developer_token
        self.authentication_type = authentication_type
        self.refresh_token = refresh_token
        self.client_id = client_id
        self.client_secret = client_secret
        self.email = email
        self.key_file_path = key_file_path
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.encrypted_credential = encrypted_credential


class GoogleAdWordsObjectDataset(Dataset):
    """Google AdWords service dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(GoogleAdWordsObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'GoogleAdWordsObject'  # type: str
        self.table_name = table_name


class GoogleAdWordsSource(TabularSource):
    """A copy activity Google AdWords service source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(GoogleAdWordsSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'GoogleAdWordsSource'  # type: str
        self.query = query


class GoogleBigQueryLinkedService(LinkedService):
    """Google BigQuery service linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar project: Required. The default BigQuery project to query against.
    :vartype project: any
    :ivar additional_projects: A comma-separated list of public BigQuery projects to access.
    :vartype additional_projects: any
    :ivar request_google_drive_scope: Whether to request access to Google Drive. Allowing Google
     Drive access enables support for federated tables that combine BigQuery data with data from
     Google Drive. The default value is false.
    :vartype request_google_drive_scope: any
    :ivar authentication_type: Required. The OAuth 2.0 authentication mechanism used for
     authentication. ServiceAuthentication can only be used on self-hosted IR. Possible values
     include: "ServiceAuthentication", "UserAuthentication".
    :vartype authentication_type: str or
     ~azure.mgmt.datafactory.models.GoogleBigQueryAuthenticationType
    :ivar refresh_token: The refresh token obtained from Google for authorizing access to BigQuery
     for UserAuthentication.
    :vartype refresh_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar client_id: The client id of the google application used to acquire the refresh token.
     Type: string (or Expression with resultType string).
    :vartype client_id: any
    :ivar client_secret: The client secret of the google application used to acquire the refresh
     token.
    :vartype client_secret: ~azure.mgmt.datafactory.models.SecretBase
    :ivar email: The service account email ID that is used for ServiceAuthentication and can only
     be used on self-hosted IR.
    :vartype email: any
    :ivar key_file_path: The full path to the .p12 key file that is used to authenticate the
     service account email address and can only be used on self-hosted IR.
    :vartype key_file_path: any
    :ivar trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :vartype trusted_cert_path: any
    :ivar use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :vartype use_system_trust_store: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'project': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'project': {'key': 'typeProperties.project', 'type': 'object'},
        'additional_projects': {'key': 'typeProperties.additionalProjects', 'type': 'object'},
        'request_google_drive_scope': {'key': 'typeProperties.requestGoogleDriveScope', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'refresh_token': {'key': 'typeProperties.refreshToken', 'type': 'SecretBase'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'object'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'email': {'key': 'typeProperties.email', 'type': 'object'},
        'key_file_path': {'key': 'typeProperties.keyFilePath', 'type': 'object'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'object'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        project: Any,
        authentication_type: Union[str, "GoogleBigQueryAuthenticationType"],
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        additional_projects: Optional[Any] = None,
        request_google_drive_scope: Optional[Any] = None,
        refresh_token: Optional["SecretBase"] = None,
        client_id: Optional[Any] = None,
        client_secret: Optional["SecretBase"] = None,
        email: Optional[Any] = None,
        key_file_path: Optional[Any] = None,
        trusted_cert_path: Optional[Any] = None,
        use_system_trust_store: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword project: Required. The default BigQuery project to query against.
        :paramtype project: any
        :keyword additional_projects: A comma-separated list of public BigQuery projects to access.
        :paramtype additional_projects: any
        :keyword request_google_drive_scope: Whether to request access to Google Drive. Allowing Google
         Drive access enables support for federated tables that combine BigQuery data with data from
         Google Drive. The default value is false.
        :paramtype request_google_drive_scope: any
        :keyword authentication_type: Required. The OAuth 2.0 authentication mechanism used for
         authentication. ServiceAuthentication can only be used on self-hosted IR. Possible values
         include: "ServiceAuthentication", "UserAuthentication".
        :paramtype authentication_type: str or
         ~azure.mgmt.datafactory.models.GoogleBigQueryAuthenticationType
        :keyword refresh_token: The refresh token obtained from Google for authorizing access to
         BigQuery for UserAuthentication.
        :paramtype refresh_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword client_id: The client id of the google application used to acquire the refresh token.
         Type: string (or Expression with resultType string).
        :paramtype client_id: any
        :keyword client_secret: The client secret of the google application used to acquire the refresh
         token.
        :paramtype client_secret: ~azure.mgmt.datafactory.models.SecretBase
        :keyword email: The service account email ID that is used for ServiceAuthentication and can
         only be used on self-hosted IR.
        :paramtype email: any
        :keyword key_file_path: The full path to the .p12 key file that is used to authenticate the
         service account email address and can only be used on self-hosted IR.
        :paramtype key_file_path: any
        :keyword trusted_cert_path: The full path of the .pem file containing trusted CA certificates
         for verifying the server when connecting over SSL. This property can only be set when using SSL
         on self-hosted IR. The default value is the cacerts.pem file installed with the IR.
        :paramtype trusted_cert_path: any
        :keyword use_system_trust_store: Specifies whether to use a CA certificate from the system
         trust store or from a specified PEM file. The default value is false.
        :paramtype use_system_trust_store: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(GoogleBigQueryLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'GoogleBigQuery'  # type: str
        self.project = project
        self.additional_projects = additional_projects
        self.request_google_drive_scope = request_google_drive_scope
        self.authentication_type = authentication_type
        self.refresh_token = refresh_token
        self.client_id = client_id
        self.client_secret = client_secret
        self.email = email
        self.key_file_path = key_file_path
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.encrypted_credential = encrypted_credential


class GoogleBigQueryObjectDataset(Dataset):
    """Google BigQuery service dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using database + table
     properties instead.
    :vartype table_name: any
    :ivar table: The table name of the Google BigQuery. Type: string (or Expression with resultType
     string).
    :vartype table: any
    :ivar dataset: The database name of the Google BigQuery. Type: string (or Expression with
     resultType string).
    :vartype dataset: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'dataset': {'key': 'typeProperties.dataset', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        dataset: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using database + table
         properties instead.
        :paramtype table_name: any
        :keyword table: The table name of the Google BigQuery. Type: string (or Expression with
         resultType string).
        :paramtype table: any
        :keyword dataset: The database name of the Google BigQuery. Type: string (or Expression with
         resultType string).
        :paramtype dataset: any
        """
        super(GoogleBigQueryObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'GoogleBigQueryObject'  # type: str
        self.table_name = table_name
        self.table = table
        self.dataset = dataset


class GoogleBigQuerySource(TabularSource):
    """A copy activity Google BigQuery service source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(GoogleBigQuerySource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'GoogleBigQuerySource'  # type: str
        self.query = query


class GoogleCloudStorageLinkedService(LinkedService):
    """Linked service for Google Cloud Storage.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar access_key_id: The access key identifier of the Google Cloud Storage Identity and Access
     Management (IAM) user. Type: string (or Expression with resultType string).
    :vartype access_key_id: any
    :ivar secret_access_key: The secret access key of the Google Cloud Storage Identity and Access
     Management (IAM) user.
    :vartype secret_access_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar service_url: This value specifies the endpoint to access with the Google Cloud Storage
     Connector. This is an optional property; change it only if you want to try a different service
     endpoint or want to switch between https and http. Type: string (or Expression with resultType
     string).
    :vartype service_url: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'access_key_id': {'key': 'typeProperties.accessKeyId', 'type': 'object'},
        'secret_access_key': {'key': 'typeProperties.secretAccessKey', 'type': 'SecretBase'},
        'service_url': {'key': 'typeProperties.serviceUrl', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        access_key_id: Optional[Any] = None,
        secret_access_key: Optional["SecretBase"] = None,
        service_url: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword access_key_id: The access key identifier of the Google Cloud Storage Identity and
         Access Management (IAM) user. Type: string (or Expression with resultType string).
        :paramtype access_key_id: any
        :keyword secret_access_key: The secret access key of the Google Cloud Storage Identity and
         Access Management (IAM) user.
        :paramtype secret_access_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword service_url: This value specifies the endpoint to access with the Google Cloud Storage
         Connector. This is an optional property; change it only if you want to try a different service
         endpoint or want to switch between https and http. Type: string (or Expression with resultType
         string).
        :paramtype service_url: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(GoogleCloudStorageLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'GoogleCloudStorage'  # type: str
        self.access_key_id = access_key_id
        self.secret_access_key = secret_access_key
        self.service_url = service_url
        self.encrypted_credential = encrypted_credential


class GoogleCloudStorageLocation(DatasetLocation):
    """The location of Google Cloud Storage dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    :ivar bucket_name: Specify the bucketName of Google Cloud Storage. Type: string (or Expression
     with resultType string).
    :vartype bucket_name: any
    :ivar version: Specify the version of Google Cloud Storage. Type: string (or Expression with
     resultType string).
    :vartype version: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
        'bucket_name': {'key': 'bucketName', 'type': 'object'},
        'version': {'key': 'version', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        bucket_name: Optional[Any] = None,
        version: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        :keyword bucket_name: Specify the bucketName of Google Cloud Storage. Type: string (or
         Expression with resultType string).
        :paramtype bucket_name: any
        :keyword version: Specify the version of Google Cloud Storage. Type: string (or Expression with
         resultType string).
        :paramtype version: any
        """
        super(GoogleCloudStorageLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'GoogleCloudStorageLocation'  # type: str
        self.bucket_name = bucket_name
        self.version = version


class GoogleCloudStorageReadSettings(StoreReadSettings):
    """Google Cloud Storage read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar wildcard_folder_path: Google Cloud Storage wildcardFolderPath. Type: string (or
     Expression with resultType string).
    :vartype wildcard_folder_path: any
    :ivar wildcard_file_name: Google Cloud Storage wildcardFileName. Type: string (or Expression
     with resultType string).
    :vartype wildcard_file_name: any
    :ivar prefix: The prefix filter for the Google Cloud Storage object name. Type: string (or
     Expression with resultType string).
    :vartype prefix: any
    :ivar file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :vartype file_list_path: any
    :ivar enable_partition_discovery: Indicates whether to enable partition discovery.
    :vartype enable_partition_discovery: bool
    :ivar partition_root_path: Specify the root path where partition discovery starts from. Type:
     string (or Expression with resultType string).
    :vartype partition_root_path: any
    :ivar delete_files_after_completion: Indicates whether the source files need to be deleted
     after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
    :vartype delete_files_after_completion: any
    :ivar modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :vartype modified_datetime_end: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'object'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'object'},
        'prefix': {'key': 'prefix', 'type': 'object'},
        'file_list_path': {'key': 'fileListPath', 'type': 'object'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'partition_root_path': {'key': 'partitionRootPath', 'type': 'object'},
        'delete_files_after_completion': {'key': 'deleteFilesAfterCompletion', 'type': 'object'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        wildcard_folder_path: Optional[Any] = None,
        wildcard_file_name: Optional[Any] = None,
        prefix: Optional[Any] = None,
        file_list_path: Optional[Any] = None,
        enable_partition_discovery: Optional[bool] = None,
        partition_root_path: Optional[Any] = None,
        delete_files_after_completion: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword wildcard_folder_path: Google Cloud Storage wildcardFolderPath. Type: string (or
         Expression with resultType string).
        :paramtype wildcard_folder_path: any
        :keyword wildcard_file_name: Google Cloud Storage wildcardFileName. Type: string (or Expression
         with resultType string).
        :paramtype wildcard_file_name: any
        :keyword prefix: The prefix filter for the Google Cloud Storage object name. Type: string (or
         Expression with resultType string).
        :paramtype prefix: any
        :keyword file_list_path: Point to a text file that lists each file (relative path to the path
         configured in the dataset) that you want to copy. Type: string (or Expression with resultType
         string).
        :paramtype file_list_path: any
        :keyword enable_partition_discovery: Indicates whether to enable partition discovery.
        :paramtype enable_partition_discovery: bool
        :keyword partition_root_path: Specify the root path where partition discovery starts from.
         Type: string (or Expression with resultType string).
        :paramtype partition_root_path: any
        :keyword delete_files_after_completion: Indicates whether the source files need to be deleted
         after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype delete_files_after_completion: any
        :keyword modified_datetime_start: The start of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        """
        super(GoogleCloudStorageReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'GoogleCloudStorageReadSettings'  # type: str
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.prefix = prefix
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.partition_root_path = partition_root_path
        self.delete_files_after_completion = delete_files_after_completion
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class GreenplumLinkedService(LinkedService):
    """Greenplum Database linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar pwd: The Azure key vault secret reference of password in connection string.
    :vartype pwd: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'pwd': {'key': 'typeProperties.pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: An ODBC connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword pwd: The Azure key vault secret reference of password in connection string.
        :paramtype pwd: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(GreenplumLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Greenplum'  # type: str
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class GreenplumSource(TabularSource):
    """A copy activity Greenplum Database source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(GreenplumSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'GreenplumSource'  # type: str
        self.query = query


class GreenplumTableDataset(Dataset):
    """Greenplum Database dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar table: The table name of Greenplum. Type: string (or Expression with resultType string).
    :vartype table: any
    :ivar schema_type_properties_schema: The schema name of Greenplum. Type: string (or Expression
     with resultType string).
    :vartype schema_type_properties_schema: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword table: The table name of Greenplum. Type: string (or Expression with resultType
         string).
        :paramtype table: any
        :keyword schema_type_properties_schema: The schema name of Greenplum. Type: string (or
         Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        """
        super(GreenplumTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'GreenplumTable'  # type: str
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class HBaseLinkedService(LinkedService):
    """HBase server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. The IP address or host name of the HBase server. (i.e. 192.168.222.160).
    :vartype host: any
    :ivar port: The TCP port that the HBase instance uses to listen for client connections. The
     default value is 9090.
    :vartype port: any
    :ivar http_path: The partial URL corresponding to the HBase server. (i.e.
     /gateway/sandbox/hbase/version).
    :vartype http_path: any
    :ivar authentication_type: Required. The authentication mechanism to use to connect to the
     HBase server. Possible values include: "Anonymous", "Basic".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.HBaseAuthenticationType
    :ivar username: The user name used to connect to the HBase instance.
    :vartype username: any
    :ivar password: The password corresponding to the user name.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :vartype enable_ssl: any
    :ivar trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :vartype trusted_cert_path: any
    :ivar allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :vartype allow_host_name_cn_mismatch: any
    :ivar allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :vartype allow_self_signed_server_cert: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'http_path': {'key': 'typeProperties.httpPath', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'object'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'object'},
        'allow_host_name_cn_mismatch': {'key': 'typeProperties.allowHostNameCNMismatch', 'type': 'object'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        authentication_type: Union[str, "HBaseAuthenticationType"],
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        port: Optional[Any] = None,
        http_path: Optional[Any] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        enable_ssl: Optional[Any] = None,
        trusted_cert_path: Optional[Any] = None,
        allow_host_name_cn_mismatch: Optional[Any] = None,
        allow_self_signed_server_cert: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. The IP address or host name of the HBase server. (i.e.
         192.168.222.160).
        :paramtype host: any
        :keyword port: The TCP port that the HBase instance uses to listen for client connections. The
         default value is 9090.
        :paramtype port: any
        :keyword http_path: The partial URL corresponding to the HBase server. (i.e.
         /gateway/sandbox/hbase/version).
        :paramtype http_path: any
        :keyword authentication_type: Required. The authentication mechanism to use to connect to the
         HBase server. Possible values include: "Anonymous", "Basic".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.HBaseAuthenticationType
        :keyword username: The user name used to connect to the HBase instance.
        :paramtype username: any
        :keyword password: The password corresponding to the user name.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword enable_ssl: Specifies whether the connections to the server are encrypted using SSL.
         The default value is false.
        :paramtype enable_ssl: any
        :keyword trusted_cert_path: The full path of the .pem file containing trusted CA certificates
         for verifying the server when connecting over SSL. This property can only be set when using SSL
         on self-hosted IR. The default value is the cacerts.pem file installed with the IR.
        :paramtype trusted_cert_path: any
        :keyword allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
         name to match the host name of the server when connecting over SSL. The default value is false.
        :paramtype allow_host_name_cn_mismatch: any
        :keyword allow_self_signed_server_cert: Specifies whether to allow self-signed certificates
         from the server. The default value is false.
        :paramtype allow_self_signed_server_cert: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(HBaseLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'HBase'  # type: str
        self.host = host
        self.port = port
        self.http_path = http_path
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class HBaseObjectDataset(Dataset):
    """HBase server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(HBaseObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'HBaseObject'  # type: str
        self.table_name = table_name


class HBaseSource(TabularSource):
    """A copy activity HBase server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(HBaseSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'HBaseSource'  # type: str
        self.query = query


class HdfsLinkedService(LinkedService):
    """Hadoop Distributed File System (HDFS) linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar url: Required. The URL of the HDFS service endpoint, e.g.
     http://myhostname:50070/webhdfs/v1 . Type: string (or Expression with resultType string).
    :vartype url: any
    :ivar authentication_type: Type of authentication used to connect to the HDFS. Possible values
     are: Anonymous and Windows. Type: string (or Expression with resultType string).
    :vartype authentication_type: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar user_name: User name for Windows authentication. Type: string (or Expression with
     resultType string).
    :vartype user_name: any
    :ivar password: Password for Windows authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'url': {'key': 'typeProperties.url', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        url: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        authentication_type: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword url: Required. The URL of the HDFS service endpoint, e.g.
         http://myhostname:50070/webhdfs/v1 . Type: string (or Expression with resultType string).
        :paramtype url: any
        :keyword authentication_type: Type of authentication used to connect to the HDFS. Possible
         values are: Anonymous and Windows. Type: string (or Expression with resultType string).
        :paramtype authentication_type: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword user_name: User name for Windows authentication. Type: string (or Expression with
         resultType string).
        :paramtype user_name: any
        :keyword password: Password for Windows authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        """
        super(HdfsLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Hdfs'  # type: str
        self.url = url
        self.authentication_type = authentication_type
        self.encrypted_credential = encrypted_credential
        self.user_name = user_name
        self.password = password


class HdfsLocation(DatasetLocation):
    """The location of HDFS.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        """
        super(HdfsLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'HdfsLocation'  # type: str


class HdfsReadSettings(StoreReadSettings):
    """HDFS read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar wildcard_folder_path: HDFS wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :vartype wildcard_folder_path: any
    :ivar wildcard_file_name: HDFS wildcardFileName. Type: string (or Expression with resultType
     string).
    :vartype wildcard_file_name: any
    :ivar file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :vartype file_list_path: any
    :ivar enable_partition_discovery: Indicates whether to enable partition discovery.
    :vartype enable_partition_discovery: bool
    :ivar partition_root_path: Specify the root path where partition discovery starts from. Type:
     string (or Expression with resultType string).
    :vartype partition_root_path: any
    :ivar modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :vartype modified_datetime_end: any
    :ivar distcp_settings: Specifies Distcp-related settings.
    :vartype distcp_settings: ~azure.mgmt.datafactory.models.DistcpSettings
    :ivar delete_files_after_completion: Indicates whether the source files need to be deleted
     after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
    :vartype delete_files_after_completion: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'object'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'object'},
        'file_list_path': {'key': 'fileListPath', 'type': 'object'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'partition_root_path': {'key': 'partitionRootPath', 'type': 'object'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'object'},
        'distcp_settings': {'key': 'distcpSettings', 'type': 'DistcpSettings'},
        'delete_files_after_completion': {'key': 'deleteFilesAfterCompletion', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        wildcard_folder_path: Optional[Any] = None,
        wildcard_file_name: Optional[Any] = None,
        file_list_path: Optional[Any] = None,
        enable_partition_discovery: Optional[bool] = None,
        partition_root_path: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        distcp_settings: Optional["DistcpSettings"] = None,
        delete_files_after_completion: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword wildcard_folder_path: HDFS wildcardFolderPath. Type: string (or Expression with
         resultType string).
        :paramtype wildcard_folder_path: any
        :keyword wildcard_file_name: HDFS wildcardFileName. Type: string (or Expression with resultType
         string).
        :paramtype wildcard_file_name: any
        :keyword file_list_path: Point to a text file that lists each file (relative path to the path
         configured in the dataset) that you want to copy. Type: string (or Expression with resultType
         string).
        :paramtype file_list_path: any
        :keyword enable_partition_discovery: Indicates whether to enable partition discovery.
        :paramtype enable_partition_discovery: bool
        :keyword partition_root_path: Specify the root path where partition discovery starts from.
         Type: string (or Expression with resultType string).
        :paramtype partition_root_path: any
        :keyword modified_datetime_start: The start of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        :keyword distcp_settings: Specifies Distcp-related settings.
        :paramtype distcp_settings: ~azure.mgmt.datafactory.models.DistcpSettings
        :keyword delete_files_after_completion: Indicates whether the source files need to be deleted
         after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype delete_files_after_completion: any
        """
        super(HdfsReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'HdfsReadSettings'  # type: str
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.partition_root_path = partition_root_path
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end
        self.distcp_settings = distcp_settings
        self.delete_files_after_completion = delete_files_after_completion


class HdfsSource(CopySource):
    """A copy activity HDFS source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar distcp_settings: Specifies Distcp-related settings.
    :vartype distcp_settings: ~azure.mgmt.datafactory.models.DistcpSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'distcp_settings': {'key': 'distcpSettings', 'type': 'DistcpSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        distcp_settings: Optional["DistcpSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword distcp_settings: Specifies Distcp-related settings.
        :paramtype distcp_settings: ~azure.mgmt.datafactory.models.DistcpSettings
        """
        super(HdfsSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'HdfsSource'  # type: str
        self.recursive = recursive
        self.distcp_settings = distcp_settings


class HDInsightHiveActivity(ExecutionActivity):
    """HDInsight Hive activity type.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar storage_linked_services: Storage linked service references.
    :vartype storage_linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceReference]
    :ivar arguments: User specified arguments to HDInsightActivity.
    :vartype arguments: list[any]
    :ivar get_debug_info: Debug info option. Possible values include: "None", "Always", "Failure".
    :vartype get_debug_info: str or ~azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption
    :ivar script_path: Script path. Type: string (or Expression with resultType string).
    :vartype script_path: any
    :ivar script_linked_service: Script linked service reference.
    :vartype script_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar defines: Allows user to specify defines for Hive job request.
    :vartype defines: dict[str, any]
    :ivar variables: User specified arguments under hivevar namespace.
    :vartype variables: list[any]
    :ivar query_timeout: Query timeout value (in minutes).  Effective when the HDInsight cluster is
     with ESP (Enterprise Security Package).
    :vartype query_timeout: int
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'storage_linked_services': {'key': 'typeProperties.storageLinkedServices', 'type': '[LinkedServiceReference]'},
        'arguments': {'key': 'typeProperties.arguments', 'type': '[object]'},
        'get_debug_info': {'key': 'typeProperties.getDebugInfo', 'type': 'str'},
        'script_path': {'key': 'typeProperties.scriptPath', 'type': 'object'},
        'script_linked_service': {'key': 'typeProperties.scriptLinkedService', 'type': 'LinkedServiceReference'},
        'defines': {'key': 'typeProperties.defines', 'type': '{object}'},
        'variables': {'key': 'typeProperties.variables', 'type': '[object]'},
        'query_timeout': {'key': 'typeProperties.queryTimeout', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        storage_linked_services: Optional[List["LinkedServiceReference"]] = None,
        arguments: Optional[List[Any]] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        script_path: Optional[Any] = None,
        script_linked_service: Optional["LinkedServiceReference"] = None,
        defines: Optional[Dict[str, Any]] = None,
        variables: Optional[List[Any]] = None,
        query_timeout: Optional[int] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword storage_linked_services: Storage linked service references.
        :paramtype storage_linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceReference]
        :keyword arguments: User specified arguments to HDInsightActivity.
        :paramtype arguments: list[any]
        :keyword get_debug_info: Debug info option. Possible values include: "None", "Always",
         "Failure".
        :paramtype get_debug_info: str or
         ~azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption
        :keyword script_path: Script path. Type: string (or Expression with resultType string).
        :paramtype script_path: any
        :keyword script_linked_service: Script linked service reference.
        :paramtype script_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword defines: Allows user to specify defines for Hive job request.
        :paramtype defines: dict[str, any]
        :keyword variables: User specified arguments under hivevar namespace.
        :paramtype variables: list[any]
        :keyword query_timeout: Query timeout value (in minutes).  Effective when the HDInsight cluster
         is with ESP (Enterprise Security Package).
        :paramtype query_timeout: int
        """
        super(HDInsightHiveActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'HDInsightHive'  # type: str
        self.storage_linked_services = storage_linked_services
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.script_path = script_path
        self.script_linked_service = script_linked_service
        self.defines = defines
        self.variables = variables
        self.query_timeout = query_timeout


class HDInsightLinkedService(LinkedService):
    """HDInsight linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar cluster_uri: Required. HDInsight cluster URI. Type: string (or Expression with resultType
     string).
    :vartype cluster_uri: any
    :ivar user_name: HDInsight cluster user name. Type: string (or Expression with resultType
     string).
    :vartype user_name: any
    :ivar password: HDInsight cluster password.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar linked_service_name: The Azure Storage linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar hcatalog_linked_service_name: A reference to the Azure SQL linked service that points to
     the HCatalog database.
    :vartype hcatalog_linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar is_esp_enabled: Specify if the HDInsight is created with ESP (Enterprise Security
     Package). Type: Boolean.
    :vartype is_esp_enabled: any
    :ivar file_system: Specify the FileSystem if the main storage for the HDInsight is ADLS Gen2.
     Type: string (or Expression with resultType string).
    :vartype file_system: any
    """

    _validation = {
        'type': {'required': True},
        'cluster_uri': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'cluster_uri': {'key': 'typeProperties.clusterUri', 'type': 'object'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'linked_service_name': {'key': 'typeProperties.linkedServiceName', 'type': 'LinkedServiceReference'},
        'hcatalog_linked_service_name': {'key': 'typeProperties.hcatalogLinkedServiceName', 'type': 'LinkedServiceReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'is_esp_enabled': {'key': 'typeProperties.isEspEnabled', 'type': 'object'},
        'file_system': {'key': 'typeProperties.fileSystem', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        cluster_uri: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        hcatalog_linked_service_name: Optional["LinkedServiceReference"] = None,
        encrypted_credential: Optional[Any] = None,
        is_esp_enabled: Optional[Any] = None,
        file_system: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword cluster_uri: Required. HDInsight cluster URI. Type: string (or Expression with
         resultType string).
        :paramtype cluster_uri: any
        :keyword user_name: HDInsight cluster user name. Type: string (or Expression with resultType
         string).
        :paramtype user_name: any
        :keyword password: HDInsight cluster password.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword linked_service_name: The Azure Storage linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword hcatalog_linked_service_name: A reference to the Azure SQL linked service that points
         to the HCatalog database.
        :paramtype hcatalog_linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword is_esp_enabled: Specify if the HDInsight is created with ESP (Enterprise Security
         Package). Type: Boolean.
        :paramtype is_esp_enabled: any
        :keyword file_system: Specify the FileSystem if the main storage for the HDInsight is ADLS
         Gen2. Type: string (or Expression with resultType string).
        :paramtype file_system: any
        """
        super(HDInsightLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'HDInsight'  # type: str
        self.cluster_uri = cluster_uri
        self.user_name = user_name
        self.password = password
        self.linked_service_name = linked_service_name
        self.hcatalog_linked_service_name = hcatalog_linked_service_name
        self.encrypted_credential = encrypted_credential
        self.is_esp_enabled = is_esp_enabled
        self.file_system = file_system


class HDInsightMapReduceActivity(ExecutionActivity):
    """HDInsight MapReduce activity type.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar storage_linked_services: Storage linked service references.
    :vartype storage_linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceReference]
    :ivar arguments: User specified arguments to HDInsightActivity.
    :vartype arguments: list[any]
    :ivar get_debug_info: Debug info option. Possible values include: "None", "Always", "Failure".
    :vartype get_debug_info: str or ~azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption
    :ivar class_name: Required. Class name. Type: string (or Expression with resultType string).
    :vartype class_name: any
    :ivar jar_file_path: Required. Jar path. Type: string (or Expression with resultType string).
    :vartype jar_file_path: any
    :ivar jar_linked_service: Jar linked service reference.
    :vartype jar_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar jar_libs: Jar libs.
    :vartype jar_libs: list[any]
    :ivar defines: Allows user to specify defines for the MapReduce job request.
    :vartype defines: dict[str, any]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'class_name': {'required': True},
        'jar_file_path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'storage_linked_services': {'key': 'typeProperties.storageLinkedServices', 'type': '[LinkedServiceReference]'},
        'arguments': {'key': 'typeProperties.arguments', 'type': '[object]'},
        'get_debug_info': {'key': 'typeProperties.getDebugInfo', 'type': 'str'},
        'class_name': {'key': 'typeProperties.className', 'type': 'object'},
        'jar_file_path': {'key': 'typeProperties.jarFilePath', 'type': 'object'},
        'jar_linked_service': {'key': 'typeProperties.jarLinkedService', 'type': 'LinkedServiceReference'},
        'jar_libs': {'key': 'typeProperties.jarLibs', 'type': '[object]'},
        'defines': {'key': 'typeProperties.defines', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        name: str,
        class_name: Any,
        jar_file_path: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        storage_linked_services: Optional[List["LinkedServiceReference"]] = None,
        arguments: Optional[List[Any]] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        jar_linked_service: Optional["LinkedServiceReference"] = None,
        jar_libs: Optional[List[Any]] = None,
        defines: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword storage_linked_services: Storage linked service references.
        :paramtype storage_linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceReference]
        :keyword arguments: User specified arguments to HDInsightActivity.
        :paramtype arguments: list[any]
        :keyword get_debug_info: Debug info option. Possible values include: "None", "Always",
         "Failure".
        :paramtype get_debug_info: str or
         ~azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption
        :keyword class_name: Required. Class name. Type: string (or Expression with resultType string).
        :paramtype class_name: any
        :keyword jar_file_path: Required. Jar path. Type: string (or Expression with resultType
         string).
        :paramtype jar_file_path: any
        :keyword jar_linked_service: Jar linked service reference.
        :paramtype jar_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword jar_libs: Jar libs.
        :paramtype jar_libs: list[any]
        :keyword defines: Allows user to specify defines for the MapReduce job request.
        :paramtype defines: dict[str, any]
        """
        super(HDInsightMapReduceActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'HDInsightMapReduce'  # type: str
        self.storage_linked_services = storage_linked_services
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.class_name = class_name
        self.jar_file_path = jar_file_path
        self.jar_linked_service = jar_linked_service
        self.jar_libs = jar_libs
        self.defines = defines


class HDInsightOnDemandLinkedService(LinkedService):
    """HDInsight ondemand linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar cluster_size: Required. Number of worker/data nodes in the cluster. Suggestion value: 4.
     Type: string (or Expression with resultType string).
    :vartype cluster_size: any
    :ivar time_to_live: Required. The allowed idle time for the on-demand HDInsight cluster.
     Specifies how long the on-demand HDInsight cluster stays alive after completion of an activity
     run if there are no other active jobs in the cluster. The minimum value is 5 mins. Type: string
     (or Expression with resultType string).
    :vartype time_to_live: any
    :ivar version: Required. Version of the HDInsight cluster. Type: string (or Expression with
     resultType string).
    :vartype version: any
    :ivar linked_service_name: Required. Azure Storage linked service to be used by the on-demand
     cluster for storing and processing data.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar host_subscription_id: Required. The customers subscription to host the cluster. Type:
     string (or Expression with resultType string).
    :vartype host_subscription_id: any
    :ivar service_principal_id: The service principal id for the hostSubscriptionId. Type: string
     (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: The key for the service principal id.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar tenant: Required. The Tenant id/name to which the service principal belongs. Type: string
     (or Expression with resultType string).
    :vartype tenant: any
    :ivar cluster_resource_group: Required. The resource group where the cluster belongs. Type:
     string (or Expression with resultType string).
    :vartype cluster_resource_group: any
    :ivar cluster_name_prefix: The prefix of cluster name, postfix will be distinct with timestamp.
     Type: string (or Expression with resultType string).
    :vartype cluster_name_prefix: any
    :ivar cluster_user_name: The username to access the cluster. Type: string (or Expression with
     resultType string).
    :vartype cluster_user_name: any
    :ivar cluster_password: The password to access the cluster.
    :vartype cluster_password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar cluster_ssh_user_name: The username to SSH remotely connect to clusters node (for
     Linux). Type: string (or Expression with resultType string).
    :vartype cluster_ssh_user_name: any
    :ivar cluster_ssh_password: The password to SSH remotely connect clusters node (for Linux).
    :vartype cluster_ssh_password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar additional_linked_service_names: Specifies additional storage accounts for the HDInsight
     linked service so that the Data Factory service can register them on your behalf.
    :vartype additional_linked_service_names:
     list[~azure.mgmt.datafactory.models.LinkedServiceReference]
    :ivar hcatalog_linked_service_name: The name of Azure SQL linked service that point to the
     HCatalog database. The on-demand HDInsight cluster is created by using the Azure SQL database
     as the metastore.
    :vartype hcatalog_linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar cluster_type: The cluster type. Type: string (or Expression with resultType string).
    :vartype cluster_type: any
    :ivar spark_version: The version of spark if the cluster type is 'spark'. Type: string (or
     Expression with resultType string).
    :vartype spark_version: any
    :ivar core_configuration: Specifies the core configuration parameters (as in core-site.xml) for
     the HDInsight cluster to be created.
    :vartype core_configuration: any
    :ivar h_base_configuration: Specifies the HBase configuration parameters (hbase-site.xml) for
     the HDInsight cluster.
    :vartype h_base_configuration: any
    :ivar hdfs_configuration: Specifies the HDFS configuration parameters (hdfs-site.xml) for the
     HDInsight cluster.
    :vartype hdfs_configuration: any
    :ivar hive_configuration: Specifies the hive configuration parameters (hive-site.xml) for the
     HDInsight cluster.
    :vartype hive_configuration: any
    :ivar map_reduce_configuration: Specifies the MapReduce configuration parameters
     (mapred-site.xml) for the HDInsight cluster.
    :vartype map_reduce_configuration: any
    :ivar oozie_configuration: Specifies the Oozie configuration parameters (oozie-site.xml) for
     the HDInsight cluster.
    :vartype oozie_configuration: any
    :ivar storm_configuration: Specifies the Storm configuration parameters (storm-site.xml) for
     the HDInsight cluster.
    :vartype storm_configuration: any
    :ivar yarn_configuration: Specifies the Yarn configuration parameters (yarn-site.xml) for the
     HDInsight cluster.
    :vartype yarn_configuration: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar head_node_size: Specifies the size of the head node for the HDInsight cluster.
    :vartype head_node_size: any
    :ivar data_node_size: Specifies the size of the data node for the HDInsight cluster.
    :vartype data_node_size: any
    :ivar zookeeper_node_size: Specifies the size of the Zoo Keeper node for the HDInsight cluster.
    :vartype zookeeper_node_size: any
    :ivar script_actions: Custom script actions to run on HDI ondemand cluster once it's up. Please
     refer to
     https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-customize-cluster-linux?toc=%2Fen-us%2Fazure%2Fhdinsight%2Fr-server%2FTOC.json&bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json#understanding-script-actions.
    :vartype script_actions: list[~azure.mgmt.datafactory.models.ScriptAction]
    :ivar virtual_network_id: The ARM resource ID for the vNet to which the cluster should be
     joined after creation. Type: string (or Expression with resultType string).
    :vartype virtual_network_id: any
    :ivar subnet_name: The ARM resource ID for the subnet in the vNet. If virtualNetworkId was
     specified, then this property is required. Type: string (or Expression with resultType string).
    :vartype subnet_name: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'type': {'required': True},
        'cluster_size': {'required': True},
        'time_to_live': {'required': True},
        'version': {'required': True},
        'linked_service_name': {'required': True},
        'host_subscription_id': {'required': True},
        'tenant': {'required': True},
        'cluster_resource_group': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'cluster_size': {'key': 'typeProperties.clusterSize', 'type': 'object'},
        'time_to_live': {'key': 'typeProperties.timeToLive', 'type': 'object'},
        'version': {'key': 'typeProperties.version', 'type': 'object'},
        'linked_service_name': {'key': 'typeProperties.linkedServiceName', 'type': 'LinkedServiceReference'},
        'host_subscription_id': {'key': 'typeProperties.hostSubscriptionId', 'type': 'object'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'cluster_resource_group': {'key': 'typeProperties.clusterResourceGroup', 'type': 'object'},
        'cluster_name_prefix': {'key': 'typeProperties.clusterNamePrefix', 'type': 'object'},
        'cluster_user_name': {'key': 'typeProperties.clusterUserName', 'type': 'object'},
        'cluster_password': {'key': 'typeProperties.clusterPassword', 'type': 'SecretBase'},
        'cluster_ssh_user_name': {'key': 'typeProperties.clusterSshUserName', 'type': 'object'},
        'cluster_ssh_password': {'key': 'typeProperties.clusterSshPassword', 'type': 'SecretBase'},
        'additional_linked_service_names': {'key': 'typeProperties.additionalLinkedServiceNames', 'type': '[LinkedServiceReference]'},
        'hcatalog_linked_service_name': {'key': 'typeProperties.hcatalogLinkedServiceName', 'type': 'LinkedServiceReference'},
        'cluster_type': {'key': 'typeProperties.clusterType', 'type': 'object'},
        'spark_version': {'key': 'typeProperties.sparkVersion', 'type': 'object'},
        'core_configuration': {'key': 'typeProperties.coreConfiguration', 'type': 'object'},
        'h_base_configuration': {'key': 'typeProperties.hBaseConfiguration', 'type': 'object'},
        'hdfs_configuration': {'key': 'typeProperties.hdfsConfiguration', 'type': 'object'},
        'hive_configuration': {'key': 'typeProperties.hiveConfiguration', 'type': 'object'},
        'map_reduce_configuration': {'key': 'typeProperties.mapReduceConfiguration', 'type': 'object'},
        'oozie_configuration': {'key': 'typeProperties.oozieConfiguration', 'type': 'object'},
        'storm_configuration': {'key': 'typeProperties.stormConfiguration', 'type': 'object'},
        'yarn_configuration': {'key': 'typeProperties.yarnConfiguration', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'head_node_size': {'key': 'typeProperties.headNodeSize', 'type': 'object'},
        'data_node_size': {'key': 'typeProperties.dataNodeSize', 'type': 'object'},
        'zookeeper_node_size': {'key': 'typeProperties.zookeeperNodeSize', 'type': 'object'},
        'script_actions': {'key': 'typeProperties.scriptActions', 'type': '[ScriptAction]'},
        'virtual_network_id': {'key': 'typeProperties.virtualNetworkId', 'type': 'object'},
        'subnet_name': {'key': 'typeProperties.subnetName', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        cluster_size: Any,
        time_to_live: Any,
        version: Any,
        linked_service_name: "LinkedServiceReference",
        host_subscription_id: Any,
        tenant: Any,
        cluster_resource_group: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["SecretBase"] = None,
        cluster_name_prefix: Optional[Any] = None,
        cluster_user_name: Optional[Any] = None,
        cluster_password: Optional["SecretBase"] = None,
        cluster_ssh_user_name: Optional[Any] = None,
        cluster_ssh_password: Optional["SecretBase"] = None,
        additional_linked_service_names: Optional[List["LinkedServiceReference"]] = None,
        hcatalog_linked_service_name: Optional["LinkedServiceReference"] = None,
        cluster_type: Optional[Any] = None,
        spark_version: Optional[Any] = None,
        core_configuration: Optional[Any] = None,
        h_base_configuration: Optional[Any] = None,
        hdfs_configuration: Optional[Any] = None,
        hive_configuration: Optional[Any] = None,
        map_reduce_configuration: Optional[Any] = None,
        oozie_configuration: Optional[Any] = None,
        storm_configuration: Optional[Any] = None,
        yarn_configuration: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        head_node_size: Optional[Any] = None,
        data_node_size: Optional[Any] = None,
        zookeeper_node_size: Optional[Any] = None,
        script_actions: Optional[List["ScriptAction"]] = None,
        virtual_network_id: Optional[Any] = None,
        subnet_name: Optional[Any] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword cluster_size: Required. Number of worker/data nodes in the cluster. Suggestion value:
         4. Type: string (or Expression with resultType string).
        :paramtype cluster_size: any
        :keyword time_to_live: Required. The allowed idle time for the on-demand HDInsight cluster.
         Specifies how long the on-demand HDInsight cluster stays alive after completion of an activity
         run if there are no other active jobs in the cluster. The minimum value is 5 mins. Type: string
         (or Expression with resultType string).
        :paramtype time_to_live: any
        :keyword version: Required. Version of the HDInsight cluster. Type: string (or Expression with
         resultType string).
        :paramtype version: any
        :keyword linked_service_name: Required. Azure Storage linked service to be used by the
         on-demand cluster for storing and processing data.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword host_subscription_id: Required. The customers subscription to host the cluster. Type:
         string (or Expression with resultType string).
        :paramtype host_subscription_id: any
        :keyword service_principal_id: The service principal id for the hostSubscriptionId. Type:
         string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: The key for the service principal id.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword tenant: Required. The Tenant id/name to which the service principal belongs. Type:
         string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword cluster_resource_group: Required. The resource group where the cluster belongs. Type:
         string (or Expression with resultType string).
        :paramtype cluster_resource_group: any
        :keyword cluster_name_prefix: The prefix of cluster name, postfix will be distinct with
         timestamp. Type: string (or Expression with resultType string).
        :paramtype cluster_name_prefix: any
        :keyword cluster_user_name: The username to access the cluster. Type: string (or Expression
         with resultType string).
        :paramtype cluster_user_name: any
        :keyword cluster_password: The password to access the cluster.
        :paramtype cluster_password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword cluster_ssh_user_name: The username to SSH remotely connect to clusters node (for
         Linux). Type: string (or Expression with resultType string).
        :paramtype cluster_ssh_user_name: any
        :keyword cluster_ssh_password: The password to SSH remotely connect clusters node (for Linux).
        :paramtype cluster_ssh_password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword additional_linked_service_names: Specifies additional storage accounts for the
         HDInsight linked service so that the Data Factory service can register them on your behalf.
        :paramtype additional_linked_service_names:
         list[~azure.mgmt.datafactory.models.LinkedServiceReference]
        :keyword hcatalog_linked_service_name: The name of Azure SQL linked service that point to the
         HCatalog database. The on-demand HDInsight cluster is created by using the Azure SQL database
         as the metastore.
        :paramtype hcatalog_linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword cluster_type: The cluster type. Type: string (or Expression with resultType string).
        :paramtype cluster_type: any
        :keyword spark_version: The version of spark if the cluster type is 'spark'. Type: string (or
         Expression with resultType string).
        :paramtype spark_version: any
        :keyword core_configuration: Specifies the core configuration parameters (as in core-site.xml)
         for the HDInsight cluster to be created.
        :paramtype core_configuration: any
        :keyword h_base_configuration: Specifies the HBase configuration parameters (hbase-site.xml)
         for the HDInsight cluster.
        :paramtype h_base_configuration: any
        :keyword hdfs_configuration: Specifies the HDFS configuration parameters (hdfs-site.xml) for
         the HDInsight cluster.
        :paramtype hdfs_configuration: any
        :keyword hive_configuration: Specifies the hive configuration parameters (hive-site.xml) for
         the HDInsight cluster.
        :paramtype hive_configuration: any
        :keyword map_reduce_configuration: Specifies the MapReduce configuration parameters
         (mapred-site.xml) for the HDInsight cluster.
        :paramtype map_reduce_configuration: any
        :keyword oozie_configuration: Specifies the Oozie configuration parameters (oozie-site.xml) for
         the HDInsight cluster.
        :paramtype oozie_configuration: any
        :keyword storm_configuration: Specifies the Storm configuration parameters (storm-site.xml) for
         the HDInsight cluster.
        :paramtype storm_configuration: any
        :keyword yarn_configuration: Specifies the Yarn configuration parameters (yarn-site.xml) for
         the HDInsight cluster.
        :paramtype yarn_configuration: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword head_node_size: Specifies the size of the head node for the HDInsight cluster.
        :paramtype head_node_size: any
        :keyword data_node_size: Specifies the size of the data node for the HDInsight cluster.
        :paramtype data_node_size: any
        :keyword zookeeper_node_size: Specifies the size of the Zoo Keeper node for the HDInsight
         cluster.
        :paramtype zookeeper_node_size: any
        :keyword script_actions: Custom script actions to run on HDI ondemand cluster once it's up.
         Please refer to
         https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-customize-cluster-linux?toc=%2Fen-us%2Fazure%2Fhdinsight%2Fr-server%2FTOC.json&bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json#understanding-script-actions.
        :paramtype script_actions: list[~azure.mgmt.datafactory.models.ScriptAction]
        :keyword virtual_network_id: The ARM resource ID for the vNet to which the cluster should be
         joined after creation. Type: string (or Expression with resultType string).
        :paramtype virtual_network_id: any
        :keyword subnet_name: The ARM resource ID for the subnet in the vNet. If virtualNetworkId was
         specified, then this property is required. Type: string (or Expression with resultType string).
        :paramtype subnet_name: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(HDInsightOnDemandLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'HDInsightOnDemand'  # type: str
        self.cluster_size = cluster_size
        self.time_to_live = time_to_live
        self.version = version
        self.linked_service_name = linked_service_name
        self.host_subscription_id = host_subscription_id
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.cluster_resource_group = cluster_resource_group
        self.cluster_name_prefix = cluster_name_prefix
        self.cluster_user_name = cluster_user_name
        self.cluster_password = cluster_password
        self.cluster_ssh_user_name = cluster_ssh_user_name
        self.cluster_ssh_password = cluster_ssh_password
        self.additional_linked_service_names = additional_linked_service_names
        self.hcatalog_linked_service_name = hcatalog_linked_service_name
        self.cluster_type = cluster_type
        self.spark_version = spark_version
        self.core_configuration = core_configuration
        self.h_base_configuration = h_base_configuration
        self.hdfs_configuration = hdfs_configuration
        self.hive_configuration = hive_configuration
        self.map_reduce_configuration = map_reduce_configuration
        self.oozie_configuration = oozie_configuration
        self.storm_configuration = storm_configuration
        self.yarn_configuration = yarn_configuration
        self.encrypted_credential = encrypted_credential
        self.head_node_size = head_node_size
        self.data_node_size = data_node_size
        self.zookeeper_node_size = zookeeper_node_size
        self.script_actions = script_actions
        self.virtual_network_id = virtual_network_id
        self.subnet_name = subnet_name
        self.credential = credential


class HDInsightPigActivity(ExecutionActivity):
    """HDInsight Pig activity type.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar storage_linked_services: Storage linked service references.
    :vartype storage_linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceReference]
    :ivar arguments: User specified arguments to HDInsightActivity. Type: array (or Expression with
     resultType array).
    :vartype arguments: any
    :ivar get_debug_info: Debug info option. Possible values include: "None", "Always", "Failure".
    :vartype get_debug_info: str or ~azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption
    :ivar script_path: Script path. Type: string (or Expression with resultType string).
    :vartype script_path: any
    :ivar script_linked_service: Script linked service reference.
    :vartype script_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar defines: Allows user to specify defines for Pig job request.
    :vartype defines: dict[str, any]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'storage_linked_services': {'key': 'typeProperties.storageLinkedServices', 'type': '[LinkedServiceReference]'},
        'arguments': {'key': 'typeProperties.arguments', 'type': 'object'},
        'get_debug_info': {'key': 'typeProperties.getDebugInfo', 'type': 'str'},
        'script_path': {'key': 'typeProperties.scriptPath', 'type': 'object'},
        'script_linked_service': {'key': 'typeProperties.scriptLinkedService', 'type': 'LinkedServiceReference'},
        'defines': {'key': 'typeProperties.defines', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        storage_linked_services: Optional[List["LinkedServiceReference"]] = None,
        arguments: Optional[Any] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        script_path: Optional[Any] = None,
        script_linked_service: Optional["LinkedServiceReference"] = None,
        defines: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword storage_linked_services: Storage linked service references.
        :paramtype storage_linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceReference]
        :keyword arguments: User specified arguments to HDInsightActivity. Type: array (or Expression
         with resultType array).
        :paramtype arguments: any
        :keyword get_debug_info: Debug info option. Possible values include: "None", "Always",
         "Failure".
        :paramtype get_debug_info: str or
         ~azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption
        :keyword script_path: Script path. Type: string (or Expression with resultType string).
        :paramtype script_path: any
        :keyword script_linked_service: Script linked service reference.
        :paramtype script_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword defines: Allows user to specify defines for Pig job request.
        :paramtype defines: dict[str, any]
        """
        super(HDInsightPigActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'HDInsightPig'  # type: str
        self.storage_linked_services = storage_linked_services
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.script_path = script_path
        self.script_linked_service = script_linked_service
        self.defines = defines


class HDInsightSparkActivity(ExecutionActivity):
    """HDInsight Spark activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar root_path: Required. The root path in 'sparkJobLinkedService' for all the jobs files.
     Type: string (or Expression with resultType string).
    :vartype root_path: any
    :ivar entry_file_path: Required. The relative path to the root folder of the code/package to be
     executed. Type: string (or Expression with resultType string).
    :vartype entry_file_path: any
    :ivar arguments: The user-specified arguments to HDInsightSparkActivity.
    :vartype arguments: list[any]
    :ivar get_debug_info: Debug info option. Possible values include: "None", "Always", "Failure".
    :vartype get_debug_info: str or ~azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption
    :ivar spark_job_linked_service: The storage linked service for uploading the entry file and
     dependencies, and for receiving logs.
    :vartype spark_job_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar class_name: The application's Java/Spark main class.
    :vartype class_name: str
    :ivar proxy_user: The user to impersonate that will execute the job. Type: string (or
     Expression with resultType string).
    :vartype proxy_user: any
    :ivar spark_config: Spark configuration property.
    :vartype spark_config: dict[str, any]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'root_path': {'required': True},
        'entry_file_path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'root_path': {'key': 'typeProperties.rootPath', 'type': 'object'},
        'entry_file_path': {'key': 'typeProperties.entryFilePath', 'type': 'object'},
        'arguments': {'key': 'typeProperties.arguments', 'type': '[object]'},
        'get_debug_info': {'key': 'typeProperties.getDebugInfo', 'type': 'str'},
        'spark_job_linked_service': {'key': 'typeProperties.sparkJobLinkedService', 'type': 'LinkedServiceReference'},
        'class_name': {'key': 'typeProperties.className', 'type': 'str'},
        'proxy_user': {'key': 'typeProperties.proxyUser', 'type': 'object'},
        'spark_config': {'key': 'typeProperties.sparkConfig', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        name: str,
        root_path: Any,
        entry_file_path: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        arguments: Optional[List[Any]] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        spark_job_linked_service: Optional["LinkedServiceReference"] = None,
        class_name: Optional[str] = None,
        proxy_user: Optional[Any] = None,
        spark_config: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword root_path: Required. The root path in 'sparkJobLinkedService' for all the jobs files.
         Type: string (or Expression with resultType string).
        :paramtype root_path: any
        :keyword entry_file_path: Required. The relative path to the root folder of the code/package to
         be executed. Type: string (or Expression with resultType string).
        :paramtype entry_file_path: any
        :keyword arguments: The user-specified arguments to HDInsightSparkActivity.
        :paramtype arguments: list[any]
        :keyword get_debug_info: Debug info option. Possible values include: "None", "Always",
         "Failure".
        :paramtype get_debug_info: str or
         ~azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption
        :keyword spark_job_linked_service: The storage linked service for uploading the entry file and
         dependencies, and for receiving logs.
        :paramtype spark_job_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword class_name: The application's Java/Spark main class.
        :paramtype class_name: str
        :keyword proxy_user: The user to impersonate that will execute the job. Type: string (or
         Expression with resultType string).
        :paramtype proxy_user: any
        :keyword spark_config: Spark configuration property.
        :paramtype spark_config: dict[str, any]
        """
        super(HDInsightSparkActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'HDInsightSpark'  # type: str
        self.root_path = root_path
        self.entry_file_path = entry_file_path
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.spark_job_linked_service = spark_job_linked_service
        self.class_name = class_name
        self.proxy_user = proxy_user
        self.spark_config = spark_config


class HDInsightStreamingActivity(ExecutionActivity):
    """HDInsight streaming activity type.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar storage_linked_services: Storage linked service references.
    :vartype storage_linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceReference]
    :ivar arguments: User specified arguments to HDInsightActivity.
    :vartype arguments: list[any]
    :ivar get_debug_info: Debug info option. Possible values include: "None", "Always", "Failure".
    :vartype get_debug_info: str or ~azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption
    :ivar mapper: Required. Mapper executable name. Type: string (or Expression with resultType
     string).
    :vartype mapper: any
    :ivar reducer: Required. Reducer executable name. Type: string (or Expression with resultType
     string).
    :vartype reducer: any
    :ivar input: Required. Input blob path. Type: string (or Expression with resultType string).
    :vartype input: any
    :ivar output: Required. Output blob path. Type: string (or Expression with resultType string).
    :vartype output: any
    :ivar file_paths: Required. Paths to streaming job files. Can be directories.
    :vartype file_paths: list[any]
    :ivar file_linked_service: Linked service reference where the files are located.
    :vartype file_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar combiner: Combiner executable name. Type: string (or Expression with resultType string).
    :vartype combiner: any
    :ivar command_environment: Command line environment values.
    :vartype command_environment: list[any]
    :ivar defines: Allows user to specify defines for streaming job request.
    :vartype defines: dict[str, any]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'mapper': {'required': True},
        'reducer': {'required': True},
        'input': {'required': True},
        'output': {'required': True},
        'file_paths': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'storage_linked_services': {'key': 'typeProperties.storageLinkedServices', 'type': '[LinkedServiceReference]'},
        'arguments': {'key': 'typeProperties.arguments', 'type': '[object]'},
        'get_debug_info': {'key': 'typeProperties.getDebugInfo', 'type': 'str'},
        'mapper': {'key': 'typeProperties.mapper', 'type': 'object'},
        'reducer': {'key': 'typeProperties.reducer', 'type': 'object'},
        'input': {'key': 'typeProperties.input', 'type': 'object'},
        'output': {'key': 'typeProperties.output', 'type': 'object'},
        'file_paths': {'key': 'typeProperties.filePaths', 'type': '[object]'},
        'file_linked_service': {'key': 'typeProperties.fileLinkedService', 'type': 'LinkedServiceReference'},
        'combiner': {'key': 'typeProperties.combiner', 'type': 'object'},
        'command_environment': {'key': 'typeProperties.commandEnvironment', 'type': '[object]'},
        'defines': {'key': 'typeProperties.defines', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        name: str,
        mapper: Any,
        reducer: Any,
        input: Any,
        output: Any,
        file_paths: List[Any],
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        storage_linked_services: Optional[List["LinkedServiceReference"]] = None,
        arguments: Optional[List[Any]] = None,
        get_debug_info: Optional[Union[str, "HDInsightActivityDebugInfoOption"]] = None,
        file_linked_service: Optional["LinkedServiceReference"] = None,
        combiner: Optional[Any] = None,
        command_environment: Optional[List[Any]] = None,
        defines: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword storage_linked_services: Storage linked service references.
        :paramtype storage_linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceReference]
        :keyword arguments: User specified arguments to HDInsightActivity.
        :paramtype arguments: list[any]
        :keyword get_debug_info: Debug info option. Possible values include: "None", "Always",
         "Failure".
        :paramtype get_debug_info: str or
         ~azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption
        :keyword mapper: Required. Mapper executable name. Type: string (or Expression with resultType
         string).
        :paramtype mapper: any
        :keyword reducer: Required. Reducer executable name. Type: string (or Expression with
         resultType string).
        :paramtype reducer: any
        :keyword input: Required. Input blob path. Type: string (or Expression with resultType string).
        :paramtype input: any
        :keyword output: Required. Output blob path. Type: string (or Expression with resultType
         string).
        :paramtype output: any
        :keyword file_paths: Required. Paths to streaming job files. Can be directories.
        :paramtype file_paths: list[any]
        :keyword file_linked_service: Linked service reference where the files are located.
        :paramtype file_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword combiner: Combiner executable name. Type: string (or Expression with resultType
         string).
        :paramtype combiner: any
        :keyword command_environment: Command line environment values.
        :paramtype command_environment: list[any]
        :keyword defines: Allows user to specify defines for streaming job request.
        :paramtype defines: dict[str, any]
        """
        super(HDInsightStreamingActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'HDInsightStreaming'  # type: str
        self.storage_linked_services = storage_linked_services
        self.arguments = arguments
        self.get_debug_info = get_debug_info
        self.mapper = mapper
        self.reducer = reducer
        self.input = input
        self.output = output
        self.file_paths = file_paths
        self.file_linked_service = file_linked_service
        self.combiner = combiner
        self.command_environment = command_environment
        self.defines = defines


class HiveLinkedService(LinkedService):
    """Hive Server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. IP address or host name of the Hive server, separated by ';' for multiple
     hosts (only when serviceDiscoveryMode is enable).
    :vartype host: any
    :ivar port: The TCP port that the Hive server uses to listen for client connections.
    :vartype port: any
    :ivar server_type: The type of Hive server. Possible values include: "HiveServer1",
     "HiveServer2", "HiveThriftServer".
    :vartype server_type: str or ~azure.mgmt.datafactory.models.HiveServerType
    :ivar thrift_transport_protocol: The transport protocol to use in the Thrift layer. Possible
     values include: "Binary", "SASL", "HTTP ".
    :vartype thrift_transport_protocol: str or
     ~azure.mgmt.datafactory.models.HiveThriftTransportProtocol
    :ivar authentication_type: Required. The authentication method used to access the Hive server.
     Possible values include: "Anonymous", "Username", "UsernameAndPassword",
     "WindowsAzureHDInsightService".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.HiveAuthenticationType
    :ivar service_discovery_mode: true to indicate using the ZooKeeper service, false not.
    :vartype service_discovery_mode: any
    :ivar zoo_keeper_name_space: The namespace on ZooKeeper under which Hive Server 2 nodes are
     added.
    :vartype zoo_keeper_name_space: any
    :ivar use_native_query: Specifies whether the driver uses native HiveQL queries,or converts
     them into an equivalent form in HiveQL.
    :vartype use_native_query: any
    :ivar username: The user name that you use to access Hive Server.
    :vartype username: any
    :ivar password: The password corresponding to the user name that you provided in the Username
     field.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar http_path: The partial URL corresponding to the Hive server.
    :vartype http_path: any
    :ivar enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :vartype enable_ssl: any
    :ivar trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :vartype trusted_cert_path: any
    :ivar use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :vartype use_system_trust_store: any
    :ivar allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :vartype allow_host_name_cn_mismatch: any
    :ivar allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :vartype allow_self_signed_server_cert: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'server_type': {'key': 'typeProperties.serverType', 'type': 'str'},
        'thrift_transport_protocol': {'key': 'typeProperties.thriftTransportProtocol', 'type': 'str'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'service_discovery_mode': {'key': 'typeProperties.serviceDiscoveryMode', 'type': 'object'},
        'zoo_keeper_name_space': {'key': 'typeProperties.zooKeeperNameSpace', 'type': 'object'},
        'use_native_query': {'key': 'typeProperties.useNativeQuery', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'http_path': {'key': 'typeProperties.httpPath', 'type': 'object'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'object'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'object'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'object'},
        'allow_host_name_cn_mismatch': {'key': 'typeProperties.allowHostNameCNMismatch', 'type': 'object'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        authentication_type: Union[str, "HiveAuthenticationType"],
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        port: Optional[Any] = None,
        server_type: Optional[Union[str, "HiveServerType"]] = None,
        thrift_transport_protocol: Optional[Union[str, "HiveThriftTransportProtocol"]] = None,
        service_discovery_mode: Optional[Any] = None,
        zoo_keeper_name_space: Optional[Any] = None,
        use_native_query: Optional[Any] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        http_path: Optional[Any] = None,
        enable_ssl: Optional[Any] = None,
        trusted_cert_path: Optional[Any] = None,
        use_system_trust_store: Optional[Any] = None,
        allow_host_name_cn_mismatch: Optional[Any] = None,
        allow_self_signed_server_cert: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. IP address or host name of the Hive server, separated by ';' for
         multiple hosts (only when serviceDiscoveryMode is enable).
        :paramtype host: any
        :keyword port: The TCP port that the Hive server uses to listen for client connections.
        :paramtype port: any
        :keyword server_type: The type of Hive server. Possible values include: "HiveServer1",
         "HiveServer2", "HiveThriftServer".
        :paramtype server_type: str or ~azure.mgmt.datafactory.models.HiveServerType
        :keyword thrift_transport_protocol: The transport protocol to use in the Thrift layer. Possible
         values include: "Binary", "SASL", "HTTP ".
        :paramtype thrift_transport_protocol: str or
         ~azure.mgmt.datafactory.models.HiveThriftTransportProtocol
        :keyword authentication_type: Required. The authentication method used to access the Hive
         server. Possible values include: "Anonymous", "Username", "UsernameAndPassword",
         "WindowsAzureHDInsightService".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.HiveAuthenticationType
        :keyword service_discovery_mode: true to indicate using the ZooKeeper service, false not.
        :paramtype service_discovery_mode: any
        :keyword zoo_keeper_name_space: The namespace on ZooKeeper under which Hive Server 2 nodes are
         added.
        :paramtype zoo_keeper_name_space: any
        :keyword use_native_query: Specifies whether the driver uses native HiveQL queries,or converts
         them into an equivalent form in HiveQL.
        :paramtype use_native_query: any
        :keyword username: The user name that you use to access Hive Server.
        :paramtype username: any
        :keyword password: The password corresponding to the user name that you provided in the
         Username field.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword http_path: The partial URL corresponding to the Hive server.
        :paramtype http_path: any
        :keyword enable_ssl: Specifies whether the connections to the server are encrypted using SSL.
         The default value is false.
        :paramtype enable_ssl: any
        :keyword trusted_cert_path: The full path of the .pem file containing trusted CA certificates
         for verifying the server when connecting over SSL. This property can only be set when using SSL
         on self-hosted IR. The default value is the cacerts.pem file installed with the IR.
        :paramtype trusted_cert_path: any
        :keyword use_system_trust_store: Specifies whether to use a CA certificate from the system
         trust store or from a specified PEM file. The default value is false.
        :paramtype use_system_trust_store: any
        :keyword allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
         name to match the host name of the server when connecting over SSL. The default value is false.
        :paramtype allow_host_name_cn_mismatch: any
        :keyword allow_self_signed_server_cert: Specifies whether to allow self-signed certificates
         from the server. The default value is false.
        :paramtype allow_self_signed_server_cert: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(HiveLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Hive'  # type: str
        self.host = host
        self.port = port
        self.server_type = server_type
        self.thrift_transport_protocol = thrift_transport_protocol
        self.authentication_type = authentication_type
        self.service_discovery_mode = service_discovery_mode
        self.zoo_keeper_name_space = zoo_keeper_name_space
        self.use_native_query = use_native_query
        self.username = username
        self.password = password
        self.http_path = http_path
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class HiveObjectDataset(Dataset):
    """Hive Server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar table: The table name of the Hive. Type: string (or Expression with resultType string).
    :vartype table: any
    :ivar schema_type_properties_schema: The schema name of the Hive. Type: string (or Expression
     with resultType string).
    :vartype schema_type_properties_schema: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword table: The table name of the Hive. Type: string (or Expression with resultType
         string).
        :paramtype table: any
        :keyword schema_type_properties_schema: The schema name of the Hive. Type: string (or
         Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        """
        super(HiveObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'HiveObject'  # type: str
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class HiveSource(TabularSource):
    """A copy activity Hive Server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(HiveSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'HiveSource'  # type: str
        self.query = query


class HttpDataset(Dataset):
    """A file in an HTTP web server.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar relative_url: The relative URL based on the URL in the HttpLinkedService refers to an
     HTTP file Type: string (or Expression with resultType string).
    :vartype relative_url: any
    :ivar request_method: The HTTP method for the HTTP request. Type: string (or Expression with
     resultType string).
    :vartype request_method: any
    :ivar request_body: The body for the HTTP request. Type: string (or Expression with resultType
     string).
    :vartype request_body: any
    :ivar additional_headers: The headers for the HTTP Request. e.g.
     request-header-name-1:request-header-value-1
     ...
     request-header-name-n:request-header-value-n Type: string (or Expression with resultType
     string).
    :vartype additional_headers: any
    :ivar format: The format of files.
    :vartype format: ~azure.mgmt.datafactory.models.DatasetStorageFormat
    :ivar compression: The data compression method used on files.
    :vartype compression: ~azure.mgmt.datafactory.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'relative_url': {'key': 'typeProperties.relativeUrl', 'type': 'object'},
        'request_method': {'key': 'typeProperties.requestMethod', 'type': 'object'},
        'request_body': {'key': 'typeProperties.requestBody', 'type': 'object'},
        'additional_headers': {'key': 'typeProperties.additionalHeaders', 'type': 'object'},
        'format': {'key': 'typeProperties.format', 'type': 'DatasetStorageFormat'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        relative_url: Optional[Any] = None,
        request_method: Optional[Any] = None,
        request_body: Optional[Any] = None,
        additional_headers: Optional[Any] = None,
        format: Optional["DatasetStorageFormat"] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword relative_url: The relative URL based on the URL in the HttpLinkedService refers to an
         HTTP file Type: string (or Expression with resultType string).
        :paramtype relative_url: any
        :keyword request_method: The HTTP method for the HTTP request. Type: string (or Expression with
         resultType string).
        :paramtype request_method: any
        :keyword request_body: The body for the HTTP request. Type: string (or Expression with
         resultType string).
        :paramtype request_body: any
        :keyword additional_headers: The headers for the HTTP Request. e.g.
         request-header-name-1:request-header-value-1
         ...
         request-header-name-n:request-header-value-n Type: string (or Expression with resultType
         string).
        :paramtype additional_headers: any
        :keyword format: The format of files.
        :paramtype format: ~azure.mgmt.datafactory.models.DatasetStorageFormat
        :keyword compression: The data compression method used on files.
        :paramtype compression: ~azure.mgmt.datafactory.models.DatasetCompression
        """
        super(HttpDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'HttpFile'  # type: str
        self.relative_url = relative_url
        self.request_method = request_method
        self.request_body = request_body
        self.additional_headers = additional_headers
        self.format = format
        self.compression = compression


class HttpLinkedService(LinkedService):
    """Linked service for an HTTP source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar url: Required. The base URL of the HTTP endpoint, e.g. http://www.microsoft.com. Type:
     string (or Expression with resultType string).
    :vartype url: any
    :ivar authentication_type: The authentication type to be used to connect to the HTTP server.
     Possible values include: "Basic", "Anonymous", "Digest", "Windows", "ClientCertificate".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.HttpAuthenticationType
    :ivar user_name: User name for Basic, Digest, or Windows authentication. Type: string (or
     Expression with resultType string).
    :vartype user_name: any
    :ivar password: Password for Basic, Digest, Windows, or ClientCertificate with EmbeddedCertData
     authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar auth_headers: The additional HTTP headers in the request to RESTful API used for
     authorization. Type: object (or Expression with resultType object).
    :vartype auth_headers: any
    :ivar embedded_cert_data: Base64 encoded certificate data for ClientCertificate authentication.
     For on-premises copy with ClientCertificate authentication, either CertThumbprint or
     EmbeddedCertData/Password should be specified. Type: string (or Expression with resultType
     string).
    :vartype embedded_cert_data: any
    :ivar cert_thumbprint: Thumbprint of certificate for ClientCertificate authentication. Only
     valid for on-premises copy. For on-premises copy with ClientCertificate authentication, either
     CertThumbprint or EmbeddedCertData/Password should be specified. Type: string (or Expression
     with resultType string).
    :vartype cert_thumbprint: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar enable_server_certificate_validation: If true, validate the HTTPS server SSL certificate.
     Default value is true. Type: boolean (or Expression with resultType boolean).
    :vartype enable_server_certificate_validation: any
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'url': {'key': 'typeProperties.url', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'auth_headers': {'key': 'typeProperties.authHeaders', 'type': 'object'},
        'embedded_cert_data': {'key': 'typeProperties.embeddedCertData', 'type': 'object'},
        'cert_thumbprint': {'key': 'typeProperties.certThumbprint', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'enable_server_certificate_validation': {'key': 'typeProperties.enableServerCertificateValidation', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        url: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        authentication_type: Optional[Union[str, "HttpAuthenticationType"]] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        auth_headers: Optional[Any] = None,
        embedded_cert_data: Optional[Any] = None,
        cert_thumbprint: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        enable_server_certificate_validation: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword url: Required. The base URL of the HTTP endpoint, e.g. http://www.microsoft.com. Type:
         string (or Expression with resultType string).
        :paramtype url: any
        :keyword authentication_type: The authentication type to be used to connect to the HTTP server.
         Possible values include: "Basic", "Anonymous", "Digest", "Windows", "ClientCertificate".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.HttpAuthenticationType
        :keyword user_name: User name for Basic, Digest, or Windows authentication. Type: string (or
         Expression with resultType string).
        :paramtype user_name: any
        :keyword password: Password for Basic, Digest, Windows, or ClientCertificate with
         EmbeddedCertData authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword auth_headers: The additional HTTP headers in the request to RESTful API used for
         authorization. Type: object (or Expression with resultType object).
        :paramtype auth_headers: any
        :keyword embedded_cert_data: Base64 encoded certificate data for ClientCertificate
         authentication. For on-premises copy with ClientCertificate authentication, either
         CertThumbprint or EmbeddedCertData/Password should be specified. Type: string (or Expression
         with resultType string).
        :paramtype embedded_cert_data: any
        :keyword cert_thumbprint: Thumbprint of certificate for ClientCertificate authentication. Only
         valid for on-premises copy. For on-premises copy with ClientCertificate authentication, either
         CertThumbprint or EmbeddedCertData/Password should be specified. Type: string (or Expression
         with resultType string).
        :paramtype cert_thumbprint: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword enable_server_certificate_validation: If true, validate the HTTPS server SSL
         certificate. Default value is true. Type: boolean (or Expression with resultType boolean).
        :paramtype enable_server_certificate_validation: any
        """
        super(HttpLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'HttpServer'  # type: str
        self.url = url
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.auth_headers = auth_headers
        self.embedded_cert_data = embedded_cert_data
        self.cert_thumbprint = cert_thumbprint
        self.encrypted_credential = encrypted_credential
        self.enable_server_certificate_validation = enable_server_certificate_validation


class HttpReadSettings(StoreReadSettings):
    """Sftp read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar request_method: The HTTP method used to call the RESTful API. The default is GET. Type:
     string (or Expression with resultType string).
    :vartype request_method: any
    :ivar request_body: The HTTP request body to the RESTful API if requestMethod is POST. Type:
     string (or Expression with resultType string).
    :vartype request_body: any
    :ivar additional_headers: The additional HTTP headers in the request to the RESTful API. Type:
     string (or Expression with resultType string).
    :vartype additional_headers: any
    :ivar request_timeout: Specifies the timeout for a HTTP client to get HTTP response from HTTP
     server.
    :vartype request_timeout: any
    :ivar enable_partition_discovery: Indicates whether to enable partition discovery.
    :vartype enable_partition_discovery: bool
    :ivar partition_root_path: Specify the root path where partition discovery starts from. Type:
     string (or Expression with resultType string).
    :vartype partition_root_path: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'request_method': {'key': 'requestMethod', 'type': 'object'},
        'request_body': {'key': 'requestBody', 'type': 'object'},
        'additional_headers': {'key': 'additionalHeaders', 'type': 'object'},
        'request_timeout': {'key': 'requestTimeout', 'type': 'object'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'partition_root_path': {'key': 'partitionRootPath', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        request_method: Optional[Any] = None,
        request_body: Optional[Any] = None,
        additional_headers: Optional[Any] = None,
        request_timeout: Optional[Any] = None,
        enable_partition_discovery: Optional[bool] = None,
        partition_root_path: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword request_method: The HTTP method used to call the RESTful API. The default is GET.
         Type: string (or Expression with resultType string).
        :paramtype request_method: any
        :keyword request_body: The HTTP request body to the RESTful API if requestMethod is POST. Type:
         string (or Expression with resultType string).
        :paramtype request_body: any
        :keyword additional_headers: The additional HTTP headers in the request to the RESTful API.
         Type: string (or Expression with resultType string).
        :paramtype additional_headers: any
        :keyword request_timeout: Specifies the timeout for a HTTP client to get HTTP response from
         HTTP server.
        :paramtype request_timeout: any
        :keyword enable_partition_discovery: Indicates whether to enable partition discovery.
        :paramtype enable_partition_discovery: bool
        :keyword partition_root_path: Specify the root path where partition discovery starts from.
         Type: string (or Expression with resultType string).
        :paramtype partition_root_path: any
        """
        super(HttpReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'HttpReadSettings'  # type: str
        self.request_method = request_method
        self.request_body = request_body
        self.additional_headers = additional_headers
        self.request_timeout = request_timeout
        self.enable_partition_discovery = enable_partition_discovery
        self.partition_root_path = partition_root_path


class HttpServerLocation(DatasetLocation):
    """The location of http server.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    :ivar relative_url: Specify the relativeUrl of http server. Type: string (or Expression with
     resultType string).
    :vartype relative_url: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
        'relative_url': {'key': 'relativeUrl', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        relative_url: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        :keyword relative_url: Specify the relativeUrl of http server. Type: string (or Expression with
         resultType string).
        :paramtype relative_url: any
        """
        super(HttpServerLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'HttpServerLocation'  # type: str
        self.relative_url = relative_url


class HttpSource(CopySource):
    """A copy activity source for an HTTP file.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar http_request_timeout: Specifies the timeout for a HTTP client to get HTTP response from
     HTTP server. The default value is equivalent to System.Net.HttpWebRequest.Timeout. Type: string
     (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype http_request_timeout: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'http_request_timeout': {'key': 'httpRequestTimeout', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        http_request_timeout: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword http_request_timeout: Specifies the timeout for a HTTP client to get HTTP response
         from HTTP server. The default value is equivalent to System.Net.HttpWebRequest.Timeout. Type:
         string (or Expression with resultType string), pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype http_request_timeout: any
        """
        super(HttpSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'HttpSource'  # type: str
        self.http_request_timeout = http_request_timeout


class HubspotLinkedService(LinkedService):
    """Hubspot Service linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar client_id: Required. The client ID associated with your Hubspot application.
    :vartype client_id: any
    :ivar client_secret: The client secret associated with your Hubspot application.
    :vartype client_secret: ~azure.mgmt.datafactory.models.SecretBase
    :ivar access_token: The access token obtained when initiallyauthenticatingyourOAuth
     integration.
    :vartype access_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar refresh_token: The refresh token obtained when initiallyauthenticatingyourOAuth
     integration.
    :vartype refresh_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'object'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'access_token': {'key': 'typeProperties.accessToken', 'type': 'SecretBase'},
        'refresh_token': {'key': 'typeProperties.refreshToken', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        client_id: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        client_secret: Optional["SecretBase"] = None,
        access_token: Optional["SecretBase"] = None,
        refresh_token: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword client_id: Required. The client ID associated with your Hubspot application.
        :paramtype client_id: any
        :keyword client_secret: The client secret associated with your Hubspot application.
        :paramtype client_secret: ~azure.mgmt.datafactory.models.SecretBase
        :keyword access_token: The access token obtained when initiallyauthenticatingyourOAuth
         integration.
        :paramtype access_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword refresh_token: The refresh token obtained when initiallyauthenticatingyourOAuth
         integration.
        :paramtype refresh_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true.
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true.
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(HubspotLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Hubspot'  # type: str
        self.client_id = client_id
        self.client_secret = client_secret
        self.access_token = access_token
        self.refresh_token = refresh_token
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class HubspotObjectDataset(Dataset):
    """Hubspot Service dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(HubspotObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'HubspotObject'  # type: str
        self.table_name = table_name


class HubspotSource(TabularSource):
    """A copy activity Hubspot Service source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(HubspotSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'HubspotSource'  # type: str
        self.query = query


class IfConditionActivity(ControlActivity):
    """This activity evaluates a boolean expression and executes either the activities under the ifTrueActivities property or the ifFalseActivities property depending on the result of the expression.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar expression: Required. An expression that would evaluate to Boolean. This is used to
     determine the block of activities (ifTrueActivities or ifFalseActivities) that will be
     executed.
    :vartype expression: ~azure.mgmt.datafactory.models.Expression
    :ivar if_true_activities: List of activities to execute if expression is evaluated to true.
     This is an optional property and if not provided, the activity will exit without any action.
    :vartype if_true_activities: list[~azure.mgmt.datafactory.models.Activity]
    :ivar if_false_activities: List of activities to execute if expression is evaluated to false.
     This is an optional property and if not provided, the activity will exit without any action.
    :vartype if_false_activities: list[~azure.mgmt.datafactory.models.Activity]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'expression': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'expression': {'key': 'typeProperties.expression', 'type': 'Expression'},
        'if_true_activities': {'key': 'typeProperties.ifTrueActivities', 'type': '[Activity]'},
        'if_false_activities': {'key': 'typeProperties.ifFalseActivities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        name: str,
        expression: "Expression",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        if_true_activities: Optional[List["Activity"]] = None,
        if_false_activities: Optional[List["Activity"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword expression: Required. An expression that would evaluate to Boolean. This is used to
         determine the block of activities (ifTrueActivities or ifFalseActivities) that will be
         executed.
        :paramtype expression: ~azure.mgmt.datafactory.models.Expression
        :keyword if_true_activities: List of activities to execute if expression is evaluated to true.
         This is an optional property and if not provided, the activity will exit without any action.
        :paramtype if_true_activities: list[~azure.mgmt.datafactory.models.Activity]
        :keyword if_false_activities: List of activities to execute if expression is evaluated to
         false. This is an optional property and if not provided, the activity will exit without any
         action.
        :paramtype if_false_activities: list[~azure.mgmt.datafactory.models.Activity]
        """
        super(IfConditionActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'IfCondition'  # type: str
        self.expression = expression
        self.if_true_activities = if_true_activities
        self.if_false_activities = if_false_activities


class ImpalaLinkedService(LinkedService):
    """Impala server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. The IP address or host name of the Impala server. (i.e. 192.168.222.160).
    :vartype host: any
    :ivar port: The TCP port that the Impala server uses to listen for client connections. The
     default value is 21050.
    :vartype port: any
    :ivar authentication_type: Required. The authentication type to use. Possible values include:
     "Anonymous", "SASLUsername", "UsernameAndPassword".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.ImpalaAuthenticationType
    :ivar username: The user name used to access the Impala server. The default value is anonymous
     when using SASLUsername.
    :vartype username: any
    :ivar password: The password corresponding to the user name when using UsernameAndPassword.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :vartype enable_ssl: any
    :ivar trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :vartype trusted_cert_path: any
    :ivar use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :vartype use_system_trust_store: any
    :ivar allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :vartype allow_host_name_cn_mismatch: any
    :ivar allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :vartype allow_self_signed_server_cert: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'object'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'object'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'object'},
        'allow_host_name_cn_mismatch': {'key': 'typeProperties.allowHostNameCNMismatch', 'type': 'object'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        authentication_type: Union[str, "ImpalaAuthenticationType"],
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        port: Optional[Any] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        enable_ssl: Optional[Any] = None,
        trusted_cert_path: Optional[Any] = None,
        use_system_trust_store: Optional[Any] = None,
        allow_host_name_cn_mismatch: Optional[Any] = None,
        allow_self_signed_server_cert: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. The IP address or host name of the Impala server. (i.e.
         192.168.222.160).
        :paramtype host: any
        :keyword port: The TCP port that the Impala server uses to listen for client connections. The
         default value is 21050.
        :paramtype port: any
        :keyword authentication_type: Required. The authentication type to use. Possible values
         include: "Anonymous", "SASLUsername", "UsernameAndPassword".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.ImpalaAuthenticationType
        :keyword username: The user name used to access the Impala server. The default value is
         anonymous when using SASLUsername.
        :paramtype username: any
        :keyword password: The password corresponding to the user name when using UsernameAndPassword.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword enable_ssl: Specifies whether the connections to the server are encrypted using SSL.
         The default value is false.
        :paramtype enable_ssl: any
        :keyword trusted_cert_path: The full path of the .pem file containing trusted CA certificates
         for verifying the server when connecting over SSL. This property can only be set when using SSL
         on self-hosted IR. The default value is the cacerts.pem file installed with the IR.
        :paramtype trusted_cert_path: any
        :keyword use_system_trust_store: Specifies whether to use a CA certificate from the system
         trust store or from a specified PEM file. The default value is false.
        :paramtype use_system_trust_store: any
        :keyword allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
         name to match the host name of the server when connecting over SSL. The default value is false.
        :paramtype allow_host_name_cn_mismatch: any
        :keyword allow_self_signed_server_cert: Specifies whether to allow self-signed certificates
         from the server. The default value is false.
        :paramtype allow_self_signed_server_cert: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(ImpalaLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Impala'  # type: str
        self.host = host
        self.port = port
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class ImpalaObjectDataset(Dataset):
    """Impala server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar table: The table name of the Impala. Type: string (or Expression with resultType string).
    :vartype table: any
    :ivar schema_type_properties_schema: The schema name of the Impala. Type: string (or Expression
     with resultType string).
    :vartype schema_type_properties_schema: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword table: The table name of the Impala. Type: string (or Expression with resultType
         string).
        :paramtype table: any
        :keyword schema_type_properties_schema: The schema name of the Impala. Type: string (or
         Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        """
        super(ImpalaObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ImpalaObject'  # type: str
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class ImpalaSource(TabularSource):
    """A copy activity Impala server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(ImpalaSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'ImpalaSource'  # type: str
        self.query = query


class InformixLinkedService(LinkedService):
    """Informix linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The non-access credential portion of the connection string
     as well as an optional encrypted credential. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar authentication_type: Type of authentication used to connect to the Informix as ODBC data
     store. Possible values are: Anonymous and Basic. Type: string (or Expression with resultType
     string).
    :vartype authentication_type: any
    :ivar credential: The access credential portion of the connection string specified in
     driver-specific property-value format.
    :vartype credential: ~azure.mgmt.datafactory.models.SecretBase
    :ivar user_name: User name for Basic authentication. Type: string (or Expression with
     resultType string).
    :vartype user_name: any
    :ivar password: Password for Basic authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'SecretBase'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        authentication_type: Optional[Any] = None,
        credential: Optional["SecretBase"] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The non-access credential portion of the connection
         string as well as an optional encrypted credential. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword authentication_type: Type of authentication used to connect to the Informix as ODBC
         data store. Possible values are: Anonymous and Basic. Type: string (or Expression with
         resultType string).
        :paramtype authentication_type: any
        :keyword credential: The access credential portion of the connection string specified in
         driver-specific property-value format.
        :paramtype credential: ~azure.mgmt.datafactory.models.SecretBase
        :keyword user_name: User name for Basic authentication. Type: string (or Expression with
         resultType string).
        :paramtype user_name: any
        :keyword password: Password for Basic authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(InformixLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Informix'  # type: str
        self.connection_string = connection_string
        self.authentication_type = authentication_type
        self.credential = credential
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class InformixSink(CopySink):
    """A copy activity Informix sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar pre_copy_script: A query to execute before starting the copy. Type: string (or Expression
     with resultType string).
    :vartype pre_copy_script: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        pre_copy_script: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword pre_copy_script: A query to execute before starting the copy. Type: string (or
         Expression with resultType string).
        :paramtype pre_copy_script: any
        """
        super(InformixSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'InformixSink'  # type: str
        self.pre_copy_script = pre_copy_script


class InformixSource(TabularSource):
    """A copy activity source for Informix.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: Database query. Type: string (or Expression with resultType string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: Database query. Type: string (or Expression with resultType string).
        :paramtype query: any
        """
        super(InformixSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'InformixSource'  # type: str
        self.query = query


class InformixTableDataset(Dataset):
    """The Informix table dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The Informix table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The Informix table name. Type: string (or Expression with resultType
         string).
        :paramtype table_name: any
        """
        super(InformixTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'InformixTable'  # type: str
        self.table_name = table_name


class IntegrationRuntime(msrest.serialization.Model):
    """Azure Data Factory nested object which serves as a compute resource for activities.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: ManagedIntegrationRuntime, SelfHostedIntegrationRuntime.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of integration runtime.Constant filled by server. Possible values
     include: "Managed", "SelfHosted".
    :vartype type: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeType
    :ivar description: Integration runtime description.
    :vartype description: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'Managed': 'ManagedIntegrationRuntime', 'SelfHosted': 'SelfHostedIntegrationRuntime'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Integration runtime description.
        :paramtype description: str
        """
        super(IntegrationRuntime, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'IntegrationRuntime'  # type: str
        self.description = description


class IntegrationRuntimeAuthKeys(msrest.serialization.Model):
    """The integration runtime authentication keys.

    :ivar auth_key1: The primary integration runtime authentication key.
    :vartype auth_key1: str
    :ivar auth_key2: The secondary integration runtime authentication key.
    :vartype auth_key2: str
    """

    _attribute_map = {
        'auth_key1': {'key': 'authKey1', 'type': 'str'},
        'auth_key2': {'key': 'authKey2', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        auth_key1: Optional[str] = None,
        auth_key2: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword auth_key1: The primary integration runtime authentication key.
        :paramtype auth_key1: str
        :keyword auth_key2: The secondary integration runtime authentication key.
        :paramtype auth_key2: str
        """
        super(IntegrationRuntimeAuthKeys, self).__init__(**kwargs)
        self.auth_key1 = auth_key1
        self.auth_key2 = auth_key2


class IntegrationRuntimeComputeProperties(msrest.serialization.Model):
    """The compute resource properties for managed integration runtime.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar location: The location for managed integration runtime. The supported regions could be
     found on
     https://docs.microsoft.com/en-us/azure/data-factory/data-factory-data-movement-activities.
    :vartype location: str
    :ivar node_size: The node size requirement to managed integration runtime.
    :vartype node_size: str
    :ivar number_of_nodes: The required number of nodes for managed integration runtime.
    :vartype number_of_nodes: int
    :ivar max_parallel_executions_per_node: Maximum parallel executions count per node for managed
     integration runtime.
    :vartype max_parallel_executions_per_node: int
    :ivar data_flow_properties: Data flow properties for managed integration runtime.
    :vartype data_flow_properties:
     ~azure.mgmt.datafactory.models.IntegrationRuntimeDataFlowProperties
    :ivar v_net_properties: VNet properties for managed integration runtime.
    :vartype v_net_properties: ~azure.mgmt.datafactory.models.IntegrationRuntimeVNetProperties
    """

    _validation = {
        'number_of_nodes': {'minimum': 1},
        'max_parallel_executions_per_node': {'minimum': 1},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'location': {'key': 'location', 'type': 'str'},
        'node_size': {'key': 'nodeSize', 'type': 'str'},
        'number_of_nodes': {'key': 'numberOfNodes', 'type': 'int'},
        'max_parallel_executions_per_node': {'key': 'maxParallelExecutionsPerNode', 'type': 'int'},
        'data_flow_properties': {'key': 'dataFlowProperties', 'type': 'IntegrationRuntimeDataFlowProperties'},
        'v_net_properties': {'key': 'vNetProperties', 'type': 'IntegrationRuntimeVNetProperties'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        location: Optional[str] = None,
        node_size: Optional[str] = None,
        number_of_nodes: Optional[int] = None,
        max_parallel_executions_per_node: Optional[int] = None,
        data_flow_properties: Optional["IntegrationRuntimeDataFlowProperties"] = None,
        v_net_properties: Optional["IntegrationRuntimeVNetProperties"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword location: The location for managed integration runtime. The supported regions could be
         found on
         https://docs.microsoft.com/en-us/azure/data-factory/data-factory-data-movement-activities.
        :paramtype location: str
        :keyword node_size: The node size requirement to managed integration runtime.
        :paramtype node_size: str
        :keyword number_of_nodes: The required number of nodes for managed integration runtime.
        :paramtype number_of_nodes: int
        :keyword max_parallel_executions_per_node: Maximum parallel executions count per node for
         managed integration runtime.
        :paramtype max_parallel_executions_per_node: int
        :keyword data_flow_properties: Data flow properties for managed integration runtime.
        :paramtype data_flow_properties:
         ~azure.mgmt.datafactory.models.IntegrationRuntimeDataFlowProperties
        :keyword v_net_properties: VNet properties for managed integration runtime.
        :paramtype v_net_properties: ~azure.mgmt.datafactory.models.IntegrationRuntimeVNetProperties
        """
        super(IntegrationRuntimeComputeProperties, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.location = location
        self.node_size = node_size
        self.number_of_nodes = number_of_nodes
        self.max_parallel_executions_per_node = max_parallel_executions_per_node
        self.data_flow_properties = data_flow_properties
        self.v_net_properties = v_net_properties


class IntegrationRuntimeConnectionInfo(msrest.serialization.Model):
    """Connection information for encrypting the on-premises data source credentials.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar service_token: The token generated in service. Callers use this token to authenticate to
     integration runtime.
    :vartype service_token: str
    :ivar identity_cert_thumbprint: The integration runtime SSL certificate thumbprint. Click-Once
     application uses it to do server validation.
    :vartype identity_cert_thumbprint: str
    :ivar host_service_uri: The on-premises integration runtime host URL.
    :vartype host_service_uri: str
    :ivar version: The integration runtime version.
    :vartype version: str
    :ivar public_key: The public key for encrypting a credential when transferring the credential
     to the integration runtime.
    :vartype public_key: str
    :ivar is_identity_cert_exprired: Whether the identity certificate is expired.
    :vartype is_identity_cert_exprired: bool
    """

    _validation = {
        'service_token': {'readonly': True},
        'identity_cert_thumbprint': {'readonly': True},
        'host_service_uri': {'readonly': True},
        'version': {'readonly': True},
        'public_key': {'readonly': True},
        'is_identity_cert_exprired': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'service_token': {'key': 'serviceToken', 'type': 'str'},
        'identity_cert_thumbprint': {'key': 'identityCertThumbprint', 'type': 'str'},
        'host_service_uri': {'key': 'hostServiceUri', 'type': 'str'},
        'version': {'key': 'version', 'type': 'str'},
        'public_key': {'key': 'publicKey', 'type': 'str'},
        'is_identity_cert_exprired': {'key': 'isIdentityCertExprired', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(IntegrationRuntimeConnectionInfo, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.service_token = None
        self.identity_cert_thumbprint = None
        self.host_service_uri = None
        self.version = None
        self.public_key = None
        self.is_identity_cert_exprired = None


class IntegrationRuntimeCustomerVirtualNetwork(msrest.serialization.Model):
    """The definition and properties of virtual network to which Azure-SSIS integration runtime will join.

    :ivar subnet_id: The ID of subnet to which Azure-SSIS integration runtime will join.
    :vartype subnet_id: str
    """

    _attribute_map = {
        'subnet_id': {'key': 'subnetId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        subnet_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword subnet_id: The ID of subnet to which Azure-SSIS integration runtime will join.
        :paramtype subnet_id: str
        """
        super(IntegrationRuntimeCustomerVirtualNetwork, self).__init__(**kwargs)
        self.subnet_id = subnet_id


class IntegrationRuntimeCustomSetupScriptProperties(msrest.serialization.Model):
    """Custom setup script properties for a managed dedicated integration runtime.

    :ivar blob_container_uri: The URI of the Azure blob container that contains the custom setup
     script.
    :vartype blob_container_uri: str
    :ivar sas_token: The SAS token of the Azure blob container.
    :vartype sas_token: ~azure.mgmt.datafactory.models.SecureString
    """

    _attribute_map = {
        'blob_container_uri': {'key': 'blobContainerUri', 'type': 'str'},
        'sas_token': {'key': 'sasToken', 'type': 'SecureString'},
    }

    def __init__(
        self,
        *,
        blob_container_uri: Optional[str] = None,
        sas_token: Optional["SecureString"] = None,
        **kwargs
    ):
        """
        :keyword blob_container_uri: The URI of the Azure blob container that contains the custom setup
         script.
        :paramtype blob_container_uri: str
        :keyword sas_token: The SAS token of the Azure blob container.
        :paramtype sas_token: ~azure.mgmt.datafactory.models.SecureString
        """
        super(IntegrationRuntimeCustomSetupScriptProperties, self).__init__(**kwargs)
        self.blob_container_uri = blob_container_uri
        self.sas_token = sas_token


class IntegrationRuntimeDataFlowProperties(msrest.serialization.Model):
    """Data flow properties for managed integration runtime.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar compute_type: Compute type of the cluster which will execute data flow job. Possible
     values include: "General", "MemoryOptimized", "ComputeOptimized".
    :vartype compute_type: str or ~azure.mgmt.datafactory.models.DataFlowComputeType
    :ivar core_count: Core count of the cluster which will execute data flow job. Supported values
     are: 8, 16, 32, 48, 80, 144 and 272.
    :vartype core_count: int
    :ivar time_to_live: Time to live (in minutes) setting of the cluster which will execute data
     flow job.
    :vartype time_to_live: int
    :ivar cleanup: Cluster will not be recycled and it will be used in next data flow activity run
     until TTL (time to live) is reached if this is set as false. Default is true.
    :vartype cleanup: bool
    """

    _validation = {
        'time_to_live': {'minimum': 0},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'compute_type': {'key': 'computeType', 'type': 'str'},
        'core_count': {'key': 'coreCount', 'type': 'int'},
        'time_to_live': {'key': 'timeToLive', 'type': 'int'},
        'cleanup': {'key': 'cleanup', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        compute_type: Optional[Union[str, "DataFlowComputeType"]] = None,
        core_count: Optional[int] = None,
        time_to_live: Optional[int] = None,
        cleanup: Optional[bool] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword compute_type: Compute type of the cluster which will execute data flow job. Possible
         values include: "General", "MemoryOptimized", "ComputeOptimized".
        :paramtype compute_type: str or ~azure.mgmt.datafactory.models.DataFlowComputeType
        :keyword core_count: Core count of the cluster which will execute data flow job. Supported
         values are: 8, 16, 32, 48, 80, 144 and 272.
        :paramtype core_count: int
        :keyword time_to_live: Time to live (in minutes) setting of the cluster which will execute data
         flow job.
        :paramtype time_to_live: int
        :keyword cleanup: Cluster will not be recycled and it will be used in next data flow activity
         run until TTL (time to live) is reached if this is set as false. Default is true.
        :paramtype cleanup: bool
        """
        super(IntegrationRuntimeDataFlowProperties, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.compute_type = compute_type
        self.core_count = core_count
        self.time_to_live = time_to_live
        self.cleanup = cleanup


class IntegrationRuntimeDataProxyProperties(msrest.serialization.Model):
    """Data proxy properties for a managed dedicated integration runtime.

    :ivar connect_via: The self-hosted integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.EntityReference
    :ivar staging_linked_service: The staging linked service reference.
    :vartype staging_linked_service: ~azure.mgmt.datafactory.models.EntityReference
    :ivar path: The path to contain the staged data in the Blob storage.
    :vartype path: str
    """

    _attribute_map = {
        'connect_via': {'key': 'connectVia', 'type': 'EntityReference'},
        'staging_linked_service': {'key': 'stagingLinkedService', 'type': 'EntityReference'},
        'path': {'key': 'path', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        connect_via: Optional["EntityReference"] = None,
        staging_linked_service: Optional["EntityReference"] = None,
        path: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connect_via: The self-hosted integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.EntityReference
        :keyword staging_linked_service: The staging linked service reference.
        :paramtype staging_linked_service: ~azure.mgmt.datafactory.models.EntityReference
        :keyword path: The path to contain the staged data in the Blob storage.
        :paramtype path: str
        """
        super(IntegrationRuntimeDataProxyProperties, self).__init__(**kwargs)
        self.connect_via = connect_via
        self.staging_linked_service = staging_linked_service
        self.path = path


class IntegrationRuntimeDebugResource(SubResourceDebugResource):
    """Integration runtime debug resource.

    All required parameters must be populated in order to send to Azure.

    :ivar name: The resource name.
    :vartype name: str
    :ivar properties: Required. Integration runtime properties.
    :vartype properties: ~azure.mgmt.datafactory.models.IntegrationRuntime
    """

    _validation = {
        'properties': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'IntegrationRuntime'},
    }

    def __init__(
        self,
        *,
        properties: "IntegrationRuntime",
        name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword name: The resource name.
        :paramtype name: str
        :keyword properties: Required. Integration runtime properties.
        :paramtype properties: ~azure.mgmt.datafactory.models.IntegrationRuntime
        """
        super(IntegrationRuntimeDebugResource, self).__init__(name=name, **kwargs)
        self.properties = properties


class IntegrationRuntimeListResponse(msrest.serialization.Model):
    """A list of integration runtime resources.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of integration runtimes.
    :vartype value: list[~azure.mgmt.datafactory.models.IntegrationRuntimeResource]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[IntegrationRuntimeResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["IntegrationRuntimeResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of integration runtimes.
        :paramtype value: list[~azure.mgmt.datafactory.models.IntegrationRuntimeResource]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(IntegrationRuntimeListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class IntegrationRuntimeMonitoringData(msrest.serialization.Model):
    """Get monitoring data response.

    :ivar name: Integration runtime name.
    :vartype name: str
    :ivar nodes: Integration runtime node monitoring data.
    :vartype nodes: list[~azure.mgmt.datafactory.models.IntegrationRuntimeNodeMonitoringData]
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'nodes': {'key': 'nodes', 'type': '[IntegrationRuntimeNodeMonitoringData]'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        nodes: Optional[List["IntegrationRuntimeNodeMonitoringData"]] = None,
        **kwargs
    ):
        """
        :keyword name: Integration runtime name.
        :paramtype name: str
        :keyword nodes: Integration runtime node monitoring data.
        :paramtype nodes: list[~azure.mgmt.datafactory.models.IntegrationRuntimeNodeMonitoringData]
        """
        super(IntegrationRuntimeMonitoringData, self).__init__(**kwargs)
        self.name = name
        self.nodes = nodes


class IntegrationRuntimeNodeIpAddress(msrest.serialization.Model):
    """The IP address of self-hosted integration runtime node.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar ip_address: The IP address of self-hosted integration runtime node.
    :vartype ip_address: str
    """

    _validation = {
        'ip_address': {'readonly': True},
    }

    _attribute_map = {
        'ip_address': {'key': 'ipAddress', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(IntegrationRuntimeNodeIpAddress, self).__init__(**kwargs)
        self.ip_address = None


class IntegrationRuntimeNodeMonitoringData(msrest.serialization.Model):
    """Monitoring data for integration runtime node.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar node_name: Name of the integration runtime node.
    :vartype node_name: str
    :ivar available_memory_in_mb: Available memory (MB) on the integration runtime node.
    :vartype available_memory_in_mb: int
    :ivar cpu_utilization: CPU percentage on the integration runtime node.
    :vartype cpu_utilization: int
    :ivar concurrent_jobs_limit: Maximum concurrent jobs on the integration runtime node.
    :vartype concurrent_jobs_limit: int
    :ivar concurrent_jobs_running: The number of jobs currently running on the integration runtime
     node.
    :vartype concurrent_jobs_running: int
    :ivar max_concurrent_jobs: The maximum concurrent jobs in this integration runtime.
    :vartype max_concurrent_jobs: int
    :ivar sent_bytes: Sent bytes on the integration runtime node.
    :vartype sent_bytes: float
    :ivar received_bytes: Received bytes on the integration runtime node.
    :vartype received_bytes: float
    """

    _validation = {
        'node_name': {'readonly': True},
        'available_memory_in_mb': {'readonly': True},
        'cpu_utilization': {'readonly': True},
        'concurrent_jobs_limit': {'readonly': True},
        'concurrent_jobs_running': {'readonly': True},
        'max_concurrent_jobs': {'readonly': True},
        'sent_bytes': {'readonly': True},
        'received_bytes': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'node_name': {'key': 'nodeName', 'type': 'str'},
        'available_memory_in_mb': {'key': 'availableMemoryInMB', 'type': 'int'},
        'cpu_utilization': {'key': 'cpuUtilization', 'type': 'int'},
        'concurrent_jobs_limit': {'key': 'concurrentJobsLimit', 'type': 'int'},
        'concurrent_jobs_running': {'key': 'concurrentJobsRunning', 'type': 'int'},
        'max_concurrent_jobs': {'key': 'maxConcurrentJobs', 'type': 'int'},
        'sent_bytes': {'key': 'sentBytes', 'type': 'float'},
        'received_bytes': {'key': 'receivedBytes', 'type': 'float'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(IntegrationRuntimeNodeMonitoringData, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.node_name = None
        self.available_memory_in_mb = None
        self.cpu_utilization = None
        self.concurrent_jobs_limit = None
        self.concurrent_jobs_running = None
        self.max_concurrent_jobs = None
        self.sent_bytes = None
        self.received_bytes = None


class IntegrationRuntimeOutboundNetworkDependenciesCategoryEndpoint(msrest.serialization.Model):
    """Azure-SSIS integration runtime outbound network dependency endpoints for one category.

    :ivar category: The category of outbound network dependency.
    :vartype category: str
    :ivar endpoints: The endpoints for outbound network dependency.
    :vartype endpoints:
     list[~azure.mgmt.datafactory.models.IntegrationRuntimeOutboundNetworkDependenciesEndpoint]
    """

    _attribute_map = {
        'category': {'key': 'category', 'type': 'str'},
        'endpoints': {'key': 'endpoints', 'type': '[IntegrationRuntimeOutboundNetworkDependenciesEndpoint]'},
    }

    def __init__(
        self,
        *,
        category: Optional[str] = None,
        endpoints: Optional[List["IntegrationRuntimeOutboundNetworkDependenciesEndpoint"]] = None,
        **kwargs
    ):
        """
        :keyword category: The category of outbound network dependency.
        :paramtype category: str
        :keyword endpoints: The endpoints for outbound network dependency.
        :paramtype endpoints:
         list[~azure.mgmt.datafactory.models.IntegrationRuntimeOutboundNetworkDependenciesEndpoint]
        """
        super(IntegrationRuntimeOutboundNetworkDependenciesCategoryEndpoint, self).__init__(**kwargs)
        self.category = category
        self.endpoints = endpoints


class IntegrationRuntimeOutboundNetworkDependenciesEndpoint(msrest.serialization.Model):
    """The endpoint for Azure-SSIS integration runtime outbound network dependency.

    :ivar domain_name: The domain name of endpoint.
    :vartype domain_name: str
    :ivar endpoint_details: The details of endpoint.
    :vartype endpoint_details:
     list[~azure.mgmt.datafactory.models.IntegrationRuntimeOutboundNetworkDependenciesEndpointDetails]
    """

    _attribute_map = {
        'domain_name': {'key': 'domainName', 'type': 'str'},
        'endpoint_details': {'key': 'endpointDetails', 'type': '[IntegrationRuntimeOutboundNetworkDependenciesEndpointDetails]'},
    }

    def __init__(
        self,
        *,
        domain_name: Optional[str] = None,
        endpoint_details: Optional[List["IntegrationRuntimeOutboundNetworkDependenciesEndpointDetails"]] = None,
        **kwargs
    ):
        """
        :keyword domain_name: The domain name of endpoint.
        :paramtype domain_name: str
        :keyword endpoint_details: The details of endpoint.
        :paramtype endpoint_details:
         list[~azure.mgmt.datafactory.models.IntegrationRuntimeOutboundNetworkDependenciesEndpointDetails]
        """
        super(IntegrationRuntimeOutboundNetworkDependenciesEndpoint, self).__init__(**kwargs)
        self.domain_name = domain_name
        self.endpoint_details = endpoint_details


class IntegrationRuntimeOutboundNetworkDependenciesEndpointDetails(msrest.serialization.Model):
    """The details of Azure-SSIS integration runtime outbound network dependency endpoint.

    :ivar port: The port of endpoint.
    :vartype port: int
    """

    _attribute_map = {
        'port': {'key': 'port', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        port: Optional[int] = None,
        **kwargs
    ):
        """
        :keyword port: The port of endpoint.
        :paramtype port: int
        """
        super(IntegrationRuntimeOutboundNetworkDependenciesEndpointDetails, self).__init__(**kwargs)
        self.port = port


class IntegrationRuntimeOutboundNetworkDependenciesEndpointsResponse(msrest.serialization.Model):
    """Azure-SSIS integration runtime outbound network dependency endpoints.

    :ivar value: The list of outbound network dependency endpoints.
    :vartype value:
     list[~azure.mgmt.datafactory.models.IntegrationRuntimeOutboundNetworkDependenciesCategoryEndpoint]
    """

    _attribute_map = {
        'value': {'key': 'value', 'type': '[IntegrationRuntimeOutboundNetworkDependenciesCategoryEndpoint]'},
    }

    def __init__(
        self,
        *,
        value: Optional[List["IntegrationRuntimeOutboundNetworkDependenciesCategoryEndpoint"]] = None,
        **kwargs
    ):
        """
        :keyword value: The list of outbound network dependency endpoints.
        :paramtype value:
         list[~azure.mgmt.datafactory.models.IntegrationRuntimeOutboundNetworkDependenciesCategoryEndpoint]
        """
        super(IntegrationRuntimeOutboundNetworkDependenciesEndpointsResponse, self).__init__(**kwargs)
        self.value = value


class IntegrationRuntimeReference(msrest.serialization.Model):
    """Integration runtime reference type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Type of integration runtime. Has constant value: "IntegrationRuntimeReference".
    :vartype type: str
    :ivar reference_name: Required. Reference integration runtime name.
    :vartype reference_name: str
    :ivar parameters: Arguments for integration runtime.
    :vartype parameters: dict[str, any]
    """

    _validation = {
        'type': {'required': True, 'constant': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{object}'},
    }

    type = "IntegrationRuntimeReference"

    def __init__(
        self,
        *,
        reference_name: str,
        parameters: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword reference_name: Required. Reference integration runtime name.
        :paramtype reference_name: str
        :keyword parameters: Arguments for integration runtime.
        :paramtype parameters: dict[str, any]
        """
        super(IntegrationRuntimeReference, self).__init__(**kwargs)
        self.reference_name = reference_name
        self.parameters = parameters


class IntegrationRuntimeRegenerateKeyParameters(msrest.serialization.Model):
    """Parameters to regenerate the authentication key.

    :ivar key_name: The name of the authentication key to regenerate. Possible values include:
     "authKey1", "authKey2".
    :vartype key_name: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeAuthKeyName
    """

    _attribute_map = {
        'key_name': {'key': 'keyName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        key_name: Optional[Union[str, "IntegrationRuntimeAuthKeyName"]] = None,
        **kwargs
    ):
        """
        :keyword key_name: The name of the authentication key to regenerate. Possible values include:
         "authKey1", "authKey2".
        :paramtype key_name: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeAuthKeyName
        """
        super(IntegrationRuntimeRegenerateKeyParameters, self).__init__(**kwargs)
        self.key_name = key_name


class IntegrationRuntimeResource(SubResource):
    """Integration runtime resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :ivar properties: Required. Integration runtime properties.
    :vartype properties: ~azure.mgmt.datafactory.models.IntegrationRuntime
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'IntegrationRuntime'},
    }

    def __init__(
        self,
        *,
        properties: "IntegrationRuntime",
        **kwargs
    ):
        """
        :keyword properties: Required. Integration runtime properties.
        :paramtype properties: ~azure.mgmt.datafactory.models.IntegrationRuntime
        """
        super(IntegrationRuntimeResource, self).__init__(**kwargs)
        self.properties = properties


class IntegrationRuntimeSsisCatalogInfo(msrest.serialization.Model):
    """Catalog information for managed dedicated integration runtime.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar catalog_server_endpoint: The catalog database server URL.
    :vartype catalog_server_endpoint: str
    :ivar catalog_admin_user_name: The administrator user name of catalog database.
    :vartype catalog_admin_user_name: str
    :ivar catalog_admin_password: The password of the administrator user account of the catalog
     database.
    :vartype catalog_admin_password: ~azure.mgmt.datafactory.models.SecureString
    :ivar catalog_pricing_tier: The pricing tier for the catalog database. The valid values could
     be found in https://azure.microsoft.com/en-us/pricing/details/sql-database/. Possible values
     include: "Basic", "Standard", "Premium", "PremiumRS".
    :vartype catalog_pricing_tier: str or
     ~azure.mgmt.datafactory.models.IntegrationRuntimeSsisCatalogPricingTier
    :ivar dual_standby_pair_name: The dual standby pair name of Azure-SSIS Integration Runtimes to
     support SSISDB failover.
    :vartype dual_standby_pair_name: str
    """

    _validation = {
        'catalog_admin_user_name': {'max_length': 128, 'min_length': 1},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'catalog_server_endpoint': {'key': 'catalogServerEndpoint', 'type': 'str'},
        'catalog_admin_user_name': {'key': 'catalogAdminUserName', 'type': 'str'},
        'catalog_admin_password': {'key': 'catalogAdminPassword', 'type': 'SecureString'},
        'catalog_pricing_tier': {'key': 'catalogPricingTier', 'type': 'str'},
        'dual_standby_pair_name': {'key': 'dualStandbyPairName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        catalog_server_endpoint: Optional[str] = None,
        catalog_admin_user_name: Optional[str] = None,
        catalog_admin_password: Optional["SecureString"] = None,
        catalog_pricing_tier: Optional[Union[str, "IntegrationRuntimeSsisCatalogPricingTier"]] = None,
        dual_standby_pair_name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword catalog_server_endpoint: The catalog database server URL.
        :paramtype catalog_server_endpoint: str
        :keyword catalog_admin_user_name: The administrator user name of catalog database.
        :paramtype catalog_admin_user_name: str
        :keyword catalog_admin_password: The password of the administrator user account of the catalog
         database.
        :paramtype catalog_admin_password: ~azure.mgmt.datafactory.models.SecureString
        :keyword catalog_pricing_tier: The pricing tier for the catalog database. The valid values
         could be found in https://azure.microsoft.com/en-us/pricing/details/sql-database/. Possible
         values include: "Basic", "Standard", "Premium", "PremiumRS".
        :paramtype catalog_pricing_tier: str or
         ~azure.mgmt.datafactory.models.IntegrationRuntimeSsisCatalogPricingTier
        :keyword dual_standby_pair_name: The dual standby pair name of Azure-SSIS Integration Runtimes
         to support SSISDB failover.
        :paramtype dual_standby_pair_name: str
        """
        super(IntegrationRuntimeSsisCatalogInfo, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.catalog_server_endpoint = catalog_server_endpoint
        self.catalog_admin_user_name = catalog_admin_user_name
        self.catalog_admin_password = catalog_admin_password
        self.catalog_pricing_tier = catalog_pricing_tier
        self.dual_standby_pair_name = dual_standby_pair_name


class IntegrationRuntimeSsisProperties(msrest.serialization.Model):
    """SSIS properties for managed integration runtime.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar catalog_info: Catalog information for managed dedicated integration runtime.
    :vartype catalog_info: ~azure.mgmt.datafactory.models.IntegrationRuntimeSsisCatalogInfo
    :ivar license_type: License type for bringing your own license scenario. Possible values
     include: "BasePrice", "LicenseIncluded".
    :vartype license_type: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeLicenseType
    :ivar custom_setup_script_properties: Custom setup script properties for a managed dedicated
     integration runtime.
    :vartype custom_setup_script_properties:
     ~azure.mgmt.datafactory.models.IntegrationRuntimeCustomSetupScriptProperties
    :ivar data_proxy_properties: Data proxy properties for a managed dedicated integration runtime.
    :vartype data_proxy_properties:
     ~azure.mgmt.datafactory.models.IntegrationRuntimeDataProxyProperties
    :ivar edition: The edition for the SSIS Integration Runtime. Possible values include:
     "Standard", "Enterprise".
    :vartype edition: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeEdition
    :ivar express_custom_setup_properties: Custom setup without script properties for a SSIS
     integration runtime.
    :vartype express_custom_setup_properties: list[~azure.mgmt.datafactory.models.CustomSetupBase]
    :ivar package_stores: Package stores for the SSIS Integration Runtime.
    :vartype package_stores: list[~azure.mgmt.datafactory.models.PackageStore]
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'catalog_info': {'key': 'catalogInfo', 'type': 'IntegrationRuntimeSsisCatalogInfo'},
        'license_type': {'key': 'licenseType', 'type': 'str'},
        'custom_setup_script_properties': {'key': 'customSetupScriptProperties', 'type': 'IntegrationRuntimeCustomSetupScriptProperties'},
        'data_proxy_properties': {'key': 'dataProxyProperties', 'type': 'IntegrationRuntimeDataProxyProperties'},
        'edition': {'key': 'edition', 'type': 'str'},
        'express_custom_setup_properties': {'key': 'expressCustomSetupProperties', 'type': '[CustomSetupBase]'},
        'package_stores': {'key': 'packageStores', 'type': '[PackageStore]'},
        'credential': {'key': 'credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        catalog_info: Optional["IntegrationRuntimeSsisCatalogInfo"] = None,
        license_type: Optional[Union[str, "IntegrationRuntimeLicenseType"]] = None,
        custom_setup_script_properties: Optional["IntegrationRuntimeCustomSetupScriptProperties"] = None,
        data_proxy_properties: Optional["IntegrationRuntimeDataProxyProperties"] = None,
        edition: Optional[Union[str, "IntegrationRuntimeEdition"]] = None,
        express_custom_setup_properties: Optional[List["CustomSetupBase"]] = None,
        package_stores: Optional[List["PackageStore"]] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword catalog_info: Catalog information for managed dedicated integration runtime.
        :paramtype catalog_info: ~azure.mgmt.datafactory.models.IntegrationRuntimeSsisCatalogInfo
        :keyword license_type: License type for bringing your own license scenario. Possible values
         include: "BasePrice", "LicenseIncluded".
        :paramtype license_type: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeLicenseType
        :keyword custom_setup_script_properties: Custom setup script properties for a managed dedicated
         integration runtime.
        :paramtype custom_setup_script_properties:
         ~azure.mgmt.datafactory.models.IntegrationRuntimeCustomSetupScriptProperties
        :keyword data_proxy_properties: Data proxy properties for a managed dedicated integration
         runtime.
        :paramtype data_proxy_properties:
         ~azure.mgmt.datafactory.models.IntegrationRuntimeDataProxyProperties
        :keyword edition: The edition for the SSIS Integration Runtime. Possible values include:
         "Standard", "Enterprise".
        :paramtype edition: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeEdition
        :keyword express_custom_setup_properties: Custom setup without script properties for a SSIS
         integration runtime.
        :paramtype express_custom_setup_properties:
         list[~azure.mgmt.datafactory.models.CustomSetupBase]
        :keyword package_stores: Package stores for the SSIS Integration Runtime.
        :paramtype package_stores: list[~azure.mgmt.datafactory.models.PackageStore]
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(IntegrationRuntimeSsisProperties, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.catalog_info = catalog_info
        self.license_type = license_type
        self.custom_setup_script_properties = custom_setup_script_properties
        self.data_proxy_properties = data_proxy_properties
        self.edition = edition
        self.express_custom_setup_properties = express_custom_setup_properties
        self.package_stores = package_stores
        self.credential = credential


class IntegrationRuntimeStatus(msrest.serialization.Model):
    """Integration runtime status.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: ManagedIntegrationRuntimeStatus, SelfHostedIntegrationRuntimeStatus.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of integration runtime.Constant filled by server. Possible values
     include: "Managed", "SelfHosted".
    :vartype type: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeType
    :ivar data_factory_name: The data factory name which the integration runtime belong to.
    :vartype data_factory_name: str
    :ivar state: The state of integration runtime. Possible values include: "Initial", "Stopped",
     "Started", "Starting", "Stopping", "NeedRegistration", "Online", "Limited", "Offline",
     "AccessDenied".
    :vartype state: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeState
    """

    _validation = {
        'type': {'required': True},
        'data_factory_name': {'readonly': True},
        'state': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'data_factory_name': {'key': 'dataFactoryName', 'type': 'str'},
        'state': {'key': 'state', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'Managed': 'ManagedIntegrationRuntimeStatus', 'SelfHosted': 'SelfHostedIntegrationRuntimeStatus'}
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(IntegrationRuntimeStatus, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = 'IntegrationRuntimeStatus'  # type: str
        self.data_factory_name = None
        self.state = None


class IntegrationRuntimeStatusListResponse(msrest.serialization.Model):
    """A list of integration runtime status.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of integration runtime status.
    :vartype value: list[~azure.mgmt.datafactory.models.IntegrationRuntimeStatusResponse]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[IntegrationRuntimeStatusResponse]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["IntegrationRuntimeStatusResponse"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of integration runtime status.
        :paramtype value: list[~azure.mgmt.datafactory.models.IntegrationRuntimeStatusResponse]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(IntegrationRuntimeStatusListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class IntegrationRuntimeStatusResponse(msrest.serialization.Model):
    """Integration runtime status response.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar name: The integration runtime name.
    :vartype name: str
    :ivar properties: Required. Integration runtime properties.
    :vartype properties: ~azure.mgmt.datafactory.models.IntegrationRuntimeStatus
    """

    _validation = {
        'name': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'IntegrationRuntimeStatus'},
    }

    def __init__(
        self,
        *,
        properties: "IntegrationRuntimeStatus",
        **kwargs
    ):
        """
        :keyword properties: Required. Integration runtime properties.
        :paramtype properties: ~azure.mgmt.datafactory.models.IntegrationRuntimeStatus
        """
        super(IntegrationRuntimeStatusResponse, self).__init__(**kwargs)
        self.name = None
        self.properties = properties


class IntegrationRuntimeVNetProperties(msrest.serialization.Model):
    """VNet properties for managed integration runtime.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar v_net_id: The ID of the VNet that this integration runtime will join.
    :vartype v_net_id: str
    :ivar subnet: The name of the subnet this integration runtime will join.
    :vartype subnet: str
    :ivar public_i_ps: Resource IDs of the public IP addresses that this integration runtime will
     use.
    :vartype public_i_ps: list[str]
    :ivar subnet_id: The ID of subnet, to which this Azure-SSIS integration runtime will be joined.
    :vartype subnet_id: str
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'v_net_id': {'key': 'vNetId', 'type': 'str'},
        'subnet': {'key': 'subnet', 'type': 'str'},
        'public_i_ps': {'key': 'publicIPs', 'type': '[str]'},
        'subnet_id': {'key': 'subnetId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        v_net_id: Optional[str] = None,
        subnet: Optional[str] = None,
        public_i_ps: Optional[List[str]] = None,
        subnet_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword v_net_id: The ID of the VNet that this integration runtime will join.
        :paramtype v_net_id: str
        :keyword subnet: The name of the subnet this integration runtime will join.
        :paramtype subnet: str
        :keyword public_i_ps: Resource IDs of the public IP addresses that this integration runtime
         will use.
        :paramtype public_i_ps: list[str]
        :keyword subnet_id: The ID of subnet, to which this Azure-SSIS integration runtime will be
         joined.
        :paramtype subnet_id: str
        """
        super(IntegrationRuntimeVNetProperties, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.v_net_id = v_net_id
        self.subnet = subnet
        self.public_i_ps = public_i_ps
        self.subnet_id = subnet_id


class JiraLinkedService(LinkedService):
    """Jira Service linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. The IP address or host name of the Jira service. (e.g. jira.example.com).
    :vartype host: any
    :ivar port: The TCP port that the Jira server uses to listen for client connections. The
     default value is 443 if connecting through HTTPS, or 8080 if connecting through HTTP.
    :vartype port: any
    :ivar username: Required. The user name that you use to access Jira Service.
    :vartype username: any
    :ivar password: The password corresponding to the user name that you provided in the username
     field.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'username': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        username: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        port: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. The IP address or host name of the Jira service. (e.g.
         jira.example.com).
        :paramtype host: any
        :keyword port: The TCP port that the Jira server uses to listen for client connections. The
         default value is 443 if connecting through HTTPS, or 8080 if connecting through HTTP.
        :paramtype port: any
        :keyword username: Required. The user name that you use to access Jira Service.
        :paramtype username: any
        :keyword password: The password corresponding to the user name that you provided in the
         username field.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true.
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true.
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(JiraLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Jira'  # type: str
        self.host = host
        self.port = port
        self.username = username
        self.password = password
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class JiraObjectDataset(Dataset):
    """Jira Service dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(JiraObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'JiraObject'  # type: str
        self.table_name = table_name


class JiraSource(TabularSource):
    """A copy activity Jira Service source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(JiraSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'JiraSource'  # type: str
        self.query = query


class JsonDataset(Dataset):
    """Json dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar location: The location of the json data storage.
    :vartype location: ~azure.mgmt.datafactory.models.DatasetLocation
    :ivar encoding_name: The code page name of the preferred encoding. If not specified, the
     default value is UTF-8, unless BOM denotes another Unicode encoding. Refer to the name column
     of the table in the following link to set supported values:
     https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
     resultType string).
    :vartype encoding_name: any
    :ivar compression: The data compression method used for the json dataset.
    :vartype compression: ~azure.mgmt.datafactory.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'encoding_name': {'key': 'typeProperties.encodingName', 'type': 'object'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        encoding_name: Optional[Any] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword location: The location of the json data storage.
        :paramtype location: ~azure.mgmt.datafactory.models.DatasetLocation
        :keyword encoding_name: The code page name of the preferred encoding. If not specified, the
         default value is UTF-8, unless BOM denotes another Unicode encoding. Refer to the name column
         of the table in the following link to set supported values:
         https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
         resultType string).
        :paramtype encoding_name: any
        :keyword compression: The data compression method used for the json dataset.
        :paramtype compression: ~azure.mgmt.datafactory.models.DatasetCompression
        """
        super(JsonDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Json'  # type: str
        self.location = location
        self.encoding_name = encoding_name
        self.compression = compression


class JsonFormat(DatasetStorageFormat):
    """The data stored in JSON format.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage format.Constant filled by server.
    :vartype type: str
    :ivar serializer: Serializer. Type: string (or Expression with resultType string).
    :vartype serializer: any
    :ivar deserializer: Deserializer. Type: string (or Expression with resultType string).
    :vartype deserializer: any
    :ivar file_pattern: File pattern of JSON. To be more specific, the way of separating a
     collection of JSON objects. The default value is 'setOfObjects'. It is case-sensitive.
    :vartype file_pattern: any
    :ivar nesting_separator: The character used to separate nesting levels. Default value is '.'
     (dot). Type: string (or Expression with resultType string).
    :vartype nesting_separator: any
    :ivar encoding_name: The code page name of the preferred encoding. If not provided, the default
     value is 'utf-8', unless the byte order mark (BOM) denotes another Unicode encoding. The full
     list of supported values can be found in the 'Name' column of the table of encodings in the
     following reference: https://go.microsoft.com/fwlink/?linkid=861078. Type: string (or
     Expression with resultType string).
    :vartype encoding_name: any
    :ivar json_node_reference: The JSONPath of the JSON array element to be flattened. Example:
     "$.ArrayPath". Type: string (or Expression with resultType string).
    :vartype json_node_reference: any
    :ivar json_path_definition: The JSONPath definition for each column mapping with a customized
     column name to extract data from JSON file. For fields under root object, start with "$"; for
     fields inside the array chosen by jsonNodeReference property, start from the array element.
     Example: {"Column1": "$.Column1Path", "Column2": "Column2PathInArray"}. Type: object (or
     Expression with resultType object).
    :vartype json_path_definition: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'serializer': {'key': 'serializer', 'type': 'object'},
        'deserializer': {'key': 'deserializer', 'type': 'object'},
        'file_pattern': {'key': 'filePattern', 'type': 'object'},
        'nesting_separator': {'key': 'nestingSeparator', 'type': 'object'},
        'encoding_name': {'key': 'encodingName', 'type': 'object'},
        'json_node_reference': {'key': 'jsonNodeReference', 'type': 'object'},
        'json_path_definition': {'key': 'jsonPathDefinition', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        serializer: Optional[Any] = None,
        deserializer: Optional[Any] = None,
        file_pattern: Optional[Any] = None,
        nesting_separator: Optional[Any] = None,
        encoding_name: Optional[Any] = None,
        json_node_reference: Optional[Any] = None,
        json_path_definition: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword serializer: Serializer. Type: string (or Expression with resultType string).
        :paramtype serializer: any
        :keyword deserializer: Deserializer. Type: string (or Expression with resultType string).
        :paramtype deserializer: any
        :keyword file_pattern: File pattern of JSON. To be more specific, the way of separating a
         collection of JSON objects. The default value is 'setOfObjects'. It is case-sensitive.
        :paramtype file_pattern: any
        :keyword nesting_separator: The character used to separate nesting levels. Default value is '.'
         (dot). Type: string (or Expression with resultType string).
        :paramtype nesting_separator: any
        :keyword encoding_name: The code page name of the preferred encoding. If not provided, the
         default value is 'utf-8', unless the byte order mark (BOM) denotes another Unicode encoding.
         The full list of supported values can be found in the 'Name' column of the table of encodings
         in the following reference: https://go.microsoft.com/fwlink/?linkid=861078. Type: string (or
         Expression with resultType string).
        :paramtype encoding_name: any
        :keyword json_node_reference: The JSONPath of the JSON array element to be flattened. Example:
         "$.ArrayPath". Type: string (or Expression with resultType string).
        :paramtype json_node_reference: any
        :keyword json_path_definition: The JSONPath definition for each column mapping with a
         customized column name to extract data from JSON file. For fields under root object, start with
         "$"; for fields inside the array chosen by jsonNodeReference property, start from the array
         element. Example: {"Column1": "$.Column1Path", "Column2": "Column2PathInArray"}. Type: object
         (or Expression with resultType object).
        :paramtype json_path_definition: any
        """
        super(JsonFormat, self).__init__(additional_properties=additional_properties, serializer=serializer, deserializer=deserializer, **kwargs)
        self.type = 'JsonFormat'  # type: str
        self.file_pattern = file_pattern
        self.nesting_separator = nesting_separator
        self.encoding_name = encoding_name
        self.json_node_reference = json_node_reference
        self.json_path_definition = json_path_definition


class JsonReadSettings(FormatReadSettings):
    """Json read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar compression_properties: Compression settings.
    :vartype compression_properties: ~azure.mgmt.datafactory.models.CompressionReadSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'compression_properties': {'key': 'compressionProperties', 'type': 'CompressionReadSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        compression_properties: Optional["CompressionReadSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword compression_properties: Compression settings.
        :paramtype compression_properties: ~azure.mgmt.datafactory.models.CompressionReadSettings
        """
        super(JsonReadSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'JsonReadSettings'  # type: str
        self.compression_properties = compression_properties


class JsonSink(CopySink):
    """A copy activity Json sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: Json store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreWriteSettings
    :ivar format_settings: Json format settings.
    :vartype format_settings: ~azure.mgmt.datafactory.models.JsonWriteSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreWriteSettings'},
        'format_settings': {'key': 'formatSettings', 'type': 'JsonWriteSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreWriteSettings"] = None,
        format_settings: Optional["JsonWriteSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: Json store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreWriteSettings
        :keyword format_settings: Json format settings.
        :paramtype format_settings: ~azure.mgmt.datafactory.models.JsonWriteSettings
        """
        super(JsonSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'JsonSink'  # type: str
        self.store_settings = store_settings
        self.format_settings = format_settings


class JsonSource(CopySource):
    """A copy activity Json source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: Json store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
    :ivar format_settings: Json format settings.
    :vartype format_settings: ~azure.mgmt.datafactory.models.JsonReadSettings
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
        'format_settings': {'key': 'formatSettings', 'type': 'JsonReadSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        format_settings: Optional["JsonReadSettings"] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: Json store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
        :keyword format_settings: Json format settings.
        :paramtype format_settings: ~azure.mgmt.datafactory.models.JsonReadSettings
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(JsonSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'JsonSource'  # type: str
        self.store_settings = store_settings
        self.format_settings = format_settings
        self.additional_columns = additional_columns


class JsonWriteSettings(FormatWriteSettings):
    """Json write settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The write setting type.Constant filled by server.
    :vartype type: str
    :ivar file_pattern: File pattern of JSON. This setting controls the way a collection of JSON
     objects will be treated. The default value is 'setOfObjects'. It is case-sensitive.
    :vartype file_pattern: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'file_pattern': {'key': 'filePattern', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        file_pattern: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword file_pattern: File pattern of JSON. This setting controls the way a collection of JSON
         objects will be treated. The default value is 'setOfObjects'. It is case-sensitive.
        :paramtype file_pattern: any
        """
        super(JsonWriteSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'JsonWriteSettings'  # type: str
        self.file_pattern = file_pattern


class LinkedIntegrationRuntime(msrest.serialization.Model):
    """The linked integration runtime information.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar name: The name of the linked integration runtime.
    :vartype name: str
    :ivar subscription_id: The subscription ID for which the linked integration runtime belong to.
    :vartype subscription_id: str
    :ivar data_factory_name: The name of the data factory for which the linked integration runtime
     belong to.
    :vartype data_factory_name: str
    :ivar data_factory_location: The location of the data factory for which the linked integration
     runtime belong to.
    :vartype data_factory_location: str
    :ivar create_time: The creating time of the linked integration runtime.
    :vartype create_time: ~datetime.datetime
    """

    _validation = {
        'name': {'readonly': True},
        'subscription_id': {'readonly': True},
        'data_factory_name': {'readonly': True},
        'data_factory_location': {'readonly': True},
        'create_time': {'readonly': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'subscription_id': {'key': 'subscriptionId', 'type': 'str'},
        'data_factory_name': {'key': 'dataFactoryName', 'type': 'str'},
        'data_factory_location': {'key': 'dataFactoryLocation', 'type': 'str'},
        'create_time': {'key': 'createTime', 'type': 'iso-8601'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(LinkedIntegrationRuntime, self).__init__(**kwargs)
        self.name = None
        self.subscription_id = None
        self.data_factory_name = None
        self.data_factory_location = None
        self.create_time = None


class LinkedIntegrationRuntimeType(msrest.serialization.Model):
    """The base definition of a linked integration runtime.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: LinkedIntegrationRuntimeKeyAuthorization, LinkedIntegrationRuntimeRbacAuthorization.

    All required parameters must be populated in order to send to Azure.

    :ivar authorization_type: Required. The authorization type for integration runtime
     sharing.Constant filled by server.
    :vartype authorization_type: str
    """

    _validation = {
        'authorization_type': {'required': True},
    }

    _attribute_map = {
        'authorization_type': {'key': 'authorizationType', 'type': 'str'},
    }

    _subtype_map = {
        'authorization_type': {'Key': 'LinkedIntegrationRuntimeKeyAuthorization', 'RBAC': 'LinkedIntegrationRuntimeRbacAuthorization'}
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(LinkedIntegrationRuntimeType, self).__init__(**kwargs)
        self.authorization_type = None  # type: Optional[str]


class LinkedIntegrationRuntimeKeyAuthorization(LinkedIntegrationRuntimeType):
    """The key authorization type integration runtime.

    All required parameters must be populated in order to send to Azure.

    :ivar authorization_type: Required. The authorization type for integration runtime
     sharing.Constant filled by server.
    :vartype authorization_type: str
    :ivar key: Required. The key used for authorization.
    :vartype key: ~azure.mgmt.datafactory.models.SecureString
    """

    _validation = {
        'authorization_type': {'required': True},
        'key': {'required': True},
    }

    _attribute_map = {
        'authorization_type': {'key': 'authorizationType', 'type': 'str'},
        'key': {'key': 'key', 'type': 'SecureString'},
    }

    def __init__(
        self,
        *,
        key: "SecureString",
        **kwargs
    ):
        """
        :keyword key: Required. The key used for authorization.
        :paramtype key: ~azure.mgmt.datafactory.models.SecureString
        """
        super(LinkedIntegrationRuntimeKeyAuthorization, self).__init__(**kwargs)
        self.authorization_type = 'Key'  # type: str
        self.key = key


class LinkedIntegrationRuntimeRbacAuthorization(LinkedIntegrationRuntimeType):
    """The role based access control (RBAC) authorization type integration runtime.

    All required parameters must be populated in order to send to Azure.

    :ivar authorization_type: Required. The authorization type for integration runtime
     sharing.Constant filled by server.
    :vartype authorization_type: str
    :ivar resource_id: Required. The resource identifier of the integration runtime to be shared.
    :vartype resource_id: str
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'authorization_type': {'required': True},
        'resource_id': {'required': True},
    }

    _attribute_map = {
        'authorization_type': {'key': 'authorizationType', 'type': 'str'},
        'resource_id': {'key': 'resourceId', 'type': 'str'},
        'credential': {'key': 'credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        resource_id: str,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword resource_id: Required. The resource identifier of the integration runtime to be
         shared.
        :paramtype resource_id: str
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(LinkedIntegrationRuntimeRbacAuthorization, self).__init__(**kwargs)
        self.authorization_type = 'RBAC'  # type: str
        self.resource_id = resource_id
        self.credential = credential


class LinkedIntegrationRuntimeRequest(msrest.serialization.Model):
    """Data factory name for linked integration runtime request.

    All required parameters must be populated in order to send to Azure.

    :ivar linked_factory_name: Required. The data factory name for linked integration runtime.
    :vartype linked_factory_name: str
    """

    _validation = {
        'linked_factory_name': {'required': True},
    }

    _attribute_map = {
        'linked_factory_name': {'key': 'factoryName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        linked_factory_name: str,
        **kwargs
    ):
        """
        :keyword linked_factory_name: Required. The data factory name for linked integration runtime.
        :paramtype linked_factory_name: str
        """
        super(LinkedIntegrationRuntimeRequest, self).__init__(**kwargs)
        self.linked_factory_name = linked_factory_name


class LinkedServiceDebugResource(SubResourceDebugResource):
    """Linked service debug resource.

    All required parameters must be populated in order to send to Azure.

    :ivar name: The resource name.
    :vartype name: str
    :ivar properties: Required. Properties of linked service.
    :vartype properties: ~azure.mgmt.datafactory.models.LinkedService
    """

    _validation = {
        'properties': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'LinkedService'},
    }

    def __init__(
        self,
        *,
        properties: "LinkedService",
        name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword name: The resource name.
        :paramtype name: str
        :keyword properties: Required. Properties of linked service.
        :paramtype properties: ~azure.mgmt.datafactory.models.LinkedService
        """
        super(LinkedServiceDebugResource, self).__init__(name=name, **kwargs)
        self.properties = properties


class LinkedServiceListResponse(msrest.serialization.Model):
    """A list of linked service resources.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of linked services.
    :vartype value: list[~azure.mgmt.datafactory.models.LinkedServiceResource]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[LinkedServiceResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["LinkedServiceResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of linked services.
        :paramtype value: list[~azure.mgmt.datafactory.models.LinkedServiceResource]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(LinkedServiceListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class LinkedServiceReference(msrest.serialization.Model):
    """Linked service reference type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Linked service reference type. Has constant value: "LinkedServiceReference".
    :vartype type: str
    :ivar reference_name: Required. Reference LinkedService name.
    :vartype reference_name: str
    :ivar parameters: Arguments for LinkedService.
    :vartype parameters: dict[str, any]
    """

    _validation = {
        'type': {'required': True, 'constant': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{object}'},
    }

    type = "LinkedServiceReference"

    def __init__(
        self,
        *,
        reference_name: str,
        parameters: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword reference_name: Required. Reference LinkedService name.
        :paramtype reference_name: str
        :keyword parameters: Arguments for LinkedService.
        :paramtype parameters: dict[str, any]
        """
        super(LinkedServiceReference, self).__init__(**kwargs)
        self.reference_name = reference_name
        self.parameters = parameters


class LinkedServiceResource(SubResource):
    """Linked service resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :ivar properties: Required. Properties of linked service.
    :vartype properties: ~azure.mgmt.datafactory.models.LinkedService
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'LinkedService'},
    }

    def __init__(
        self,
        *,
        properties: "LinkedService",
        **kwargs
    ):
        """
        :keyword properties: Required. Properties of linked service.
        :paramtype properties: ~azure.mgmt.datafactory.models.LinkedService
        """
        super(LinkedServiceResource, self).__init__(**kwargs)
        self.properties = properties


class LogLocationSettings(msrest.serialization.Model):
    """Log location settings.

    All required parameters must be populated in order to send to Azure.

    :ivar linked_service_name: Required. Log storage linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar path: The path to storage for storing detailed logs of activity execution. Type: string
     (or Expression with resultType string).
    :vartype path: any
    """

    _validation = {
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'path': {'key': 'path', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        path: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword linked_service_name: Required. Log storage linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword path: The path to storage for storing detailed logs of activity execution. Type:
         string (or Expression with resultType string).
        :paramtype path: any
        """
        super(LogLocationSettings, self).__init__(**kwargs)
        self.linked_service_name = linked_service_name
        self.path = path


class LogSettings(msrest.serialization.Model):
    """Log settings.

    All required parameters must be populated in order to send to Azure.

    :ivar enable_copy_activity_log: Specifies whether to enable copy activity log. Type: boolean
     (or Expression with resultType boolean).
    :vartype enable_copy_activity_log: any
    :ivar copy_activity_log_settings: Specifies settings for copy activity log.
    :vartype copy_activity_log_settings: ~azure.mgmt.datafactory.models.CopyActivityLogSettings
    :ivar log_location_settings: Required. Log location settings customer needs to provide when
     enabling log.
    :vartype log_location_settings: ~azure.mgmt.datafactory.models.LogLocationSettings
    """

    _validation = {
        'log_location_settings': {'required': True},
    }

    _attribute_map = {
        'enable_copy_activity_log': {'key': 'enableCopyActivityLog', 'type': 'object'},
        'copy_activity_log_settings': {'key': 'copyActivityLogSettings', 'type': 'CopyActivityLogSettings'},
        'log_location_settings': {'key': 'logLocationSettings', 'type': 'LogLocationSettings'},
    }

    def __init__(
        self,
        *,
        log_location_settings: "LogLocationSettings",
        enable_copy_activity_log: Optional[Any] = None,
        copy_activity_log_settings: Optional["CopyActivityLogSettings"] = None,
        **kwargs
    ):
        """
        :keyword enable_copy_activity_log: Specifies whether to enable copy activity log. Type: boolean
         (or Expression with resultType boolean).
        :paramtype enable_copy_activity_log: any
        :keyword copy_activity_log_settings: Specifies settings for copy activity log.
        :paramtype copy_activity_log_settings: ~azure.mgmt.datafactory.models.CopyActivityLogSettings
        :keyword log_location_settings: Required. Log location settings customer needs to provide when
         enabling log.
        :paramtype log_location_settings: ~azure.mgmt.datafactory.models.LogLocationSettings
        """
        super(LogSettings, self).__init__(**kwargs)
        self.enable_copy_activity_log = enable_copy_activity_log
        self.copy_activity_log_settings = copy_activity_log_settings
        self.log_location_settings = log_location_settings


class LogStorageSettings(msrest.serialization.Model):
    """(Deprecated. Please use LogSettings) Log storage settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar linked_service_name: Required. Log storage linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar path: The path to storage for storing detailed logs of activity execution. Type: string
     (or Expression with resultType string).
    :vartype path: any
    :ivar log_level: Gets or sets the log level, support: Info, Warning. Type: string (or
     Expression with resultType string).
    :vartype log_level: any
    :ivar enable_reliable_logging: Specifies whether to enable reliable logging. Type: boolean (or
     Expression with resultType boolean).
    :vartype enable_reliable_logging: any
    """

    _validation = {
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'path': {'key': 'path', 'type': 'object'},
        'log_level': {'key': 'logLevel', 'type': 'object'},
        'enable_reliable_logging': {'key': 'enableReliableLogging', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        path: Optional[Any] = None,
        log_level: Optional[Any] = None,
        enable_reliable_logging: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword linked_service_name: Required. Log storage linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword path: The path to storage for storing detailed logs of activity execution. Type:
         string (or Expression with resultType string).
        :paramtype path: any
        :keyword log_level: Gets or sets the log level, support: Info, Warning. Type: string (or
         Expression with resultType string).
        :paramtype log_level: any
        :keyword enable_reliable_logging: Specifies whether to enable reliable logging. Type: boolean
         (or Expression with resultType boolean).
        :paramtype enable_reliable_logging: any
        """
        super(LogStorageSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.linked_service_name = linked_service_name
        self.path = path
        self.log_level = log_level
        self.enable_reliable_logging = enable_reliable_logging


class LookupActivity(ExecutionActivity):
    """Lookup activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar source: Required. Dataset-specific source properties, same as copy activity source.
    :vartype source: ~azure.mgmt.datafactory.models.CopySource
    :ivar dataset: Required. Lookup activity dataset reference.
    :vartype dataset: ~azure.mgmt.datafactory.models.DatasetReference
    :ivar first_row_only: Whether to return first row or all rows. Default value is true. Type:
     boolean (or Expression with resultType boolean).
    :vartype first_row_only: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'source': {'required': True},
        'dataset': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'source': {'key': 'typeProperties.source', 'type': 'CopySource'},
        'dataset': {'key': 'typeProperties.dataset', 'type': 'DatasetReference'},
        'first_row_only': {'key': 'typeProperties.firstRowOnly', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        source: "CopySource",
        dataset: "DatasetReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        first_row_only: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword source: Required. Dataset-specific source properties, same as copy activity source.
        :paramtype source: ~azure.mgmt.datafactory.models.CopySource
        :keyword dataset: Required. Lookup activity dataset reference.
        :paramtype dataset: ~azure.mgmt.datafactory.models.DatasetReference
        :keyword first_row_only: Whether to return first row or all rows. Default value is true. Type:
         boolean (or Expression with resultType boolean).
        :paramtype first_row_only: any
        """
        super(LookupActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'Lookup'  # type: str
        self.source = source
        self.dataset = dataset
        self.first_row_only = first_row_only


class MagentoLinkedService(LinkedService):
    """Magento server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. The URL of the Magento instance. (i.e. 192.168.222.110/magento3).
    :vartype host: any
    :ivar access_token: The access token from Magento.
    :vartype access_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'access_token': {'key': 'typeProperties.accessToken', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        access_token: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. The URL of the Magento instance. (i.e. 192.168.222.110/magento3).
        :paramtype host: any
        :keyword access_token: The access token from Magento.
        :paramtype access_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true.
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true.
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(MagentoLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Magento'  # type: str
        self.host = host
        self.access_token = access_token
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class MagentoObjectDataset(Dataset):
    """Magento server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(MagentoObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MagentoObject'  # type: str
        self.table_name = table_name


class MagentoSource(TabularSource):
    """A copy activity Magento server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(MagentoSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'MagentoSource'  # type: str
        self.query = query


class ManagedIdentityCredential(Credential):
    """Managed identity credential.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of credential.Constant filled by server.
    :vartype type: str
    :ivar description: Credential description.
    :vartype description: str
    :ivar annotations: List of tags that can be used for describing the Credential.
    :vartype annotations: list[any]
    :ivar resource_id: The resource id of user assigned managed identity.
    :vartype resource_id: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'resource_id': {'key': 'typeProperties.resourceId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        resource_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Credential description.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the Credential.
        :paramtype annotations: list[any]
        :keyword resource_id: The resource id of user assigned managed identity.
        :paramtype resource_id: str
        """
        super(ManagedIdentityCredential, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, **kwargs)
        self.type = 'ManagedIdentity'  # type: str
        self.resource_id = resource_id


class ManagedIntegrationRuntime(IntegrationRuntime):
    """Managed integration runtime, including managed elastic and managed dedicated integration runtimes.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of integration runtime.Constant filled by server. Possible values
     include: "Managed", "SelfHosted".
    :vartype type: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeType
    :ivar description: Integration runtime description.
    :vartype description: str
    :ivar state: Integration runtime state, only valid for managed dedicated integration runtime.
     Possible values include: "Initial", "Stopped", "Started", "Starting", "Stopping",
     "NeedRegistration", "Online", "Limited", "Offline", "AccessDenied".
    :vartype state: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeState
    :ivar managed_virtual_network: Managed Virtual Network reference.
    :vartype managed_virtual_network: ~azure.mgmt.datafactory.models.ManagedVirtualNetworkReference
    :ivar compute_properties: The compute resource for managed integration runtime.
    :vartype compute_properties: ~azure.mgmt.datafactory.models.IntegrationRuntimeComputeProperties
    :ivar ssis_properties: SSIS properties for managed integration runtime.
    :vartype ssis_properties: ~azure.mgmt.datafactory.models.IntegrationRuntimeSsisProperties
    :ivar customer_virtual_network: The name of virtual network to which Azure-SSIS integration
     runtime will join.
    :vartype customer_virtual_network:
     ~azure.mgmt.datafactory.models.IntegrationRuntimeCustomerVirtualNetwork
    """

    _validation = {
        'type': {'required': True},
        'state': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'state': {'key': 'state', 'type': 'str'},
        'managed_virtual_network': {'key': 'managedVirtualNetwork', 'type': 'ManagedVirtualNetworkReference'},
        'compute_properties': {'key': 'typeProperties.computeProperties', 'type': 'IntegrationRuntimeComputeProperties'},
        'ssis_properties': {'key': 'typeProperties.ssisProperties', 'type': 'IntegrationRuntimeSsisProperties'},
        'customer_virtual_network': {'key': 'typeProperties.customerVirtualNetwork', 'type': 'IntegrationRuntimeCustomerVirtualNetwork'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        managed_virtual_network: Optional["ManagedVirtualNetworkReference"] = None,
        compute_properties: Optional["IntegrationRuntimeComputeProperties"] = None,
        ssis_properties: Optional["IntegrationRuntimeSsisProperties"] = None,
        customer_virtual_network: Optional["IntegrationRuntimeCustomerVirtualNetwork"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Integration runtime description.
        :paramtype description: str
        :keyword managed_virtual_network: Managed Virtual Network reference.
        :paramtype managed_virtual_network:
         ~azure.mgmt.datafactory.models.ManagedVirtualNetworkReference
        :keyword compute_properties: The compute resource for managed integration runtime.
        :paramtype compute_properties:
         ~azure.mgmt.datafactory.models.IntegrationRuntimeComputeProperties
        :keyword ssis_properties: SSIS properties for managed integration runtime.
        :paramtype ssis_properties: ~azure.mgmt.datafactory.models.IntegrationRuntimeSsisProperties
        :keyword customer_virtual_network: The name of virtual network to which Azure-SSIS integration
         runtime will join.
        :paramtype customer_virtual_network:
         ~azure.mgmt.datafactory.models.IntegrationRuntimeCustomerVirtualNetwork
        """
        super(ManagedIntegrationRuntime, self).__init__(additional_properties=additional_properties, description=description, **kwargs)
        self.type = 'Managed'  # type: str
        self.state = None
        self.managed_virtual_network = managed_virtual_network
        self.compute_properties = compute_properties
        self.ssis_properties = ssis_properties
        self.customer_virtual_network = customer_virtual_network


class ManagedIntegrationRuntimeError(msrest.serialization.Model):
    """Error definition for managed integration runtime.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar time: The time when the error occurred.
    :vartype time: ~datetime.datetime
    :ivar code: Error code.
    :vartype code: str
    :ivar parameters: Managed integration runtime error parameters.
    :vartype parameters: list[str]
    :ivar message: Error message.
    :vartype message: str
    """

    _validation = {
        'time': {'readonly': True},
        'code': {'readonly': True},
        'parameters': {'readonly': True},
        'message': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'time': {'key': 'time', 'type': 'iso-8601'},
        'code': {'key': 'code', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '[str]'},
        'message': {'key': 'message', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(ManagedIntegrationRuntimeError, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.time = None
        self.code = None
        self.parameters = None
        self.message = None


class ManagedIntegrationRuntimeNode(msrest.serialization.Model):
    """Properties of integration runtime node.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar node_id: The managed integration runtime node id.
    :vartype node_id: str
    :ivar status: The managed integration runtime node status. Possible values include: "Starting",
     "Available", "Recycling", "Unavailable".
    :vartype status: str or ~azure.mgmt.datafactory.models.ManagedIntegrationRuntimeNodeStatus
    :ivar errors: The errors that occurred on this integration runtime node.
    :vartype errors: list[~azure.mgmt.datafactory.models.ManagedIntegrationRuntimeError]
    """

    _validation = {
        'node_id': {'readonly': True},
        'status': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'node_id': {'key': 'nodeId', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'errors': {'key': 'errors', 'type': '[ManagedIntegrationRuntimeError]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        errors: Optional[List["ManagedIntegrationRuntimeError"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword errors: The errors that occurred on this integration runtime node.
        :paramtype errors: list[~azure.mgmt.datafactory.models.ManagedIntegrationRuntimeError]
        """
        super(ManagedIntegrationRuntimeNode, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.node_id = None
        self.status = None
        self.errors = errors


class ManagedIntegrationRuntimeOperationResult(msrest.serialization.Model):
    """Properties of managed integration runtime operation result.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: The operation type. Could be start or stop.
    :vartype type: str
    :ivar start_time: The start time of the operation.
    :vartype start_time: ~datetime.datetime
    :ivar result: The operation result.
    :vartype result: str
    :ivar error_code: The error code.
    :vartype error_code: str
    :ivar parameters: Managed integration runtime error parameters.
    :vartype parameters: list[str]
    :ivar activity_id: The activity id for the operation request.
    :vartype activity_id: str
    """

    _validation = {
        'type': {'readonly': True},
        'start_time': {'readonly': True},
        'result': {'readonly': True},
        'error_code': {'readonly': True},
        'parameters': {'readonly': True},
        'activity_id': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'result': {'key': 'result', 'type': 'str'},
        'error_code': {'key': 'errorCode', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '[str]'},
        'activity_id': {'key': 'activityId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(ManagedIntegrationRuntimeOperationResult, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.type = None
        self.start_time = None
        self.result = None
        self.error_code = None
        self.parameters = None
        self.activity_id = None


class ManagedIntegrationRuntimeStatus(IntegrationRuntimeStatus):
    """Managed integration runtime status.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of integration runtime.Constant filled by server. Possible values
     include: "Managed", "SelfHosted".
    :vartype type: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeType
    :ivar data_factory_name: The data factory name which the integration runtime belong to.
    :vartype data_factory_name: str
    :ivar state: The state of integration runtime. Possible values include: "Initial", "Stopped",
     "Started", "Starting", "Stopping", "NeedRegistration", "Online", "Limited", "Offline",
     "AccessDenied".
    :vartype state: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeState
    :ivar create_time: The time at which the integration runtime was created, in ISO8601 format.
    :vartype create_time: ~datetime.datetime
    :ivar nodes: The list of nodes for managed integration runtime.
    :vartype nodes: list[~azure.mgmt.datafactory.models.ManagedIntegrationRuntimeNode]
    :ivar other_errors: The errors that occurred on this integration runtime.
    :vartype other_errors: list[~azure.mgmt.datafactory.models.ManagedIntegrationRuntimeError]
    :ivar last_operation: The last operation result that occurred on this integration runtime.
    :vartype last_operation:
     ~azure.mgmt.datafactory.models.ManagedIntegrationRuntimeOperationResult
    """

    _validation = {
        'type': {'required': True},
        'data_factory_name': {'readonly': True},
        'state': {'readonly': True},
        'create_time': {'readonly': True},
        'nodes': {'readonly': True},
        'other_errors': {'readonly': True},
        'last_operation': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'data_factory_name': {'key': 'dataFactoryName', 'type': 'str'},
        'state': {'key': 'state', 'type': 'str'},
        'create_time': {'key': 'typeProperties.createTime', 'type': 'iso-8601'},
        'nodes': {'key': 'typeProperties.nodes', 'type': '[ManagedIntegrationRuntimeNode]'},
        'other_errors': {'key': 'typeProperties.otherErrors', 'type': '[ManagedIntegrationRuntimeError]'},
        'last_operation': {'key': 'typeProperties.lastOperation', 'type': 'ManagedIntegrationRuntimeOperationResult'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(ManagedIntegrationRuntimeStatus, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'Managed'  # type: str
        self.create_time = None
        self.nodes = None
        self.other_errors = None
        self.last_operation = None


class ManagedPrivateEndpoint(msrest.serialization.Model):
    """Properties of a managed private endpoint.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar connection_state: The managed private endpoint connection state.
    :vartype connection_state: ~azure.mgmt.datafactory.models.ConnectionStateProperties
    :ivar fqdns: Fully qualified domain names.
    :vartype fqdns: list[str]
    :ivar group_id: The groupId to which the managed private endpoint is created.
    :vartype group_id: str
    :ivar is_reserved: Denotes whether the managed private endpoint is reserved.
    :vartype is_reserved: bool
    :ivar private_link_resource_id: The ARM resource ID of the resource to which the managed
     private endpoint is created.
    :vartype private_link_resource_id: str
    :ivar provisioning_state: The managed private endpoint provisioning state.
    :vartype provisioning_state: str
    """

    _validation = {
        'is_reserved': {'readonly': True},
        'provisioning_state': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'connection_state': {'key': 'connectionState', 'type': 'ConnectionStateProperties'},
        'fqdns': {'key': 'fqdns', 'type': '[str]'},
        'group_id': {'key': 'groupId', 'type': 'str'},
        'is_reserved': {'key': 'isReserved', 'type': 'bool'},
        'private_link_resource_id': {'key': 'privateLinkResourceId', 'type': 'str'},
        'provisioning_state': {'key': 'provisioningState', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connection_state: Optional["ConnectionStateProperties"] = None,
        fqdns: Optional[List[str]] = None,
        group_id: Optional[str] = None,
        private_link_resource_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connection_state: The managed private endpoint connection state.
        :paramtype connection_state: ~azure.mgmt.datafactory.models.ConnectionStateProperties
        :keyword fqdns: Fully qualified domain names.
        :paramtype fqdns: list[str]
        :keyword group_id: The groupId to which the managed private endpoint is created.
        :paramtype group_id: str
        :keyword private_link_resource_id: The ARM resource ID of the resource to which the managed
         private endpoint is created.
        :paramtype private_link_resource_id: str
        """
        super(ManagedPrivateEndpoint, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.connection_state = connection_state
        self.fqdns = fqdns
        self.group_id = group_id
        self.is_reserved = None
        self.private_link_resource_id = private_link_resource_id
        self.provisioning_state = None


class ManagedPrivateEndpointListResponse(msrest.serialization.Model):
    """A list of managed private endpoint resources.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of managed private endpoints.
    :vartype value: list[~azure.mgmt.datafactory.models.ManagedPrivateEndpointResource]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[ManagedPrivateEndpointResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["ManagedPrivateEndpointResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of managed private endpoints.
        :paramtype value: list[~azure.mgmt.datafactory.models.ManagedPrivateEndpointResource]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(ManagedPrivateEndpointListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class ManagedPrivateEndpointResource(SubResource):
    """Managed private endpoint resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :ivar properties: Required. Managed private endpoint properties.
    :vartype properties: ~azure.mgmt.datafactory.models.ManagedPrivateEndpoint
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'ManagedPrivateEndpoint'},
    }

    def __init__(
        self,
        *,
        properties: "ManagedPrivateEndpoint",
        **kwargs
    ):
        """
        :keyword properties: Required. Managed private endpoint properties.
        :paramtype properties: ~azure.mgmt.datafactory.models.ManagedPrivateEndpoint
        """
        super(ManagedPrivateEndpointResource, self).__init__(**kwargs)
        self.properties = properties


class ManagedVirtualNetwork(msrest.serialization.Model):
    """A managed Virtual Network associated with the Azure Data Factory.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar v_net_id: Managed Virtual Network ID.
    :vartype v_net_id: str
    :ivar alias: Managed Virtual Network alias.
    :vartype alias: str
    """

    _validation = {
        'v_net_id': {'readonly': True},
        'alias': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'v_net_id': {'key': 'vNetId', 'type': 'str'},
        'alias': {'key': 'alias', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(ManagedVirtualNetwork, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.v_net_id = None
        self.alias = None


class ManagedVirtualNetworkListResponse(msrest.serialization.Model):
    """A list of managed Virtual Network resources.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of managed Virtual Networks.
    :vartype value: list[~azure.mgmt.datafactory.models.ManagedVirtualNetworkResource]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[ManagedVirtualNetworkResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["ManagedVirtualNetworkResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of managed Virtual Networks.
        :paramtype value: list[~azure.mgmt.datafactory.models.ManagedVirtualNetworkResource]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(ManagedVirtualNetworkListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class ManagedVirtualNetworkReference(msrest.serialization.Model):
    """Managed Virtual Network reference type.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Managed Virtual Network reference type. Possible values include:
     "ManagedVirtualNetworkReference".
    :vartype type: str or ~azure.mgmt.datafactory.models.ManagedVirtualNetworkReferenceType
    :ivar reference_name: Required. Reference ManagedVirtualNetwork name.
    :vartype reference_name: str
    """

    _validation = {
        'type': {'required': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        type: Union[str, "ManagedVirtualNetworkReferenceType"],
        reference_name: str,
        **kwargs
    ):
        """
        :keyword type: Required. Managed Virtual Network reference type. Possible values include:
         "ManagedVirtualNetworkReference".
        :paramtype type: str or ~azure.mgmt.datafactory.models.ManagedVirtualNetworkReferenceType
        :keyword reference_name: Required. Reference ManagedVirtualNetwork name.
        :paramtype reference_name: str
        """
        super(ManagedVirtualNetworkReference, self).__init__(**kwargs)
        self.type = type
        self.reference_name = reference_name


class ManagedVirtualNetworkResource(SubResource):
    """Managed Virtual Network resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :ivar properties: Required. Managed Virtual Network properties.
    :vartype properties: ~azure.mgmt.datafactory.models.ManagedVirtualNetwork
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'ManagedVirtualNetwork'},
    }

    def __init__(
        self,
        *,
        properties: "ManagedVirtualNetwork",
        **kwargs
    ):
        """
        :keyword properties: Required. Managed Virtual Network properties.
        :paramtype properties: ~azure.mgmt.datafactory.models.ManagedVirtualNetwork
        """
        super(ManagedVirtualNetworkResource, self).__init__(**kwargs)
        self.properties = properties


class MappingDataFlow(DataFlow):
    """Mapping data flow.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of data flow.Constant filled by server.
    :vartype type: str
    :ivar description: The description of the data flow.
    :vartype description: str
    :ivar annotations: List of tags that can be used for describing the data flow.
    :vartype annotations: list[any]
    :ivar folder: The folder that this data flow is in. If not specified, Data flow will appear at
     the root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DataFlowFolder
    :ivar sources: List of sources in data flow.
    :vartype sources: list[~azure.mgmt.datafactory.models.DataFlowSource]
    :ivar sinks: List of sinks in data flow.
    :vartype sinks: list[~azure.mgmt.datafactory.models.DataFlowSink]
    :ivar transformations: List of transformations in data flow.
    :vartype transformations: list[~azure.mgmt.datafactory.models.Transformation]
    :ivar script: DataFlow script.
    :vartype script: str
    :ivar script_lines: Data flow script lines.
    :vartype script_lines: list[str]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DataFlowFolder'},
        'sources': {'key': 'typeProperties.sources', 'type': '[DataFlowSource]'},
        'sinks': {'key': 'typeProperties.sinks', 'type': '[DataFlowSink]'},
        'transformations': {'key': 'typeProperties.transformations', 'type': '[Transformation]'},
        'script': {'key': 'typeProperties.script', 'type': 'str'},
        'script_lines': {'key': 'typeProperties.scriptLines', 'type': '[str]'},
    }

    def __init__(
        self,
        *,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DataFlowFolder"] = None,
        sources: Optional[List["DataFlowSource"]] = None,
        sinks: Optional[List["DataFlowSink"]] = None,
        transformations: Optional[List["Transformation"]] = None,
        script: Optional[str] = None,
        script_lines: Optional[List[str]] = None,
        **kwargs
    ):
        """
        :keyword description: The description of the data flow.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the data flow.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this data flow is in. If not specified, Data flow will appear
         at the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DataFlowFolder
        :keyword sources: List of sources in data flow.
        :paramtype sources: list[~azure.mgmt.datafactory.models.DataFlowSource]
        :keyword sinks: List of sinks in data flow.
        :paramtype sinks: list[~azure.mgmt.datafactory.models.DataFlowSink]
        :keyword transformations: List of transformations in data flow.
        :paramtype transformations: list[~azure.mgmt.datafactory.models.Transformation]
        :keyword script: DataFlow script.
        :paramtype script: str
        :keyword script_lines: Data flow script lines.
        :paramtype script_lines: list[str]
        """
        super(MappingDataFlow, self).__init__(description=description, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MappingDataFlow'  # type: str
        self.sources = sources
        self.sinks = sinks
        self.transformations = transformations
        self.script = script
        self.script_lines = script_lines


class MariaDBLinkedService(LinkedService):
    """MariaDB server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar pwd: The Azure key vault secret reference of password in connection string.
    :vartype pwd: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'pwd': {'key': 'typeProperties.pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: An ODBC connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword pwd: The Azure key vault secret reference of password in connection string.
        :paramtype pwd: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(MariaDBLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'MariaDB'  # type: str
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class MariaDBSource(TabularSource):
    """A copy activity MariaDB server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(MariaDBSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'MariaDBSource'  # type: str
        self.query = query


class MariaDBTableDataset(Dataset):
    """MariaDB server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(MariaDBTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MariaDBTable'  # type: str
        self.table_name = table_name


class MarketoLinkedService(LinkedService):
    """Marketo server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar endpoint: Required. The endpoint of the Marketo server. (i.e. 123-ABC-321.mktorest.com).
    :vartype endpoint: any
    :ivar client_id: Required. The client Id of your Marketo service.
    :vartype client_id: any
    :ivar client_secret: The client secret of your Marketo service.
    :vartype client_secret: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'object'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'object'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        endpoint: Any,
        client_id: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword endpoint: Required. The endpoint of the Marketo server. (i.e.
         123-ABC-321.mktorest.com).
        :paramtype endpoint: any
        :keyword client_id: Required. The client Id of your Marketo service.
        :paramtype client_id: any
        :keyword client_secret: The client secret of your Marketo service.
        :paramtype client_secret: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true.
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true.
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(MarketoLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Marketo'  # type: str
        self.endpoint = endpoint
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class MarketoObjectDataset(Dataset):
    """Marketo server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(MarketoObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MarketoObject'  # type: str
        self.table_name = table_name


class MarketoSource(TabularSource):
    """A copy activity Marketo server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(MarketoSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'MarketoSource'  # type: str
        self.query = query


class MetadataItem(msrest.serialization.Model):
    """Specify the name and value of custom metadata item.

    :ivar name: Metadata item key name. Type: string (or Expression with resultType string).
    :vartype name: any
    :ivar value: Metadata item value. Type: string (or Expression with resultType string).
    :vartype value: any
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'object'},
        'value': {'key': 'value', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: Optional[Any] = None,
        value: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword name: Metadata item key name. Type: string (or Expression with resultType string).
        :paramtype name: any
        :keyword value: Metadata item value. Type: string (or Expression with resultType string).
        :paramtype value: any
        """
        super(MetadataItem, self).__init__(**kwargs)
        self.name = name
        self.value = value


class MicrosoftAccessLinkedService(LinkedService):
    """Microsoft Access linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The non-access credential portion of the connection string
     as well as an optional encrypted credential. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar authentication_type: Type of authentication used to connect to the Microsoft Access as
     ODBC data store. Possible values are: Anonymous and Basic. Type: string (or Expression with
     resultType string).
    :vartype authentication_type: any
    :ivar credential: The access credential portion of the connection string specified in
     driver-specific property-value format.
    :vartype credential: ~azure.mgmt.datafactory.models.SecretBase
    :ivar user_name: User name for Basic authentication. Type: string (or Expression with
     resultType string).
    :vartype user_name: any
    :ivar password: Password for Basic authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'SecretBase'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        authentication_type: Optional[Any] = None,
        credential: Optional["SecretBase"] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The non-access credential portion of the connection
         string as well as an optional encrypted credential. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword authentication_type: Type of authentication used to connect to the Microsoft Access as
         ODBC data store. Possible values are: Anonymous and Basic. Type: string (or Expression with
         resultType string).
        :paramtype authentication_type: any
        :keyword credential: The access credential portion of the connection string specified in
         driver-specific property-value format.
        :paramtype credential: ~azure.mgmt.datafactory.models.SecretBase
        :keyword user_name: User name for Basic authentication. Type: string (or Expression with
         resultType string).
        :paramtype user_name: any
        :keyword password: Password for Basic authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(MicrosoftAccessLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'MicrosoftAccess'  # type: str
        self.connection_string = connection_string
        self.authentication_type = authentication_type
        self.credential = credential
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class MicrosoftAccessSink(CopySink):
    """A copy activity Microsoft Access sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar pre_copy_script: A query to execute before starting the copy. Type: string (or Expression
     with resultType string).
    :vartype pre_copy_script: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        pre_copy_script: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword pre_copy_script: A query to execute before starting the copy. Type: string (or
         Expression with resultType string).
        :paramtype pre_copy_script: any
        """
        super(MicrosoftAccessSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'MicrosoftAccessSink'  # type: str
        self.pre_copy_script = pre_copy_script


class MicrosoftAccessSource(CopySource):
    """A copy activity source for Microsoft Access.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: Database query. Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: Database query. Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(MicrosoftAccessSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'MicrosoftAccessSource'  # type: str
        self.query = query
        self.additional_columns = additional_columns


class MicrosoftAccessTableDataset(Dataset):
    """The Microsoft Access table dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The Microsoft Access table name. Type: string (or Expression with resultType
     string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The Microsoft Access table name. Type: string (or Expression with
         resultType string).
        :paramtype table_name: any
        """
        super(MicrosoftAccessTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MicrosoftAccessTable'  # type: str
        self.table_name = table_name


class MongoDbAtlasCollectionDataset(Dataset):
    """The MongoDB Atlas database dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar collection: Required. The collection name of the MongoDB Atlas database. Type: string (or
     Expression with resultType string).
    :vartype collection: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'collection': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'collection': {'key': 'typeProperties.collection', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        collection: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword collection: Required. The collection name of the MongoDB Atlas database. Type: string
         (or Expression with resultType string).
        :paramtype collection: any
        """
        super(MongoDbAtlasCollectionDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MongoDbAtlasCollection'  # type: str
        self.collection = collection


class MongoDbAtlasLinkedService(LinkedService):
    """Linked service for MongoDB Atlas data source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The MongoDB Atlas connection string. Type: string,
     SecureString or AzureKeyVaultSecretReference. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar database: Required. The name of the MongoDB Atlas database that you want to access. Type:
     string (or Expression with resultType string).
    :vartype database: any
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'database': {'key': 'typeProperties.database', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        database: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The MongoDB Atlas connection string. Type: string,
         SecureString or AzureKeyVaultSecretReference. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword database: Required. The name of the MongoDB Atlas database that you want to access.
         Type: string (or Expression with resultType string).
        :paramtype database: any
        """
        super(MongoDbAtlasLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'MongoDbAtlas'  # type: str
        self.connection_string = connection_string
        self.database = database


class MongoDbAtlasSink(CopySink):
    """A copy activity MongoDB Atlas sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar write_behavior: Specifies whether the document with same key to be overwritten (upsert)
     rather than throw exception (insert). The default value is "insert". Type: string (or
     Expression with resultType string). Type: string (or Expression with resultType string).
    :vartype write_behavior: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        write_behavior: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword write_behavior: Specifies whether the document with same key to be overwritten
         (upsert) rather than throw exception (insert). The default value is "insert". Type: string (or
         Expression with resultType string). Type: string (or Expression with resultType string).
        :paramtype write_behavior: any
        """
        super(MongoDbAtlasSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'MongoDbAtlasSink'  # type: str
        self.write_behavior = write_behavior


class MongoDbAtlasSource(CopySource):
    """A copy activity source for a MongoDB Atlas database.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar filter: Specifies selection filter using query operators. To return all documents in a
     collection, omit this parameter or pass an empty document ({}). Type: string (or Expression
     with resultType string).
    :vartype filter: any
    :ivar cursor_methods: Cursor methods for Mongodb query.
    :vartype cursor_methods: ~azure.mgmt.datafactory.models.MongoDbCursorMethodsProperties
    :ivar batch_size: Specifies the number of documents to return in each batch of the response
     from MongoDB Atlas instance. In most cases, modifying the batch size will not affect the user
     or the application. This property's main purpose is to avoid hit the limitation of response
     size. Type: integer (or Expression with resultType integer).
    :vartype batch_size: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'filter': {'key': 'filter', 'type': 'object'},
        'cursor_methods': {'key': 'cursorMethods', 'type': 'MongoDbCursorMethodsProperties'},
        'batch_size': {'key': 'batchSize', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        filter: Optional[Any] = None,
        cursor_methods: Optional["MongoDbCursorMethodsProperties"] = None,
        batch_size: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword filter: Specifies selection filter using query operators. To return all documents in a
         collection, omit this parameter or pass an empty document ({}). Type: string (or Expression
         with resultType string).
        :paramtype filter: any
        :keyword cursor_methods: Cursor methods for Mongodb query.
        :paramtype cursor_methods: ~azure.mgmt.datafactory.models.MongoDbCursorMethodsProperties
        :keyword batch_size: Specifies the number of documents to return in each batch of the response
         from MongoDB Atlas instance. In most cases, modifying the batch size will not affect the user
         or the application. This property's main purpose is to avoid hit the limitation of response
         size. Type: integer (or Expression with resultType integer).
        :paramtype batch_size: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(MongoDbAtlasSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'MongoDbAtlasSource'  # type: str
        self.filter = filter
        self.cursor_methods = cursor_methods
        self.batch_size = batch_size
        self.query_timeout = query_timeout
        self.additional_columns = additional_columns


class MongoDbCollectionDataset(Dataset):
    """The MongoDB database dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar collection_name: Required. The table name of the MongoDB database. Type: string (or
     Expression with resultType string).
    :vartype collection_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'collection_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'collection_name': {'key': 'typeProperties.collectionName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        collection_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword collection_name: Required. The table name of the MongoDB database. Type: string (or
         Expression with resultType string).
        :paramtype collection_name: any
        """
        super(MongoDbCollectionDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MongoDbCollection'  # type: str
        self.collection_name = collection_name


class MongoDbCursorMethodsProperties(msrest.serialization.Model):
    """Cursor methods for Mongodb query.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar project: Specifies the fields to return in the documents that match the query filter. To
     return all fields in the matching documents, omit this parameter. Type: string (or Expression
     with resultType string).
    :vartype project: any
    :ivar sort: Specifies the order in which the query returns matching documents. Type: string (or
     Expression with resultType string). Type: string (or Expression with resultType string).
    :vartype sort: any
    :ivar skip: Specifies the how many documents skipped and where MongoDB begins returning
     results. This approach may be useful in implementing paginated results. Type: integer (or
     Expression with resultType integer).
    :vartype skip: any
    :ivar limit: Specifies the maximum number of documents the server returns. limit() is analogous
     to the LIMIT statement in a SQL database. Type: integer (or Expression with resultType
     integer).
    :vartype limit: any
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'project': {'key': 'project', 'type': 'object'},
        'sort': {'key': 'sort', 'type': 'object'},
        'skip': {'key': 'skip', 'type': 'object'},
        'limit': {'key': 'limit', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        project: Optional[Any] = None,
        sort: Optional[Any] = None,
        skip: Optional[Any] = None,
        limit: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword project: Specifies the fields to return in the documents that match the query filter.
         To return all fields in the matching documents, omit this parameter. Type: string (or
         Expression with resultType string).
        :paramtype project: any
        :keyword sort: Specifies the order in which the query returns matching documents. Type: string
         (or Expression with resultType string). Type: string (or Expression with resultType string).
        :paramtype sort: any
        :keyword skip: Specifies the how many documents skipped and where MongoDB begins returning
         results. This approach may be useful in implementing paginated results. Type: integer (or
         Expression with resultType integer).
        :paramtype skip: any
        :keyword limit: Specifies the maximum number of documents the server returns. limit() is
         analogous to the LIMIT statement in a SQL database. Type: integer (or Expression with
         resultType integer).
        :paramtype limit: any
        """
        super(MongoDbCursorMethodsProperties, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.project = project
        self.sort = sort
        self.skip = skip
        self.limit = limit


class MongoDbLinkedService(LinkedService):
    """Linked service for MongoDb data source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar server: Required. The IP address or server name of the MongoDB server. Type: string (or
     Expression with resultType string).
    :vartype server: any
    :ivar authentication_type: The authentication type to be used to connect to the MongoDB
     database. Possible values include: "Basic", "Anonymous".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.MongoDbAuthenticationType
    :ivar database_name: Required. The name of the MongoDB database that you want to access. Type:
     string (or Expression with resultType string).
    :vartype database_name: any
    :ivar username: Username for authentication. Type: string (or Expression with resultType
     string).
    :vartype username: any
    :ivar password: Password for authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar auth_source: Database to verify the username and password. Type: string (or Expression
     with resultType string).
    :vartype auth_source: any
    :ivar port: The TCP port number that the MongoDB server uses to listen for client connections.
     The default value is 27017. Type: integer (or Expression with resultType integer), minimum: 0.
    :vartype port: any
    :ivar enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false. Type: boolean (or Expression with resultType boolean).
    :vartype enable_ssl: any
    :ivar allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false. Type: boolean (or Expression with resultType boolean).
    :vartype allow_self_signed_server_cert: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'server': {'required': True},
        'database_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'server': {'key': 'typeProperties.server', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'database_name': {'key': 'typeProperties.databaseName', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'auth_source': {'key': 'typeProperties.authSource', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'object'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        server: Any,
        database_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        authentication_type: Optional[Union[str, "MongoDbAuthenticationType"]] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        auth_source: Optional[Any] = None,
        port: Optional[Any] = None,
        enable_ssl: Optional[Any] = None,
        allow_self_signed_server_cert: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword server: Required. The IP address or server name of the MongoDB server. Type: string
         (or Expression with resultType string).
        :paramtype server: any
        :keyword authentication_type: The authentication type to be used to connect to the MongoDB
         database. Possible values include: "Basic", "Anonymous".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.MongoDbAuthenticationType
        :keyword database_name: Required. The name of the MongoDB database that you want to access.
         Type: string (or Expression with resultType string).
        :paramtype database_name: any
        :keyword username: Username for authentication. Type: string (or Expression with resultType
         string).
        :paramtype username: any
        :keyword password: Password for authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword auth_source: Database to verify the username and password. Type: string (or Expression
         with resultType string).
        :paramtype auth_source: any
        :keyword port: The TCP port number that the MongoDB server uses to listen for client
         connections. The default value is 27017. Type: integer (or Expression with resultType integer),
         minimum: 0.
        :paramtype port: any
        :keyword enable_ssl: Specifies whether the connections to the server are encrypted using SSL.
         The default value is false. Type: boolean (or Expression with resultType boolean).
        :paramtype enable_ssl: any
        :keyword allow_self_signed_server_cert: Specifies whether to allow self-signed certificates
         from the server. The default value is false. Type: boolean (or Expression with resultType
         boolean).
        :paramtype allow_self_signed_server_cert: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(MongoDbLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'MongoDb'  # type: str
        self.server = server
        self.authentication_type = authentication_type
        self.database_name = database_name
        self.username = username
        self.password = password
        self.auth_source = auth_source
        self.port = port
        self.enable_ssl = enable_ssl
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class MongoDbSource(CopySource):
    """A copy activity source for a MongoDB database.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: Database query. Should be a SQL-92 query expression. Type: string (or Expression
     with resultType string).
    :vartype query: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: Database query. Should be a SQL-92 query expression. Type: string (or
         Expression with resultType string).
        :paramtype query: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(MongoDbSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'MongoDbSource'  # type: str
        self.query = query
        self.additional_columns = additional_columns


class MongoDbV2CollectionDataset(Dataset):
    """The MongoDB database dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar collection: Required. The collection name of the MongoDB database. Type: string (or
     Expression with resultType string).
    :vartype collection: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'collection': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'collection': {'key': 'typeProperties.collection', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        collection: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword collection: Required. The collection name of the MongoDB database. Type: string (or
         Expression with resultType string).
        :paramtype collection: any
        """
        super(MongoDbV2CollectionDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MongoDbV2Collection'  # type: str
        self.collection = collection


class MongoDbV2LinkedService(LinkedService):
    """Linked service for MongoDB data source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The MongoDB connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference. Type: string, SecureString or AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar database: Required. The name of the MongoDB database that you want to access. Type:
     string (or Expression with resultType string).
    :vartype database: any
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'database': {'key': 'typeProperties.database', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        database: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The MongoDB connection string. Type: string, SecureString
         or AzureKeyVaultSecretReference. Type: string, SecureString or AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword database: Required. The name of the MongoDB database that you want to access. Type:
         string (or Expression with resultType string).
        :paramtype database: any
        """
        super(MongoDbV2LinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'MongoDbV2'  # type: str
        self.connection_string = connection_string
        self.database = database


class MongoDbV2Sink(CopySink):
    """A copy activity MongoDB sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar write_behavior: Specifies whether the document with same key to be overwritten (upsert)
     rather than throw exception (insert). The default value is "insert". Type: string (or
     Expression with resultType string). Type: string (or Expression with resultType string).
    :vartype write_behavior: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        write_behavior: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword write_behavior: Specifies whether the document with same key to be overwritten
         (upsert) rather than throw exception (insert). The default value is "insert". Type: string (or
         Expression with resultType string). Type: string (or Expression with resultType string).
        :paramtype write_behavior: any
        """
        super(MongoDbV2Sink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'MongoDbV2Sink'  # type: str
        self.write_behavior = write_behavior


class MongoDbV2Source(CopySource):
    """A copy activity source for a MongoDB database.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar filter: Specifies selection filter using query operators. To return all documents in a
     collection, omit this parameter or pass an empty document ({}). Type: string (or Expression
     with resultType string).
    :vartype filter: any
    :ivar cursor_methods: Cursor methods for Mongodb query.
    :vartype cursor_methods: ~azure.mgmt.datafactory.models.MongoDbCursorMethodsProperties
    :ivar batch_size: Specifies the number of documents to return in each batch of the response
     from MongoDB instance. In most cases, modifying the batch size will not affect the user or the
     application. This property's main purpose is to avoid hit the limitation of response size.
     Type: integer (or Expression with resultType integer).
    :vartype batch_size: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'filter': {'key': 'filter', 'type': 'object'},
        'cursor_methods': {'key': 'cursorMethods', 'type': 'MongoDbCursorMethodsProperties'},
        'batch_size': {'key': 'batchSize', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        filter: Optional[Any] = None,
        cursor_methods: Optional["MongoDbCursorMethodsProperties"] = None,
        batch_size: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword filter: Specifies selection filter using query operators. To return all documents in a
         collection, omit this parameter or pass an empty document ({}). Type: string (or Expression
         with resultType string).
        :paramtype filter: any
        :keyword cursor_methods: Cursor methods for Mongodb query.
        :paramtype cursor_methods: ~azure.mgmt.datafactory.models.MongoDbCursorMethodsProperties
        :keyword batch_size: Specifies the number of documents to return in each batch of the response
         from MongoDB instance. In most cases, modifying the batch size will not affect the user or the
         application. This property's main purpose is to avoid hit the limitation of response size.
         Type: integer (or Expression with resultType integer).
        :paramtype batch_size: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(MongoDbV2Source, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'MongoDbV2Source'  # type: str
        self.filter = filter
        self.cursor_methods = cursor_methods
        self.batch_size = batch_size
        self.query_timeout = query_timeout
        self.additional_columns = additional_columns


class MySqlLinkedService(LinkedService):
    """Linked service for MySQL data source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The connection string.
    :vartype connection_string: any
    :ivar password: The Azure key vault secret reference of password in connection string.
    :vartype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The connection string.
        :paramtype connection_string: any
        :keyword password: The Azure key vault secret reference of password in connection string.
        :paramtype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(MySqlLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'MySql'  # type: str
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class MySqlSource(TabularSource):
    """A copy activity source for MySQL databases.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: Database query. Type: string (or Expression with resultType string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: Database query. Type: string (or Expression with resultType string).
        :paramtype query: any
        """
        super(MySqlSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'MySqlSource'  # type: str
        self.query = query


class MySqlTableDataset(Dataset):
    """The MySQL table dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The MySQL table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The MySQL table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(MySqlTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'MySqlTable'  # type: str
        self.table_name = table_name


class NetezzaLinkedService(LinkedService):
    """Netezza linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar pwd: The Azure key vault secret reference of password in connection string.
    :vartype pwd: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'pwd': {'key': 'typeProperties.pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: An ODBC connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword pwd: The Azure key vault secret reference of password in connection string.
        :paramtype pwd: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(NetezzaLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Netezza'  # type: str
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class NetezzaPartitionSettings(msrest.serialization.Model):
    """The settings that will be leveraged for Netezza source partitioning.

    :ivar partition_column_name: The name of the column in integer type that will be used for
     proceeding range partitioning. Type: string (or Expression with resultType string).
    :vartype partition_column_name: any
    :ivar partition_upper_bound: The maximum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :vartype partition_upper_bound: any
    :ivar partition_lower_bound: The minimum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :vartype partition_lower_bound: any
    """

    _attribute_map = {
        'partition_column_name': {'key': 'partitionColumnName', 'type': 'object'},
        'partition_upper_bound': {'key': 'partitionUpperBound', 'type': 'object'},
        'partition_lower_bound': {'key': 'partitionLowerBound', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        partition_column_name: Optional[Any] = None,
        partition_upper_bound: Optional[Any] = None,
        partition_lower_bound: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword partition_column_name: The name of the column in integer type that will be used for
         proceeding range partitioning. Type: string (or Expression with resultType string).
        :paramtype partition_column_name: any
        :keyword partition_upper_bound: The maximum value of column specified in partitionColumnName
         that will be used for proceeding range partitioning. Type: string (or Expression with
         resultType string).
        :paramtype partition_upper_bound: any
        :keyword partition_lower_bound: The minimum value of column specified in partitionColumnName
         that will be used for proceeding range partitioning. Type: string (or Expression with
         resultType string).
        :paramtype partition_lower_bound: any
        """
        super(NetezzaPartitionSettings, self).__init__(**kwargs)
        self.partition_column_name = partition_column_name
        self.partition_upper_bound = partition_upper_bound
        self.partition_lower_bound = partition_lower_bound


class NetezzaSource(TabularSource):
    """A copy activity Netezza source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    :ivar partition_option: The partition mechanism that will be used for Netezza read in parallel.
     Possible values include: "None", "DataSlice", "DynamicRange".
    :vartype partition_option: any
    :ivar partition_settings: The settings that will be leveraged for Netezza source partitioning.
    :vartype partition_settings: ~azure.mgmt.datafactory.models.NetezzaPartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'partition_option': {'key': 'partitionOption', 'type': 'object'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'NetezzaPartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        partition_option: Optional[Any] = None,
        partition_settings: Optional["NetezzaPartitionSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        :keyword partition_option: The partition mechanism that will be used for Netezza read in
         parallel. Possible values include: "None", "DataSlice", "DynamicRange".
        :paramtype partition_option: any
        :keyword partition_settings: The settings that will be leveraged for Netezza source
         partitioning.
        :paramtype partition_settings: ~azure.mgmt.datafactory.models.NetezzaPartitionSettings
        """
        super(NetezzaSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'NetezzaSource'  # type: str
        self.query = query
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class NetezzaTableDataset(Dataset):
    """Netezza dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar table: The table name of the Netezza. Type: string (or Expression with resultType
     string).
    :vartype table: any
    :ivar schema_type_properties_schema: The schema name of the Netezza. Type: string (or
     Expression with resultType string).
    :vartype schema_type_properties_schema: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword table: The table name of the Netezza. Type: string (or Expression with resultType
         string).
        :paramtype table: any
        :keyword schema_type_properties_schema: The schema name of the Netezza. Type: string (or
         Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        """
        super(NetezzaTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'NetezzaTable'  # type: str
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class ODataLinkedService(LinkedService):
    """Open Data Protocol (OData) linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar url: Required. The URL of the OData service endpoint. Type: string (or Expression with
     resultType string).
    :vartype url: any
    :ivar authentication_type: Type of authentication used to connect to the OData service.
     Possible values include: "Basic", "Anonymous", "Windows", "AadServicePrincipal",
     "ManagedServiceIdentity".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.ODataAuthenticationType
    :ivar user_name: User name of the OData service. Type: string (or Expression with resultType
     string).
    :vartype user_name: any
    :ivar password: Password of the OData service.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar auth_headers: The additional HTTP headers in the request to RESTful API used for
     authorization. Type: object (or Expression with resultType object).
    :vartype auth_headers: any
    :ivar tenant: Specify the tenant information (domain name or tenant ID) under which your
     application resides. Type: string (or Expression with resultType string).
    :vartype tenant: any
    :ivar service_principal_id: Specify the application id of your application registered in Azure
     Active Directory. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar azure_cloud_type: Indicates the azure cloud type of the service principle auth. Allowed
     values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is the data
     factory regions cloud type. Type: string (or Expression with resultType string).
    :vartype azure_cloud_type: any
    :ivar aad_resource_id: Specify the resource you are requesting authorization to use Directory.
     Type: string (or Expression with resultType string).
    :vartype aad_resource_id: any
    :ivar aad_service_principal_credential_type: Specify the credential type (key or cert) is used
     for service principal. Possible values include: "ServicePrincipalKey", "ServicePrincipalCert".
    :vartype aad_service_principal_credential_type: str or
     ~azure.mgmt.datafactory.models.ODataAadServicePrincipalCredentialType
    :ivar service_principal_key: Specify the secret of your application registered in Azure Active
     Directory. Type: string (or Expression with resultType string).
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar service_principal_embedded_cert: Specify the base64 encoded certificate of your
     application registered in Azure Active Directory. Type: string (or Expression with resultType
     string).
    :vartype service_principal_embedded_cert: ~azure.mgmt.datafactory.models.SecretBase
    :ivar service_principal_embedded_cert_password: Specify the password of your certificate if
     your certificate has a password and you are using AadServicePrincipal authentication. Type:
     string (or Expression with resultType string).
    :vartype service_principal_embedded_cert_password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'url': {'key': 'typeProperties.url', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'auth_headers': {'key': 'typeProperties.authHeaders', 'type': 'object'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'azure_cloud_type': {'key': 'typeProperties.azureCloudType', 'type': 'object'},
        'aad_resource_id': {'key': 'typeProperties.aadResourceId', 'type': 'object'},
        'aad_service_principal_credential_type': {'key': 'typeProperties.aadServicePrincipalCredentialType', 'type': 'str'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'service_principal_embedded_cert': {'key': 'typeProperties.servicePrincipalEmbeddedCert', 'type': 'SecretBase'},
        'service_principal_embedded_cert_password': {'key': 'typeProperties.servicePrincipalEmbeddedCertPassword', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        url: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        authentication_type: Optional[Union[str, "ODataAuthenticationType"]] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        auth_headers: Optional[Any] = None,
        tenant: Optional[Any] = None,
        service_principal_id: Optional[Any] = None,
        azure_cloud_type: Optional[Any] = None,
        aad_resource_id: Optional[Any] = None,
        aad_service_principal_credential_type: Optional[Union[str, "ODataAadServicePrincipalCredentialType"]] = None,
        service_principal_key: Optional["SecretBase"] = None,
        service_principal_embedded_cert: Optional["SecretBase"] = None,
        service_principal_embedded_cert_password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword url: Required. The URL of the OData service endpoint. Type: string (or Expression with
         resultType string).
        :paramtype url: any
        :keyword authentication_type: Type of authentication used to connect to the OData service.
         Possible values include: "Basic", "Anonymous", "Windows", "AadServicePrincipal",
         "ManagedServiceIdentity".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.ODataAuthenticationType
        :keyword user_name: User name of the OData service. Type: string (or Expression with resultType
         string).
        :paramtype user_name: any
        :keyword password: Password of the OData service.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword auth_headers: The additional HTTP headers in the request to RESTful API used for
         authorization. Type: object (or Expression with resultType object).
        :paramtype auth_headers: any
        :keyword tenant: Specify the tenant information (domain name or tenant ID) under which your
         application resides. Type: string (or Expression with resultType string).
        :paramtype tenant: any
        :keyword service_principal_id: Specify the application id of your application registered in
         Azure Active Directory. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword azure_cloud_type: Indicates the azure cloud type of the service principle auth.
         Allowed values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is
         the data factory regions cloud type. Type: string (or Expression with resultType string).
        :paramtype azure_cloud_type: any
        :keyword aad_resource_id: Specify the resource you are requesting authorization to use
         Directory. Type: string (or Expression with resultType string).
        :paramtype aad_resource_id: any
        :keyword aad_service_principal_credential_type: Specify the credential type (key or cert) is
         used for service principal. Possible values include: "ServicePrincipalKey",
         "ServicePrincipalCert".
        :paramtype aad_service_principal_credential_type: str or
         ~azure.mgmt.datafactory.models.ODataAadServicePrincipalCredentialType
        :keyword service_principal_key: Specify the secret of your application registered in Azure
         Active Directory. Type: string (or Expression with resultType string).
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword service_principal_embedded_cert: Specify the base64 encoded certificate of your
         application registered in Azure Active Directory. Type: string (or Expression with resultType
         string).
        :paramtype service_principal_embedded_cert: ~azure.mgmt.datafactory.models.SecretBase
        :keyword service_principal_embedded_cert_password: Specify the password of your certificate if
         your certificate has a password and you are using AadServicePrincipal authentication. Type:
         string (or Expression with resultType string).
        :paramtype service_principal_embedded_cert_password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(ODataLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'OData'  # type: str
        self.url = url
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.auth_headers = auth_headers
        self.tenant = tenant
        self.service_principal_id = service_principal_id
        self.azure_cloud_type = azure_cloud_type
        self.aad_resource_id = aad_resource_id
        self.aad_service_principal_credential_type = aad_service_principal_credential_type
        self.service_principal_key = service_principal_key
        self.service_principal_embedded_cert = service_principal_embedded_cert
        self.service_principal_embedded_cert_password = service_principal_embedded_cert_password
        self.encrypted_credential = encrypted_credential


class ODataResourceDataset(Dataset):
    """The Open Data Protocol (OData) resource dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar path: The OData resource path. Type: string (or Expression with resultType string).
    :vartype path: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'path': {'key': 'typeProperties.path', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        path: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword path: The OData resource path. Type: string (or Expression with resultType string).
        :paramtype path: any
        """
        super(ODataResourceDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ODataResource'  # type: str
        self.path = path


class ODataSource(CopySource):
    """A copy activity source for OData source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: OData query. For example, "$top=1". Type: string (or Expression with resultType
     string).
    :vartype query: any
    :ivar http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the timeout
     to get a response, not the timeout to read response data. Default value: 00:05:00. Type: string
     (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype http_request_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'http_request_timeout': {'key': 'httpRequestTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query: Optional[Any] = None,
        http_request_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: OData query. For example, "$top=1". Type: string (or Expression with resultType
         string).
        :paramtype query: any
        :keyword http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the
         timeout to get a response, not the timeout to read response data. Default value: 00:05:00.
         Type: string (or Expression with resultType string), pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype http_request_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(ODataSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'ODataSource'  # type: str
        self.query = query
        self.http_request_timeout = http_request_timeout
        self.additional_columns = additional_columns


class OdbcLinkedService(LinkedService):
    """Open Database Connectivity (ODBC) linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The non-access credential portion of the connection string
     as well as an optional encrypted credential. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar authentication_type: Type of authentication used to connect to the ODBC data store.
     Possible values are: Anonymous and Basic. Type: string (or Expression with resultType string).
    :vartype authentication_type: any
    :ivar credential: The access credential portion of the connection string specified in
     driver-specific property-value format.
    :vartype credential: ~azure.mgmt.datafactory.models.SecretBase
    :ivar user_name: User name for Basic authentication. Type: string (or Expression with
     resultType string).
    :vartype user_name: any
    :ivar password: Password for Basic authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'SecretBase'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        authentication_type: Optional[Any] = None,
        credential: Optional["SecretBase"] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The non-access credential portion of the connection
         string as well as an optional encrypted credential. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword authentication_type: Type of authentication used to connect to the ODBC data store.
         Possible values are: Anonymous and Basic. Type: string (or Expression with resultType string).
        :paramtype authentication_type: any
        :keyword credential: The access credential portion of the connection string specified in
         driver-specific property-value format.
        :paramtype credential: ~azure.mgmt.datafactory.models.SecretBase
        :keyword user_name: User name for Basic authentication. Type: string (or Expression with
         resultType string).
        :paramtype user_name: any
        :keyword password: Password for Basic authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(OdbcLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Odbc'  # type: str
        self.connection_string = connection_string
        self.authentication_type = authentication_type
        self.credential = credential
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class OdbcSink(CopySink):
    """A copy activity ODBC sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar pre_copy_script: A query to execute before starting the copy. Type: string (or Expression
     with resultType string).
    :vartype pre_copy_script: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        pre_copy_script: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword pre_copy_script: A query to execute before starting the copy. Type: string (or
         Expression with resultType string).
        :paramtype pre_copy_script: any
        """
        super(OdbcSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'OdbcSink'  # type: str
        self.pre_copy_script = pre_copy_script


class OdbcSource(TabularSource):
    """A copy activity source for ODBC databases.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: Database query. Type: string (or Expression with resultType string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: Database query. Type: string (or Expression with resultType string).
        :paramtype query: any
        """
        super(OdbcSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'OdbcSource'  # type: str
        self.query = query


class OdbcTableDataset(Dataset):
    """The ODBC table dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The ODBC table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The ODBC table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(OdbcTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'OdbcTable'  # type: str
        self.table_name = table_name


class Office365Dataset(Dataset):
    """The Office365 account.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: Required. Name of the dataset to extract from Office 365. Type: string (or
     Expression with resultType string).
    :vartype table_name: any
    :ivar predicate: A predicate expression that can be used to filter the specific rows to extract
     from Office 365. Type: string (or Expression with resultType string).
    :vartype predicate: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'table_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'predicate': {'key': 'typeProperties.predicate', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        table_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        predicate: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: Required. Name of the dataset to extract from Office 365. Type: string (or
         Expression with resultType string).
        :paramtype table_name: any
        :keyword predicate: A predicate expression that can be used to filter the specific rows to
         extract from Office 365. Type: string (or Expression with resultType string).
        :paramtype predicate: any
        """
        super(Office365Dataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Office365Table'  # type: str
        self.table_name = table_name
        self.predicate = predicate


class Office365LinkedService(LinkedService):
    """Office365 linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar office365_tenant_id: Required. Azure tenant ID to which the Office 365 account belongs.
     Type: string (or Expression with resultType string).
    :vartype office365_tenant_id: any
    :ivar service_principal_tenant_id: Required. Specify the tenant information under which your
     Azure AD web application resides. Type: string (or Expression with resultType string).
    :vartype service_principal_tenant_id: any
    :ivar service_principal_id: Required. Specify the application's client ID. Type: string (or
     Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: Required. Specify the application's key.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'office365_tenant_id': {'required': True},
        'service_principal_tenant_id': {'required': True},
        'service_principal_id': {'required': True},
        'service_principal_key': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'office365_tenant_id': {'key': 'typeProperties.office365TenantId', 'type': 'object'},
        'service_principal_tenant_id': {'key': 'typeProperties.servicePrincipalTenantId', 'type': 'object'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        office365_tenant_id: Any,
        service_principal_tenant_id: Any,
        service_principal_id: Any,
        service_principal_key: "SecretBase",
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword office365_tenant_id: Required. Azure tenant ID to which the Office 365 account
         belongs. Type: string (or Expression with resultType string).
        :paramtype office365_tenant_id: any
        :keyword service_principal_tenant_id: Required. Specify the tenant information under which your
         Azure AD web application resides. Type: string (or Expression with resultType string).
        :paramtype service_principal_tenant_id: any
        :keyword service_principal_id: Required. Specify the application's client ID. Type: string (or
         Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: Required. Specify the application's key.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(Office365LinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Office365'  # type: str
        self.office365_tenant_id = office365_tenant_id
        self.service_principal_tenant_id = service_principal_tenant_id
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.encrypted_credential = encrypted_credential


class Office365Source(CopySource):
    """A copy activity source for an Office 365 service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar allowed_groups: The groups containing all the users. Type: array of strings (or
     Expression with resultType array of strings).
    :vartype allowed_groups: any
    :ivar user_scope_filter_uri: The user scope uri. Type: string (or Expression with resultType
     string).
    :vartype user_scope_filter_uri: any
    :ivar date_filter_column: The Column to apply the :code:`<paramref name="StartTime"/>` and
     :code:`<paramref name="EndTime"/>`. Type: string (or Expression with resultType string).
    :vartype date_filter_column: any
    :ivar start_time: Start time of the requested range for this dataset. Type: string (or
     Expression with resultType string).
    :vartype start_time: any
    :ivar end_time: End time of the requested range for this dataset. Type: string (or Expression
     with resultType string).
    :vartype end_time: any
    :ivar output_columns: The columns to be read out from the Office 365 table. Type: array of
     objects (or Expression with resultType array of objects). Example: [ { "name": "Id" }, {
     "name": "CreatedDateTime" } ].
    :vartype output_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'allowed_groups': {'key': 'allowedGroups', 'type': 'object'},
        'user_scope_filter_uri': {'key': 'userScopeFilterUri', 'type': 'object'},
        'date_filter_column': {'key': 'dateFilterColumn', 'type': 'object'},
        'start_time': {'key': 'startTime', 'type': 'object'},
        'end_time': {'key': 'endTime', 'type': 'object'},
        'output_columns': {'key': 'outputColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        allowed_groups: Optional[Any] = None,
        user_scope_filter_uri: Optional[Any] = None,
        date_filter_column: Optional[Any] = None,
        start_time: Optional[Any] = None,
        end_time: Optional[Any] = None,
        output_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword allowed_groups: The groups containing all the users. Type: array of strings (or
         Expression with resultType array of strings).
        :paramtype allowed_groups: any
        :keyword user_scope_filter_uri: The user scope uri. Type: string (or Expression with resultType
         string).
        :paramtype user_scope_filter_uri: any
        :keyword date_filter_column: The Column to apply the :code:`<paramref name="StartTime"/>` and
         :code:`<paramref name="EndTime"/>`. Type: string (or Expression with resultType string).
        :paramtype date_filter_column: any
        :keyword start_time: Start time of the requested range for this dataset. Type: string (or
         Expression with resultType string).
        :paramtype start_time: any
        :keyword end_time: End time of the requested range for this dataset. Type: string (or
         Expression with resultType string).
        :paramtype end_time: any
        :keyword output_columns: The columns to be read out from the Office 365 table. Type: array of
         objects (or Expression with resultType array of objects). Example: [ { "name": "Id" }, {
         "name": "CreatedDateTime" } ].
        :paramtype output_columns: any
        """
        super(Office365Source, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'Office365Source'  # type: str
        self.allowed_groups = allowed_groups
        self.user_scope_filter_uri = user_scope_filter_uri
        self.date_filter_column = date_filter_column
        self.start_time = start_time
        self.end_time = end_time
        self.output_columns = output_columns


class Operation(msrest.serialization.Model):
    """Azure Data Factory API operation definition.

    :ivar name: Operation name: {provider}/{resource}/{operation}.
    :vartype name: str
    :ivar origin: The intended executor of the operation.
    :vartype origin: str
    :ivar display: Metadata associated with the operation.
    :vartype display: ~azure.mgmt.datafactory.models.OperationDisplay
    :ivar service_specification: Details about a service operation.
    :vartype service_specification: ~azure.mgmt.datafactory.models.OperationServiceSpecification
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'origin': {'key': 'origin', 'type': 'str'},
        'display': {'key': 'display', 'type': 'OperationDisplay'},
        'service_specification': {'key': 'properties.serviceSpecification', 'type': 'OperationServiceSpecification'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        origin: Optional[str] = None,
        display: Optional["OperationDisplay"] = None,
        service_specification: Optional["OperationServiceSpecification"] = None,
        **kwargs
    ):
        """
        :keyword name: Operation name: {provider}/{resource}/{operation}.
        :paramtype name: str
        :keyword origin: The intended executor of the operation.
        :paramtype origin: str
        :keyword display: Metadata associated with the operation.
        :paramtype display: ~azure.mgmt.datafactory.models.OperationDisplay
        :keyword service_specification: Details about a service operation.
        :paramtype service_specification: ~azure.mgmt.datafactory.models.OperationServiceSpecification
        """
        super(Operation, self).__init__(**kwargs)
        self.name = name
        self.origin = origin
        self.display = display
        self.service_specification = service_specification


class OperationDisplay(msrest.serialization.Model):
    """Metadata associated with the operation.

    :ivar description: The description of the operation.
    :vartype description: str
    :ivar provider: The name of the provider.
    :vartype provider: str
    :ivar resource: The name of the resource type on which the operation is performed.
    :vartype resource: str
    :ivar operation: The type of operation: get, read, delete, etc.
    :vartype operation: str
    """

    _attribute_map = {
        'description': {'key': 'description', 'type': 'str'},
        'provider': {'key': 'provider', 'type': 'str'},
        'resource': {'key': 'resource', 'type': 'str'},
        'operation': {'key': 'operation', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        description: Optional[str] = None,
        provider: Optional[str] = None,
        resource: Optional[str] = None,
        operation: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword description: The description of the operation.
        :paramtype description: str
        :keyword provider: The name of the provider.
        :paramtype provider: str
        :keyword resource: The name of the resource type on which the operation is performed.
        :paramtype resource: str
        :keyword operation: The type of operation: get, read, delete, etc.
        :paramtype operation: str
        """
        super(OperationDisplay, self).__init__(**kwargs)
        self.description = description
        self.provider = provider
        self.resource = resource
        self.operation = operation


class OperationListResponse(msrest.serialization.Model):
    """A list of operations that can be performed by the Data Factory service.

    :ivar value: List of Data Factory operations supported by the Data Factory resource provider.
    :vartype value: list[~azure.mgmt.datafactory.models.Operation]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _attribute_map = {
        'value': {'key': 'value', 'type': '[Operation]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: Optional[List["Operation"]] = None,
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: List of Data Factory operations supported by the Data Factory resource
         provider.
        :paramtype value: list[~azure.mgmt.datafactory.models.Operation]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(OperationListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class OperationLogSpecification(msrest.serialization.Model):
    """Details about an operation related to logs.

    :ivar name: The name of the log category.
    :vartype name: str
    :ivar display_name: Localized display name.
    :vartype display_name: str
    :ivar blob_duration: Blobs created in the customer storage account, per hour.
    :vartype blob_duration: str
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'display_name': {'key': 'displayName', 'type': 'str'},
        'blob_duration': {'key': 'blobDuration', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        display_name: Optional[str] = None,
        blob_duration: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword name: The name of the log category.
        :paramtype name: str
        :keyword display_name: Localized display name.
        :paramtype display_name: str
        :keyword blob_duration: Blobs created in the customer storage account, per hour.
        :paramtype blob_duration: str
        """
        super(OperationLogSpecification, self).__init__(**kwargs)
        self.name = name
        self.display_name = display_name
        self.blob_duration = blob_duration


class OperationMetricAvailability(msrest.serialization.Model):
    """Defines how often data for a metric becomes available.

    :ivar time_grain: The granularity for the metric.
    :vartype time_grain: str
    :ivar blob_duration: Blob created in the customer storage account, per hour.
    :vartype blob_duration: str
    """

    _attribute_map = {
        'time_grain': {'key': 'timeGrain', 'type': 'str'},
        'blob_duration': {'key': 'blobDuration', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        time_grain: Optional[str] = None,
        blob_duration: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword time_grain: The granularity for the metric.
        :paramtype time_grain: str
        :keyword blob_duration: Blob created in the customer storage account, per hour.
        :paramtype blob_duration: str
        """
        super(OperationMetricAvailability, self).__init__(**kwargs)
        self.time_grain = time_grain
        self.blob_duration = blob_duration


class OperationMetricDimension(msrest.serialization.Model):
    """Defines the metric dimension.

    :ivar name: The name of the dimension for the metric.
    :vartype name: str
    :ivar display_name: The display name of the metric dimension.
    :vartype display_name: str
    :ivar to_be_exported_for_shoebox: Whether the dimension should be exported to Azure Monitor.
    :vartype to_be_exported_for_shoebox: bool
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'display_name': {'key': 'displayName', 'type': 'str'},
        'to_be_exported_for_shoebox': {'key': 'toBeExportedForShoebox', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        display_name: Optional[str] = None,
        to_be_exported_for_shoebox: Optional[bool] = None,
        **kwargs
    ):
        """
        :keyword name: The name of the dimension for the metric.
        :paramtype name: str
        :keyword display_name: The display name of the metric dimension.
        :paramtype display_name: str
        :keyword to_be_exported_for_shoebox: Whether the dimension should be exported to Azure Monitor.
        :paramtype to_be_exported_for_shoebox: bool
        """
        super(OperationMetricDimension, self).__init__(**kwargs)
        self.name = name
        self.display_name = display_name
        self.to_be_exported_for_shoebox = to_be_exported_for_shoebox


class OperationMetricSpecification(msrest.serialization.Model):
    """Details about an operation related to metrics.

    :ivar name: The name of the metric.
    :vartype name: str
    :ivar display_name: Localized display name of the metric.
    :vartype display_name: str
    :ivar display_description: The description of the metric.
    :vartype display_description: str
    :ivar unit: The unit that the metric is measured in.
    :vartype unit: str
    :ivar aggregation_type: The type of metric aggregation.
    :vartype aggregation_type: str
    :ivar enable_regional_mdm_account: Whether or not the service is using regional MDM accounts.
    :vartype enable_regional_mdm_account: str
    :ivar source_mdm_account: The name of the MDM account.
    :vartype source_mdm_account: str
    :ivar source_mdm_namespace: The name of the MDM namespace.
    :vartype source_mdm_namespace: str
    :ivar availabilities: Defines how often data for metrics becomes available.
    :vartype availabilities: list[~azure.mgmt.datafactory.models.OperationMetricAvailability]
    :ivar dimensions: Defines the metric dimension.
    :vartype dimensions: list[~azure.mgmt.datafactory.models.OperationMetricDimension]
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'display_name': {'key': 'displayName', 'type': 'str'},
        'display_description': {'key': 'displayDescription', 'type': 'str'},
        'unit': {'key': 'unit', 'type': 'str'},
        'aggregation_type': {'key': 'aggregationType', 'type': 'str'},
        'enable_regional_mdm_account': {'key': 'enableRegionalMdmAccount', 'type': 'str'},
        'source_mdm_account': {'key': 'sourceMdmAccount', 'type': 'str'},
        'source_mdm_namespace': {'key': 'sourceMdmNamespace', 'type': 'str'},
        'availabilities': {'key': 'availabilities', 'type': '[OperationMetricAvailability]'},
        'dimensions': {'key': 'dimensions', 'type': '[OperationMetricDimension]'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        display_name: Optional[str] = None,
        display_description: Optional[str] = None,
        unit: Optional[str] = None,
        aggregation_type: Optional[str] = None,
        enable_regional_mdm_account: Optional[str] = None,
        source_mdm_account: Optional[str] = None,
        source_mdm_namespace: Optional[str] = None,
        availabilities: Optional[List["OperationMetricAvailability"]] = None,
        dimensions: Optional[List["OperationMetricDimension"]] = None,
        **kwargs
    ):
        """
        :keyword name: The name of the metric.
        :paramtype name: str
        :keyword display_name: Localized display name of the metric.
        :paramtype display_name: str
        :keyword display_description: The description of the metric.
        :paramtype display_description: str
        :keyword unit: The unit that the metric is measured in.
        :paramtype unit: str
        :keyword aggregation_type: The type of metric aggregation.
        :paramtype aggregation_type: str
        :keyword enable_regional_mdm_account: Whether or not the service is using regional MDM
         accounts.
        :paramtype enable_regional_mdm_account: str
        :keyword source_mdm_account: The name of the MDM account.
        :paramtype source_mdm_account: str
        :keyword source_mdm_namespace: The name of the MDM namespace.
        :paramtype source_mdm_namespace: str
        :keyword availabilities: Defines how often data for metrics becomes available.
        :paramtype availabilities: list[~azure.mgmt.datafactory.models.OperationMetricAvailability]
        :keyword dimensions: Defines the metric dimension.
        :paramtype dimensions: list[~azure.mgmt.datafactory.models.OperationMetricDimension]
        """
        super(OperationMetricSpecification, self).__init__(**kwargs)
        self.name = name
        self.display_name = display_name
        self.display_description = display_description
        self.unit = unit
        self.aggregation_type = aggregation_type
        self.enable_regional_mdm_account = enable_regional_mdm_account
        self.source_mdm_account = source_mdm_account
        self.source_mdm_namespace = source_mdm_namespace
        self.availabilities = availabilities
        self.dimensions = dimensions


class OperationServiceSpecification(msrest.serialization.Model):
    """Details about a service operation.

    :ivar log_specifications: Details about operations related to logs.
    :vartype log_specifications: list[~azure.mgmt.datafactory.models.OperationLogSpecification]
    :ivar metric_specifications: Details about operations related to metrics.
    :vartype metric_specifications:
     list[~azure.mgmt.datafactory.models.OperationMetricSpecification]
    """

    _attribute_map = {
        'log_specifications': {'key': 'logSpecifications', 'type': '[OperationLogSpecification]'},
        'metric_specifications': {'key': 'metricSpecifications', 'type': '[OperationMetricSpecification]'},
    }

    def __init__(
        self,
        *,
        log_specifications: Optional[List["OperationLogSpecification"]] = None,
        metric_specifications: Optional[List["OperationMetricSpecification"]] = None,
        **kwargs
    ):
        """
        :keyword log_specifications: Details about operations related to logs.
        :paramtype log_specifications: list[~azure.mgmt.datafactory.models.OperationLogSpecification]
        :keyword metric_specifications: Details about operations related to metrics.
        :paramtype metric_specifications:
         list[~azure.mgmt.datafactory.models.OperationMetricSpecification]
        """
        super(OperationServiceSpecification, self).__init__(**kwargs)
        self.log_specifications = log_specifications
        self.metric_specifications = metric_specifications


class OracleCloudStorageLinkedService(LinkedService):
    """Linked service for Oracle Cloud Storage.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar access_key_id: The access key identifier of the Oracle Cloud Storage Identity and Access
     Management (IAM) user. Type: string (or Expression with resultType string).
    :vartype access_key_id: any
    :ivar secret_access_key: The secret access key of the Oracle Cloud Storage Identity and Access
     Management (IAM) user.
    :vartype secret_access_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar service_url: This value specifies the endpoint to access with the Oracle Cloud Storage
     Connector. This is an optional property; change it only if you want to try a different service
     endpoint or want to switch between https and http. Type: string (or Expression with resultType
     string).
    :vartype service_url: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'access_key_id': {'key': 'typeProperties.accessKeyId', 'type': 'object'},
        'secret_access_key': {'key': 'typeProperties.secretAccessKey', 'type': 'SecretBase'},
        'service_url': {'key': 'typeProperties.serviceUrl', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        access_key_id: Optional[Any] = None,
        secret_access_key: Optional["SecretBase"] = None,
        service_url: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword access_key_id: The access key identifier of the Oracle Cloud Storage Identity and
         Access Management (IAM) user. Type: string (or Expression with resultType string).
        :paramtype access_key_id: any
        :keyword secret_access_key: The secret access key of the Oracle Cloud Storage Identity and
         Access Management (IAM) user.
        :paramtype secret_access_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword service_url: This value specifies the endpoint to access with the Oracle Cloud Storage
         Connector. This is an optional property; change it only if you want to try a different service
         endpoint or want to switch between https and http. Type: string (or Expression with resultType
         string).
        :paramtype service_url: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(OracleCloudStorageLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'OracleCloudStorage'  # type: str
        self.access_key_id = access_key_id
        self.secret_access_key = secret_access_key
        self.service_url = service_url
        self.encrypted_credential = encrypted_credential


class OracleCloudStorageLocation(DatasetLocation):
    """The location of Oracle Cloud Storage dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    :ivar bucket_name: Specify the bucketName of Oracle Cloud Storage. Type: string (or Expression
     with resultType string).
    :vartype bucket_name: any
    :ivar version: Specify the version of Oracle Cloud Storage. Type: string (or Expression with
     resultType string).
    :vartype version: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
        'bucket_name': {'key': 'bucketName', 'type': 'object'},
        'version': {'key': 'version', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        bucket_name: Optional[Any] = None,
        version: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        :keyword bucket_name: Specify the bucketName of Oracle Cloud Storage. Type: string (or
         Expression with resultType string).
        :paramtype bucket_name: any
        :keyword version: Specify the version of Oracle Cloud Storage. Type: string (or Expression with
         resultType string).
        :paramtype version: any
        """
        super(OracleCloudStorageLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'OracleCloudStorageLocation'  # type: str
        self.bucket_name = bucket_name
        self.version = version


class OracleCloudStorageReadSettings(StoreReadSettings):
    """Oracle Cloud Storage read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar wildcard_folder_path: Oracle Cloud Storage wildcardFolderPath. Type: string (or
     Expression with resultType string).
    :vartype wildcard_folder_path: any
    :ivar wildcard_file_name: Oracle Cloud Storage wildcardFileName. Type: string (or Expression
     with resultType string).
    :vartype wildcard_file_name: any
    :ivar prefix: The prefix filter for the Oracle Cloud Storage object name. Type: string (or
     Expression with resultType string).
    :vartype prefix: any
    :ivar file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :vartype file_list_path: any
    :ivar enable_partition_discovery: Indicates whether to enable partition discovery.
    :vartype enable_partition_discovery: bool
    :ivar partition_root_path: Specify the root path where partition discovery starts from. Type:
     string (or Expression with resultType string).
    :vartype partition_root_path: any
    :ivar delete_files_after_completion: Indicates whether the source files need to be deleted
     after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
    :vartype delete_files_after_completion: any
    :ivar modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :vartype modified_datetime_end: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'object'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'object'},
        'prefix': {'key': 'prefix', 'type': 'object'},
        'file_list_path': {'key': 'fileListPath', 'type': 'object'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'partition_root_path': {'key': 'partitionRootPath', 'type': 'object'},
        'delete_files_after_completion': {'key': 'deleteFilesAfterCompletion', 'type': 'object'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        wildcard_folder_path: Optional[Any] = None,
        wildcard_file_name: Optional[Any] = None,
        prefix: Optional[Any] = None,
        file_list_path: Optional[Any] = None,
        enable_partition_discovery: Optional[bool] = None,
        partition_root_path: Optional[Any] = None,
        delete_files_after_completion: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword wildcard_folder_path: Oracle Cloud Storage wildcardFolderPath. Type: string (or
         Expression with resultType string).
        :paramtype wildcard_folder_path: any
        :keyword wildcard_file_name: Oracle Cloud Storage wildcardFileName. Type: string (or Expression
         with resultType string).
        :paramtype wildcard_file_name: any
        :keyword prefix: The prefix filter for the Oracle Cloud Storage object name. Type: string (or
         Expression with resultType string).
        :paramtype prefix: any
        :keyword file_list_path: Point to a text file that lists each file (relative path to the path
         configured in the dataset) that you want to copy. Type: string (or Expression with resultType
         string).
        :paramtype file_list_path: any
        :keyword enable_partition_discovery: Indicates whether to enable partition discovery.
        :paramtype enable_partition_discovery: bool
        :keyword partition_root_path: Specify the root path where partition discovery starts from.
         Type: string (or Expression with resultType string).
        :paramtype partition_root_path: any
        :keyword delete_files_after_completion: Indicates whether the source files need to be deleted
         after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype delete_files_after_completion: any
        :keyword modified_datetime_start: The start of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        """
        super(OracleCloudStorageReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'OracleCloudStorageReadSettings'  # type: str
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.prefix = prefix
        self.file_list_path = file_list_path
        self.enable_partition_discovery = enable_partition_discovery
        self.partition_root_path = partition_root_path
        self.delete_files_after_completion = delete_files_after_completion
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end


class OracleLinkedService(LinkedService):
    """Oracle database.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar password: The Azure key vault secret reference of password in connection string.
    :vartype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword password: The Azure key vault secret reference of password in connection string.
        :paramtype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(OracleLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Oracle'  # type: str
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class OraclePartitionSettings(msrest.serialization.Model):
    """The settings that will be leveraged for Oracle source partitioning.

    :ivar partition_names: Names of the physical partitions of Oracle table.
    :vartype partition_names: any
    :ivar partition_column_name: The name of the column in integer type that will be used for
     proceeding range partitioning. Type: string (or Expression with resultType string).
    :vartype partition_column_name: any
    :ivar partition_upper_bound: The maximum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :vartype partition_upper_bound: any
    :ivar partition_lower_bound: The minimum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :vartype partition_lower_bound: any
    """

    _attribute_map = {
        'partition_names': {'key': 'partitionNames', 'type': 'object'},
        'partition_column_name': {'key': 'partitionColumnName', 'type': 'object'},
        'partition_upper_bound': {'key': 'partitionUpperBound', 'type': 'object'},
        'partition_lower_bound': {'key': 'partitionLowerBound', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        partition_names: Optional[Any] = None,
        partition_column_name: Optional[Any] = None,
        partition_upper_bound: Optional[Any] = None,
        partition_lower_bound: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword partition_names: Names of the physical partitions of Oracle table.
        :paramtype partition_names: any
        :keyword partition_column_name: The name of the column in integer type that will be used for
         proceeding range partitioning. Type: string (or Expression with resultType string).
        :paramtype partition_column_name: any
        :keyword partition_upper_bound: The maximum value of column specified in partitionColumnName
         that will be used for proceeding range partitioning. Type: string (or Expression with
         resultType string).
        :paramtype partition_upper_bound: any
        :keyword partition_lower_bound: The minimum value of column specified in partitionColumnName
         that will be used for proceeding range partitioning. Type: string (or Expression with
         resultType string).
        :paramtype partition_lower_bound: any
        """
        super(OraclePartitionSettings, self).__init__(**kwargs)
        self.partition_names = partition_names
        self.partition_column_name = partition_column_name
        self.partition_upper_bound = partition_upper_bound
        self.partition_lower_bound = partition_lower_bound


class OracleServiceCloudLinkedService(LinkedService):
    """Oracle Service Cloud linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. The URL of the Oracle Service Cloud instance.
    :vartype host: any
    :ivar username: Required. The user name that you use to access Oracle Service Cloud server.
    :vartype username: any
    :ivar password: Required. The password corresponding to the user name that you provided in the
     username key.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true. Type: boolean (or Expression with resultType
     boolean).
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'username': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        username: Any,
        password: "SecretBase",
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. The URL of the Oracle Service Cloud instance.
        :paramtype host: any
        :keyword username: Required. The user name that you use to access Oracle Service Cloud server.
        :paramtype username: any
        :keyword password: Required. The password corresponding to the user name that you provided in
         the username key.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true. Type: boolean (or Expression with resultType
         boolean).
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(OracleServiceCloudLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'OracleServiceCloud'  # type: str
        self.host = host
        self.username = username
        self.password = password
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class OracleServiceCloudObjectDataset(Dataset):
    """Oracle Service Cloud dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(OracleServiceCloudObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'OracleServiceCloudObject'  # type: str
        self.table_name = table_name


class OracleServiceCloudSource(TabularSource):
    """A copy activity Oracle Service Cloud source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(OracleServiceCloudSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'OracleServiceCloudSource'  # type: str
        self.query = query


class OracleSink(CopySink):
    """A copy activity Oracle sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :vartype pre_copy_script: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        pre_copy_script: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
         string).
        :paramtype pre_copy_script: any
        """
        super(OracleSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'OracleSink'  # type: str
        self.pre_copy_script = pre_copy_script


class OracleSource(CopySource):
    """A copy activity Oracle source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar oracle_reader_query: Oracle reader query. Type: string (or Expression with resultType
     string).
    :vartype oracle_reader_query: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar partition_option: The partition mechanism that will be used for Oracle read in parallel.
     Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
    :vartype partition_option: any
    :ivar partition_settings: The settings that will be leveraged for Oracle source partitioning.
    :vartype partition_settings: ~azure.mgmt.datafactory.models.OraclePartitionSettings
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'oracle_reader_query': {'key': 'oracleReaderQuery', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'partition_option': {'key': 'partitionOption', 'type': 'object'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'OraclePartitionSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        oracle_reader_query: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        partition_option: Optional[Any] = None,
        partition_settings: Optional["OraclePartitionSettings"] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword oracle_reader_query: Oracle reader query. Type: string (or Expression with resultType
         string).
        :paramtype oracle_reader_query: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword partition_option: The partition mechanism that will be used for Oracle read in
         parallel. Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
        :paramtype partition_option: any
        :keyword partition_settings: The settings that will be leveraged for Oracle source
         partitioning.
        :paramtype partition_settings: ~azure.mgmt.datafactory.models.OraclePartitionSettings
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(OracleSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'OracleSource'  # type: str
        self.oracle_reader_query = oracle_reader_query
        self.query_timeout = query_timeout
        self.partition_option = partition_option
        self.partition_settings = partition_settings
        self.additional_columns = additional_columns


class OracleTableDataset(Dataset):
    """The on-premises Oracle database dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar schema_type_properties_schema: The schema name of the on-premises Oracle database. Type:
     string (or Expression with resultType string).
    :vartype schema_type_properties_schema: any
    :ivar table: The table name of the on-premises Oracle database. Type: string (or Expression
     with resultType string).
    :vartype table: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        table: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword schema_type_properties_schema: The schema name of the on-premises Oracle database.
         Type: string (or Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        :keyword table: The table name of the on-premises Oracle database. Type: string (or Expression
         with resultType string).
        :paramtype table: any
        """
        super(OracleTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'OracleTable'  # type: str
        self.table_name = table_name
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class OrcDataset(Dataset):
    """ORC dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar location: The location of the ORC data storage.
    :vartype location: ~azure.mgmt.datafactory.models.DatasetLocation
    :ivar orc_compression_codec: The data orcCompressionCodec. Type: string (or Expression with
     resultType string).
    :vartype orc_compression_codec: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'orc_compression_codec': {'key': 'typeProperties.orcCompressionCodec', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        orc_compression_codec: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword location: The location of the ORC data storage.
        :paramtype location: ~azure.mgmt.datafactory.models.DatasetLocation
        :keyword orc_compression_codec: The data orcCompressionCodec. Type: string (or Expression with
         resultType string).
        :paramtype orc_compression_codec: any
        """
        super(OrcDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Orc'  # type: str
        self.location = location
        self.orc_compression_codec = orc_compression_codec


class OrcFormat(DatasetStorageFormat):
    """The data stored in Optimized Row Columnar (ORC) format.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage format.Constant filled by server.
    :vartype type: str
    :ivar serializer: Serializer. Type: string (or Expression with resultType string).
    :vartype serializer: any
    :ivar deserializer: Deserializer. Type: string (or Expression with resultType string).
    :vartype deserializer: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'serializer': {'key': 'serializer', 'type': 'object'},
        'deserializer': {'key': 'deserializer', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        serializer: Optional[Any] = None,
        deserializer: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword serializer: Serializer. Type: string (or Expression with resultType string).
        :paramtype serializer: any
        :keyword deserializer: Deserializer. Type: string (or Expression with resultType string).
        :paramtype deserializer: any
        """
        super(OrcFormat, self).__init__(additional_properties=additional_properties, serializer=serializer, deserializer=deserializer, **kwargs)
        self.type = 'OrcFormat'  # type: str


class OrcSink(CopySink):
    """A copy activity ORC sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: ORC store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreWriteSettings
    :ivar format_settings: ORC format settings.
    :vartype format_settings: ~azure.mgmt.datafactory.models.OrcWriteSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreWriteSettings'},
        'format_settings': {'key': 'formatSettings', 'type': 'OrcWriteSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreWriteSettings"] = None,
        format_settings: Optional["OrcWriteSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: ORC store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreWriteSettings
        :keyword format_settings: ORC format settings.
        :paramtype format_settings: ~azure.mgmt.datafactory.models.OrcWriteSettings
        """
        super(OrcSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'OrcSink'  # type: str
        self.store_settings = store_settings
        self.format_settings = format_settings


class OrcSource(CopySource):
    """A copy activity ORC source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: ORC store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: ORC store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(OrcSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'OrcSource'  # type: str
        self.store_settings = store_settings
        self.additional_columns = additional_columns


class OrcWriteSettings(FormatWriteSettings):
    """Orc write settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The write setting type.Constant filled by server.
    :vartype type: str
    :ivar max_rows_per_file: Limit the written file's row count to be smaller than or equal to the
     specified count. Type: integer (or Expression with resultType integer).
    :vartype max_rows_per_file: any
    :ivar file_name_prefix: Specifies the file name pattern
     :code:`<fileNamePrefix>`_:code:`<fileIndex>`.:code:`<fileExtension>` when copy from non-file
     based store without partitionOptions. Type: string (or Expression with resultType string).
    :vartype file_name_prefix: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_rows_per_file': {'key': 'maxRowsPerFile', 'type': 'object'},
        'file_name_prefix': {'key': 'fileNamePrefix', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_rows_per_file: Optional[Any] = None,
        file_name_prefix: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_rows_per_file: Limit the written file's row count to be smaller than or equal to
         the specified count. Type: integer (or Expression with resultType integer).
        :paramtype max_rows_per_file: any
        :keyword file_name_prefix: Specifies the file name pattern
         :code:`<fileNamePrefix>`_:code:`<fileIndex>`.:code:`<fileExtension>` when copy from non-file
         based store without partitionOptions. Type: string (or Expression with resultType string).
        :paramtype file_name_prefix: any
        """
        super(OrcWriteSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'OrcWriteSettings'  # type: str
        self.max_rows_per_file = max_rows_per_file
        self.file_name_prefix = file_name_prefix


class PackageStore(msrest.serialization.Model):
    """Package store for the SSIS integration runtime.

    All required parameters must be populated in order to send to Azure.

    :ivar name: Required. The name of the package store.
    :vartype name: str
    :ivar package_store_linked_service: Required. The package store linked service reference.
    :vartype package_store_linked_service: ~azure.mgmt.datafactory.models.EntityReference
    """

    _validation = {
        'name': {'required': True},
        'package_store_linked_service': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'package_store_linked_service': {'key': 'packageStoreLinkedService', 'type': 'EntityReference'},
    }

    def __init__(
        self,
        *,
        name: str,
        package_store_linked_service: "EntityReference",
        **kwargs
    ):
        """
        :keyword name: Required. The name of the package store.
        :paramtype name: str
        :keyword package_store_linked_service: Required. The package store linked service reference.
        :paramtype package_store_linked_service: ~azure.mgmt.datafactory.models.EntityReference
        """
        super(PackageStore, self).__init__(**kwargs)
        self.name = name
        self.package_store_linked_service = package_store_linked_service


class ParameterSpecification(msrest.serialization.Model):
    """Definition of a single parameter for an entity.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Parameter type. Possible values include: "Object", "String", "Int",
     "Float", "Bool", "Array", "SecureString".
    :vartype type: str or ~azure.mgmt.datafactory.models.ParameterType
    :ivar default_value: Default value of parameter.
    :vartype default_value: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'default_value': {'key': 'defaultValue', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        type: Union[str, "ParameterType"],
        default_value: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword type: Required. Parameter type. Possible values include: "Object", "String", "Int",
         "Float", "Bool", "Array", "SecureString".
        :paramtype type: str or ~azure.mgmt.datafactory.models.ParameterType
        :keyword default_value: Default value of parameter.
        :paramtype default_value: any
        """
        super(ParameterSpecification, self).__init__(**kwargs)
        self.type = type
        self.default_value = default_value


class ParquetDataset(Dataset):
    """Parquet dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar location: The location of the parquet storage.
    :vartype location: ~azure.mgmt.datafactory.models.DatasetLocation
    :ivar compression_codec: The data compressionCodec. Type: string (or Expression with resultType
     string).
    :vartype compression_codec: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'compression_codec': {'key': 'typeProperties.compressionCodec', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        compression_codec: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword location: The location of the parquet storage.
        :paramtype location: ~azure.mgmt.datafactory.models.DatasetLocation
        :keyword compression_codec: The data compressionCodec. Type: string (or Expression with
         resultType string).
        :paramtype compression_codec: any
        """
        super(ParquetDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Parquet'  # type: str
        self.location = location
        self.compression_codec = compression_codec


class ParquetFormat(DatasetStorageFormat):
    """The data stored in Parquet format.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage format.Constant filled by server.
    :vartype type: str
    :ivar serializer: Serializer. Type: string (or Expression with resultType string).
    :vartype serializer: any
    :ivar deserializer: Deserializer. Type: string (or Expression with resultType string).
    :vartype deserializer: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'serializer': {'key': 'serializer', 'type': 'object'},
        'deserializer': {'key': 'deserializer', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        serializer: Optional[Any] = None,
        deserializer: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword serializer: Serializer. Type: string (or Expression with resultType string).
        :paramtype serializer: any
        :keyword deserializer: Deserializer. Type: string (or Expression with resultType string).
        :paramtype deserializer: any
        """
        super(ParquetFormat, self).__init__(additional_properties=additional_properties, serializer=serializer, deserializer=deserializer, **kwargs)
        self.type = 'ParquetFormat'  # type: str


class ParquetSink(CopySink):
    """A copy activity Parquet sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: Parquet store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreWriteSettings
    :ivar format_settings: Parquet format settings.
    :vartype format_settings: ~azure.mgmt.datafactory.models.ParquetWriteSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreWriteSettings'},
        'format_settings': {'key': 'formatSettings', 'type': 'ParquetWriteSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreWriteSettings"] = None,
        format_settings: Optional["ParquetWriteSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: Parquet store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreWriteSettings
        :keyword format_settings: Parquet format settings.
        :paramtype format_settings: ~azure.mgmt.datafactory.models.ParquetWriteSettings
        """
        super(ParquetSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'ParquetSink'  # type: str
        self.store_settings = store_settings
        self.format_settings = format_settings


class ParquetSource(CopySource):
    """A copy activity Parquet source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: Parquet store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: Parquet store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(ParquetSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'ParquetSource'  # type: str
        self.store_settings = store_settings
        self.additional_columns = additional_columns


class ParquetWriteSettings(FormatWriteSettings):
    """Parquet write settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The write setting type.Constant filled by server.
    :vartype type: str
    :ivar max_rows_per_file: Limit the written file's row count to be smaller than or equal to the
     specified count. Type: integer (or Expression with resultType integer).
    :vartype max_rows_per_file: any
    :ivar file_name_prefix: Specifies the file name pattern
     :code:`<fileNamePrefix>`_:code:`<fileIndex>`.:code:`<fileExtension>` when copy from non-file
     based store without partitionOptions. Type: string (or Expression with resultType string).
    :vartype file_name_prefix: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_rows_per_file': {'key': 'maxRowsPerFile', 'type': 'object'},
        'file_name_prefix': {'key': 'fileNamePrefix', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_rows_per_file: Optional[Any] = None,
        file_name_prefix: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_rows_per_file: Limit the written file's row count to be smaller than or equal to
         the specified count. Type: integer (or Expression with resultType integer).
        :paramtype max_rows_per_file: any
        :keyword file_name_prefix: Specifies the file name pattern
         :code:`<fileNamePrefix>`_:code:`<fileIndex>`.:code:`<fileExtension>` when copy from non-file
         based store without partitionOptions. Type: string (or Expression with resultType string).
        :paramtype file_name_prefix: any
        """
        super(ParquetWriteSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'ParquetWriteSettings'  # type: str
        self.max_rows_per_file = max_rows_per_file
        self.file_name_prefix = file_name_prefix


class PaypalLinkedService(LinkedService):
    """Paypal Service linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. The URLof the PayPal instance. (i.e. api.sandbox.paypal.com).
    :vartype host: any
    :ivar client_id: Required. The client ID associated with your PayPal application.
    :vartype client_id: any
    :ivar client_secret: The client secret associated with your PayPal application.
    :vartype client_secret: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'object'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        client_id: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. The URLof the PayPal instance. (i.e. api.sandbox.paypal.com).
        :paramtype host: any
        :keyword client_id: Required. The client ID associated with your PayPal application.
        :paramtype client_id: any
        :keyword client_secret: The client secret associated with your PayPal application.
        :paramtype client_secret: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true.
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true.
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(PaypalLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Paypal'  # type: str
        self.host = host
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class PaypalObjectDataset(Dataset):
    """Paypal Service dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(PaypalObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'PaypalObject'  # type: str
        self.table_name = table_name


class PaypalSource(TabularSource):
    """A copy activity Paypal Service source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(PaypalSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'PaypalSource'  # type: str
        self.query = query


class PhoenixLinkedService(LinkedService):
    """Phoenix server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. The IP address or host name of the Phoenix server. (i.e.
     192.168.222.160).
    :vartype host: any
    :ivar port: The TCP port that the Phoenix server uses to listen for client connections. The
     default value is 8765.
    :vartype port: any
    :ivar http_path: The partial URL corresponding to the Phoenix server. (i.e.
     /gateway/sandbox/phoenix/version). The default value is hbasephoenix if using
     WindowsAzureHDInsightService.
    :vartype http_path: any
    :ivar authentication_type: Required. The authentication mechanism used to connect to the
     Phoenix server. Possible values include: "Anonymous", "UsernameAndPassword",
     "WindowsAzureHDInsightService".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.PhoenixAuthenticationType
    :ivar username: The user name used to connect to the Phoenix server.
    :vartype username: any
    :ivar password: The password corresponding to the user name.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :vartype enable_ssl: any
    :ivar trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :vartype trusted_cert_path: any
    :ivar use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :vartype use_system_trust_store: any
    :ivar allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :vartype allow_host_name_cn_mismatch: any
    :ivar allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :vartype allow_self_signed_server_cert: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'http_path': {'key': 'typeProperties.httpPath', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'object'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'object'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'object'},
        'allow_host_name_cn_mismatch': {'key': 'typeProperties.allowHostNameCNMismatch', 'type': 'object'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        authentication_type: Union[str, "PhoenixAuthenticationType"],
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        port: Optional[Any] = None,
        http_path: Optional[Any] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        enable_ssl: Optional[Any] = None,
        trusted_cert_path: Optional[Any] = None,
        use_system_trust_store: Optional[Any] = None,
        allow_host_name_cn_mismatch: Optional[Any] = None,
        allow_self_signed_server_cert: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. The IP address or host name of the Phoenix server. (i.e.
         192.168.222.160).
        :paramtype host: any
        :keyword port: The TCP port that the Phoenix server uses to listen for client connections. The
         default value is 8765.
        :paramtype port: any
        :keyword http_path: The partial URL corresponding to the Phoenix server. (i.e.
         /gateway/sandbox/phoenix/version). The default value is hbasephoenix if using
         WindowsAzureHDInsightService.
        :paramtype http_path: any
        :keyword authentication_type: Required. The authentication mechanism used to connect to the
         Phoenix server. Possible values include: "Anonymous", "UsernameAndPassword",
         "WindowsAzureHDInsightService".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.PhoenixAuthenticationType
        :keyword username: The user name used to connect to the Phoenix server.
        :paramtype username: any
        :keyword password: The password corresponding to the user name.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword enable_ssl: Specifies whether the connections to the server are encrypted using SSL.
         The default value is false.
        :paramtype enable_ssl: any
        :keyword trusted_cert_path: The full path of the .pem file containing trusted CA certificates
         for verifying the server when connecting over SSL. This property can only be set when using SSL
         on self-hosted IR. The default value is the cacerts.pem file installed with the IR.
        :paramtype trusted_cert_path: any
        :keyword use_system_trust_store: Specifies whether to use a CA certificate from the system
         trust store or from a specified PEM file. The default value is false.
        :paramtype use_system_trust_store: any
        :keyword allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
         name to match the host name of the server when connecting over SSL. The default value is false.
        :paramtype allow_host_name_cn_mismatch: any
        :keyword allow_self_signed_server_cert: Specifies whether to allow self-signed certificates
         from the server. The default value is false.
        :paramtype allow_self_signed_server_cert: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(PhoenixLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Phoenix'  # type: str
        self.host = host
        self.port = port
        self.http_path = http_path
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class PhoenixObjectDataset(Dataset):
    """Phoenix server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar table: The table name of the Phoenix. Type: string (or Expression with resultType
     string).
    :vartype table: any
    :ivar schema_type_properties_schema: The schema name of the Phoenix. Type: string (or
     Expression with resultType string).
    :vartype schema_type_properties_schema: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword table: The table name of the Phoenix. Type: string (or Expression with resultType
         string).
        :paramtype table: any
        :keyword schema_type_properties_schema: The schema name of the Phoenix. Type: string (or
         Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        """
        super(PhoenixObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'PhoenixObject'  # type: str
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class PhoenixSource(TabularSource):
    """A copy activity Phoenix server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(PhoenixSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'PhoenixSource'  # type: str
        self.query = query


class PipelineElapsedTimeMetricPolicy(msrest.serialization.Model):
    """Pipeline ElapsedTime Metric Policy.

    :ivar duration: TimeSpan value, after which an Azure Monitoring Metric is fired.
    :vartype duration: any
    """

    _attribute_map = {
        'duration': {'key': 'duration', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        duration: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword duration: TimeSpan value, after which an Azure Monitoring Metric is fired.
        :paramtype duration: any
        """
        super(PipelineElapsedTimeMetricPolicy, self).__init__(**kwargs)
        self.duration = duration


class PipelineFolder(msrest.serialization.Model):
    """The folder that this Pipeline is in. If not specified, Pipeline will appear at the root level.

    :ivar name: The name of the folder that this Pipeline is in.
    :vartype name: str
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword name: The name of the folder that this Pipeline is in.
        :paramtype name: str
        """
        super(PipelineFolder, self).__init__(**kwargs)
        self.name = name


class PipelineListResponse(msrest.serialization.Model):
    """A list of pipeline resources.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of pipelines.
    :vartype value: list[~azure.mgmt.datafactory.models.PipelineResource]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[PipelineResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["PipelineResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of pipelines.
        :paramtype value: list[~azure.mgmt.datafactory.models.PipelineResource]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(PipelineListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class PipelinePolicy(msrest.serialization.Model):
    """Pipeline Policy.

    :ivar elapsed_time_metric: Pipeline ElapsedTime Metric Policy.
    :vartype elapsed_time_metric: ~azure.mgmt.datafactory.models.PipelineElapsedTimeMetricPolicy
    """

    _attribute_map = {
        'elapsed_time_metric': {'key': 'elapsedTimeMetric', 'type': 'PipelineElapsedTimeMetricPolicy'},
    }

    def __init__(
        self,
        *,
        elapsed_time_metric: Optional["PipelineElapsedTimeMetricPolicy"] = None,
        **kwargs
    ):
        """
        :keyword elapsed_time_metric: Pipeline ElapsedTime Metric Policy.
        :paramtype elapsed_time_metric: ~azure.mgmt.datafactory.models.PipelineElapsedTimeMetricPolicy
        """
        super(PipelinePolicy, self).__init__(**kwargs)
        self.elapsed_time_metric = elapsed_time_metric


class PipelineReference(msrest.serialization.Model):
    """Pipeline reference type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Pipeline reference type. Has constant value: "PipelineReference".
    :vartype type: str
    :ivar reference_name: Required. Reference pipeline name.
    :vartype reference_name: str
    :ivar name: Reference name.
    :vartype name: str
    """

    _validation = {
        'type': {'required': True, 'constant': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
    }

    type = "PipelineReference"

    def __init__(
        self,
        *,
        reference_name: str,
        name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword reference_name: Required. Reference pipeline name.
        :paramtype reference_name: str
        :keyword name: Reference name.
        :paramtype name: str
        """
        super(PipelineReference, self).__init__(**kwargs)
        self.reference_name = reference_name
        self.name = name


class PipelineResource(SubResource):
    """Pipeline resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar description: The description of the pipeline.
    :vartype description: str
    :ivar activities: List of activities in pipeline.
    :vartype activities: list[~azure.mgmt.datafactory.models.Activity]
    :ivar parameters: List of parameters for pipeline.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar variables: List of variables for pipeline.
    :vartype variables: dict[str, ~azure.mgmt.datafactory.models.VariableSpecification]
    :ivar concurrency: The max number of concurrent runs for the pipeline.
    :vartype concurrency: int
    :ivar annotations: List of tags that can be used for describing the Pipeline.
    :vartype annotations: list[any]
    :ivar run_dimensions: Dimensions emitted by Pipeline.
    :vartype run_dimensions: dict[str, any]
    :ivar folder: The folder that this Pipeline is in. If not specified, Pipeline will appear at
     the root level.
    :vartype folder: ~azure.mgmt.datafactory.models.PipelineFolder
    :ivar policy: Pipeline Policy.
    :vartype policy: ~azure.mgmt.datafactory.models.PipelinePolicy
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'concurrency': {'minimum': 1},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'additional_properties': {'key': '', 'type': '{object}'},
        'description': {'key': 'properties.description', 'type': 'str'},
        'activities': {'key': 'properties.activities', 'type': '[Activity]'},
        'parameters': {'key': 'properties.parameters', 'type': '{ParameterSpecification}'},
        'variables': {'key': 'properties.variables', 'type': '{VariableSpecification}'},
        'concurrency': {'key': 'properties.concurrency', 'type': 'int'},
        'annotations': {'key': 'properties.annotations', 'type': '[object]'},
        'run_dimensions': {'key': 'properties.runDimensions', 'type': '{object}'},
        'folder': {'key': 'properties.folder', 'type': 'PipelineFolder'},
        'policy': {'key': 'properties.policy', 'type': 'PipelinePolicy'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        activities: Optional[List["Activity"]] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        variables: Optional[Dict[str, "VariableSpecification"]] = None,
        concurrency: Optional[int] = None,
        annotations: Optional[List[Any]] = None,
        run_dimensions: Optional[Dict[str, Any]] = None,
        folder: Optional["PipelineFolder"] = None,
        policy: Optional["PipelinePolicy"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: The description of the pipeline.
        :paramtype description: str
        :keyword activities: List of activities in pipeline.
        :paramtype activities: list[~azure.mgmt.datafactory.models.Activity]
        :keyword parameters: List of parameters for pipeline.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword variables: List of variables for pipeline.
        :paramtype variables: dict[str, ~azure.mgmt.datafactory.models.VariableSpecification]
        :keyword concurrency: The max number of concurrent runs for the pipeline.
        :paramtype concurrency: int
        :keyword annotations: List of tags that can be used for describing the Pipeline.
        :paramtype annotations: list[any]
        :keyword run_dimensions: Dimensions emitted by Pipeline.
        :paramtype run_dimensions: dict[str, any]
        :keyword folder: The folder that this Pipeline is in. If not specified, Pipeline will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.PipelineFolder
        :keyword policy: Pipeline Policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.PipelinePolicy
        """
        super(PipelineResource, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.description = description
        self.activities = activities
        self.parameters = parameters
        self.variables = variables
        self.concurrency = concurrency
        self.annotations = annotations
        self.run_dimensions = run_dimensions
        self.folder = folder
        self.policy = policy


class PipelineRun(msrest.serialization.Model):
    """Information about a pipeline run.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar run_id: Identifier of a run.
    :vartype run_id: str
    :ivar run_group_id: Identifier that correlates all the recovery runs of a pipeline run.
    :vartype run_group_id: str
    :ivar is_latest: Indicates if the recovered pipeline run is the latest in its group.
    :vartype is_latest: bool
    :ivar pipeline_name: The pipeline name.
    :vartype pipeline_name: str
    :ivar parameters: The full or partial list of parameter name, value pair used in the pipeline
     run.
    :vartype parameters: dict[str, str]
    :ivar run_dimensions: Run dimensions emitted by Pipeline run.
    :vartype run_dimensions: dict[str, str]
    :ivar invoked_by: Entity that started the pipeline run.
    :vartype invoked_by: ~azure.mgmt.datafactory.models.PipelineRunInvokedBy
    :ivar last_updated: The last updated timestamp for the pipeline run event in ISO8601 format.
    :vartype last_updated: ~datetime.datetime
    :ivar run_start: The start time of a pipeline run in ISO8601 format.
    :vartype run_start: ~datetime.datetime
    :ivar run_end: The end time of a pipeline run in ISO8601 format.
    :vartype run_end: ~datetime.datetime
    :ivar duration_in_ms: The duration of a pipeline run.
    :vartype duration_in_ms: int
    :ivar status: The status of a pipeline run. Possible values: Queued, InProgress, Succeeded,
     Failed, Canceling, Cancelled.
    :vartype status: str
    :ivar message: The message from a pipeline run.
    :vartype message: str
    """

    _validation = {
        'run_id': {'readonly': True},
        'run_group_id': {'readonly': True},
        'is_latest': {'readonly': True},
        'pipeline_name': {'readonly': True},
        'parameters': {'readonly': True},
        'run_dimensions': {'readonly': True},
        'invoked_by': {'readonly': True},
        'last_updated': {'readonly': True},
        'run_start': {'readonly': True},
        'run_end': {'readonly': True},
        'duration_in_ms': {'readonly': True},
        'status': {'readonly': True},
        'message': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'run_id': {'key': 'runId', 'type': 'str'},
        'run_group_id': {'key': 'runGroupId', 'type': 'str'},
        'is_latest': {'key': 'isLatest', 'type': 'bool'},
        'pipeline_name': {'key': 'pipelineName', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{str}'},
        'run_dimensions': {'key': 'runDimensions', 'type': '{str}'},
        'invoked_by': {'key': 'invokedBy', 'type': 'PipelineRunInvokedBy'},
        'last_updated': {'key': 'lastUpdated', 'type': 'iso-8601'},
        'run_start': {'key': 'runStart', 'type': 'iso-8601'},
        'run_end': {'key': 'runEnd', 'type': 'iso-8601'},
        'duration_in_ms': {'key': 'durationInMs', 'type': 'int'},
        'status': {'key': 'status', 'type': 'str'},
        'message': {'key': 'message', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(PipelineRun, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.run_id = None
        self.run_group_id = None
        self.is_latest = None
        self.pipeline_name = None
        self.parameters = None
        self.run_dimensions = None
        self.invoked_by = None
        self.last_updated = None
        self.run_start = None
        self.run_end = None
        self.duration_in_ms = None
        self.status = None
        self.message = None


class PipelineRunInvokedBy(msrest.serialization.Model):
    """Provides entity name and id that started the pipeline run.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar name: Name of the entity that started the pipeline run.
    :vartype name: str
    :ivar id: The ID of the entity that started the run.
    :vartype id: str
    :ivar invoked_by_type: The type of the entity that started the run.
    :vartype invoked_by_type: str
    :ivar pipeline_name: The name of the pipeline that triggered the run, if any.
    :vartype pipeline_name: str
    :ivar pipeline_run_id: The run id of the pipeline that triggered the run, if any.
    :vartype pipeline_run_id: str
    """

    _validation = {
        'name': {'readonly': True},
        'id': {'readonly': True},
        'invoked_by_type': {'readonly': True},
        'pipeline_name': {'readonly': True},
        'pipeline_run_id': {'readonly': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'id': {'key': 'id', 'type': 'str'},
        'invoked_by_type': {'key': 'invokedByType', 'type': 'str'},
        'pipeline_name': {'key': 'pipelineName', 'type': 'str'},
        'pipeline_run_id': {'key': 'pipelineRunId', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(PipelineRunInvokedBy, self).__init__(**kwargs)
        self.name = None
        self.id = None
        self.invoked_by_type = None
        self.pipeline_name = None
        self.pipeline_run_id = None


class PipelineRunsQueryResponse(msrest.serialization.Model):
    """A list pipeline runs.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of pipeline runs.
    :vartype value: list[~azure.mgmt.datafactory.models.PipelineRun]
    :ivar continuation_token: The continuation token for getting the next page of results, if any
     remaining results exist, null otherwise.
    :vartype continuation_token: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[PipelineRun]'},
        'continuation_token': {'key': 'continuationToken', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["PipelineRun"],
        continuation_token: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of pipeline runs.
        :paramtype value: list[~azure.mgmt.datafactory.models.PipelineRun]
        :keyword continuation_token: The continuation token for getting the next page of results, if
         any remaining results exist, null otherwise.
        :paramtype continuation_token: str
        """
        super(PipelineRunsQueryResponse, self).__init__(**kwargs)
        self.value = value
        self.continuation_token = continuation_token


class PolybaseSettings(msrest.serialization.Model):
    """PolyBase settings.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar reject_type: Reject type. Possible values include: "value", "percentage".
    :vartype reject_type: str or ~azure.mgmt.datafactory.models.PolybaseSettingsRejectType
    :ivar reject_value: Specifies the value or the percentage of rows that can be rejected before
     the query fails. Type: number (or Expression with resultType number), minimum: 0.
    :vartype reject_value: any
    :ivar reject_sample_value: Determines the number of rows to attempt to retrieve before the
     PolyBase recalculates the percentage of rejected rows. Type: integer (or Expression with
     resultType integer), minimum: 0.
    :vartype reject_sample_value: any
    :ivar use_type_default: Specifies how to handle missing values in delimited text files when
     PolyBase retrieves data from the text file. Type: boolean (or Expression with resultType
     boolean).
    :vartype use_type_default: any
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'reject_type': {'key': 'rejectType', 'type': 'str'},
        'reject_value': {'key': 'rejectValue', 'type': 'object'},
        'reject_sample_value': {'key': 'rejectSampleValue', 'type': 'object'},
        'use_type_default': {'key': 'useTypeDefault', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        reject_type: Optional[Union[str, "PolybaseSettingsRejectType"]] = None,
        reject_value: Optional[Any] = None,
        reject_sample_value: Optional[Any] = None,
        use_type_default: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword reject_type: Reject type. Possible values include: "value", "percentage".
        :paramtype reject_type: str or ~azure.mgmt.datafactory.models.PolybaseSettingsRejectType
        :keyword reject_value: Specifies the value or the percentage of rows that can be rejected
         before the query fails. Type: number (or Expression with resultType number), minimum: 0.
        :paramtype reject_value: any
        :keyword reject_sample_value: Determines the number of rows to attempt to retrieve before the
         PolyBase recalculates the percentage of rejected rows. Type: integer (or Expression with
         resultType integer), minimum: 0.
        :paramtype reject_sample_value: any
        :keyword use_type_default: Specifies how to handle missing values in delimited text files when
         PolyBase retrieves data from the text file. Type: boolean (or Expression with resultType
         boolean).
        :paramtype use_type_default: any
        """
        super(PolybaseSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.reject_type = reject_type
        self.reject_value = reject_value
        self.reject_sample_value = reject_sample_value
        self.use_type_default = use_type_default


class PostgreSqlLinkedService(LinkedService):
    """Linked service for PostgreSQL data source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The connection string.
    :vartype connection_string: any
    :ivar password: The Azure key vault secret reference of password in connection string.
    :vartype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The connection string.
        :paramtype connection_string: any
        :keyword password: The Azure key vault secret reference of password in connection string.
        :paramtype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(PostgreSqlLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'PostgreSql'  # type: str
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class PostgreSqlSource(TabularSource):
    """A copy activity source for PostgreSQL databases.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: Database query. Type: string (or Expression with resultType string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: Database query. Type: string (or Expression with resultType string).
        :paramtype query: any
        """
        super(PostgreSqlSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'PostgreSqlSource'  # type: str
        self.query = query


class PostgreSqlTableDataset(Dataset):
    """The PostgreSQL table dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar table: The PostgreSQL table name. Type: string (or Expression with resultType string).
    :vartype table: any
    :ivar schema_type_properties_schema: The PostgreSQL schema name. Type: string (or Expression
     with resultType string).
    :vartype schema_type_properties_schema: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword table: The PostgreSQL table name. Type: string (or Expression with resultType string).
        :paramtype table: any
        :keyword schema_type_properties_schema: The PostgreSQL schema name. Type: string (or Expression
         with resultType string).
        :paramtype schema_type_properties_schema: any
        """
        super(PostgreSqlTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'PostgreSqlTable'  # type: str
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class PowerQuerySink(DataFlowSink):
    """Power query sink.

    All required parameters must be populated in order to send to Azure.

    :ivar name: Required. Transformation name.
    :vartype name: str
    :ivar description: Transformation description.
    :vartype description: str
    :ivar dataset: Dataset reference.
    :vartype dataset: ~azure.mgmt.datafactory.models.DatasetReference
    :ivar linked_service: Linked service reference.
    :vartype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar flowlet: Flowlet Reference.
    :vartype flowlet: ~azure.mgmt.datafactory.models.DataFlowReference
    :ivar schema_linked_service: Schema linked service reference.
    :vartype schema_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar script: sink script.
    :vartype script: str
    """

    _validation = {
        'name': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'dataset': {'key': 'dataset', 'type': 'DatasetReference'},
        'linked_service': {'key': 'linkedService', 'type': 'LinkedServiceReference'},
        'flowlet': {'key': 'flowlet', 'type': 'DataFlowReference'},
        'schema_linked_service': {'key': 'schemaLinkedService', 'type': 'LinkedServiceReference'},
        'script': {'key': 'script', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: str,
        description: Optional[str] = None,
        dataset: Optional["DatasetReference"] = None,
        linked_service: Optional["LinkedServiceReference"] = None,
        flowlet: Optional["DataFlowReference"] = None,
        schema_linked_service: Optional["LinkedServiceReference"] = None,
        script: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword name: Required. Transformation name.
        :paramtype name: str
        :keyword description: Transformation description.
        :paramtype description: str
        :keyword dataset: Dataset reference.
        :paramtype dataset: ~azure.mgmt.datafactory.models.DatasetReference
        :keyword linked_service: Linked service reference.
        :paramtype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword flowlet: Flowlet Reference.
        :paramtype flowlet: ~azure.mgmt.datafactory.models.DataFlowReference
        :keyword schema_linked_service: Schema linked service reference.
        :paramtype schema_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword script: sink script.
        :paramtype script: str
        """
        super(PowerQuerySink, self).__init__(name=name, description=description, dataset=dataset, linked_service=linked_service, flowlet=flowlet, schema_linked_service=schema_linked_service, **kwargs)
        self.script = script


class PowerQuerySinkMapping(msrest.serialization.Model):
    """Map Power Query mashup query to sink dataset(s).

    :ivar query_name: Name of the query in Power Query mashup document.
    :vartype query_name: str
    :ivar dataflow_sinks: List of sinks mapped to Power Query mashup query.
    :vartype dataflow_sinks: list[~azure.mgmt.datafactory.models.PowerQuerySink]
    """

    _attribute_map = {
        'query_name': {'key': 'queryName', 'type': 'str'},
        'dataflow_sinks': {'key': 'dataflowSinks', 'type': '[PowerQuerySink]'},
    }

    def __init__(
        self,
        *,
        query_name: Optional[str] = None,
        dataflow_sinks: Optional[List["PowerQuerySink"]] = None,
        **kwargs
    ):
        """
        :keyword query_name: Name of the query in Power Query mashup document.
        :paramtype query_name: str
        :keyword dataflow_sinks: List of sinks mapped to Power Query mashup query.
        :paramtype dataflow_sinks: list[~azure.mgmt.datafactory.models.PowerQuerySink]
        """
        super(PowerQuerySinkMapping, self).__init__(**kwargs)
        self.query_name = query_name
        self.dataflow_sinks = dataflow_sinks


class PowerQuerySource(DataFlowSource):
    """Power query source.

    All required parameters must be populated in order to send to Azure.

    :ivar name: Required. Transformation name.
    :vartype name: str
    :ivar description: Transformation description.
    :vartype description: str
    :ivar dataset: Dataset reference.
    :vartype dataset: ~azure.mgmt.datafactory.models.DatasetReference
    :ivar linked_service: Linked service reference.
    :vartype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar flowlet: Flowlet Reference.
    :vartype flowlet: ~azure.mgmt.datafactory.models.DataFlowReference
    :ivar schema_linked_service: Schema linked service reference.
    :vartype schema_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar script: source script.
    :vartype script: str
    """

    _validation = {
        'name': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'dataset': {'key': 'dataset', 'type': 'DatasetReference'},
        'linked_service': {'key': 'linkedService', 'type': 'LinkedServiceReference'},
        'flowlet': {'key': 'flowlet', 'type': 'DataFlowReference'},
        'schema_linked_service': {'key': 'schemaLinkedService', 'type': 'LinkedServiceReference'},
        'script': {'key': 'script', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: str,
        description: Optional[str] = None,
        dataset: Optional["DatasetReference"] = None,
        linked_service: Optional["LinkedServiceReference"] = None,
        flowlet: Optional["DataFlowReference"] = None,
        schema_linked_service: Optional["LinkedServiceReference"] = None,
        script: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword name: Required. Transformation name.
        :paramtype name: str
        :keyword description: Transformation description.
        :paramtype description: str
        :keyword dataset: Dataset reference.
        :paramtype dataset: ~azure.mgmt.datafactory.models.DatasetReference
        :keyword linked_service: Linked service reference.
        :paramtype linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword flowlet: Flowlet Reference.
        :paramtype flowlet: ~azure.mgmt.datafactory.models.DataFlowReference
        :keyword schema_linked_service: Schema linked service reference.
        :paramtype schema_linked_service: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword script: source script.
        :paramtype script: str
        """
        super(PowerQuerySource, self).__init__(name=name, description=description, dataset=dataset, linked_service=linked_service, flowlet=flowlet, schema_linked_service=schema_linked_service, **kwargs)
        self.script = script


class PrestoLinkedService(LinkedService):
    """Presto server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. The IP address or host name of the Presto server. (i.e. 192.168.222.160).
    :vartype host: any
    :ivar server_version: Required. The version of the Presto server. (i.e. 0.148-t).
    :vartype server_version: any
    :ivar catalog: Required. The catalog context for all request against the server.
    :vartype catalog: any
    :ivar port: The TCP port that the Presto server uses to listen for client connections. The
     default value is 8080.
    :vartype port: any
    :ivar authentication_type: Required. The authentication mechanism used to connect to the Presto
     server. Possible values include: "Anonymous", "LDAP".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.PrestoAuthenticationType
    :ivar username: The user name used to connect to the Presto server.
    :vartype username: any
    :ivar password: The password corresponding to the user name.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :vartype enable_ssl: any
    :ivar trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :vartype trusted_cert_path: any
    :ivar use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :vartype use_system_trust_store: any
    :ivar allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :vartype allow_host_name_cn_mismatch: any
    :ivar allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :vartype allow_self_signed_server_cert: any
    :ivar time_zone_id: The local time zone used by the connection. Valid values for this option
     are specified in the IANA Time Zone Database. The default value is the system time zone.
    :vartype time_zone_id: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'server_version': {'required': True},
        'catalog': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'server_version': {'key': 'typeProperties.serverVersion', 'type': 'object'},
        'catalog': {'key': 'typeProperties.catalog', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'object'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'object'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'object'},
        'allow_host_name_cn_mismatch': {'key': 'typeProperties.allowHostNameCNMismatch', 'type': 'object'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'object'},
        'time_zone_id': {'key': 'typeProperties.timeZoneID', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        server_version: Any,
        catalog: Any,
        authentication_type: Union[str, "PrestoAuthenticationType"],
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        port: Optional[Any] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        enable_ssl: Optional[Any] = None,
        trusted_cert_path: Optional[Any] = None,
        use_system_trust_store: Optional[Any] = None,
        allow_host_name_cn_mismatch: Optional[Any] = None,
        allow_self_signed_server_cert: Optional[Any] = None,
        time_zone_id: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. The IP address or host name of the Presto server. (i.e.
         192.168.222.160).
        :paramtype host: any
        :keyword server_version: Required. The version of the Presto server. (i.e. 0.148-t).
        :paramtype server_version: any
        :keyword catalog: Required. The catalog context for all request against the server.
        :paramtype catalog: any
        :keyword port: The TCP port that the Presto server uses to listen for client connections. The
         default value is 8080.
        :paramtype port: any
        :keyword authentication_type: Required. The authentication mechanism used to connect to the
         Presto server. Possible values include: "Anonymous", "LDAP".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.PrestoAuthenticationType
        :keyword username: The user name used to connect to the Presto server.
        :paramtype username: any
        :keyword password: The password corresponding to the user name.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword enable_ssl: Specifies whether the connections to the server are encrypted using SSL.
         The default value is false.
        :paramtype enable_ssl: any
        :keyword trusted_cert_path: The full path of the .pem file containing trusted CA certificates
         for verifying the server when connecting over SSL. This property can only be set when using SSL
         on self-hosted IR. The default value is the cacerts.pem file installed with the IR.
        :paramtype trusted_cert_path: any
        :keyword use_system_trust_store: Specifies whether to use a CA certificate from the system
         trust store or from a specified PEM file. The default value is false.
        :paramtype use_system_trust_store: any
        :keyword allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
         name to match the host name of the server when connecting over SSL. The default value is false.
        :paramtype allow_host_name_cn_mismatch: any
        :keyword allow_self_signed_server_cert: Specifies whether to allow self-signed certificates
         from the server. The default value is false.
        :paramtype allow_self_signed_server_cert: any
        :keyword time_zone_id: The local time zone used by the connection. Valid values for this option
         are specified in the IANA Time Zone Database. The default value is the system time zone.
        :paramtype time_zone_id: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(PrestoLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Presto'  # type: str
        self.host = host
        self.server_version = server_version
        self.catalog = catalog
        self.port = port
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.time_zone_id = time_zone_id
        self.encrypted_credential = encrypted_credential


class PrestoObjectDataset(Dataset):
    """Presto server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar table: The table name of the Presto. Type: string (or Expression with resultType string).
    :vartype table: any
    :ivar schema_type_properties_schema: The schema name of the Presto. Type: string (or Expression
     with resultType string).
    :vartype schema_type_properties_schema: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword table: The table name of the Presto. Type: string (or Expression with resultType
         string).
        :paramtype table: any
        :keyword schema_type_properties_schema: The schema name of the Presto. Type: string (or
         Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        """
        super(PrestoObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'PrestoObject'  # type: str
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class PrestoSource(TabularSource):
    """A copy activity Presto server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(PrestoSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'PrestoSource'  # type: str
        self.query = query


class PrivateEndpointConnectionListResponse(msrest.serialization.Model):
    """A list of linked service resources.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of Private Endpoint Connections.
    :vartype value: list[~azure.mgmt.datafactory.models.PrivateEndpointConnectionResource]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[PrivateEndpointConnectionResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["PrivateEndpointConnectionResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of Private Endpoint Connections.
        :paramtype value: list[~azure.mgmt.datafactory.models.PrivateEndpointConnectionResource]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(PrivateEndpointConnectionListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class PrivateEndpointConnectionResource(SubResource):
    """Private Endpoint Connection ARM resource.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :ivar properties: Core resource properties.
    :vartype properties: ~azure.mgmt.datafactory.models.RemotePrivateEndpointConnection
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'RemotePrivateEndpointConnection'},
    }

    def __init__(
        self,
        *,
        properties: Optional["RemotePrivateEndpointConnection"] = None,
        **kwargs
    ):
        """
        :keyword properties: Core resource properties.
        :paramtype properties: ~azure.mgmt.datafactory.models.RemotePrivateEndpointConnection
        """
        super(PrivateEndpointConnectionResource, self).__init__(**kwargs)
        self.properties = properties


class PrivateLinkConnectionApprovalRequest(msrest.serialization.Model):
    """A request to approve or reject a private endpoint connection.

    :ivar private_link_service_connection_state: The state of a private link connection.
    :vartype private_link_service_connection_state:
     ~azure.mgmt.datafactory.models.PrivateLinkConnectionState
    """

    _attribute_map = {
        'private_link_service_connection_state': {'key': 'privateLinkServiceConnectionState', 'type': 'PrivateLinkConnectionState'},
    }

    def __init__(
        self,
        *,
        private_link_service_connection_state: Optional["PrivateLinkConnectionState"] = None,
        **kwargs
    ):
        """
        :keyword private_link_service_connection_state: The state of a private link connection.
        :paramtype private_link_service_connection_state:
         ~azure.mgmt.datafactory.models.PrivateLinkConnectionState
        """
        super(PrivateLinkConnectionApprovalRequest, self).__init__(**kwargs)
        self.private_link_service_connection_state = private_link_service_connection_state


class PrivateLinkConnectionApprovalRequestResource(SubResource):
    """Private Endpoint Connection Approval ARM resource.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :ivar properties: Core resource properties.
    :vartype properties: ~azure.mgmt.datafactory.models.PrivateLinkConnectionApprovalRequest
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'PrivateLinkConnectionApprovalRequest'},
    }

    def __init__(
        self,
        *,
        properties: Optional["PrivateLinkConnectionApprovalRequest"] = None,
        **kwargs
    ):
        """
        :keyword properties: Core resource properties.
        :paramtype properties: ~azure.mgmt.datafactory.models.PrivateLinkConnectionApprovalRequest
        """
        super(PrivateLinkConnectionApprovalRequestResource, self).__init__(**kwargs)
        self.properties = properties


class PrivateLinkConnectionState(msrest.serialization.Model):
    """The state of a private link connection.

    :ivar status: Status of a private link connection.
    :vartype status: str
    :ivar description: Description of a private link connection.
    :vartype description: str
    :ivar actions_required: ActionsRequired for a private link connection.
    :vartype actions_required: str
    """

    _attribute_map = {
        'status': {'key': 'status', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'actions_required': {'key': 'actionsRequired', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        status: Optional[str] = None,
        description: Optional[str] = None,
        actions_required: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword status: Status of a private link connection.
        :paramtype status: str
        :keyword description: Description of a private link connection.
        :paramtype description: str
        :keyword actions_required: ActionsRequired for a private link connection.
        :paramtype actions_required: str
        """
        super(PrivateLinkConnectionState, self).__init__(**kwargs)
        self.status = status
        self.description = description
        self.actions_required = actions_required


class PrivateLinkResource(SubResource):
    """A private link resource.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :ivar properties: Core resource properties.
    :vartype properties: ~azure.mgmt.datafactory.models.PrivateLinkResourceProperties
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'PrivateLinkResourceProperties'},
    }

    def __init__(
        self,
        *,
        properties: Optional["PrivateLinkResourceProperties"] = None,
        **kwargs
    ):
        """
        :keyword properties: Core resource properties.
        :paramtype properties: ~azure.mgmt.datafactory.models.PrivateLinkResourceProperties
        """
        super(PrivateLinkResource, self).__init__(**kwargs)
        self.properties = properties


class PrivateLinkResourceProperties(msrest.serialization.Model):
    """Properties of a private link resource.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar group_id: GroupId of a private link resource.
    :vartype group_id: str
    :ivar required_members: RequiredMembers of a private link resource.
    :vartype required_members: list[str]
    :ivar required_zone_names: RequiredZoneNames of a private link resource.
    :vartype required_zone_names: list[str]
    """

    _validation = {
        'group_id': {'readonly': True},
        'required_members': {'readonly': True},
        'required_zone_names': {'readonly': True},
    }

    _attribute_map = {
        'group_id': {'key': 'groupId', 'type': 'str'},
        'required_members': {'key': 'requiredMembers', 'type': '[str]'},
        'required_zone_names': {'key': 'requiredZoneNames', 'type': '[str]'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(PrivateLinkResourceProperties, self).__init__(**kwargs)
        self.group_id = None
        self.required_members = None
        self.required_zone_names = None


class PrivateLinkResourcesWrapper(msrest.serialization.Model):
    """Wrapper for a collection of private link resources.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required.
    :vartype value: list[~azure.mgmt.datafactory.models.PrivateLinkResource]
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[PrivateLinkResource]'},
    }

    def __init__(
        self,
        *,
        value: List["PrivateLinkResource"],
        **kwargs
    ):
        """
        :keyword value: Required.
        :paramtype value: list[~azure.mgmt.datafactory.models.PrivateLinkResource]
        """
        super(PrivateLinkResourcesWrapper, self).__init__(**kwargs)
        self.value = value


class QueryDataFlowDebugSessionsResponse(msrest.serialization.Model):
    """A list of active debug sessions.

    :ivar value: Array with all active debug sessions.
    :vartype value: list[~azure.mgmt.datafactory.models.DataFlowDebugSessionInfo]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _attribute_map = {
        'value': {'key': 'value', 'type': '[DataFlowDebugSessionInfo]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: Optional[List["DataFlowDebugSessionInfo"]] = None,
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Array with all active debug sessions.
        :paramtype value: list[~azure.mgmt.datafactory.models.DataFlowDebugSessionInfo]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(QueryDataFlowDebugSessionsResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class QuickbaseLinkedService(LinkedService):
    """Linked service for Quickbase.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar url: Required. The url to connect Quickbase source. Type: string (or Expression with
     resultType string).
    :vartype url: any
    :ivar user_token: Required. The user token for the Quickbase source.
    :vartype user_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
        'user_token': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'url': {'key': 'typeProperties.url', 'type': 'object'},
        'user_token': {'key': 'typeProperties.userToken', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        url: Any,
        user_token: "SecretBase",
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword url: Required. The url to connect Quickbase source. Type: string (or Expression with
         resultType string).
        :paramtype url: any
        :keyword user_token: Required. The user token for the Quickbase source.
        :paramtype user_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(QuickbaseLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Quickbase'  # type: str
        self.url = url
        self.user_token = user_token
        self.encrypted_credential = encrypted_credential


class QuickBooksLinkedService(LinkedService):
    """QuickBooks server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_properties: Properties used to connect to QuickBooks. It is mutually exclusive
     with any other properties in the linked service. Type: object.
    :vartype connection_properties: any
    :ivar endpoint: The endpoint of the QuickBooks server. (i.e. quickbooks.api.intuit.com).
    :vartype endpoint: any
    :ivar company_id: The company ID of the QuickBooks company to authorize.
    :vartype company_id: any
    :ivar consumer_key: The consumer key for OAuth 1.0 authentication.
    :vartype consumer_key: any
    :ivar consumer_secret: The consumer secret for OAuth 1.0 authentication.
    :vartype consumer_secret: ~azure.mgmt.datafactory.models.SecretBase
    :ivar access_token: The access token for OAuth 1.0 authentication.
    :vartype access_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar access_token_secret: The access token secret for OAuth 1.0 authentication.
    :vartype access_token_secret: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_properties': {'key': 'typeProperties.connectionProperties', 'type': 'object'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'object'},
        'company_id': {'key': 'typeProperties.companyId', 'type': 'object'},
        'consumer_key': {'key': 'typeProperties.consumerKey', 'type': 'object'},
        'consumer_secret': {'key': 'typeProperties.consumerSecret', 'type': 'SecretBase'},
        'access_token': {'key': 'typeProperties.accessToken', 'type': 'SecretBase'},
        'access_token_secret': {'key': 'typeProperties.accessTokenSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_properties: Optional[Any] = None,
        endpoint: Optional[Any] = None,
        company_id: Optional[Any] = None,
        consumer_key: Optional[Any] = None,
        consumer_secret: Optional["SecretBase"] = None,
        access_token: Optional["SecretBase"] = None,
        access_token_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_properties: Properties used to connect to QuickBooks. It is mutually
         exclusive with any other properties in the linked service. Type: object.
        :paramtype connection_properties: any
        :keyword endpoint: The endpoint of the QuickBooks server. (i.e. quickbooks.api.intuit.com).
        :paramtype endpoint: any
        :keyword company_id: The company ID of the QuickBooks company to authorize.
        :paramtype company_id: any
        :keyword consumer_key: The consumer key for OAuth 1.0 authentication.
        :paramtype consumer_key: any
        :keyword consumer_secret: The consumer secret for OAuth 1.0 authentication.
        :paramtype consumer_secret: ~azure.mgmt.datafactory.models.SecretBase
        :keyword access_token: The access token for OAuth 1.0 authentication.
        :paramtype access_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword access_token_secret: The access token secret for OAuth 1.0 authentication.
        :paramtype access_token_secret: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(QuickBooksLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'QuickBooks'  # type: str
        self.connection_properties = connection_properties
        self.endpoint = endpoint
        self.company_id = company_id
        self.consumer_key = consumer_key
        self.consumer_secret = consumer_secret
        self.access_token = access_token
        self.access_token_secret = access_token_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.encrypted_credential = encrypted_credential


class QuickBooksObjectDataset(Dataset):
    """QuickBooks server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(QuickBooksObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'QuickBooksObject'  # type: str
        self.table_name = table_name


class QuickBooksSource(TabularSource):
    """A copy activity QuickBooks server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(QuickBooksSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'QuickBooksSource'  # type: str
        self.query = query


class RecurrenceSchedule(msrest.serialization.Model):
    """The recurrence schedule.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar minutes: The minutes.
    :vartype minutes: list[int]
    :ivar hours: The hours.
    :vartype hours: list[int]
    :ivar week_days: The days of the week.
    :vartype week_days: list[str or ~azure.mgmt.datafactory.models.DaysOfWeek]
    :ivar month_days: The month days.
    :vartype month_days: list[int]
    :ivar monthly_occurrences: The monthly occurrences.
    :vartype monthly_occurrences: list[~azure.mgmt.datafactory.models.RecurrenceScheduleOccurrence]
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'minutes': {'key': 'minutes', 'type': '[int]'},
        'hours': {'key': 'hours', 'type': '[int]'},
        'week_days': {'key': 'weekDays', 'type': '[str]'},
        'month_days': {'key': 'monthDays', 'type': '[int]'},
        'monthly_occurrences': {'key': 'monthlyOccurrences', 'type': '[RecurrenceScheduleOccurrence]'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        minutes: Optional[List[int]] = None,
        hours: Optional[List[int]] = None,
        week_days: Optional[List[Union[str, "DaysOfWeek"]]] = None,
        month_days: Optional[List[int]] = None,
        monthly_occurrences: Optional[List["RecurrenceScheduleOccurrence"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword minutes: The minutes.
        :paramtype minutes: list[int]
        :keyword hours: The hours.
        :paramtype hours: list[int]
        :keyword week_days: The days of the week.
        :paramtype week_days: list[str or ~azure.mgmt.datafactory.models.DaysOfWeek]
        :keyword month_days: The month days.
        :paramtype month_days: list[int]
        :keyword monthly_occurrences: The monthly occurrences.
        :paramtype monthly_occurrences:
         list[~azure.mgmt.datafactory.models.RecurrenceScheduleOccurrence]
        """
        super(RecurrenceSchedule, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.minutes = minutes
        self.hours = hours
        self.week_days = week_days
        self.month_days = month_days
        self.monthly_occurrences = monthly_occurrences


class RecurrenceScheduleOccurrence(msrest.serialization.Model):
    """The recurrence schedule occurrence.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar day: The day of the week. Possible values include: "Sunday", "Monday", "Tuesday",
     "Wednesday", "Thursday", "Friday", "Saturday".
    :vartype day: str or ~azure.mgmt.datafactory.models.DayOfWeek
    :ivar occurrence: The occurrence.
    :vartype occurrence: int
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'day': {'key': 'day', 'type': 'str'},
        'occurrence': {'key': 'occurrence', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        day: Optional[Union[str, "DayOfWeek"]] = None,
        occurrence: Optional[int] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword day: The day of the week. Possible values include: "Sunday", "Monday", "Tuesday",
         "Wednesday", "Thursday", "Friday", "Saturday".
        :paramtype day: str or ~azure.mgmt.datafactory.models.DayOfWeek
        :keyword occurrence: The occurrence.
        :paramtype occurrence: int
        """
        super(RecurrenceScheduleOccurrence, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.day = day
        self.occurrence = occurrence


class RedirectIncompatibleRowSettings(msrest.serialization.Model):
    """Redirect incompatible row settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar linked_service_name: Required. Name of the Azure Storage, Storage SAS, or Azure Data Lake
     Store linked service used for redirecting incompatible row. Must be specified if
     redirectIncompatibleRowSettings is specified. Type: string (or Expression with resultType
     string).
    :vartype linked_service_name: any
    :ivar path: The path for storing the redirect incompatible row data. Type: string (or
     Expression with resultType string).
    :vartype path: any
    """

    _validation = {
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'object'},
        'path': {'key': 'path', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        path: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword linked_service_name: Required. Name of the Azure Storage, Storage SAS, or Azure Data
         Lake Store linked service used for redirecting incompatible row. Must be specified if
         redirectIncompatibleRowSettings is specified. Type: string (or Expression with resultType
         string).
        :paramtype linked_service_name: any
        :keyword path: The path for storing the redirect incompatible row data. Type: string (or
         Expression with resultType string).
        :paramtype path: any
        """
        super(RedirectIncompatibleRowSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.linked_service_name = linked_service_name
        self.path = path


class RedshiftUnloadSettings(msrest.serialization.Model):
    """The Amazon S3 settings needed for the interim Amazon S3 when copying from Amazon Redshift with unload. With this, data from Amazon Redshift source will be unloaded into S3 first and then copied into the targeted sink from the interim S3.

    All required parameters must be populated in order to send to Azure.

    :ivar s3_linked_service_name: Required. The name of the Amazon S3 linked service which will be
     used for the unload operation when copying from the Amazon Redshift source.
    :vartype s3_linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar bucket_name: Required. The bucket of the interim Amazon S3 which will be used to store
     the unloaded data from Amazon Redshift source. The bucket must be in the same region as the
     Amazon Redshift source. Type: string (or Expression with resultType string).
    :vartype bucket_name: any
    """

    _validation = {
        's3_linked_service_name': {'required': True},
        'bucket_name': {'required': True},
    }

    _attribute_map = {
        's3_linked_service_name': {'key': 's3LinkedServiceName', 'type': 'LinkedServiceReference'},
        'bucket_name': {'key': 'bucketName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        s3_linked_service_name: "LinkedServiceReference",
        bucket_name: Any,
        **kwargs
    ):
        """
        :keyword s3_linked_service_name: Required. The name of the Amazon S3 linked service which will
         be used for the unload operation when copying from the Amazon Redshift source.
        :paramtype s3_linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword bucket_name: Required. The bucket of the interim Amazon S3 which will be used to store
         the unloaded data from Amazon Redshift source. The bucket must be in the same region as the
         Amazon Redshift source. Type: string (or Expression with resultType string).
        :paramtype bucket_name: any
        """
        super(RedshiftUnloadSettings, self).__init__(**kwargs)
        self.s3_linked_service_name = s3_linked_service_name
        self.bucket_name = bucket_name


class RelationalSource(CopySource):
    """A copy activity source for various relational databases.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: Database query. Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: Database query. Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(RelationalSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'RelationalSource'  # type: str
        self.query = query
        self.additional_columns = additional_columns


class RelationalTableDataset(Dataset):
    """The relational table dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The relational table name. Type: string (or Expression with resultType
     string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The relational table name. Type: string (or Expression with resultType
         string).
        :paramtype table_name: any
        """
        super(RelationalTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'RelationalTable'  # type: str
        self.table_name = table_name


class RemotePrivateEndpointConnection(msrest.serialization.Model):
    """A remote private endpoint connection.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar provisioning_state:
    :vartype provisioning_state: str
    :ivar private_endpoint: PrivateEndpoint of a remote private endpoint connection.
    :vartype private_endpoint: ~azure.mgmt.datafactory.models.ArmIdWrapper
    :ivar private_link_service_connection_state: The state of a private link connection.
    :vartype private_link_service_connection_state:
     ~azure.mgmt.datafactory.models.PrivateLinkConnectionState
    """

    _validation = {
        'provisioning_state': {'readonly': True},
    }

    _attribute_map = {
        'provisioning_state': {'key': 'provisioningState', 'type': 'str'},
        'private_endpoint': {'key': 'privateEndpoint', 'type': 'ArmIdWrapper'},
        'private_link_service_connection_state': {'key': 'privateLinkServiceConnectionState', 'type': 'PrivateLinkConnectionState'},
    }

    def __init__(
        self,
        *,
        private_endpoint: Optional["ArmIdWrapper"] = None,
        private_link_service_connection_state: Optional["PrivateLinkConnectionState"] = None,
        **kwargs
    ):
        """
        :keyword private_endpoint: PrivateEndpoint of a remote private endpoint connection.
        :paramtype private_endpoint: ~azure.mgmt.datafactory.models.ArmIdWrapper
        :keyword private_link_service_connection_state: The state of a private link connection.
        :paramtype private_link_service_connection_state:
         ~azure.mgmt.datafactory.models.PrivateLinkConnectionState
        """
        super(RemotePrivateEndpointConnection, self).__init__(**kwargs)
        self.provisioning_state = None
        self.private_endpoint = private_endpoint
        self.private_link_service_connection_state = private_link_service_connection_state


class RerunTumblingWindowTrigger(Trigger):
    """Trigger that schedules pipeline reruns for all fixed time interval windows from a requested start time to requested end time.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Trigger type.Constant filled by server.
    :vartype type: str
    :ivar description: Trigger description.
    :vartype description: str
    :ivar runtime_state: Indicates if trigger is running or not. Updated when Start/Stop APIs are
     called on the Trigger. Possible values include: "Started", "Stopped", "Disabled".
    :vartype runtime_state: str or ~azure.mgmt.datafactory.models.TriggerRuntimeState
    :ivar annotations: List of tags that can be used for describing the trigger.
    :vartype annotations: list[any]
    :ivar parent_trigger: Required. The parent trigger reference.
    :vartype parent_trigger: any
    :ivar requested_start_time: Required. The start time for the time period for which restatement
     is initiated. Only UTC time is currently supported.
    :vartype requested_start_time: ~datetime.datetime
    :ivar requested_end_time: Required. The end time for the time period for which restatement is
     initiated. Only UTC time is currently supported.
    :vartype requested_end_time: ~datetime.datetime
    :ivar rerun_concurrency: Required. The max number of parallel time windows (ready for
     execution) for which a rerun is triggered.
    :vartype rerun_concurrency: int
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
        'parent_trigger': {'required': True},
        'requested_start_time': {'required': True},
        'requested_end_time': {'required': True},
        'rerun_concurrency': {'required': True, 'maximum': 50, 'minimum': 1},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'parent_trigger': {'key': 'typeProperties.parentTrigger', 'type': 'object'},
        'requested_start_time': {'key': 'typeProperties.requestedStartTime', 'type': 'iso-8601'},
        'requested_end_time': {'key': 'typeProperties.requestedEndTime', 'type': 'iso-8601'},
        'rerun_concurrency': {'key': 'typeProperties.rerunConcurrency', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        parent_trigger: Any,
        requested_start_time: datetime.datetime,
        requested_end_time: datetime.datetime,
        rerun_concurrency: int,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Trigger description.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the trigger.
        :paramtype annotations: list[any]
        :keyword parent_trigger: Required. The parent trigger reference.
        :paramtype parent_trigger: any
        :keyword requested_start_time: Required. The start time for the time period for which
         restatement is initiated. Only UTC time is currently supported.
        :paramtype requested_start_time: ~datetime.datetime
        :keyword requested_end_time: Required. The end time for the time period for which restatement
         is initiated. Only UTC time is currently supported.
        :paramtype requested_end_time: ~datetime.datetime
        :keyword rerun_concurrency: Required. The max number of parallel time windows (ready for
         execution) for which a rerun is triggered.
        :paramtype rerun_concurrency: int
        """
        super(RerunTumblingWindowTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, **kwargs)
        self.type = 'RerunTumblingWindowTrigger'  # type: str
        self.parent_trigger = parent_trigger
        self.requested_start_time = requested_start_time
        self.requested_end_time = requested_end_time
        self.rerun_concurrency = rerun_concurrency


class ResponsysLinkedService(LinkedService):
    """Responsys linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar endpoint: Required. The endpoint of the Responsys server.
    :vartype endpoint: any
    :ivar client_id: Required. The client ID associated with the Responsys application. Type:
     string (or Expression with resultType string).
    :vartype client_id: any
    :ivar client_secret: The client secret associated with the Responsys application. Type: string
     (or Expression with resultType string).
    :vartype client_secret: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true. Type: boolean (or Expression with resultType
     boolean).
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'object'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'object'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        endpoint: Any,
        client_id: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword endpoint: Required. The endpoint of the Responsys server.
        :paramtype endpoint: any
        :keyword client_id: Required. The client ID associated with the Responsys application. Type:
         string (or Expression with resultType string).
        :paramtype client_id: any
        :keyword client_secret: The client secret associated with the Responsys application. Type:
         string (or Expression with resultType string).
        :paramtype client_secret: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true. Type: boolean (or Expression with resultType
         boolean).
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(ResponsysLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Responsys'  # type: str
        self.endpoint = endpoint
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ResponsysObjectDataset(Dataset):
    """Responsys dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(ResponsysObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ResponsysObject'  # type: str
        self.table_name = table_name


class ResponsysSource(TabularSource):
    """A copy activity Responsys source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(ResponsysSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'ResponsysSource'  # type: str
        self.query = query


class RestResourceDataset(Dataset):
    """A Rest service dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar relative_url: The relative URL to the resource that the RESTful API provides. Type:
     string (or Expression with resultType string).
    :vartype relative_url: any
    :ivar request_method: The HTTP method used to call the RESTful API. The default is GET. Type:
     string (or Expression with resultType string).
    :vartype request_method: any
    :ivar request_body: The HTTP request body to the RESTful API if requestMethod is POST. Type:
     string (or Expression with resultType string).
    :vartype request_body: any
    :ivar additional_headers: The additional HTTP headers in the request to the RESTful API. Type:
     string (or Expression with resultType string).
    :vartype additional_headers: any
    :ivar pagination_rules: The pagination rules to compose next page requests. Type: string (or
     Expression with resultType string).
    :vartype pagination_rules: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'relative_url': {'key': 'typeProperties.relativeUrl', 'type': 'object'},
        'request_method': {'key': 'typeProperties.requestMethod', 'type': 'object'},
        'request_body': {'key': 'typeProperties.requestBody', 'type': 'object'},
        'additional_headers': {'key': 'typeProperties.additionalHeaders', 'type': 'object'},
        'pagination_rules': {'key': 'typeProperties.paginationRules', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        relative_url: Optional[Any] = None,
        request_method: Optional[Any] = None,
        request_body: Optional[Any] = None,
        additional_headers: Optional[Any] = None,
        pagination_rules: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword relative_url: The relative URL to the resource that the RESTful API provides. Type:
         string (or Expression with resultType string).
        :paramtype relative_url: any
        :keyword request_method: The HTTP method used to call the RESTful API. The default is GET.
         Type: string (or Expression with resultType string).
        :paramtype request_method: any
        :keyword request_body: The HTTP request body to the RESTful API if requestMethod is POST. Type:
         string (or Expression with resultType string).
        :paramtype request_body: any
        :keyword additional_headers: The additional HTTP headers in the request to the RESTful API.
         Type: string (or Expression with resultType string).
        :paramtype additional_headers: any
        :keyword pagination_rules: The pagination rules to compose next page requests. Type: string (or
         Expression with resultType string).
        :paramtype pagination_rules: any
        """
        super(RestResourceDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'RestResource'  # type: str
        self.relative_url = relative_url
        self.request_method = request_method
        self.request_body = request_body
        self.additional_headers = additional_headers
        self.pagination_rules = pagination_rules


class RestServiceLinkedService(LinkedService):
    """Rest Service linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar url: Required. The base URL of the REST service.
    :vartype url: any
    :ivar enable_server_certificate_validation: Whether to validate server side SSL certificate
     when connecting to the endpoint.The default value is true. Type: boolean (or Expression with
     resultType boolean).
    :vartype enable_server_certificate_validation: any
    :ivar authentication_type: Required. Type of authentication used to connect to the REST
     service. Possible values include: "Anonymous", "Basic", "AadServicePrincipal",
     "ManagedServiceIdentity".
    :vartype authentication_type: str or
     ~azure.mgmt.datafactory.models.RestServiceAuthenticationType
    :ivar user_name: The user name used in Basic authentication type.
    :vartype user_name: any
    :ivar password: The password used in Basic authentication type.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar auth_headers: The additional HTTP headers in the request to RESTful API used for
     authorization. Type: object (or Expression with resultType object).
    :vartype auth_headers: any
    :ivar service_principal_id: The application's client ID used in AadServicePrincipal
     authentication type.
    :vartype service_principal_id: any
    :ivar service_principal_key: The application's key used in AadServicePrincipal authentication
     type.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar tenant: The tenant information (domain name or tenant ID) used in AadServicePrincipal
     authentication type under which your application resides.
    :vartype tenant: any
    :ivar azure_cloud_type: Indicates the azure cloud type of the service principle auth. Allowed
     values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is the data
     factory regions cloud type. Type: string (or Expression with resultType string).
    :vartype azure_cloud_type: any
    :ivar aad_resource_id: The resource you are requesting authorization to use.
    :vartype aad_resource_id: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'url': {'key': 'typeProperties.url', 'type': 'object'},
        'enable_server_certificate_validation': {'key': 'typeProperties.enableServerCertificateValidation', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'auth_headers': {'key': 'typeProperties.authHeaders', 'type': 'object'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
        'azure_cloud_type': {'key': 'typeProperties.azureCloudType', 'type': 'object'},
        'aad_resource_id': {'key': 'typeProperties.aadResourceId', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'credential': {'key': 'typeProperties.credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        url: Any,
        authentication_type: Union[str, "RestServiceAuthenticationType"],
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        enable_server_certificate_validation: Optional[Any] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        auth_headers: Optional[Any] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["SecretBase"] = None,
        tenant: Optional[Any] = None,
        azure_cloud_type: Optional[Any] = None,
        aad_resource_id: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword url: Required. The base URL of the REST service.
        :paramtype url: any
        :keyword enable_server_certificate_validation: Whether to validate server side SSL certificate
         when connecting to the endpoint.The default value is true. Type: boolean (or Expression with
         resultType boolean).
        :paramtype enable_server_certificate_validation: any
        :keyword authentication_type: Required. Type of authentication used to connect to the REST
         service. Possible values include: "Anonymous", "Basic", "AadServicePrincipal",
         "ManagedServiceIdentity".
        :paramtype authentication_type: str or
         ~azure.mgmt.datafactory.models.RestServiceAuthenticationType
        :keyword user_name: The user name used in Basic authentication type.
        :paramtype user_name: any
        :keyword password: The password used in Basic authentication type.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword auth_headers: The additional HTTP headers in the request to RESTful API used for
         authorization. Type: object (or Expression with resultType object).
        :paramtype auth_headers: any
        :keyword service_principal_id: The application's client ID used in AadServicePrincipal
         authentication type.
        :paramtype service_principal_id: any
        :keyword service_principal_key: The application's key used in AadServicePrincipal
         authentication type.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword tenant: The tenant information (domain name or tenant ID) used in AadServicePrincipal
         authentication type under which your application resides.
        :paramtype tenant: any
        :keyword azure_cloud_type: Indicates the azure cloud type of the service principle auth.
         Allowed values are AzurePublic, AzureChina, AzureUsGovernment, AzureGermany. Default value is
         the data factory regions cloud type. Type: string (or Expression with resultType string).
        :paramtype azure_cloud_type: any
        :keyword aad_resource_id: The resource you are requesting authorization to use.
        :paramtype aad_resource_id: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(RestServiceLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'RestService'  # type: str
        self.url = url
        self.enable_server_certificate_validation = enable_server_certificate_validation
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.auth_headers = auth_headers
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant
        self.azure_cloud_type = azure_cloud_type
        self.aad_resource_id = aad_resource_id
        self.encrypted_credential = encrypted_credential
        self.credential = credential


class RestSink(CopySink):
    """A copy activity Rest service Sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar request_method: The HTTP method used to call the RESTful API. The default is POST. Type:
     string (or Expression with resultType string).
    :vartype request_method: any
    :ivar additional_headers: The additional HTTP headers in the request to the RESTful API. Type:
     string (or Expression with resultType string).
    :vartype additional_headers: any
    :ivar http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the timeout
     to get a response, not the timeout to read response data. Default value: 00:01:40. Type: string
     (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype http_request_timeout: any
    :ivar request_interval: The time to await before sending next request, in milliseconds.
    :vartype request_interval: any
    :ivar http_compression_type: Http Compression Type to Send data in compressed format with
     Optimal Compression Level, Default is None. And The Only Supported option is Gzip.
    :vartype http_compression_type: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'request_method': {'key': 'requestMethod', 'type': 'object'},
        'additional_headers': {'key': 'additionalHeaders', 'type': 'object'},
        'http_request_timeout': {'key': 'httpRequestTimeout', 'type': 'object'},
        'request_interval': {'key': 'requestInterval', 'type': 'object'},
        'http_compression_type': {'key': 'httpCompressionType', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        request_method: Optional[Any] = None,
        additional_headers: Optional[Any] = None,
        http_request_timeout: Optional[Any] = None,
        request_interval: Optional[Any] = None,
        http_compression_type: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword request_method: The HTTP method used to call the RESTful API. The default is POST.
         Type: string (or Expression with resultType string).
        :paramtype request_method: any
        :keyword additional_headers: The additional HTTP headers in the request to the RESTful API.
         Type: string (or Expression with resultType string).
        :paramtype additional_headers: any
        :keyword http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the
         timeout to get a response, not the timeout to read response data. Default value: 00:01:40.
         Type: string (or Expression with resultType string), pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype http_request_timeout: any
        :keyword request_interval: The time to await before sending next request, in milliseconds.
        :paramtype request_interval: any
        :keyword http_compression_type: Http Compression Type to Send data in compressed format with
         Optimal Compression Level, Default is None. And The Only Supported option is Gzip.
        :paramtype http_compression_type: any
        """
        super(RestSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'RestSink'  # type: str
        self.request_method = request_method
        self.additional_headers = additional_headers
        self.http_request_timeout = http_request_timeout
        self.request_interval = request_interval
        self.http_compression_type = http_compression_type


class RestSource(CopySource):
    """A copy activity Rest service source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar request_method: The HTTP method used to call the RESTful API. The default is GET. Type:
     string (or Expression with resultType string).
    :vartype request_method: any
    :ivar request_body: The HTTP request body to the RESTful API if requestMethod is POST. Type:
     string (or Expression with resultType string).
    :vartype request_body: any
    :ivar additional_headers: The additional HTTP headers in the request to the RESTful API. Type:
     string (or Expression with resultType string).
    :vartype additional_headers: any
    :ivar pagination_rules: The pagination rules to compose next page requests. Type: string (or
     Expression with resultType string).
    :vartype pagination_rules: any
    :ivar http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the timeout
     to get a response, not the timeout to read response data. Default value: 00:01:40. Type: string
     (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype http_request_timeout: any
    :ivar request_interval: The time to await before sending next page request.
    :vartype request_interval: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'request_method': {'key': 'requestMethod', 'type': 'object'},
        'request_body': {'key': 'requestBody', 'type': 'object'},
        'additional_headers': {'key': 'additionalHeaders', 'type': 'object'},
        'pagination_rules': {'key': 'paginationRules', 'type': 'object'},
        'http_request_timeout': {'key': 'httpRequestTimeout', 'type': 'object'},
        'request_interval': {'key': 'requestInterval', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        request_method: Optional[Any] = None,
        request_body: Optional[Any] = None,
        additional_headers: Optional[Any] = None,
        pagination_rules: Optional[Any] = None,
        http_request_timeout: Optional[Any] = None,
        request_interval: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword request_method: The HTTP method used to call the RESTful API. The default is GET.
         Type: string (or Expression with resultType string).
        :paramtype request_method: any
        :keyword request_body: The HTTP request body to the RESTful API if requestMethod is POST. Type:
         string (or Expression with resultType string).
        :paramtype request_body: any
        :keyword additional_headers: The additional HTTP headers in the request to the RESTful API.
         Type: string (or Expression with resultType string).
        :paramtype additional_headers: any
        :keyword pagination_rules: The pagination rules to compose next page requests. Type: string (or
         Expression with resultType string).
        :paramtype pagination_rules: any
        :keyword http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the
         timeout to get a response, not the timeout to read response data. Default value: 00:01:40.
         Type: string (or Expression with resultType string), pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype http_request_timeout: any
        :keyword request_interval: The time to await before sending next page request.
        :paramtype request_interval: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(RestSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'RestSource'  # type: str
        self.request_method = request_method
        self.request_body = request_body
        self.additional_headers = additional_headers
        self.pagination_rules = pagination_rules
        self.http_request_timeout = http_request_timeout
        self.request_interval = request_interval
        self.additional_columns = additional_columns


class RetryPolicy(msrest.serialization.Model):
    """Execution policy for an activity.

    :ivar count: Maximum ordinary retry attempts. Default is 0. Type: integer (or Expression with
     resultType integer), minimum: 0.
    :vartype count: any
    :ivar interval_in_seconds: Interval between retries in seconds. Default is 30.
    :vartype interval_in_seconds: int
    """

    _validation = {
        'interval_in_seconds': {'maximum': 86400, 'minimum': 30},
    }

    _attribute_map = {
        'count': {'key': 'count', 'type': 'object'},
        'interval_in_seconds': {'key': 'intervalInSeconds', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        count: Optional[Any] = None,
        interval_in_seconds: Optional[int] = None,
        **kwargs
    ):
        """
        :keyword count: Maximum ordinary retry attempts. Default is 0. Type: integer (or Expression
         with resultType integer), minimum: 0.
        :paramtype count: any
        :keyword interval_in_seconds: Interval between retries in seconds. Default is 30.
        :paramtype interval_in_seconds: int
        """
        super(RetryPolicy, self).__init__(**kwargs)
        self.count = count
        self.interval_in_seconds = interval_in_seconds


class RunFilterParameters(msrest.serialization.Model):
    """Query parameters for listing runs.

    All required parameters must be populated in order to send to Azure.

    :ivar continuation_token: The continuation token for getting the next page of results. Null for
     first page.
    :vartype continuation_token: str
    :ivar last_updated_after: Required. The time at or after which the run event was updated in
     'ISO 8601' format.
    :vartype last_updated_after: ~datetime.datetime
    :ivar last_updated_before: Required. The time at or before which the run event was updated in
     'ISO 8601' format.
    :vartype last_updated_before: ~datetime.datetime
    :ivar filters: List of filters.
    :vartype filters: list[~azure.mgmt.datafactory.models.RunQueryFilter]
    :ivar order_by: List of OrderBy option.
    :vartype order_by: list[~azure.mgmt.datafactory.models.RunQueryOrderBy]
    """

    _validation = {
        'last_updated_after': {'required': True},
        'last_updated_before': {'required': True},
    }

    _attribute_map = {
        'continuation_token': {'key': 'continuationToken', 'type': 'str'},
        'last_updated_after': {'key': 'lastUpdatedAfter', 'type': 'iso-8601'},
        'last_updated_before': {'key': 'lastUpdatedBefore', 'type': 'iso-8601'},
        'filters': {'key': 'filters', 'type': '[RunQueryFilter]'},
        'order_by': {'key': 'orderBy', 'type': '[RunQueryOrderBy]'},
    }

    def __init__(
        self,
        *,
        last_updated_after: datetime.datetime,
        last_updated_before: datetime.datetime,
        continuation_token: Optional[str] = None,
        filters: Optional[List["RunQueryFilter"]] = None,
        order_by: Optional[List["RunQueryOrderBy"]] = None,
        **kwargs
    ):
        """
        :keyword continuation_token: The continuation token for getting the next page of results. Null
         for first page.
        :paramtype continuation_token: str
        :keyword last_updated_after: Required. The time at or after which the run event was updated in
         'ISO 8601' format.
        :paramtype last_updated_after: ~datetime.datetime
        :keyword last_updated_before: Required. The time at or before which the run event was updated
         in 'ISO 8601' format.
        :paramtype last_updated_before: ~datetime.datetime
        :keyword filters: List of filters.
        :paramtype filters: list[~azure.mgmt.datafactory.models.RunQueryFilter]
        :keyword order_by: List of OrderBy option.
        :paramtype order_by: list[~azure.mgmt.datafactory.models.RunQueryOrderBy]
        """
        super(RunFilterParameters, self).__init__(**kwargs)
        self.continuation_token = continuation_token
        self.last_updated_after = last_updated_after
        self.last_updated_before = last_updated_before
        self.filters = filters
        self.order_by = order_by


class RunQueryFilter(msrest.serialization.Model):
    """Query filter option for listing runs.

    All required parameters must be populated in order to send to Azure.

    :ivar operand: Required. Parameter name to be used for filter. The allowed operands to query
     pipeline runs are PipelineName, RunStart, RunEnd and Status; to query activity runs are
     ActivityName, ActivityRunStart, ActivityRunEnd, ActivityType and Status, and to query trigger
     runs are TriggerName, TriggerRunTimestamp and Status. Possible values include: "PipelineName",
     "Status", "RunStart", "RunEnd", "ActivityName", "ActivityRunStart", "ActivityRunEnd",
     "ActivityType", "TriggerName", "TriggerRunTimestamp", "RunGroupId", "LatestOnly".
    :vartype operand: str or ~azure.mgmt.datafactory.models.RunQueryFilterOperand
    :ivar operator: Required. Operator to be used for filter. Possible values include: "Equals",
     "NotEquals", "In", "NotIn".
    :vartype operator: str or ~azure.mgmt.datafactory.models.RunQueryFilterOperator
    :ivar values: Required. List of filter values.
    :vartype values: list[str]
    """

    _validation = {
        'operand': {'required': True},
        'operator': {'required': True},
        'values': {'required': True},
    }

    _attribute_map = {
        'operand': {'key': 'operand', 'type': 'str'},
        'operator': {'key': 'operator', 'type': 'str'},
        'values': {'key': 'values', 'type': '[str]'},
    }

    def __init__(
        self,
        *,
        operand: Union[str, "RunQueryFilterOperand"],
        operator: Union[str, "RunQueryFilterOperator"],
        values: List[str],
        **kwargs
    ):
        """
        :keyword operand: Required. Parameter name to be used for filter. The allowed operands to query
         pipeline runs are PipelineName, RunStart, RunEnd and Status; to query activity runs are
         ActivityName, ActivityRunStart, ActivityRunEnd, ActivityType and Status, and to query trigger
         runs are TriggerName, TriggerRunTimestamp and Status. Possible values include: "PipelineName",
         "Status", "RunStart", "RunEnd", "ActivityName", "ActivityRunStart", "ActivityRunEnd",
         "ActivityType", "TriggerName", "TriggerRunTimestamp", "RunGroupId", "LatestOnly".
        :paramtype operand: str or ~azure.mgmt.datafactory.models.RunQueryFilterOperand
        :keyword operator: Required. Operator to be used for filter. Possible values include: "Equals",
         "NotEquals", "In", "NotIn".
        :paramtype operator: str or ~azure.mgmt.datafactory.models.RunQueryFilterOperator
        :keyword values: Required. List of filter values.
        :paramtype values: list[str]
        """
        super(RunQueryFilter, self).__init__(**kwargs)
        self.operand = operand
        self.operator = operator
        self.values = values


class RunQueryOrderBy(msrest.serialization.Model):
    """An object to provide order by options for listing runs.

    All required parameters must be populated in order to send to Azure.

    :ivar order_by: Required. Parameter name to be used for order by. The allowed parameters to
     order by for pipeline runs are PipelineName, RunStart, RunEnd and Status; for activity runs are
     ActivityName, ActivityRunStart, ActivityRunEnd and Status; for trigger runs are TriggerName,
     TriggerRunTimestamp and Status. Possible values include: "RunStart", "RunEnd", "PipelineName",
     "Status", "ActivityName", "ActivityRunStart", "ActivityRunEnd", "TriggerName",
     "TriggerRunTimestamp".
    :vartype order_by: str or ~azure.mgmt.datafactory.models.RunQueryOrderByField
    :ivar order: Required. Sorting order of the parameter. Possible values include: "ASC", "DESC".
    :vartype order: str or ~azure.mgmt.datafactory.models.RunQueryOrder
    """

    _validation = {
        'order_by': {'required': True},
        'order': {'required': True},
    }

    _attribute_map = {
        'order_by': {'key': 'orderBy', 'type': 'str'},
        'order': {'key': 'order', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        order_by: Union[str, "RunQueryOrderByField"],
        order: Union[str, "RunQueryOrder"],
        **kwargs
    ):
        """
        :keyword order_by: Required. Parameter name to be used for order by. The allowed parameters to
         order by for pipeline runs are PipelineName, RunStart, RunEnd and Status; for activity runs are
         ActivityName, ActivityRunStart, ActivityRunEnd and Status; for trigger runs are TriggerName,
         TriggerRunTimestamp and Status. Possible values include: "RunStart", "RunEnd", "PipelineName",
         "Status", "ActivityName", "ActivityRunStart", "ActivityRunEnd", "TriggerName",
         "TriggerRunTimestamp".
        :paramtype order_by: str or ~azure.mgmt.datafactory.models.RunQueryOrderByField
        :keyword order: Required. Sorting order of the parameter. Possible values include: "ASC",
         "DESC".
        :paramtype order: str or ~azure.mgmt.datafactory.models.RunQueryOrder
        """
        super(RunQueryOrderBy, self).__init__(**kwargs)
        self.order_by = order_by
        self.order = order


class SalesforceLinkedService(LinkedService):
    """Linked service for Salesforce.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar environment_url: The URL of Salesforce instance. Default is
     'https://login.salesforce.com'. To copy data from sandbox, specify
     'https://test.salesforce.com'. To copy data from custom domain, specify, for example,
     'https://[domain].my.salesforce.com'. Type: string (or Expression with resultType string).
    :vartype environment_url: any
    :ivar username: The username for Basic authentication of the Salesforce instance. Type: string
     (or Expression with resultType string).
    :vartype username: any
    :ivar password: The password for Basic authentication of the Salesforce instance.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar security_token: The security token is optional to remotely access Salesforce instance.
    :vartype security_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar api_version: The Salesforce API version used in ADF. Type: string (or Expression with
     resultType string).
    :vartype api_version: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'environment_url': {'key': 'typeProperties.environmentUrl', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'security_token': {'key': 'typeProperties.securityToken', 'type': 'SecretBase'},
        'api_version': {'key': 'typeProperties.apiVersion', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        environment_url: Optional[Any] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        security_token: Optional["SecretBase"] = None,
        api_version: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword environment_url: The URL of Salesforce instance. Default is
         'https://login.salesforce.com'. To copy data from sandbox, specify
         'https://test.salesforce.com'. To copy data from custom domain, specify, for example,
         'https://[domain].my.salesforce.com'. Type: string (or Expression with resultType string).
        :paramtype environment_url: any
        :keyword username: The username for Basic authentication of the Salesforce instance. Type:
         string (or Expression with resultType string).
        :paramtype username: any
        :keyword password: The password for Basic authentication of the Salesforce instance.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword security_token: The security token is optional to remotely access Salesforce instance.
        :paramtype security_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword api_version: The Salesforce API version used in ADF. Type: string (or Expression with
         resultType string).
        :paramtype api_version: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SalesforceLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Salesforce'  # type: str
        self.environment_url = environment_url
        self.username = username
        self.password = password
        self.security_token = security_token
        self.api_version = api_version
        self.encrypted_credential = encrypted_credential


class SalesforceMarketingCloudLinkedService(LinkedService):
    """Salesforce Marketing Cloud linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_properties: Properties used to connect to Salesforce Marketing Cloud. It is
     mutually exclusive with any other properties in the linked service. Type: object.
    :vartype connection_properties: any
    :ivar client_id: The client ID associated with the Salesforce Marketing Cloud application.
     Type: string (or Expression with resultType string).
    :vartype client_id: any
    :ivar client_secret: The client secret associated with the Salesforce Marketing Cloud
     application. Type: string (or Expression with resultType string).
    :vartype client_secret: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true. Type: boolean (or Expression with resultType
     boolean).
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_properties': {'key': 'typeProperties.connectionProperties', 'type': 'object'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'object'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_properties: Optional[Any] = None,
        client_id: Optional[Any] = None,
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_properties: Properties used to connect to Salesforce Marketing Cloud. It is
         mutually exclusive with any other properties in the linked service. Type: object.
        :paramtype connection_properties: any
        :keyword client_id: The client ID associated with the Salesforce Marketing Cloud application.
         Type: string (or Expression with resultType string).
        :paramtype client_id: any
        :keyword client_secret: The client secret associated with the Salesforce Marketing Cloud
         application. Type: string (or Expression with resultType string).
        :paramtype client_secret: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true. Type: boolean (or Expression with resultType boolean).
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true. Type: boolean (or Expression with resultType
         boolean).
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SalesforceMarketingCloudLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SalesforceMarketingCloud'  # type: str
        self.connection_properties = connection_properties
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class SalesforceMarketingCloudObjectDataset(Dataset):
    """Salesforce Marketing Cloud dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(SalesforceMarketingCloudObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SalesforceMarketingCloudObject'  # type: str
        self.table_name = table_name


class SalesforceMarketingCloudSource(TabularSource):
    """A copy activity Salesforce Marketing Cloud source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(SalesforceMarketingCloudSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SalesforceMarketingCloudSource'  # type: str
        self.query = query


class SalesforceObjectDataset(Dataset):
    """The Salesforce object dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar object_api_name: The Salesforce object API name. Type: string (or Expression with
     resultType string).
    :vartype object_api_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'object_api_name': {'key': 'typeProperties.objectApiName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        object_api_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword object_api_name: The Salesforce object API name. Type: string (or Expression with
         resultType string).
        :paramtype object_api_name: any
        """
        super(SalesforceObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SalesforceObject'  # type: str
        self.object_api_name = object_api_name


class SalesforceServiceCloudLinkedService(LinkedService):
    """Linked service for Salesforce Service Cloud.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar environment_url: The URL of Salesforce Service Cloud instance. Default is
     'https://login.salesforce.com'. To copy data from sandbox, specify
     'https://test.salesforce.com'. To copy data from custom domain, specify, for example,
     'https://[domain].my.salesforce.com'. Type: string (or Expression with resultType string).
    :vartype environment_url: any
    :ivar username: The username for Basic authentication of the Salesforce instance. Type: string
     (or Expression with resultType string).
    :vartype username: any
    :ivar password: The password for Basic authentication of the Salesforce instance.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar security_token: The security token is optional to remotely access Salesforce instance.
    :vartype security_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar api_version: The Salesforce API version used in ADF. Type: string (or Expression with
     resultType string).
    :vartype api_version: any
    :ivar extended_properties: Extended properties appended to the connection string. Type: string
     (or Expression with resultType string).
    :vartype extended_properties: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'environment_url': {'key': 'typeProperties.environmentUrl', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'security_token': {'key': 'typeProperties.securityToken', 'type': 'SecretBase'},
        'api_version': {'key': 'typeProperties.apiVersion', 'type': 'object'},
        'extended_properties': {'key': 'typeProperties.extendedProperties', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        environment_url: Optional[Any] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        security_token: Optional["SecretBase"] = None,
        api_version: Optional[Any] = None,
        extended_properties: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword environment_url: The URL of Salesforce Service Cloud instance. Default is
         'https://login.salesforce.com'. To copy data from sandbox, specify
         'https://test.salesforce.com'. To copy data from custom domain, specify, for example,
         'https://[domain].my.salesforce.com'. Type: string (or Expression with resultType string).
        :paramtype environment_url: any
        :keyword username: The username for Basic authentication of the Salesforce instance. Type:
         string (or Expression with resultType string).
        :paramtype username: any
        :keyword password: The password for Basic authentication of the Salesforce instance.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword security_token: The security token is optional to remotely access Salesforce instance.
        :paramtype security_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword api_version: The Salesforce API version used in ADF. Type: string (or Expression with
         resultType string).
        :paramtype api_version: any
        :keyword extended_properties: Extended properties appended to the connection string. Type:
         string (or Expression with resultType string).
        :paramtype extended_properties: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SalesforceServiceCloudLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SalesforceServiceCloud'  # type: str
        self.environment_url = environment_url
        self.username = username
        self.password = password
        self.security_token = security_token
        self.api_version = api_version
        self.extended_properties = extended_properties
        self.encrypted_credential = encrypted_credential


class SalesforceServiceCloudObjectDataset(Dataset):
    """The Salesforce Service Cloud object dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar object_api_name: The Salesforce Service Cloud object API name. Type: string (or
     Expression with resultType string).
    :vartype object_api_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'object_api_name': {'key': 'typeProperties.objectApiName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        object_api_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword object_api_name: The Salesforce Service Cloud object API name. Type: string (or
         Expression with resultType string).
        :paramtype object_api_name: any
        """
        super(SalesforceServiceCloudObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SalesforceServiceCloudObject'  # type: str
        self.object_api_name = object_api_name


class SalesforceServiceCloudSink(CopySink):
    """A copy activity Salesforce Service Cloud sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar write_behavior: The write behavior for the operation. Default is Insert. Possible values
     include: "Insert", "Upsert".
    :vartype write_behavior: str or ~azure.mgmt.datafactory.models.SalesforceSinkWriteBehavior
    :ivar external_id_field_name: The name of the external ID field for upsert operation. Default
     value is 'Id' column. Type: string (or Expression with resultType string).
    :vartype external_id_field_name: any
    :ivar ignore_null_values: The flag indicating whether or not to ignore null values from input
     dataset (except key fields) during write operation. Default value is false. If set it to true,
     it means ADF will leave the data in the destination object unchanged when doing upsert/update
     operation and insert defined default value when doing insert operation, versus ADF will update
     the data in the destination object to NULL when doing upsert/update operation and insert NULL
     value when doing insert operation. Type: boolean (or Expression with resultType boolean).
    :vartype ignore_null_values: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
        'external_id_field_name': {'key': 'externalIdFieldName', 'type': 'object'},
        'ignore_null_values': {'key': 'ignoreNullValues', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        write_behavior: Optional[Union[str, "SalesforceSinkWriteBehavior"]] = None,
        external_id_field_name: Optional[Any] = None,
        ignore_null_values: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword write_behavior: The write behavior for the operation. Default is Insert. Possible
         values include: "Insert", "Upsert".
        :paramtype write_behavior: str or ~azure.mgmt.datafactory.models.SalesforceSinkWriteBehavior
        :keyword external_id_field_name: The name of the external ID field for upsert operation.
         Default value is 'Id' column. Type: string (or Expression with resultType string).
        :paramtype external_id_field_name: any
        :keyword ignore_null_values: The flag indicating whether or not to ignore null values from
         input dataset (except key fields) during write operation. Default value is false. If set it to
         true, it means ADF will leave the data in the destination object unchanged when doing
         upsert/update operation and insert defined default value when doing insert operation, versus
         ADF will update the data in the destination object to NULL when doing upsert/update operation
         and insert NULL value when doing insert operation. Type: boolean (or Expression with resultType
         boolean).
        :paramtype ignore_null_values: any
        """
        super(SalesforceServiceCloudSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'SalesforceServiceCloudSink'  # type: str
        self.write_behavior = write_behavior
        self.external_id_field_name = external_id_field_name
        self.ignore_null_values = ignore_null_values


class SalesforceServiceCloudSource(CopySource):
    """A copy activity Salesforce Service Cloud source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: Database query. Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar read_behavior: The read behavior for the operation. Default is Query. Possible values
     include: "Query", "QueryAll".
    :vartype read_behavior: str or ~azure.mgmt.datafactory.models.SalesforceSourceReadBehavior
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'read_behavior': {'key': 'readBehavior', 'type': 'str'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query: Optional[Any] = None,
        read_behavior: Optional[Union[str, "SalesforceSourceReadBehavior"]] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: Database query. Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword read_behavior: The read behavior for the operation. Default is Query. Possible values
         include: "Query", "QueryAll".
        :paramtype read_behavior: str or ~azure.mgmt.datafactory.models.SalesforceSourceReadBehavior
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(SalesforceServiceCloudSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'SalesforceServiceCloudSource'  # type: str
        self.query = query
        self.read_behavior = read_behavior
        self.additional_columns = additional_columns


class SalesforceSink(CopySink):
    """A copy activity Salesforce sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar write_behavior: The write behavior for the operation. Default is Insert. Possible values
     include: "Insert", "Upsert".
    :vartype write_behavior: str or ~azure.mgmt.datafactory.models.SalesforceSinkWriteBehavior
    :ivar external_id_field_name: The name of the external ID field for upsert operation. Default
     value is 'Id' column. Type: string (or Expression with resultType string).
    :vartype external_id_field_name: any
    :ivar ignore_null_values: The flag indicating whether or not to ignore null values from input
     dataset (except key fields) during write operation. Default value is false. If set it to true,
     it means ADF will leave the data in the destination object unchanged when doing upsert/update
     operation and insert defined default value when doing insert operation, versus ADF will update
     the data in the destination object to NULL when doing upsert/update operation and insert NULL
     value when doing insert operation. Type: boolean (or Expression with resultType boolean).
    :vartype ignore_null_values: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
        'external_id_field_name': {'key': 'externalIdFieldName', 'type': 'object'},
        'ignore_null_values': {'key': 'ignoreNullValues', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        write_behavior: Optional[Union[str, "SalesforceSinkWriteBehavior"]] = None,
        external_id_field_name: Optional[Any] = None,
        ignore_null_values: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword write_behavior: The write behavior for the operation. Default is Insert. Possible
         values include: "Insert", "Upsert".
        :paramtype write_behavior: str or ~azure.mgmt.datafactory.models.SalesforceSinkWriteBehavior
        :keyword external_id_field_name: The name of the external ID field for upsert operation.
         Default value is 'Id' column. Type: string (or Expression with resultType string).
        :paramtype external_id_field_name: any
        :keyword ignore_null_values: The flag indicating whether or not to ignore null values from
         input dataset (except key fields) during write operation. Default value is false. If set it to
         true, it means ADF will leave the data in the destination object unchanged when doing
         upsert/update operation and insert defined default value when doing insert operation, versus
         ADF will update the data in the destination object to NULL when doing upsert/update operation
         and insert NULL value when doing insert operation. Type: boolean (or Expression with resultType
         boolean).
        :paramtype ignore_null_values: any
        """
        super(SalesforceSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'SalesforceSink'  # type: str
        self.write_behavior = write_behavior
        self.external_id_field_name = external_id_field_name
        self.ignore_null_values = ignore_null_values


class SalesforceSource(TabularSource):
    """A copy activity Salesforce source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: Database query. Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar read_behavior: The read behavior for the operation. Default is Query. Possible values
     include: "Query", "QueryAll".
    :vartype read_behavior: str or ~azure.mgmt.datafactory.models.SalesforceSourceReadBehavior
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'read_behavior': {'key': 'readBehavior', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        read_behavior: Optional[Union[str, "SalesforceSourceReadBehavior"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: Database query. Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword read_behavior: The read behavior for the operation. Default is Query. Possible values
         include: "Query", "QueryAll".
        :paramtype read_behavior: str or ~azure.mgmt.datafactory.models.SalesforceSourceReadBehavior
        """
        super(SalesforceSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SalesforceSource'  # type: str
        self.query = query
        self.read_behavior = read_behavior


class SapBwCubeDataset(Dataset):
    """The SAP BW cube dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        """
        super(SapBwCubeDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SapBwCube'  # type: str


class SapBWLinkedService(LinkedService):
    """SAP Business Warehouse Linked Service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar server: Required. Host name of the SAP BW instance. Type: string (or Expression with
     resultType string).
    :vartype server: any
    :ivar system_number: Required. System number of the BW system. (Usually a two-digit decimal
     number represented as a string.) Type: string (or Expression with resultType string).
    :vartype system_number: any
    :ivar client_id: Required. Client ID of the client on the BW system. (Usually a three-digit
     decimal number represented as a string) Type: string (or Expression with resultType string).
    :vartype client_id: any
    :ivar user_name: Username to access the SAP BW server. Type: string (or Expression with
     resultType string).
    :vartype user_name: any
    :ivar password: Password to access the SAP BW server.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'server': {'required': True},
        'system_number': {'required': True},
        'client_id': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'server': {'key': 'typeProperties.server', 'type': 'object'},
        'system_number': {'key': 'typeProperties.systemNumber', 'type': 'object'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'object'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        server: Any,
        system_number: Any,
        client_id: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword server: Required. Host name of the SAP BW instance. Type: string (or Expression with
         resultType string).
        :paramtype server: any
        :keyword system_number: Required. System number of the BW system. (Usually a two-digit decimal
         number represented as a string.) Type: string (or Expression with resultType string).
        :paramtype system_number: any
        :keyword client_id: Required. Client ID of the client on the BW system. (Usually a three-digit
         decimal number represented as a string) Type: string (or Expression with resultType string).
        :paramtype client_id: any
        :keyword user_name: Username to access the SAP BW server. Type: string (or Expression with
         resultType string).
        :paramtype user_name: any
        :keyword password: Password to access the SAP BW server.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SapBWLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SapBW'  # type: str
        self.server = server
        self.system_number = system_number
        self.client_id = client_id
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapBwSource(TabularSource):
    """A copy activity source for SapBW server via MDX.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: MDX query. Type: string (or Expression with resultType string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: MDX query. Type: string (or Expression with resultType string).
        :paramtype query: any
        """
        super(SapBwSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SapBwSource'  # type: str
        self.query = query


class SapCloudForCustomerLinkedService(LinkedService):
    """Linked service for SAP Cloud for Customer.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar url: Required. The URL of SAP Cloud for Customer OData API. For example,
     '[https://[tenantname].crm.ondemand.com/sap/c4c/odata/v1]'. Type: string (or Expression with
     resultType string).
    :vartype url: any
    :ivar username: The username for Basic authentication. Type: string (or Expression with
     resultType string).
    :vartype username: any
    :ivar password: The password for Basic authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Either encryptedCredential or
     username/password must be provided. Type: string (or Expression with resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'url': {'key': 'typeProperties.url', 'type': 'object'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        url: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword url: Required. The URL of SAP Cloud for Customer OData API. For example,
         '[https://[tenantname].crm.ondemand.com/sap/c4c/odata/v1]'. Type: string (or Expression with
         resultType string).
        :paramtype url: any
        :keyword username: The username for Basic authentication. Type: string (or Expression with
         resultType string).
        :paramtype username: any
        :keyword password: The password for Basic authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Either encryptedCredential or
         username/password must be provided. Type: string (or Expression with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SapCloudForCustomerLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SapCloudForCustomer'  # type: str
        self.url = url
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapCloudForCustomerResourceDataset(Dataset):
    """The path of the SAP Cloud for Customer OData entity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar path: Required. The path of the SAP Cloud for Customer OData entity. Type: string (or
     Expression with resultType string).
    :vartype path: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'path': {'key': 'typeProperties.path', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        path: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword path: Required. The path of the SAP Cloud for Customer OData entity. Type: string (or
         Expression with resultType string).
        :paramtype path: any
        """
        super(SapCloudForCustomerResourceDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SapCloudForCustomerResource'  # type: str
        self.path = path


class SapCloudForCustomerSink(CopySink):
    """A copy activity SAP Cloud for Customer sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar write_behavior: The write behavior for the operation. Default is 'Insert'. Possible
     values include: "Insert", "Update".
    :vartype write_behavior: str or
     ~azure.mgmt.datafactory.models.SapCloudForCustomerSinkWriteBehavior
    :ivar http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the timeout
     to get a response, not the timeout to read response data. Default value: 00:05:00. Type: string
     (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype http_request_timeout: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'str'},
        'http_request_timeout': {'key': 'httpRequestTimeout', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        write_behavior: Optional[Union[str, "SapCloudForCustomerSinkWriteBehavior"]] = None,
        http_request_timeout: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword write_behavior: The write behavior for the operation. Default is 'Insert'. Possible
         values include: "Insert", "Update".
        :paramtype write_behavior: str or
         ~azure.mgmt.datafactory.models.SapCloudForCustomerSinkWriteBehavior
        :keyword http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the
         timeout to get a response, not the timeout to read response data. Default value: 00:05:00.
         Type: string (or Expression with resultType string), pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype http_request_timeout: any
        """
        super(SapCloudForCustomerSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'SapCloudForCustomerSink'  # type: str
        self.write_behavior = write_behavior
        self.http_request_timeout = http_request_timeout


class SapCloudForCustomerSource(TabularSource):
    """A copy activity source for SAP Cloud for Customer source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: SAP Cloud for Customer OData query. For example, "$top=1". Type: string (or
     Expression with resultType string).
    :vartype query: any
    :ivar http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the timeout
     to get a response, not the timeout to read response data. Default value: 00:05:00. Type: string
     (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype http_request_timeout: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'http_request_timeout': {'key': 'httpRequestTimeout', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        http_request_timeout: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: SAP Cloud for Customer OData query. For example, "$top=1". Type: string (or
         Expression with resultType string).
        :paramtype query: any
        :keyword http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the
         timeout to get a response, not the timeout to read response data. Default value: 00:05:00.
         Type: string (or Expression with resultType string), pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype http_request_timeout: any
        """
        super(SapCloudForCustomerSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SapCloudForCustomerSource'  # type: str
        self.query = query
        self.http_request_timeout = http_request_timeout


class SapEccLinkedService(LinkedService):
    """Linked service for SAP ERP Central Component(SAP ECC).

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar url: Required. The URL of SAP ECC OData API. For example,
     '[https://hostname:port/sap/opu/odata/sap/servicename/]'. Type: string (or Expression with
     resultType string).
    :vartype url: str
    :ivar username: The username for Basic authentication. Type: string (or Expression with
     resultType string).
    :vartype username: str
    :ivar password: The password for Basic authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Either encryptedCredential or
     username/password must be provided. Type: string (or Expression with resultType string).
    :vartype encrypted_credential: str
    """

    _validation = {
        'type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'url': {'key': 'typeProperties.url', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'str'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        url: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        username: Optional[str] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword url: Required. The URL of SAP ECC OData API. For example,
         '[https://hostname:port/sap/opu/odata/sap/servicename/]'. Type: string (or Expression with
         resultType string).
        :paramtype url: str
        :keyword username: The username for Basic authentication. Type: string (or Expression with
         resultType string).
        :paramtype username: str
        :keyword password: The password for Basic authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Either encryptedCredential or
         username/password must be provided. Type: string (or Expression with resultType string).
        :paramtype encrypted_credential: str
        """
        super(SapEccLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SapEcc'  # type: str
        self.url = url
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapEccResourceDataset(Dataset):
    """The path of the SAP ECC OData entity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar path: Required. The path of the SAP ECC OData entity. Type: string (or Expression with
     resultType string).
    :vartype path: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'path': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'path': {'key': 'typeProperties.path', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        path: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword path: Required. The path of the SAP ECC OData entity. Type: string (or Expression with
         resultType string).
        :paramtype path: any
        """
        super(SapEccResourceDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SapEccResource'  # type: str
        self.path = path


class SapEccSource(TabularSource):
    """A copy activity source for SAP ECC source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: SAP ECC OData query. For example, "$top=1". Type: string (or Expression with
     resultType string).
    :vartype query: any
    :ivar http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the timeout
     to get a response, not the timeout to read response data. Default value: 00:05:00. Type: string
     (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype http_request_timeout: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'http_request_timeout': {'key': 'httpRequestTimeout', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        http_request_timeout: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: SAP ECC OData query. For example, "$top=1". Type: string (or Expression with
         resultType string).
        :paramtype query: any
        :keyword http_request_timeout: The timeout (TimeSpan) to get an HTTP response. It is the
         timeout to get a response, not the timeout to read response data. Default value: 00:05:00.
         Type: string (or Expression with resultType string), pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype http_request_timeout: any
        """
        super(SapEccSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SapEccSource'  # type: str
        self.query = query
        self.http_request_timeout = http_request_timeout


class SapHanaLinkedService(LinkedService):
    """SAP HANA Linked Service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: SAP HANA ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar server: Host name of the SAP HANA server. Type: string (or Expression with resultType
     string).
    :vartype server: any
    :ivar authentication_type: The authentication type to be used to connect to the SAP HANA
     server. Possible values include: "Basic", "Windows".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.SapHanaAuthenticationType
    :ivar user_name: Username to access the SAP HANA server. Type: string (or Expression with
     resultType string).
    :vartype user_name: any
    :ivar password: Password to access the SAP HANA server.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'server': {'key': 'typeProperties.server', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        server: Optional[Any] = None,
        authentication_type: Optional[Union[str, "SapHanaAuthenticationType"]] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: SAP HANA ODBC connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword server: Host name of the SAP HANA server. Type: string (or Expression with resultType
         string).
        :paramtype server: any
        :keyword authentication_type: The authentication type to be used to connect to the SAP HANA
         server. Possible values include: "Basic", "Windows".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.SapHanaAuthenticationType
        :keyword user_name: Username to access the SAP HANA server. Type: string (or Expression with
         resultType string).
        :paramtype user_name: any
        :keyword password: Password to access the SAP HANA server.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SapHanaLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SapHana'  # type: str
        self.connection_string = connection_string
        self.server = server
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential


class SapHanaPartitionSettings(msrest.serialization.Model):
    """The settings that will be leveraged for SAP HANA source partitioning.

    :ivar partition_column_name: The name of the column that will be used for proceeding range
     partitioning. Type: string (or Expression with resultType string).
    :vartype partition_column_name: any
    """

    _attribute_map = {
        'partition_column_name': {'key': 'partitionColumnName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        partition_column_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword partition_column_name: The name of the column that will be used for proceeding range
         partitioning. Type: string (or Expression with resultType string).
        :paramtype partition_column_name: any
        """
        super(SapHanaPartitionSettings, self).__init__(**kwargs)
        self.partition_column_name = partition_column_name


class SapHanaSource(TabularSource):
    """A copy activity source for SAP HANA source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: SAP HANA Sql query. Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar packet_size: The packet size of data read from SAP HANA. Type: integer(or Expression with
     resultType integer).
    :vartype packet_size: any
    :ivar partition_option: The partition mechanism that will be used for SAP HANA read in
     parallel. Possible values include: "None", "PhysicalPartitionsOfTable", "SapHanaDynamicRange".
    :vartype partition_option: any
    :ivar partition_settings: The settings that will be leveraged for SAP HANA source partitioning.
    :vartype partition_settings: ~azure.mgmt.datafactory.models.SapHanaPartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'packet_size': {'key': 'packetSize', 'type': 'object'},
        'partition_option': {'key': 'partitionOption', 'type': 'object'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'SapHanaPartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        packet_size: Optional[Any] = None,
        partition_option: Optional[Any] = None,
        partition_settings: Optional["SapHanaPartitionSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: SAP HANA Sql query. Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword packet_size: The packet size of data read from SAP HANA. Type: integer(or Expression
         with resultType integer).
        :paramtype packet_size: any
        :keyword partition_option: The partition mechanism that will be used for SAP HANA read in
         parallel. Possible values include: "None", "PhysicalPartitionsOfTable", "SapHanaDynamicRange".
        :paramtype partition_option: any
        :keyword partition_settings: The settings that will be leveraged for SAP HANA source
         partitioning.
        :paramtype partition_settings: ~azure.mgmt.datafactory.models.SapHanaPartitionSettings
        """
        super(SapHanaSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SapHanaSource'  # type: str
        self.query = query
        self.packet_size = packet_size
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class SapHanaTableDataset(Dataset):
    """SAP HANA Table properties.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar schema_type_properties_schema: The schema name of SAP HANA. Type: string (or Expression
     with resultType string).
    :vartype schema_type_properties_schema: any
    :ivar table: The table name of SAP HANA. Type: string (or Expression with resultType string).
    :vartype table: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        schema_type_properties_schema: Optional[Any] = None,
        table: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword schema_type_properties_schema: The schema name of SAP HANA. Type: string (or
         Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        :keyword table: The table name of SAP HANA. Type: string (or Expression with resultType
         string).
        :paramtype table: any
        """
        super(SapHanaTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SapHanaTable'  # type: str
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class SapOpenHubLinkedService(LinkedService):
    """SAP Business Warehouse Open Hub Destination Linked Service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar server: Host name of the SAP BW instance where the open hub destination is located. Type:
     string (or Expression with resultType string).
    :vartype server: any
    :ivar system_number: System number of the BW system where the open hub destination is located.
     (Usually a two-digit decimal number represented as a string.) Type: string (or Expression with
     resultType string).
    :vartype system_number: any
    :ivar client_id: Client ID of the client on the BW system where the open hub destination is
     located. (Usually a three-digit decimal number represented as a string) Type: string (or
     Expression with resultType string).
    :vartype client_id: any
    :ivar language: Language of the BW system where the open hub destination is located. The
     default value is EN. Type: string (or Expression with resultType string).
    :vartype language: any
    :ivar system_id: SystemID of the SAP system where the table is located. Type: string (or
     Expression with resultType string).
    :vartype system_id: any
    :ivar user_name: Username to access the SAP BW server where the open hub destination is
     located. Type: string (or Expression with resultType string).
    :vartype user_name: any
    :ivar password: Password to access the SAP BW server where the open hub destination is located.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar message_server: The hostname of the SAP Message Server. Type: string (or Expression with
     resultType string).
    :vartype message_server: any
    :ivar message_server_service: The service name or port number of the Message Server. Type:
     string (or Expression with resultType string).
    :vartype message_server_service: any
    :ivar logon_group: The Logon Group for the SAP System. Type: string (or Expression with
     resultType string).
    :vartype logon_group: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'server': {'key': 'typeProperties.server', 'type': 'object'},
        'system_number': {'key': 'typeProperties.systemNumber', 'type': 'object'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'object'},
        'language': {'key': 'typeProperties.language', 'type': 'object'},
        'system_id': {'key': 'typeProperties.systemId', 'type': 'object'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'message_server': {'key': 'typeProperties.messageServer', 'type': 'object'},
        'message_server_service': {'key': 'typeProperties.messageServerService', 'type': 'object'},
        'logon_group': {'key': 'typeProperties.logonGroup', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        server: Optional[Any] = None,
        system_number: Optional[Any] = None,
        client_id: Optional[Any] = None,
        language: Optional[Any] = None,
        system_id: Optional[Any] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        message_server: Optional[Any] = None,
        message_server_service: Optional[Any] = None,
        logon_group: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword server: Host name of the SAP BW instance where the open hub destination is located.
         Type: string (or Expression with resultType string).
        :paramtype server: any
        :keyword system_number: System number of the BW system where the open hub destination is
         located. (Usually a two-digit decimal number represented as a string.) Type: string (or
         Expression with resultType string).
        :paramtype system_number: any
        :keyword client_id: Client ID of the client on the BW system where the open hub destination is
         located. (Usually a three-digit decimal number represented as a string) Type: string (or
         Expression with resultType string).
        :paramtype client_id: any
        :keyword language: Language of the BW system where the open hub destination is located. The
         default value is EN. Type: string (or Expression with resultType string).
        :paramtype language: any
        :keyword system_id: SystemID of the SAP system where the table is located. Type: string (or
         Expression with resultType string).
        :paramtype system_id: any
        :keyword user_name: Username to access the SAP BW server where the open hub destination is
         located. Type: string (or Expression with resultType string).
        :paramtype user_name: any
        :keyword password: Password to access the SAP BW server where the open hub destination is
         located.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword message_server: The hostname of the SAP Message Server. Type: string (or Expression
         with resultType string).
        :paramtype message_server: any
        :keyword message_server_service: The service name or port number of the Message Server. Type:
         string (or Expression with resultType string).
        :paramtype message_server_service: any
        :keyword logon_group: The Logon Group for the SAP System. Type: string (or Expression with
         resultType string).
        :paramtype logon_group: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SapOpenHubLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SapOpenHub'  # type: str
        self.server = server
        self.system_number = system_number
        self.client_id = client_id
        self.language = language
        self.system_id = system_id
        self.user_name = user_name
        self.password = password
        self.message_server = message_server
        self.message_server_service = message_server_service
        self.logon_group = logon_group
        self.encrypted_credential = encrypted_credential


class SapOpenHubSource(TabularSource):
    """A copy activity source for SAP Business Warehouse Open Hub Destination source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar exclude_last_request: Whether to exclude the records of the last request. The default
     value is true. Type: boolean (or Expression with resultType boolean).
    :vartype exclude_last_request: any
    :ivar base_request_id: The ID of request for delta loading. Once it is set, only data with
     requestId larger than the value of this property will be retrieved. The default value is 0.
     Type: integer (or Expression with resultType integer ).
    :vartype base_request_id: any
    :ivar custom_rfc_read_table_function_module: Specifies the custom RFC function module that will
     be used to read data from SAP Table. Type: string (or Expression with resultType string).
    :vartype custom_rfc_read_table_function_module: any
    :ivar sap_data_column_delimiter: The single character that will be used as delimiter passed to
     SAP RFC as well as splitting the output data retrieved. Type: string (or Expression with
     resultType string).
    :vartype sap_data_column_delimiter: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'exclude_last_request': {'key': 'excludeLastRequest', 'type': 'object'},
        'base_request_id': {'key': 'baseRequestId', 'type': 'object'},
        'custom_rfc_read_table_function_module': {'key': 'customRfcReadTableFunctionModule', 'type': 'object'},
        'sap_data_column_delimiter': {'key': 'sapDataColumnDelimiter', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        exclude_last_request: Optional[Any] = None,
        base_request_id: Optional[Any] = None,
        custom_rfc_read_table_function_module: Optional[Any] = None,
        sap_data_column_delimiter: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword exclude_last_request: Whether to exclude the records of the last request. The default
         value is true. Type: boolean (or Expression with resultType boolean).
        :paramtype exclude_last_request: any
        :keyword base_request_id: The ID of request for delta loading. Once it is set, only data with
         requestId larger than the value of this property will be retrieved. The default value is 0.
         Type: integer (or Expression with resultType integer ).
        :paramtype base_request_id: any
        :keyword custom_rfc_read_table_function_module: Specifies the custom RFC function module that
         will be used to read data from SAP Table. Type: string (or Expression with resultType string).
        :paramtype custom_rfc_read_table_function_module: any
        :keyword sap_data_column_delimiter: The single character that will be used as delimiter passed
         to SAP RFC as well as splitting the output data retrieved. Type: string (or Expression with
         resultType string).
        :paramtype sap_data_column_delimiter: any
        """
        super(SapOpenHubSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SapOpenHubSource'  # type: str
        self.exclude_last_request = exclude_last_request
        self.base_request_id = base_request_id
        self.custom_rfc_read_table_function_module = custom_rfc_read_table_function_module
        self.sap_data_column_delimiter = sap_data_column_delimiter


class SapOpenHubTableDataset(Dataset):
    """Sap Business Warehouse Open Hub Destination Table properties.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar open_hub_destination_name: Required. The name of the Open Hub Destination with
     destination type as Database Table. Type: string (or Expression with resultType string).
    :vartype open_hub_destination_name: any
    :ivar exclude_last_request: Whether to exclude the records of the last request. The default
     value is true. Type: boolean (or Expression with resultType boolean).
    :vartype exclude_last_request: any
    :ivar base_request_id: The ID of request for delta loading. Once it is set, only data with
     requestId larger than the value of this property will be retrieved. The default value is 0.
     Type: integer (or Expression with resultType integer ).
    :vartype base_request_id: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'open_hub_destination_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'open_hub_destination_name': {'key': 'typeProperties.openHubDestinationName', 'type': 'object'},
        'exclude_last_request': {'key': 'typeProperties.excludeLastRequest', 'type': 'object'},
        'base_request_id': {'key': 'typeProperties.baseRequestId', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        open_hub_destination_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        exclude_last_request: Optional[Any] = None,
        base_request_id: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword open_hub_destination_name: Required. The name of the Open Hub Destination with
         destination type as Database Table. Type: string (or Expression with resultType string).
        :paramtype open_hub_destination_name: any
        :keyword exclude_last_request: Whether to exclude the records of the last request. The default
         value is true. Type: boolean (or Expression with resultType boolean).
        :paramtype exclude_last_request: any
        :keyword base_request_id: The ID of request for delta loading. Once it is set, only data with
         requestId larger than the value of this property will be retrieved. The default value is 0.
         Type: integer (or Expression with resultType integer ).
        :paramtype base_request_id: any
        """
        super(SapOpenHubTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SapOpenHubTable'  # type: str
        self.open_hub_destination_name = open_hub_destination_name
        self.exclude_last_request = exclude_last_request
        self.base_request_id = base_request_id


class SapTableLinkedService(LinkedService):
    """SAP Table Linked Service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar server: Host name of the SAP instance where the table is located. Type: string (or
     Expression with resultType string).
    :vartype server: any
    :ivar system_number: System number of the SAP system where the table is located. (Usually a
     two-digit decimal number represented as a string.) Type: string (or Expression with resultType
     string).
    :vartype system_number: any
    :ivar client_id: Client ID of the client on the SAP system where the table is located. (Usually
     a three-digit decimal number represented as a string) Type: string (or Expression with
     resultType string).
    :vartype client_id: any
    :ivar language: Language of the SAP system where the table is located. The default value is EN.
     Type: string (or Expression with resultType string).
    :vartype language: any
    :ivar system_id: SystemID of the SAP system where the table is located. Type: string (or
     Expression with resultType string).
    :vartype system_id: any
    :ivar user_name: Username to access the SAP server where the table is located. Type: string (or
     Expression with resultType string).
    :vartype user_name: any
    :ivar password: Password to access the SAP server where the table is located.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar message_server: The hostname of the SAP Message Server. Type: string (or Expression with
     resultType string).
    :vartype message_server: any
    :ivar message_server_service: The service name or port number of the Message Server. Type:
     string (or Expression with resultType string).
    :vartype message_server_service: any
    :ivar snc_mode: SNC activation indicator to access the SAP server where the table is located.
     Must be either 0 (off) or 1 (on). Type: string (or Expression with resultType string).
    :vartype snc_mode: any
    :ivar snc_my_name: Initiator's SNC name to access the SAP server where the table is located.
     Type: string (or Expression with resultType string).
    :vartype snc_my_name: any
    :ivar snc_partner_name: Communication partner's SNC name to access the SAP server where the
     table is located. Type: string (or Expression with resultType string).
    :vartype snc_partner_name: any
    :ivar snc_library_path: External security product's library to access the SAP server where the
     table is located. Type: string (or Expression with resultType string).
    :vartype snc_library_path: any
    :ivar snc_qop: SNC Quality of Protection. Allowed value include: 1, 2, 3, 8, 9. Type: string
     (or Expression with resultType string).
    :vartype snc_qop: any
    :ivar logon_group: The Logon Group for the SAP System. Type: string (or Expression with
     resultType string).
    :vartype logon_group: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'server': {'key': 'typeProperties.server', 'type': 'object'},
        'system_number': {'key': 'typeProperties.systemNumber', 'type': 'object'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'object'},
        'language': {'key': 'typeProperties.language', 'type': 'object'},
        'system_id': {'key': 'typeProperties.systemId', 'type': 'object'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'message_server': {'key': 'typeProperties.messageServer', 'type': 'object'},
        'message_server_service': {'key': 'typeProperties.messageServerService', 'type': 'object'},
        'snc_mode': {'key': 'typeProperties.sncMode', 'type': 'object'},
        'snc_my_name': {'key': 'typeProperties.sncMyName', 'type': 'object'},
        'snc_partner_name': {'key': 'typeProperties.sncPartnerName', 'type': 'object'},
        'snc_library_path': {'key': 'typeProperties.sncLibraryPath', 'type': 'object'},
        'snc_qop': {'key': 'typeProperties.sncQop', 'type': 'object'},
        'logon_group': {'key': 'typeProperties.logonGroup', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        server: Optional[Any] = None,
        system_number: Optional[Any] = None,
        client_id: Optional[Any] = None,
        language: Optional[Any] = None,
        system_id: Optional[Any] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        message_server: Optional[Any] = None,
        message_server_service: Optional[Any] = None,
        snc_mode: Optional[Any] = None,
        snc_my_name: Optional[Any] = None,
        snc_partner_name: Optional[Any] = None,
        snc_library_path: Optional[Any] = None,
        snc_qop: Optional[Any] = None,
        logon_group: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword server: Host name of the SAP instance where the table is located. Type: string (or
         Expression with resultType string).
        :paramtype server: any
        :keyword system_number: System number of the SAP system where the table is located. (Usually a
         two-digit decimal number represented as a string.) Type: string (or Expression with resultType
         string).
        :paramtype system_number: any
        :keyword client_id: Client ID of the client on the SAP system where the table is located.
         (Usually a three-digit decimal number represented as a string) Type: string (or Expression with
         resultType string).
        :paramtype client_id: any
        :keyword language: Language of the SAP system where the table is located. The default value is
         EN. Type: string (or Expression with resultType string).
        :paramtype language: any
        :keyword system_id: SystemID of the SAP system where the table is located. Type: string (or
         Expression with resultType string).
        :paramtype system_id: any
        :keyword user_name: Username to access the SAP server where the table is located. Type: string
         (or Expression with resultType string).
        :paramtype user_name: any
        :keyword password: Password to access the SAP server where the table is located.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword message_server: The hostname of the SAP Message Server. Type: string (or Expression
         with resultType string).
        :paramtype message_server: any
        :keyword message_server_service: The service name or port number of the Message Server. Type:
         string (or Expression with resultType string).
        :paramtype message_server_service: any
        :keyword snc_mode: SNC activation indicator to access the SAP server where the table is
         located. Must be either 0 (off) or 1 (on). Type: string (or Expression with resultType string).
        :paramtype snc_mode: any
        :keyword snc_my_name: Initiator's SNC name to access the SAP server where the table is located.
         Type: string (or Expression with resultType string).
        :paramtype snc_my_name: any
        :keyword snc_partner_name: Communication partner's SNC name to access the SAP server where the
         table is located. Type: string (or Expression with resultType string).
        :paramtype snc_partner_name: any
        :keyword snc_library_path: External security product's library to access the SAP server where
         the table is located. Type: string (or Expression with resultType string).
        :paramtype snc_library_path: any
        :keyword snc_qop: SNC Quality of Protection. Allowed value include: 1, 2, 3, 8, 9. Type: string
         (or Expression with resultType string).
        :paramtype snc_qop: any
        :keyword logon_group: The Logon Group for the SAP System. Type: string (or Expression with
         resultType string).
        :paramtype logon_group: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SapTableLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SapTable'  # type: str
        self.server = server
        self.system_number = system_number
        self.client_id = client_id
        self.language = language
        self.system_id = system_id
        self.user_name = user_name
        self.password = password
        self.message_server = message_server
        self.message_server_service = message_server_service
        self.snc_mode = snc_mode
        self.snc_my_name = snc_my_name
        self.snc_partner_name = snc_partner_name
        self.snc_library_path = snc_library_path
        self.snc_qop = snc_qop
        self.logon_group = logon_group
        self.encrypted_credential = encrypted_credential


class SapTablePartitionSettings(msrest.serialization.Model):
    """The settings that will be leveraged for SAP table source partitioning.

    :ivar partition_column_name: The name of the column that will be used for proceeding range
     partitioning. Type: string (or Expression with resultType string).
    :vartype partition_column_name: any
    :ivar partition_upper_bound: The maximum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :vartype partition_upper_bound: any
    :ivar partition_lower_bound: The minimum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :vartype partition_lower_bound: any
    :ivar max_partitions_number: The maximum value of partitions the table will be split into.
     Type: integer (or Expression with resultType string).
    :vartype max_partitions_number: any
    """

    _attribute_map = {
        'partition_column_name': {'key': 'partitionColumnName', 'type': 'object'},
        'partition_upper_bound': {'key': 'partitionUpperBound', 'type': 'object'},
        'partition_lower_bound': {'key': 'partitionLowerBound', 'type': 'object'},
        'max_partitions_number': {'key': 'maxPartitionsNumber', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        partition_column_name: Optional[Any] = None,
        partition_upper_bound: Optional[Any] = None,
        partition_lower_bound: Optional[Any] = None,
        max_partitions_number: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword partition_column_name: The name of the column that will be used for proceeding range
         partitioning. Type: string (or Expression with resultType string).
        :paramtype partition_column_name: any
        :keyword partition_upper_bound: The maximum value of column specified in partitionColumnName
         that will be used for proceeding range partitioning. Type: string (or Expression with
         resultType string).
        :paramtype partition_upper_bound: any
        :keyword partition_lower_bound: The minimum value of column specified in partitionColumnName
         that will be used for proceeding range partitioning. Type: string (or Expression with
         resultType string).
        :paramtype partition_lower_bound: any
        :keyword max_partitions_number: The maximum value of partitions the table will be split into.
         Type: integer (or Expression with resultType string).
        :paramtype max_partitions_number: any
        """
        super(SapTablePartitionSettings, self).__init__(**kwargs)
        self.partition_column_name = partition_column_name
        self.partition_upper_bound = partition_upper_bound
        self.partition_lower_bound = partition_lower_bound
        self.max_partitions_number = max_partitions_number


class SapTableResourceDataset(Dataset):
    """SAP Table Resource properties.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: Required. The name of the SAP Table. Type: string (or Expression with
     resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'table_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        table_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: Required. The name of the SAP Table. Type: string (or Expression with
         resultType string).
        :paramtype table_name: any
        """
        super(SapTableResourceDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SapTableResource'  # type: str
        self.table_name = table_name


class SapTableSource(TabularSource):
    """A copy activity source for SAP Table source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar row_count: The number of rows to be retrieved. Type: integer(or Expression with
     resultType integer).
    :vartype row_count: any
    :ivar row_skips: The number of rows that will be skipped. Type: integer (or Expression with
     resultType integer).
    :vartype row_skips: any
    :ivar rfc_table_fields: The fields of the SAP table that will be retrieved. For example,
     column0, column1. Type: string (or Expression with resultType string).
    :vartype rfc_table_fields: any
    :ivar rfc_table_options: The options for the filtering of the SAP Table. For example, COLUMN0
     EQ SOME VALUE. Type: string (or Expression with resultType string).
    :vartype rfc_table_options: any
    :ivar batch_size: Specifies the maximum number of rows that will be retrieved at a time when
     retrieving data from SAP Table. Type: integer (or Expression with resultType integer).
    :vartype batch_size: any
    :ivar custom_rfc_read_table_function_module: Specifies the custom RFC function module that will
     be used to read data from SAP Table. Type: string (or Expression with resultType string).
    :vartype custom_rfc_read_table_function_module: any
    :ivar sap_data_column_delimiter: The single character that will be used as delimiter passed to
     SAP RFC as well as splitting the output data retrieved. Type: string (or Expression with
     resultType string).
    :vartype sap_data_column_delimiter: any
    :ivar partition_option: The partition mechanism that will be used for SAP table read in
     parallel. Possible values include: "None", "PartitionOnInt", "PartitionOnCalendarYear",
     "PartitionOnCalendarMonth", "PartitionOnCalendarDate", "PartitionOnTime".
    :vartype partition_option: any
    :ivar partition_settings: The settings that will be leveraged for SAP table source
     partitioning.
    :vartype partition_settings: ~azure.mgmt.datafactory.models.SapTablePartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'row_count': {'key': 'rowCount', 'type': 'object'},
        'row_skips': {'key': 'rowSkips', 'type': 'object'},
        'rfc_table_fields': {'key': 'rfcTableFields', 'type': 'object'},
        'rfc_table_options': {'key': 'rfcTableOptions', 'type': 'object'},
        'batch_size': {'key': 'batchSize', 'type': 'object'},
        'custom_rfc_read_table_function_module': {'key': 'customRfcReadTableFunctionModule', 'type': 'object'},
        'sap_data_column_delimiter': {'key': 'sapDataColumnDelimiter', 'type': 'object'},
        'partition_option': {'key': 'partitionOption', 'type': 'object'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'SapTablePartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        row_count: Optional[Any] = None,
        row_skips: Optional[Any] = None,
        rfc_table_fields: Optional[Any] = None,
        rfc_table_options: Optional[Any] = None,
        batch_size: Optional[Any] = None,
        custom_rfc_read_table_function_module: Optional[Any] = None,
        sap_data_column_delimiter: Optional[Any] = None,
        partition_option: Optional[Any] = None,
        partition_settings: Optional["SapTablePartitionSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword row_count: The number of rows to be retrieved. Type: integer(or Expression with
         resultType integer).
        :paramtype row_count: any
        :keyword row_skips: The number of rows that will be skipped. Type: integer (or Expression with
         resultType integer).
        :paramtype row_skips: any
        :keyword rfc_table_fields: The fields of the SAP table that will be retrieved. For example,
         column0, column1. Type: string (or Expression with resultType string).
        :paramtype rfc_table_fields: any
        :keyword rfc_table_options: The options for the filtering of the SAP Table. For example,
         COLUMN0 EQ SOME VALUE. Type: string (or Expression with resultType string).
        :paramtype rfc_table_options: any
        :keyword batch_size: Specifies the maximum number of rows that will be retrieved at a time when
         retrieving data from SAP Table. Type: integer (or Expression with resultType integer).
        :paramtype batch_size: any
        :keyword custom_rfc_read_table_function_module: Specifies the custom RFC function module that
         will be used to read data from SAP Table. Type: string (or Expression with resultType string).
        :paramtype custom_rfc_read_table_function_module: any
        :keyword sap_data_column_delimiter: The single character that will be used as delimiter passed
         to SAP RFC as well as splitting the output data retrieved. Type: string (or Expression with
         resultType string).
        :paramtype sap_data_column_delimiter: any
        :keyword partition_option: The partition mechanism that will be used for SAP table read in
         parallel. Possible values include: "None", "PartitionOnInt", "PartitionOnCalendarYear",
         "PartitionOnCalendarMonth", "PartitionOnCalendarDate", "PartitionOnTime".
        :paramtype partition_option: any
        :keyword partition_settings: The settings that will be leveraged for SAP table source
         partitioning.
        :paramtype partition_settings: ~azure.mgmt.datafactory.models.SapTablePartitionSettings
        """
        super(SapTableSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SapTableSource'  # type: str
        self.row_count = row_count
        self.row_skips = row_skips
        self.rfc_table_fields = rfc_table_fields
        self.rfc_table_options = rfc_table_options
        self.batch_size = batch_size
        self.custom_rfc_read_table_function_module = custom_rfc_read_table_function_module
        self.sap_data_column_delimiter = sap_data_column_delimiter
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class ScheduleTrigger(MultiplePipelineTrigger):
    """Trigger that creates pipeline runs periodically, on schedule.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Trigger type.Constant filled by server.
    :vartype type: str
    :ivar description: Trigger description.
    :vartype description: str
    :ivar runtime_state: Indicates if trigger is running or not. Updated when Start/Stop APIs are
     called on the Trigger. Possible values include: "Started", "Stopped", "Disabled".
    :vartype runtime_state: str or ~azure.mgmt.datafactory.models.TriggerRuntimeState
    :ivar annotations: List of tags that can be used for describing the trigger.
    :vartype annotations: list[any]
    :ivar pipelines: Pipelines that need to be started.
    :vartype pipelines: list[~azure.mgmt.datafactory.models.TriggerPipelineReference]
    :ivar recurrence: Required. Recurrence schedule configuration.
    :vartype recurrence: ~azure.mgmt.datafactory.models.ScheduleTriggerRecurrence
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
        'recurrence': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'pipelines': {'key': 'pipelines', 'type': '[TriggerPipelineReference]'},
        'recurrence': {'key': 'typeProperties.recurrence', 'type': 'ScheduleTriggerRecurrence'},
    }

    def __init__(
        self,
        *,
        recurrence: "ScheduleTriggerRecurrence",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        pipelines: Optional[List["TriggerPipelineReference"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Trigger description.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the trigger.
        :paramtype annotations: list[any]
        :keyword pipelines: Pipelines that need to be started.
        :paramtype pipelines: list[~azure.mgmt.datafactory.models.TriggerPipelineReference]
        :keyword recurrence: Required. Recurrence schedule configuration.
        :paramtype recurrence: ~azure.mgmt.datafactory.models.ScheduleTriggerRecurrence
        """
        super(ScheduleTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, pipelines=pipelines, **kwargs)
        self.type = 'ScheduleTrigger'  # type: str
        self.recurrence = recurrence


class ScheduleTriggerRecurrence(msrest.serialization.Model):
    """The workflow trigger recurrence.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar frequency: The frequency. Possible values include: "NotSpecified", "Minute", "Hour",
     "Day", "Week", "Month", "Year".
    :vartype frequency: str or ~azure.mgmt.datafactory.models.RecurrenceFrequency
    :ivar interval: The interval.
    :vartype interval: int
    :ivar start_time: The start time.
    :vartype start_time: ~datetime.datetime
    :ivar end_time: The end time.
    :vartype end_time: ~datetime.datetime
    :ivar time_zone: The time zone.
    :vartype time_zone: str
    :ivar schedule: The recurrence schedule.
    :vartype schedule: ~azure.mgmt.datafactory.models.RecurrenceSchedule
    """

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'frequency': {'key': 'frequency', 'type': 'str'},
        'interval': {'key': 'interval', 'type': 'int'},
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'endTime', 'type': 'iso-8601'},
        'time_zone': {'key': 'timeZone', 'type': 'str'},
        'schedule': {'key': 'schedule', 'type': 'RecurrenceSchedule'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        frequency: Optional[Union[str, "RecurrenceFrequency"]] = None,
        interval: Optional[int] = None,
        start_time: Optional[datetime.datetime] = None,
        end_time: Optional[datetime.datetime] = None,
        time_zone: Optional[str] = None,
        schedule: Optional["RecurrenceSchedule"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword frequency: The frequency. Possible values include: "NotSpecified", "Minute", "Hour",
         "Day", "Week", "Month", "Year".
        :paramtype frequency: str or ~azure.mgmt.datafactory.models.RecurrenceFrequency
        :keyword interval: The interval.
        :paramtype interval: int
        :keyword start_time: The start time.
        :paramtype start_time: ~datetime.datetime
        :keyword end_time: The end time.
        :paramtype end_time: ~datetime.datetime
        :keyword time_zone: The time zone.
        :paramtype time_zone: str
        :keyword schedule: The recurrence schedule.
        :paramtype schedule: ~azure.mgmt.datafactory.models.RecurrenceSchedule
        """
        super(ScheduleTriggerRecurrence, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.frequency = frequency
        self.interval = interval
        self.start_time = start_time
        self.end_time = end_time
        self.time_zone = time_zone
        self.schedule = schedule


class ScriptAction(msrest.serialization.Model):
    """Custom script action to run on HDI ondemand cluster once it's up.

    All required parameters must be populated in order to send to Azure.

    :ivar name: Required. The user provided name of the script action.
    :vartype name: str
    :ivar uri: Required. The URI for the script action.
    :vartype uri: str
    :ivar roles: Required. The node types on which the script action should be executed.
    :vartype roles: any
    :ivar parameters: The parameters for the script action.
    :vartype parameters: str
    """

    _validation = {
        'name': {'required': True},
        'uri': {'required': True},
        'roles': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'uri': {'key': 'uri', 'type': 'str'},
        'roles': {'key': 'roles', 'type': 'object'},
        'parameters': {'key': 'parameters', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        name: str,
        uri: str,
        roles: Any,
        parameters: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword name: Required. The user provided name of the script action.
        :paramtype name: str
        :keyword uri: Required. The URI for the script action.
        :paramtype uri: str
        :keyword roles: Required. The node types on which the script action should be executed.
        :paramtype roles: any
        :keyword parameters: The parameters for the script action.
        :paramtype parameters: str
        """
        super(ScriptAction, self).__init__(**kwargs)
        self.name = name
        self.uri = uri
        self.roles = roles
        self.parameters = parameters


class ScriptActivity(ExecutionActivity):
    """Script activity type.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar scripts: Array of script blocks. Type: array.
    :vartype scripts: list[~azure.mgmt.datafactory.models.ScriptActivityScriptBlock]
    :ivar log_settings: Log settings of script activity.
    :vartype log_settings: ~azure.mgmt.datafactory.models.ScriptActivityTypePropertiesLogSettings
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'scripts': {'key': 'typeProperties.scripts', 'type': '[ScriptActivityScriptBlock]'},
        'log_settings': {'key': 'typeProperties.logSettings', 'type': 'ScriptActivityTypePropertiesLogSettings'},
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        scripts: Optional[List["ScriptActivityScriptBlock"]] = None,
        log_settings: Optional["ScriptActivityTypePropertiesLogSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword scripts: Array of script blocks. Type: array.
        :paramtype scripts: list[~azure.mgmt.datafactory.models.ScriptActivityScriptBlock]
        :keyword log_settings: Log settings of script activity.
        :paramtype log_settings: ~azure.mgmt.datafactory.models.ScriptActivityTypePropertiesLogSettings
        """
        super(ScriptActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'Script'  # type: str
        self.scripts = scripts
        self.log_settings = log_settings


class ScriptActivityParameter(msrest.serialization.Model):
    """Parameters of a script block.

    :ivar name: The name of the parameter. Type: string (or Expression with resultType string).
    :vartype name: any
    :ivar type: The type of the parameter. Possible values include: "Boolean", "DateTime",
     "DateTimeOffset", "Decimal", "Double", "Guid", "Int16", "Int32", "Int64", "Single", "String",
     "Timespan".
    :vartype type: str or ~azure.mgmt.datafactory.models.ScriptActivityParameterType
    :ivar value: The value of the parameter.
    :vartype value: any
    :ivar direction: The direction of the parameter. Possible values include: "Input", "Output",
     "InputOutput".
    :vartype direction: str or ~azure.mgmt.datafactory.models.ScriptActivityParameterDirection
    :ivar size: The size of the output direction parameter.
    :vartype size: int
    """

    _attribute_map = {
        'name': {'key': 'name', 'type': 'object'},
        'type': {'key': 'type', 'type': 'str'},
        'value': {'key': 'value', 'type': 'object'},
        'direction': {'key': 'direction', 'type': 'str'},
        'size': {'key': 'size', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        name: Optional[Any] = None,
        type: Optional[Union[str, "ScriptActivityParameterType"]] = None,
        value: Optional[Any] = None,
        direction: Optional[Union[str, "ScriptActivityParameterDirection"]] = None,
        size: Optional[int] = None,
        **kwargs
    ):
        """
        :keyword name: The name of the parameter. Type: string (or Expression with resultType string).
        :paramtype name: any
        :keyword type: The type of the parameter. Possible values include: "Boolean", "DateTime",
         "DateTimeOffset", "Decimal", "Double", "Guid", "Int16", "Int32", "Int64", "Single", "String",
         "Timespan".
        :paramtype type: str or ~azure.mgmt.datafactory.models.ScriptActivityParameterType
        :keyword value: The value of the parameter.
        :paramtype value: any
        :keyword direction: The direction of the parameter. Possible values include: "Input", "Output",
         "InputOutput".
        :paramtype direction: str or ~azure.mgmt.datafactory.models.ScriptActivityParameterDirection
        :keyword size: The size of the output direction parameter.
        :paramtype size: int
        """
        super(ScriptActivityParameter, self).__init__(**kwargs)
        self.name = name
        self.type = type
        self.value = value
        self.direction = direction
        self.size = size


class ScriptActivityScriptBlock(msrest.serialization.Model):
    """Script block of scripts.

    All required parameters must be populated in order to send to Azure.

    :ivar text: Required. The query text. Type: string (or Expression with resultType string).
    :vartype text: any
    :ivar type: Required. The type of the query. Type: string. Possible values include: "Query",
     "NonQuery".
    :vartype type: str or ~azure.mgmt.datafactory.models.ScriptType
    :ivar parameters: Array of script parameters. Type: array.
    :vartype parameters: list[~azure.mgmt.datafactory.models.ScriptActivityParameter]
    """

    _validation = {
        'text': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'text': {'key': 'text', 'type': 'object'},
        'type': {'key': 'type', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '[ScriptActivityParameter]'},
    }

    def __init__(
        self,
        *,
        text: Any,
        type: Union[str, "ScriptType"],
        parameters: Optional[List["ScriptActivityParameter"]] = None,
        **kwargs
    ):
        """
        :keyword text: Required. The query text. Type: string (or Expression with resultType string).
        :paramtype text: any
        :keyword type: Required. The type of the query. Type: string. Possible values include: "Query",
         "NonQuery".
        :paramtype type: str or ~azure.mgmt.datafactory.models.ScriptType
        :keyword parameters: Array of script parameters. Type: array.
        :paramtype parameters: list[~azure.mgmt.datafactory.models.ScriptActivityParameter]
        """
        super(ScriptActivityScriptBlock, self).__init__(**kwargs)
        self.text = text
        self.type = type
        self.parameters = parameters


class ScriptActivityTypePropertiesLogSettings(msrest.serialization.Model):
    """Log settings of script activity.

    All required parameters must be populated in order to send to Azure.

    :ivar log_destination: Required. The destination of logs. Type: string. Possible values
     include: "ActivityOutput", "ExternalStore".
    :vartype log_destination: str or ~azure.mgmt.datafactory.models.ScriptActivityLogDestination
    :ivar log_location_settings: Log location settings customer needs to provide when enabling log.
    :vartype log_location_settings: ~azure.mgmt.datafactory.models.LogLocationSettings
    """

    _validation = {
        'log_destination': {'required': True},
    }

    _attribute_map = {
        'log_destination': {'key': 'logDestination', 'type': 'str'},
        'log_location_settings': {'key': 'logLocationSettings', 'type': 'LogLocationSettings'},
    }

    def __init__(
        self,
        *,
        log_destination: Union[str, "ScriptActivityLogDestination"],
        log_location_settings: Optional["LogLocationSettings"] = None,
        **kwargs
    ):
        """
        :keyword log_destination: Required. The destination of logs. Type: string. Possible values
         include: "ActivityOutput", "ExternalStore".
        :paramtype log_destination: str or ~azure.mgmt.datafactory.models.ScriptActivityLogDestination
        :keyword log_location_settings: Log location settings customer needs to provide when enabling
         log.
        :paramtype log_location_settings: ~azure.mgmt.datafactory.models.LogLocationSettings
        """
        super(ScriptActivityTypePropertiesLogSettings, self).__init__(**kwargs)
        self.log_destination = log_destination
        self.log_location_settings = log_location_settings


class SecureString(SecretBase):
    """Azure Data Factory secure string definition. The string value will be masked with asterisks '*' during Get or List API calls.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of the secret.Constant filled by server.
    :vartype type: str
    :ivar value: Required. Value of secure string.
    :vartype value: str
    """

    _validation = {
        'type': {'required': True},
        'value': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'value': {'key': 'value', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: str,
        **kwargs
    ):
        """
        :keyword value: Required. Value of secure string.
        :paramtype value: str
        """
        super(SecureString, self).__init__(**kwargs)
        self.type = 'SecureString'  # type: str
        self.value = value


class SelfDependencyTumblingWindowTriggerReference(DependencyReference):
    """Self referenced tumbling window trigger dependency.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. The type of dependency reference.Constant filled by server.
    :vartype type: str
    :ivar offset: Required. Timespan applied to the start time of a tumbling window when evaluating
     dependency.
    :vartype offset: str
    :ivar size: The size of the window when evaluating the dependency. If undefined the frequency
     of the tumbling window will be used.
    :vartype size: str
    """

    _validation = {
        'type': {'required': True},
        'offset': {'required': True, 'max_length': 15, 'min_length': 8, 'pattern': r'-((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9]))'},
        'size': {'max_length': 15, 'min_length': 8, 'pattern': r'((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9]))'},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'offset': {'key': 'offset', 'type': 'str'},
        'size': {'key': 'size', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        offset: str,
        size: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword offset: Required. Timespan applied to the start time of a tumbling window when
         evaluating dependency.
        :paramtype offset: str
        :keyword size: The size of the window when evaluating the dependency. If undefined the
         frequency of the tumbling window will be used.
        :paramtype size: str
        """
        super(SelfDependencyTumblingWindowTriggerReference, self).__init__(**kwargs)
        self.type = 'SelfDependencyTumblingWindowTriggerReference'  # type: str
        self.offset = offset
        self.size = size


class SelfHostedIntegrationRuntime(IntegrationRuntime):
    """Self-hosted integration runtime.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of integration runtime.Constant filled by server. Possible values
     include: "Managed", "SelfHosted".
    :vartype type: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeType
    :ivar description: Integration runtime description.
    :vartype description: str
    :ivar linked_info: The base definition of a linked integration runtime.
    :vartype linked_info: ~azure.mgmt.datafactory.models.LinkedIntegrationRuntimeType
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'linked_info': {'key': 'typeProperties.linkedInfo', 'type': 'LinkedIntegrationRuntimeType'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        linked_info: Optional["LinkedIntegrationRuntimeType"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Integration runtime description.
        :paramtype description: str
        :keyword linked_info: The base definition of a linked integration runtime.
        :paramtype linked_info: ~azure.mgmt.datafactory.models.LinkedIntegrationRuntimeType
        """
        super(SelfHostedIntegrationRuntime, self).__init__(additional_properties=additional_properties, description=description, **kwargs)
        self.type = 'SelfHosted'  # type: str
        self.linked_info = linked_info


class SelfHostedIntegrationRuntimeNode(msrest.serialization.Model):
    """Properties of Self-hosted integration runtime node.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar node_name: Name of the integration runtime node.
    :vartype node_name: str
    :ivar machine_name: Machine name of the integration runtime node.
    :vartype machine_name: str
    :ivar host_service_uri: URI for the host machine of the integration runtime.
    :vartype host_service_uri: str
    :ivar status: Status of the integration runtime node. Possible values include:
     "NeedRegistration", "Online", "Limited", "Offline", "Upgrading", "Initializing",
     "InitializeFailed".
    :vartype status: str or ~azure.mgmt.datafactory.models.SelfHostedIntegrationRuntimeNodeStatus
    :ivar capabilities: The integration runtime capabilities dictionary.
    :vartype capabilities: dict[str, str]
    :ivar version_status: Status of the integration runtime node version.
    :vartype version_status: str
    :ivar version: Version of the integration runtime node.
    :vartype version: str
    :ivar register_time: The time at which the integration runtime node was registered in ISO8601
     format.
    :vartype register_time: ~datetime.datetime
    :ivar last_connect_time: The most recent time at which the integration runtime was connected in
     ISO8601 format.
    :vartype last_connect_time: ~datetime.datetime
    :ivar expiry_time: The time at which the integration runtime will expire in ISO8601 format.
    :vartype expiry_time: ~datetime.datetime
    :ivar last_start_time: The time the node last started up.
    :vartype last_start_time: ~datetime.datetime
    :ivar last_stop_time: The integration runtime node last stop time.
    :vartype last_stop_time: ~datetime.datetime
    :ivar last_update_result: The result of the last integration runtime node update. Possible
     values include: "None", "Succeed", "Fail".
    :vartype last_update_result: str or
     ~azure.mgmt.datafactory.models.IntegrationRuntimeUpdateResult
    :ivar last_start_update_time: The last time for the integration runtime node update start.
    :vartype last_start_update_time: ~datetime.datetime
    :ivar last_end_update_time: The last time for the integration runtime node update end.
    :vartype last_end_update_time: ~datetime.datetime
    :ivar is_active_dispatcher: Indicates whether this node is the active dispatcher for
     integration runtime requests.
    :vartype is_active_dispatcher: bool
    :ivar concurrent_jobs_limit: Maximum concurrent jobs on the integration runtime node.
    :vartype concurrent_jobs_limit: int
    :ivar max_concurrent_jobs: The maximum concurrent jobs in this integration runtime.
    :vartype max_concurrent_jobs: int
    """

    _validation = {
        'node_name': {'readonly': True},
        'machine_name': {'readonly': True},
        'host_service_uri': {'readonly': True},
        'status': {'readonly': True},
        'capabilities': {'readonly': True},
        'version_status': {'readonly': True},
        'version': {'readonly': True},
        'register_time': {'readonly': True},
        'last_connect_time': {'readonly': True},
        'expiry_time': {'readonly': True},
        'last_start_time': {'readonly': True},
        'last_stop_time': {'readonly': True},
        'last_update_result': {'readonly': True},
        'last_start_update_time': {'readonly': True},
        'last_end_update_time': {'readonly': True},
        'is_active_dispatcher': {'readonly': True},
        'concurrent_jobs_limit': {'readonly': True},
        'max_concurrent_jobs': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'node_name': {'key': 'nodeName', 'type': 'str'},
        'machine_name': {'key': 'machineName', 'type': 'str'},
        'host_service_uri': {'key': 'hostServiceUri', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'capabilities': {'key': 'capabilities', 'type': '{str}'},
        'version_status': {'key': 'versionStatus', 'type': 'str'},
        'version': {'key': 'version', 'type': 'str'},
        'register_time': {'key': 'registerTime', 'type': 'iso-8601'},
        'last_connect_time': {'key': 'lastConnectTime', 'type': 'iso-8601'},
        'expiry_time': {'key': 'expiryTime', 'type': 'iso-8601'},
        'last_start_time': {'key': 'lastStartTime', 'type': 'iso-8601'},
        'last_stop_time': {'key': 'lastStopTime', 'type': 'iso-8601'},
        'last_update_result': {'key': 'lastUpdateResult', 'type': 'str'},
        'last_start_update_time': {'key': 'lastStartUpdateTime', 'type': 'iso-8601'},
        'last_end_update_time': {'key': 'lastEndUpdateTime', 'type': 'iso-8601'},
        'is_active_dispatcher': {'key': 'isActiveDispatcher', 'type': 'bool'},
        'concurrent_jobs_limit': {'key': 'concurrentJobsLimit', 'type': 'int'},
        'max_concurrent_jobs': {'key': 'maxConcurrentJobs', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(SelfHostedIntegrationRuntimeNode, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.node_name = None
        self.machine_name = None
        self.host_service_uri = None
        self.status = None
        self.capabilities = None
        self.version_status = None
        self.version = None
        self.register_time = None
        self.last_connect_time = None
        self.expiry_time = None
        self.last_start_time = None
        self.last_stop_time = None
        self.last_update_result = None
        self.last_start_update_time = None
        self.last_end_update_time = None
        self.is_active_dispatcher = None
        self.concurrent_jobs_limit = None
        self.max_concurrent_jobs = None


class SelfHostedIntegrationRuntimeStatus(IntegrationRuntimeStatus):
    """Self-hosted integration runtime status.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of integration runtime.Constant filled by server. Possible values
     include: "Managed", "SelfHosted".
    :vartype type: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeType
    :ivar data_factory_name: The data factory name which the integration runtime belong to.
    :vartype data_factory_name: str
    :ivar state: The state of integration runtime. Possible values include: "Initial", "Stopped",
     "Started", "Starting", "Stopping", "NeedRegistration", "Online", "Limited", "Offline",
     "AccessDenied".
    :vartype state: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeState
    :ivar create_time: The time at which the integration runtime was created, in ISO8601 format.
    :vartype create_time: ~datetime.datetime
    :ivar task_queue_id: The task queue id of the integration runtime.
    :vartype task_queue_id: str
    :ivar internal_channel_encryption: It is used to set the encryption mode for node-node
     communication channel (when more than 2 self-hosted integration runtime nodes exist). Possible
     values include: "NotSet", "SslEncrypted", "NotEncrypted".
    :vartype internal_channel_encryption: str or
     ~azure.mgmt.datafactory.models.IntegrationRuntimeInternalChannelEncryptionMode
    :ivar version: Version of the integration runtime.
    :vartype version: str
    :ivar nodes: The list of nodes for this integration runtime.
    :vartype nodes: list[~azure.mgmt.datafactory.models.SelfHostedIntegrationRuntimeNode]
    :ivar scheduled_update_date: The date at which the integration runtime will be scheduled to
     update, in ISO8601 format.
    :vartype scheduled_update_date: ~datetime.datetime
    :ivar update_delay_offset: The time in the date scheduled by service to update the integration
     runtime, e.g., PT03H is 3 hours.
    :vartype update_delay_offset: str
    :ivar local_time_zone_offset: The local time zone offset in hours.
    :vartype local_time_zone_offset: str
    :ivar capabilities: Object with additional information about integration runtime capabilities.
    :vartype capabilities: dict[str, str]
    :ivar service_urls: The URLs for the services used in integration runtime backend service.
    :vartype service_urls: list[str]
    :ivar auto_update: Whether Self-hosted integration runtime auto update has been turned on.
     Possible values include: "On", "Off".
    :vartype auto_update: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeAutoUpdate
    :ivar version_status: Status of the integration runtime version.
    :vartype version_status: str
    :ivar links: The list of linked integration runtimes that are created to share with this
     integration runtime.
    :vartype links: list[~azure.mgmt.datafactory.models.LinkedIntegrationRuntime]
    :ivar pushed_version: The version that the integration runtime is going to update to.
    :vartype pushed_version: str
    :ivar latest_version: The latest version on download center.
    :vartype latest_version: str
    :ivar auto_update_eta: The estimated time when the self-hosted integration runtime will be
     updated.
    :vartype auto_update_eta: ~datetime.datetime
    """

    _validation = {
        'type': {'required': True},
        'data_factory_name': {'readonly': True},
        'state': {'readonly': True},
        'create_time': {'readonly': True},
        'task_queue_id': {'readonly': True},
        'internal_channel_encryption': {'readonly': True},
        'version': {'readonly': True},
        'scheduled_update_date': {'readonly': True},
        'update_delay_offset': {'readonly': True},
        'local_time_zone_offset': {'readonly': True},
        'capabilities': {'readonly': True},
        'service_urls': {'readonly': True},
        'auto_update': {'readonly': True},
        'version_status': {'readonly': True},
        'pushed_version': {'readonly': True},
        'latest_version': {'readonly': True},
        'auto_update_eta': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'data_factory_name': {'key': 'dataFactoryName', 'type': 'str'},
        'state': {'key': 'state', 'type': 'str'},
        'create_time': {'key': 'typeProperties.createTime', 'type': 'iso-8601'},
        'task_queue_id': {'key': 'typeProperties.taskQueueId', 'type': 'str'},
        'internal_channel_encryption': {'key': 'typeProperties.internalChannelEncryption', 'type': 'str'},
        'version': {'key': 'typeProperties.version', 'type': 'str'},
        'nodes': {'key': 'typeProperties.nodes', 'type': '[SelfHostedIntegrationRuntimeNode]'},
        'scheduled_update_date': {'key': 'typeProperties.scheduledUpdateDate', 'type': 'iso-8601'},
        'update_delay_offset': {'key': 'typeProperties.updateDelayOffset', 'type': 'str'},
        'local_time_zone_offset': {'key': 'typeProperties.localTimeZoneOffset', 'type': 'str'},
        'capabilities': {'key': 'typeProperties.capabilities', 'type': '{str}'},
        'service_urls': {'key': 'typeProperties.serviceUrls', 'type': '[str]'},
        'auto_update': {'key': 'typeProperties.autoUpdate', 'type': 'str'},
        'version_status': {'key': 'typeProperties.versionStatus', 'type': 'str'},
        'links': {'key': 'typeProperties.links', 'type': '[LinkedIntegrationRuntime]'},
        'pushed_version': {'key': 'typeProperties.pushedVersion', 'type': 'str'},
        'latest_version': {'key': 'typeProperties.latestVersion', 'type': 'str'},
        'auto_update_eta': {'key': 'typeProperties.autoUpdateETA', 'type': 'iso-8601'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        nodes: Optional[List["SelfHostedIntegrationRuntimeNode"]] = None,
        links: Optional[List["LinkedIntegrationRuntime"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword nodes: The list of nodes for this integration runtime.
        :paramtype nodes: list[~azure.mgmt.datafactory.models.SelfHostedIntegrationRuntimeNode]
        :keyword links: The list of linked integration runtimes that are created to share with this
         integration runtime.
        :paramtype links: list[~azure.mgmt.datafactory.models.LinkedIntegrationRuntime]
        """
        super(SelfHostedIntegrationRuntimeStatus, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'SelfHosted'  # type: str
        self.create_time = None
        self.task_queue_id = None
        self.internal_channel_encryption = None
        self.version = None
        self.nodes = nodes
        self.scheduled_update_date = None
        self.update_delay_offset = None
        self.local_time_zone_offset = None
        self.capabilities = None
        self.service_urls = None
        self.auto_update = None
        self.version_status = None
        self.links = links
        self.pushed_version = None
        self.latest_version = None
        self.auto_update_eta = None


class ServiceNowLinkedService(LinkedService):
    """ServiceNow server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar endpoint: Required. The endpoint of the ServiceNow server. (i.e.
     :code:`<instance>`.service-now.com).
    :vartype endpoint: any
    :ivar authentication_type: Required. The authentication type to use. Possible values include:
     "Basic", "OAuth2".
    :vartype authentication_type: str or
     ~azure.mgmt.datafactory.models.ServiceNowAuthenticationType
    :ivar username: The user name used to connect to the ServiceNow server for Basic and OAuth2
     authentication.
    :vartype username: any
    :ivar password: The password corresponding to the user name for Basic and OAuth2
     authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar client_id: The client id for OAuth2 authentication.
    :vartype client_id: any
    :ivar client_secret: The client secret for OAuth2 authentication.
    :vartype client_secret: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'endpoint': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'object'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        endpoint: Any,
        authentication_type: Union[str, "ServiceNowAuthenticationType"],
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        client_id: Optional[Any] = None,
        client_secret: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword endpoint: Required. The endpoint of the ServiceNow server. (i.e.
         :code:`<instance>`.service-now.com).
        :paramtype endpoint: any
        :keyword authentication_type: Required. The authentication type to use. Possible values
         include: "Basic", "OAuth2".
        :paramtype authentication_type: str or
         ~azure.mgmt.datafactory.models.ServiceNowAuthenticationType
        :keyword username: The user name used to connect to the ServiceNow server for Basic and OAuth2
         authentication.
        :paramtype username: any
        :keyword password: The password corresponding to the user name for Basic and OAuth2
         authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword client_id: The client id for OAuth2 authentication.
        :paramtype client_id: any
        :keyword client_secret: The client secret for OAuth2 authentication.
        :paramtype client_secret: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true.
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true.
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(ServiceNowLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'ServiceNow'  # type: str
        self.endpoint = endpoint
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.client_id = client_id
        self.client_secret = client_secret
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ServiceNowObjectDataset(Dataset):
    """ServiceNow server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(ServiceNowObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ServiceNowObject'  # type: str
        self.table_name = table_name


class ServiceNowSource(TabularSource):
    """A copy activity ServiceNow server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(ServiceNowSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'ServiceNowSource'  # type: str
        self.query = query


class ServicePrincipalCredential(Credential):
    """Service principal credential.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of credential.Constant filled by server.
    :vartype type: str
    :ivar description: Credential description.
    :vartype description: str
    :ivar annotations: List of tags that can be used for describing the Credential.
    :vartype annotations: list[any]
    :ivar service_principal_id: The app ID of the service principal used to authenticate.
    :vartype service_principal_id: any
    :ivar service_principal_key: The key of the service principal used to authenticate.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar tenant: The ID of the tenant to which the service principal belongs.
    :vartype tenant: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'AzureKeyVaultSecretReference'},
        'tenant': {'key': 'typeProperties.tenant', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["AzureKeyVaultSecretReference"] = None,
        tenant: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Credential description.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the Credential.
        :paramtype annotations: list[any]
        :keyword service_principal_id: The app ID of the service principal used to authenticate.
        :paramtype service_principal_id: any
        :keyword service_principal_key: The key of the service principal used to authenticate.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword tenant: The ID of the tenant to which the service principal belongs.
        :paramtype tenant: any
        """
        super(ServicePrincipalCredential, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, **kwargs)
        self.type = 'ServicePrincipal'  # type: str
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.tenant = tenant


class SetVariableActivity(ControlActivity):
    """Set value for a Variable.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar variable_name: Name of the variable whose value needs to be set.
    :vartype variable_name: str
    :ivar value: Value to be set. Could be a static value or Expression.
    :vartype value: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'variable_name': {'key': 'typeProperties.variableName', 'type': 'str'},
        'value': {'key': 'typeProperties.value', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        variable_name: Optional[str] = None,
        value: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword variable_name: Name of the variable whose value needs to be set.
        :paramtype variable_name: str
        :keyword value: Value to be set. Could be a static value or Expression.
        :paramtype value: any
        """
        super(SetVariableActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'SetVariable'  # type: str
        self.variable_name = variable_name
        self.value = value


class SftpLocation(DatasetLocation):
    """The location of SFTP dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage location.Constant filled by server.
    :vartype type: str
    :ivar folder_path: Specify the folder path of dataset. Type: string (or Expression with
     resultType string).
    :vartype folder_path: any
    :ivar file_name: Specify the file name of dataset. Type: string (or Expression with resultType
     string).
    :vartype file_name: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'folder_path': {'key': 'folderPath', 'type': 'object'},
        'file_name': {'key': 'fileName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        folder_path: Optional[Any] = None,
        file_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword folder_path: Specify the folder path of dataset. Type: string (or Expression with
         resultType string).
        :paramtype folder_path: any
        :keyword file_name: Specify the file name of dataset. Type: string (or Expression with
         resultType string).
        :paramtype file_name: any
        """
        super(SftpLocation, self).__init__(additional_properties=additional_properties, folder_path=folder_path, file_name=file_name, **kwargs)
        self.type = 'SftpLocation'  # type: str


class SftpReadSettings(StoreReadSettings):
    """Sftp read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar recursive: If true, files under the folder path will be read recursively. Default is
     true. Type: boolean (or Expression with resultType boolean).
    :vartype recursive: any
    :ivar wildcard_folder_path: Sftp wildcardFolderPath. Type: string (or Expression with
     resultType string).
    :vartype wildcard_folder_path: any
    :ivar wildcard_file_name: Sftp wildcardFileName. Type: string (or Expression with resultType
     string).
    :vartype wildcard_file_name: any
    :ivar enable_partition_discovery: Indicates whether to enable partition discovery.
    :vartype enable_partition_discovery: bool
    :ivar partition_root_path: Specify the root path where partition discovery starts from. Type:
     string (or Expression with resultType string).
    :vartype partition_root_path: any
    :ivar file_list_path: Point to a text file that lists each file (relative path to the path
     configured in the dataset) that you want to copy. Type: string (or Expression with resultType
     string).
    :vartype file_list_path: any
    :ivar delete_files_after_completion: Indicates whether the source files need to be deleted
     after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
    :vartype delete_files_after_completion: any
    :ivar modified_datetime_start: The start of file's modified datetime. Type: string (or
     Expression with resultType string).
    :vartype modified_datetime_start: any
    :ivar modified_datetime_end: The end of file's modified datetime. Type: string (or Expression
     with resultType string).
    :vartype modified_datetime_end: any
    :ivar disable_chunking: If true, disable parallel reading within each file. Default is false.
     Type: boolean (or Expression with resultType boolean).
    :vartype disable_chunking: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'recursive': {'key': 'recursive', 'type': 'object'},
        'wildcard_folder_path': {'key': 'wildcardFolderPath', 'type': 'object'},
        'wildcard_file_name': {'key': 'wildcardFileName', 'type': 'object'},
        'enable_partition_discovery': {'key': 'enablePartitionDiscovery', 'type': 'bool'},
        'partition_root_path': {'key': 'partitionRootPath', 'type': 'object'},
        'file_list_path': {'key': 'fileListPath', 'type': 'object'},
        'delete_files_after_completion': {'key': 'deleteFilesAfterCompletion', 'type': 'object'},
        'modified_datetime_start': {'key': 'modifiedDatetimeStart', 'type': 'object'},
        'modified_datetime_end': {'key': 'modifiedDatetimeEnd', 'type': 'object'},
        'disable_chunking': {'key': 'disableChunking', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        recursive: Optional[Any] = None,
        wildcard_folder_path: Optional[Any] = None,
        wildcard_file_name: Optional[Any] = None,
        enable_partition_discovery: Optional[bool] = None,
        partition_root_path: Optional[Any] = None,
        file_list_path: Optional[Any] = None,
        delete_files_after_completion: Optional[Any] = None,
        modified_datetime_start: Optional[Any] = None,
        modified_datetime_end: Optional[Any] = None,
        disable_chunking: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword recursive: If true, files under the folder path will be read recursively. Default is
         true. Type: boolean (or Expression with resultType boolean).
        :paramtype recursive: any
        :keyword wildcard_folder_path: Sftp wildcardFolderPath. Type: string (or Expression with
         resultType string).
        :paramtype wildcard_folder_path: any
        :keyword wildcard_file_name: Sftp wildcardFileName. Type: string (or Expression with resultType
         string).
        :paramtype wildcard_file_name: any
        :keyword enable_partition_discovery: Indicates whether to enable partition discovery.
        :paramtype enable_partition_discovery: bool
        :keyword partition_root_path: Specify the root path where partition discovery starts from.
         Type: string (or Expression with resultType string).
        :paramtype partition_root_path: any
        :keyword file_list_path: Point to a text file that lists each file (relative path to the path
         configured in the dataset) that you want to copy. Type: string (or Expression with resultType
         string).
        :paramtype file_list_path: any
        :keyword delete_files_after_completion: Indicates whether the source files need to be deleted
         after copy completion. Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype delete_files_after_completion: any
        :keyword modified_datetime_start: The start of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_start: any
        :keyword modified_datetime_end: The end of file's modified datetime. Type: string (or
         Expression with resultType string).
        :paramtype modified_datetime_end: any
        :keyword disable_chunking: If true, disable parallel reading within each file. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_chunking: any
        """
        super(SftpReadSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'SftpReadSettings'  # type: str
        self.recursive = recursive
        self.wildcard_folder_path = wildcard_folder_path
        self.wildcard_file_name = wildcard_file_name
        self.enable_partition_discovery = enable_partition_discovery
        self.partition_root_path = partition_root_path
        self.file_list_path = file_list_path
        self.delete_files_after_completion = delete_files_after_completion
        self.modified_datetime_start = modified_datetime_start
        self.modified_datetime_end = modified_datetime_end
        self.disable_chunking = disable_chunking


class SftpServerLinkedService(LinkedService):
    """A linked service for an SSH File Transfer Protocol (SFTP) server.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. The SFTP server host name. Type: string (or Expression with resultType
     string).
    :vartype host: any
    :ivar port: The TCP port number that the SFTP server uses to listen for client connections.
     Default value is 22. Type: integer (or Expression with resultType integer), minimum: 0.
    :vartype port: any
    :ivar authentication_type: The authentication type to be used to connect to the FTP server.
     Possible values include: "Basic", "SshPublicKey", "MultiFactor".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.SftpAuthenticationType
    :ivar user_name: The username used to log on to the SFTP server. Type: string (or Expression
     with resultType string).
    :vartype user_name: any
    :ivar password: Password to logon the SFTP server for Basic authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar private_key_path: The SSH private key file path for SshPublicKey authentication. Only
     valid for on-premises copy. For on-premises copy with SshPublicKey authentication, either
     PrivateKeyPath or PrivateKeyContent should be specified. SSH private key should be OpenSSH
     format. Type: string (or Expression with resultType string).
    :vartype private_key_path: any
    :ivar private_key_content: Base64 encoded SSH private key content for SshPublicKey
     authentication. For on-premises copy with SshPublicKey authentication, either PrivateKeyPath or
     PrivateKeyContent should be specified. SSH private key should be OpenSSH format.
    :vartype private_key_content: ~azure.mgmt.datafactory.models.SecretBase
    :ivar pass_phrase: The password to decrypt the SSH private key if the SSH private key is
     encrypted.
    :vartype pass_phrase: ~azure.mgmt.datafactory.models.SecretBase
    :ivar skip_host_key_validation: If true, skip the SSH host key validation. Default value is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype skip_host_key_validation: any
    :ivar host_key_fingerprint: The host key finger-print of the SFTP server. When
     SkipHostKeyValidation is false, HostKeyFingerprint should be specified. Type: string (or
     Expression with resultType string).
    :vartype host_key_fingerprint: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'private_key_path': {'key': 'typeProperties.privateKeyPath', 'type': 'object'},
        'private_key_content': {'key': 'typeProperties.privateKeyContent', 'type': 'SecretBase'},
        'pass_phrase': {'key': 'typeProperties.passPhrase', 'type': 'SecretBase'},
        'skip_host_key_validation': {'key': 'typeProperties.skipHostKeyValidation', 'type': 'object'},
        'host_key_fingerprint': {'key': 'typeProperties.hostKeyFingerprint', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        port: Optional[Any] = None,
        authentication_type: Optional[Union[str, "SftpAuthenticationType"]] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        private_key_path: Optional[Any] = None,
        private_key_content: Optional["SecretBase"] = None,
        pass_phrase: Optional["SecretBase"] = None,
        skip_host_key_validation: Optional[Any] = None,
        host_key_fingerprint: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. The SFTP server host name. Type: string (or Expression with resultType
         string).
        :paramtype host: any
        :keyword port: The TCP port number that the SFTP server uses to listen for client connections.
         Default value is 22. Type: integer (or Expression with resultType integer), minimum: 0.
        :paramtype port: any
        :keyword authentication_type: The authentication type to be used to connect to the FTP server.
         Possible values include: "Basic", "SshPublicKey", "MultiFactor".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.SftpAuthenticationType
        :keyword user_name: The username used to log on to the SFTP server. Type: string (or Expression
         with resultType string).
        :paramtype user_name: any
        :keyword password: Password to logon the SFTP server for Basic authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword private_key_path: The SSH private key file path for SshPublicKey authentication. Only
         valid for on-premises copy. For on-premises copy with SshPublicKey authentication, either
         PrivateKeyPath or PrivateKeyContent should be specified. SSH private key should be OpenSSH
         format. Type: string (or Expression with resultType string).
        :paramtype private_key_path: any
        :keyword private_key_content: Base64 encoded SSH private key content for SshPublicKey
         authentication. For on-premises copy with SshPublicKey authentication, either PrivateKeyPath or
         PrivateKeyContent should be specified. SSH private key should be OpenSSH format.
        :paramtype private_key_content: ~azure.mgmt.datafactory.models.SecretBase
        :keyword pass_phrase: The password to decrypt the SSH private key if the SSH private key is
         encrypted.
        :paramtype pass_phrase: ~azure.mgmt.datafactory.models.SecretBase
        :keyword skip_host_key_validation: If true, skip the SSH host key validation. Default value is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype skip_host_key_validation: any
        :keyword host_key_fingerprint: The host key finger-print of the SFTP server. When
         SkipHostKeyValidation is false, HostKeyFingerprint should be specified. Type: string (or
         Expression with resultType string).
        :paramtype host_key_fingerprint: any
        """
        super(SftpServerLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Sftp'  # type: str
        self.host = host
        self.port = port
        self.authentication_type = authentication_type
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential
        self.private_key_path = private_key_path
        self.private_key_content = private_key_content
        self.pass_phrase = pass_phrase
        self.skip_host_key_validation = skip_host_key_validation
        self.host_key_fingerprint = host_key_fingerprint


class SftpWriteSettings(StoreWriteSettings):
    """Sftp write settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The write setting type.Constant filled by server.
    :vartype type: str
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar copy_behavior: The type of copy behavior for copy sink.
    :vartype copy_behavior: any
    :ivar operation_timeout: Specifies the timeout for writing each chunk to SFTP server. Default
     value: 01:00:00 (one hour). Type: string (or Expression with resultType string).
    :vartype operation_timeout: any
    :ivar use_temp_file_rename: Upload to temporary file(s) and rename. Disable this option if your
     SFTP server doesn't support rename operation. Type: boolean (or Expression with resultType
     boolean).
    :vartype use_temp_file_rename: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'copy_behavior': {'key': 'copyBehavior', 'type': 'object'},
        'operation_timeout': {'key': 'operationTimeout', 'type': 'object'},
        'use_temp_file_rename': {'key': 'useTempFileRename', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        copy_behavior: Optional[Any] = None,
        operation_timeout: Optional[Any] = None,
        use_temp_file_rename: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword copy_behavior: The type of copy behavior for copy sink.
        :paramtype copy_behavior: any
        :keyword operation_timeout: Specifies the timeout for writing each chunk to SFTP server.
         Default value: 01:00:00 (one hour). Type: string (or Expression with resultType string).
        :paramtype operation_timeout: any
        :keyword use_temp_file_rename: Upload to temporary file(s) and rename. Disable this option if
         your SFTP server doesn't support rename operation. Type: boolean (or Expression with resultType
         boolean).
        :paramtype use_temp_file_rename: any
        """
        super(SftpWriteSettings, self).__init__(additional_properties=additional_properties, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, copy_behavior=copy_behavior, **kwargs)
        self.type = 'SftpWriteSettings'  # type: str
        self.operation_timeout = operation_timeout
        self.use_temp_file_rename = use_temp_file_rename


class SharePointOnlineListLinkedService(LinkedService):
    """SharePoint Online List linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar site_url: Required. The URL of the SharePoint Online site. For example,
     https://contoso.sharepoint.com/sites/siteName. Type: string (or Expression with resultType
     string).
    :vartype site_url: any
    :ivar tenant_id: Required. The tenant ID under which your application resides. You can find it
     from Azure portal Active Directory overview page. Type: string (or Expression with resultType
     string).
    :vartype tenant_id: any
    :ivar service_principal_id: Required. The application (client) ID of your application
     registered in Azure Active Directory. Make sure to grant SharePoint site permission to this
     application. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: Required. The client secret of your application registered in
     Azure Active Directory. Type: string (or Expression with resultType string).
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'site_url': {'required': True},
        'tenant_id': {'required': True},
        'service_principal_id': {'required': True},
        'service_principal_key': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'site_url': {'key': 'typeProperties.siteUrl', 'type': 'object'},
        'tenant_id': {'key': 'typeProperties.tenantId', 'type': 'object'},
        'service_principal_id': {'key': 'typeProperties.servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'typeProperties.servicePrincipalKey', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        site_url: Any,
        tenant_id: Any,
        service_principal_id: Any,
        service_principal_key: "SecretBase",
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword site_url: Required. The URL of the SharePoint Online site. For example,
         https://contoso.sharepoint.com/sites/siteName. Type: string (or Expression with resultType
         string).
        :paramtype site_url: any
        :keyword tenant_id: Required. The tenant ID under which your application resides. You can find
         it from Azure portal Active Directory overview page. Type: string (or Expression with
         resultType string).
        :paramtype tenant_id: any
        :keyword service_principal_id: Required. The application (client) ID of your application
         registered in Azure Active Directory. Make sure to grant SharePoint site permission to this
         application. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: Required. The client secret of your application registered in
         Azure Active Directory. Type: string (or Expression with resultType string).
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SharePointOnlineListLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SharePointOnlineList'  # type: str
        self.site_url = site_url
        self.tenant_id = tenant_id
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.encrypted_credential = encrypted_credential


class SharePointOnlineListResourceDataset(Dataset):
    """The sharepoint online list resource dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar list_name: The name of the SharePoint Online list. Type: string (or Expression with
     resultType string).
    :vartype list_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'list_name': {'key': 'typeProperties.listName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        list_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword list_name: The name of the SharePoint Online list. Type: string (or Expression with
         resultType string).
        :paramtype list_name: any
        """
        super(SharePointOnlineListResourceDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SharePointOnlineListResource'  # type: str
        self.list_name = list_name


class SharePointOnlineListSource(CopySource):
    """A copy activity source for sharePoint online list source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: The OData query to filter the data in SharePoint Online list. For example,
     "$top=1". Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar http_request_timeout: The wait time to get a response from SharePoint Online. Default
     value is 5 minutes (00:05:00). Type: string (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype http_request_timeout: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'http_request_timeout': {'key': 'httpRequestTimeout', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query: Optional[Any] = None,
        http_request_timeout: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: The OData query to filter the data in SharePoint Online list. For example,
         "$top=1". Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword http_request_timeout: The wait time to get a response from SharePoint Online. Default
         value is 5 minutes (00:05:00). Type: string (or Expression with resultType string), pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype http_request_timeout: any
        """
        super(SharePointOnlineListSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'SharePointOnlineListSource'  # type: str
        self.query = query
        self.http_request_timeout = http_request_timeout


class ShopifyLinkedService(LinkedService):
    """Shopify Service linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. The endpoint of the Shopify server. (i.e. mystore.myshopify.com).
    :vartype host: any
    :ivar access_token: The API access token that can be used to access Shopifys data. The token
     won't expire if it is offline mode.
    :vartype access_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'access_token': {'key': 'typeProperties.accessToken', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        access_token: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. The endpoint of the Shopify server. (i.e. mystore.myshopify.com).
        :paramtype host: any
        :keyword access_token: The API access token that can be used to access Shopifys data. The
         token won't expire if it is offline mode.
        :paramtype access_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true.
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true.
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(ShopifyLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Shopify'  # type: str
        self.host = host
        self.access_token = access_token
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ShopifyObjectDataset(Dataset):
    """Shopify Service dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(ShopifyObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ShopifyObject'  # type: str
        self.table_name = table_name


class ShopifySource(TabularSource):
    """A copy activity Shopify Service source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(ShopifySource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'ShopifySource'  # type: str
        self.query = query


class SkipErrorFile(msrest.serialization.Model):
    """Skip error file.

    :ivar file_missing: Skip if file is deleted by other client during copy. Default is true. Type:
     boolean (or Expression with resultType boolean).
    :vartype file_missing: any
    :ivar data_inconsistency: Skip if source/sink file changed by other concurrent write. Default
     is false. Type: boolean (or Expression with resultType boolean).
    :vartype data_inconsistency: any
    """

    _attribute_map = {
        'file_missing': {'key': 'fileMissing', 'type': 'object'},
        'data_inconsistency': {'key': 'dataInconsistency', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        file_missing: Optional[Any] = None,
        data_inconsistency: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword file_missing: Skip if file is deleted by other client during copy. Default is true.
         Type: boolean (or Expression with resultType boolean).
        :paramtype file_missing: any
        :keyword data_inconsistency: Skip if source/sink file changed by other concurrent write.
         Default is false. Type: boolean (or Expression with resultType boolean).
        :paramtype data_inconsistency: any
        """
        super(SkipErrorFile, self).__init__(**kwargs)
        self.file_missing = file_missing
        self.data_inconsistency = data_inconsistency


class SmartsheetLinkedService(LinkedService):
    """Linked service for Smartsheet.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar api_token: Required. The api token for the Smartsheet source.
    :vartype api_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'api_token': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'api_token': {'key': 'typeProperties.apiToken', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        api_token: "SecretBase",
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword api_token: Required. The api token for the Smartsheet source.
        :paramtype api_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SmartsheetLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Smartsheet'  # type: str
        self.api_token = api_token
        self.encrypted_credential = encrypted_credential


class SnowflakeDataset(Dataset):
    """The snowflake dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar schema_type_properties_schema: The schema name of the Snowflake database. Type: string
     (or Expression with resultType string).
    :vartype schema_type_properties_schema: any
    :ivar table: The table name of the Snowflake database. Type: string (or Expression with
     resultType string).
    :vartype table: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        schema_type_properties_schema: Optional[Any] = None,
        table: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword schema_type_properties_schema: The schema name of the Snowflake database. Type: string
         (or Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        :keyword table: The table name of the Snowflake database. Type: string (or Expression with
         resultType string).
        :paramtype table: any
        """
        super(SnowflakeDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SnowflakeTable'  # type: str
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class SnowflakeExportCopyCommand(ExportSettings):
    """Snowflake export command settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The export setting type.Constant filled by server.
    :vartype type: str
    :ivar additional_copy_options: Additional copy options directly passed to snowflake Copy
     Command. Type: key value pairs (value should be string type) (or Expression with resultType
     object). Example: "additionalCopyOptions": { "DATE_FORMAT": "MM/DD/YYYY", "TIME_FORMAT":
     "'HH24:MI:SS.FF'" }.
    :vartype additional_copy_options: dict[str, any]
    :ivar additional_format_options: Additional format options directly passed to snowflake Copy
     Command. Type: key value pairs (value should be string type) (or Expression with resultType
     object). Example: "additionalFormatOptions": { "OVERWRITE": "TRUE", "MAX_FILE_SIZE": "'FALSE'"
     }.
    :vartype additional_format_options: dict[str, any]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'additional_copy_options': {'key': 'additionalCopyOptions', 'type': '{object}'},
        'additional_format_options': {'key': 'additionalFormatOptions', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        additional_copy_options: Optional[Dict[str, Any]] = None,
        additional_format_options: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword additional_copy_options: Additional copy options directly passed to snowflake Copy
         Command. Type: key value pairs (value should be string type) (or Expression with resultType
         object). Example: "additionalCopyOptions": { "DATE_FORMAT": "MM/DD/YYYY", "TIME_FORMAT":
         "'HH24:MI:SS.FF'" }.
        :paramtype additional_copy_options: dict[str, any]
        :keyword additional_format_options: Additional format options directly passed to snowflake Copy
         Command. Type: key value pairs (value should be string type) (or Expression with resultType
         object). Example: "additionalFormatOptions": { "OVERWRITE": "TRUE", "MAX_FILE_SIZE": "'FALSE'"
         }.
        :paramtype additional_format_options: dict[str, any]
        """
        super(SnowflakeExportCopyCommand, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'SnowflakeExportCopyCommand'  # type: str
        self.additional_copy_options = additional_copy_options
        self.additional_format_options = additional_format_options


class SnowflakeImportCopyCommand(ImportSettings):
    """Snowflake import command settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The import setting type.Constant filled by server.
    :vartype type: str
    :ivar additional_copy_options: Additional copy options directly passed to snowflake Copy
     Command. Type: key value pairs (value should be string type) (or Expression with resultType
     object). Example: "additionalCopyOptions": { "DATE_FORMAT": "MM/DD/YYYY", "TIME_FORMAT":
     "'HH24:MI:SS.FF'" }.
    :vartype additional_copy_options: dict[str, any]
    :ivar additional_format_options: Additional format options directly passed to snowflake Copy
     Command. Type: key value pairs (value should be string type) (or Expression with resultType
     object). Example: "additionalFormatOptions": { "FORCE": "TRUE", "LOAD_UNCERTAIN_FILES":
     "'FALSE'" }.
    :vartype additional_format_options: dict[str, any]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'additional_copy_options': {'key': 'additionalCopyOptions', 'type': '{object}'},
        'additional_format_options': {'key': 'additionalFormatOptions', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        additional_copy_options: Optional[Dict[str, Any]] = None,
        additional_format_options: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword additional_copy_options: Additional copy options directly passed to snowflake Copy
         Command. Type: key value pairs (value should be string type) (or Expression with resultType
         object). Example: "additionalCopyOptions": { "DATE_FORMAT": "MM/DD/YYYY", "TIME_FORMAT":
         "'HH24:MI:SS.FF'" }.
        :paramtype additional_copy_options: dict[str, any]
        :keyword additional_format_options: Additional format options directly passed to snowflake Copy
         Command. Type: key value pairs (value should be string type) (or Expression with resultType
         object). Example: "additionalFormatOptions": { "FORCE": "TRUE", "LOAD_UNCERTAIN_FILES":
         "'FALSE'" }.
        :paramtype additional_format_options: dict[str, any]
        """
        super(SnowflakeImportCopyCommand, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'SnowflakeImportCopyCommand'  # type: str
        self.additional_copy_options = additional_copy_options
        self.additional_format_options = additional_format_options


class SnowflakeLinkedService(LinkedService):
    """Snowflake linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The connection string of snowflake. Type: string,
     SecureString.
    :vartype connection_string: any
    :ivar password: The Azure key vault secret reference of password in connection string.
    :vartype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        password: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The connection string of snowflake. Type: string,
         SecureString.
        :paramtype connection_string: any
        :keyword password: The Azure key vault secret reference of password in connection string.
        :paramtype password: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SnowflakeLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Snowflake'  # type: str
        self.connection_string = connection_string
        self.password = password
        self.encrypted_credential = encrypted_credential


class SnowflakeSink(CopySink):
    """A copy activity snowflake sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :vartype pre_copy_script: any
    :ivar import_settings: Snowflake import settings.
    :vartype import_settings: ~azure.mgmt.datafactory.models.SnowflakeImportCopyCommand
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'object'},
        'import_settings': {'key': 'importSettings', 'type': 'SnowflakeImportCopyCommand'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        pre_copy_script: Optional[Any] = None,
        import_settings: Optional["SnowflakeImportCopyCommand"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
         string).
        :paramtype pre_copy_script: any
        :keyword import_settings: Snowflake import settings.
        :paramtype import_settings: ~azure.mgmt.datafactory.models.SnowflakeImportCopyCommand
        """
        super(SnowflakeSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'SnowflakeSink'  # type: str
        self.pre_copy_script = pre_copy_script
        self.import_settings = import_settings


class SnowflakeSource(CopySource):
    """A copy activity snowflake source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query: Snowflake Sql query. Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar export_settings: Snowflake export settings.
    :vartype export_settings: ~azure.mgmt.datafactory.models.SnowflakeExportCopyCommand
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'export_settings': {'key': 'exportSettings', 'type': 'SnowflakeExportCopyCommand'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query: Optional[Any] = None,
        export_settings: Optional["SnowflakeExportCopyCommand"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query: Snowflake Sql query. Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword export_settings: Snowflake export settings.
        :paramtype export_settings: ~azure.mgmt.datafactory.models.SnowflakeExportCopyCommand
        """
        super(SnowflakeSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'SnowflakeSource'  # type: str
        self.query = query
        self.export_settings = export_settings


class SparkLinkedService(LinkedService):
    """Spark Server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar host: Required. IP address or host name of the Spark server.
    :vartype host: any
    :ivar port: Required. The TCP port that the Spark server uses to listen for client connections.
    :vartype port: any
    :ivar server_type: The type of Spark server. Possible values include: "SharkServer",
     "SharkServer2", "SparkThriftServer".
    :vartype server_type: str or ~azure.mgmt.datafactory.models.SparkServerType
    :ivar thrift_transport_protocol: The transport protocol to use in the Thrift layer. Possible
     values include: "Binary", "SASL", "HTTP ".
    :vartype thrift_transport_protocol: str or
     ~azure.mgmt.datafactory.models.SparkThriftTransportProtocol
    :ivar authentication_type: Required. The authentication method used to access the Spark server.
     Possible values include: "Anonymous", "Username", "UsernameAndPassword",
     "WindowsAzureHDInsightService".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.SparkAuthenticationType
    :ivar username: The user name that you use to access Spark Server.
    :vartype username: any
    :ivar password: The password corresponding to the user name that you provided in the Username
     field.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar http_path: The partial URL corresponding to the Spark server.
    :vartype http_path: any
    :ivar enable_ssl: Specifies whether the connections to the server are encrypted using SSL. The
     default value is false.
    :vartype enable_ssl: any
    :ivar trusted_cert_path: The full path of the .pem file containing trusted CA certificates for
     verifying the server when connecting over SSL. This property can only be set when using SSL on
     self-hosted IR. The default value is the cacerts.pem file installed with the IR.
    :vartype trusted_cert_path: any
    :ivar use_system_trust_store: Specifies whether to use a CA certificate from the system trust
     store or from a specified PEM file. The default value is false.
    :vartype use_system_trust_store: any
    :ivar allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
     name to match the host name of the server when connecting over SSL. The default value is false.
    :vartype allow_host_name_cn_mismatch: any
    :ivar allow_self_signed_server_cert: Specifies whether to allow self-signed certificates from
     the server. The default value is false.
    :vartype allow_self_signed_server_cert: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'host': {'required': True},
        'port': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'port': {'key': 'typeProperties.port', 'type': 'object'},
        'server_type': {'key': 'typeProperties.serverType', 'type': 'str'},
        'thrift_transport_protocol': {'key': 'typeProperties.thriftTransportProtocol', 'type': 'str'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'http_path': {'key': 'typeProperties.httpPath', 'type': 'object'},
        'enable_ssl': {'key': 'typeProperties.enableSsl', 'type': 'object'},
        'trusted_cert_path': {'key': 'typeProperties.trustedCertPath', 'type': 'object'},
        'use_system_trust_store': {'key': 'typeProperties.useSystemTrustStore', 'type': 'object'},
        'allow_host_name_cn_mismatch': {'key': 'typeProperties.allowHostNameCNMismatch', 'type': 'object'},
        'allow_self_signed_server_cert': {'key': 'typeProperties.allowSelfSignedServerCert', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        host: Any,
        port: Any,
        authentication_type: Union[str, "SparkAuthenticationType"],
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        server_type: Optional[Union[str, "SparkServerType"]] = None,
        thrift_transport_protocol: Optional[Union[str, "SparkThriftTransportProtocol"]] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        http_path: Optional[Any] = None,
        enable_ssl: Optional[Any] = None,
        trusted_cert_path: Optional[Any] = None,
        use_system_trust_store: Optional[Any] = None,
        allow_host_name_cn_mismatch: Optional[Any] = None,
        allow_self_signed_server_cert: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword host: Required. IP address or host name of the Spark server.
        :paramtype host: any
        :keyword port: Required. The TCP port that the Spark server uses to listen for client
         connections.
        :paramtype port: any
        :keyword server_type: The type of Spark server. Possible values include: "SharkServer",
         "SharkServer2", "SparkThriftServer".
        :paramtype server_type: str or ~azure.mgmt.datafactory.models.SparkServerType
        :keyword thrift_transport_protocol: The transport protocol to use in the Thrift layer. Possible
         values include: "Binary", "SASL", "HTTP ".
        :paramtype thrift_transport_protocol: str or
         ~azure.mgmt.datafactory.models.SparkThriftTransportProtocol
        :keyword authentication_type: Required. The authentication method used to access the Spark
         server. Possible values include: "Anonymous", "Username", "UsernameAndPassword",
         "WindowsAzureHDInsightService".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.SparkAuthenticationType
        :keyword username: The user name that you use to access Spark Server.
        :paramtype username: any
        :keyword password: The password corresponding to the user name that you provided in the
         Username field.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword http_path: The partial URL corresponding to the Spark server.
        :paramtype http_path: any
        :keyword enable_ssl: Specifies whether the connections to the server are encrypted using SSL.
         The default value is false.
        :paramtype enable_ssl: any
        :keyword trusted_cert_path: The full path of the .pem file containing trusted CA certificates
         for verifying the server when connecting over SSL. This property can only be set when using SSL
         on self-hosted IR. The default value is the cacerts.pem file installed with the IR.
        :paramtype trusted_cert_path: any
        :keyword use_system_trust_store: Specifies whether to use a CA certificate from the system
         trust store or from a specified PEM file. The default value is false.
        :paramtype use_system_trust_store: any
        :keyword allow_host_name_cn_mismatch: Specifies whether to require a CA-issued SSL certificate
         name to match the host name of the server when connecting over SSL. The default value is false.
        :paramtype allow_host_name_cn_mismatch: any
        :keyword allow_self_signed_server_cert: Specifies whether to allow self-signed certificates
         from the server. The default value is false.
        :paramtype allow_self_signed_server_cert: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SparkLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Spark'  # type: str
        self.host = host
        self.port = port
        self.server_type = server_type
        self.thrift_transport_protocol = thrift_transport_protocol
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.http_path = http_path
        self.enable_ssl = enable_ssl
        self.trusted_cert_path = trusted_cert_path
        self.use_system_trust_store = use_system_trust_store
        self.allow_host_name_cn_mismatch = allow_host_name_cn_mismatch
        self.allow_self_signed_server_cert = allow_self_signed_server_cert
        self.encrypted_credential = encrypted_credential


class SparkObjectDataset(Dataset):
    """Spark Server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar table: The table name of the Spark. Type: string (or Expression with resultType string).
    :vartype table: any
    :ivar schema_type_properties_schema: The schema name of the Spark. Type: string (or Expression
     with resultType string).
    :vartype schema_type_properties_schema: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword table: The table name of the Spark. Type: string (or Expression with resultType
         string).
        :paramtype table: any
        :keyword schema_type_properties_schema: The schema name of the Spark. Type: string (or
         Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        """
        super(SparkObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SparkObject'  # type: str
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class SparkSource(TabularSource):
    """A copy activity Spark Server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(SparkSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SparkSource'  # type: str
        self.query = query


class SqlAlwaysEncryptedProperties(msrest.serialization.Model):
    """Sql always encrypted properties.

    All required parameters must be populated in order to send to Azure.

    :ivar always_encrypted_akv_auth_type: Required. Sql always encrypted AKV authentication type.
     Type: string (or Expression with resultType string). Possible values include:
     "ServicePrincipal", "ManagedIdentity", "UserAssignedManagedIdentity".
    :vartype always_encrypted_akv_auth_type: str or
     ~azure.mgmt.datafactory.models.SqlAlwaysEncryptedAkvAuthType
    :ivar service_principal_id: The client ID of the application in Azure Active Directory used for
     Azure Key Vault authentication. Type: string (or Expression with resultType string).
    :vartype service_principal_id: any
    :ivar service_principal_key: The key of the service principal used to authenticate against
     Azure Key Vault.
    :vartype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _validation = {
        'always_encrypted_akv_auth_type': {'required': True},
    }

    _attribute_map = {
        'always_encrypted_akv_auth_type': {'key': 'alwaysEncryptedAkvAuthType', 'type': 'str'},
        'service_principal_id': {'key': 'servicePrincipalId', 'type': 'object'},
        'service_principal_key': {'key': 'servicePrincipalKey', 'type': 'SecretBase'},
        'credential': {'key': 'credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        always_encrypted_akv_auth_type: Union[str, "SqlAlwaysEncryptedAkvAuthType"],
        service_principal_id: Optional[Any] = None,
        service_principal_key: Optional["SecretBase"] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword always_encrypted_akv_auth_type: Required. Sql always encrypted AKV authentication
         type. Type: string (or Expression with resultType string). Possible values include:
         "ServicePrincipal", "ManagedIdentity", "UserAssignedManagedIdentity".
        :paramtype always_encrypted_akv_auth_type: str or
         ~azure.mgmt.datafactory.models.SqlAlwaysEncryptedAkvAuthType
        :keyword service_principal_id: The client ID of the application in Azure Active Directory used
         for Azure Key Vault authentication. Type: string (or Expression with resultType string).
        :paramtype service_principal_id: any
        :keyword service_principal_key: The key of the service principal used to authenticate against
         Azure Key Vault.
        :paramtype service_principal_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(SqlAlwaysEncryptedProperties, self).__init__(**kwargs)
        self.always_encrypted_akv_auth_type = always_encrypted_akv_auth_type
        self.service_principal_id = service_principal_id
        self.service_principal_key = service_principal_key
        self.credential = credential


class SqlDWSink(CopySink):
    """A copy activity SQL Data Warehouse sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :vartype pre_copy_script: any
    :ivar allow_poly_base: Indicates to use PolyBase to copy data into SQL Data Warehouse when
     applicable. Type: boolean (or Expression with resultType boolean).
    :vartype allow_poly_base: any
    :ivar poly_base_settings: Specifies PolyBase-related settings when allowPolyBase is true.
    :vartype poly_base_settings: ~azure.mgmt.datafactory.models.PolybaseSettings
    :ivar allow_copy_command: Indicates to use Copy Command to copy data into SQL Data Warehouse.
     Type: boolean (or Expression with resultType boolean).
    :vartype allow_copy_command: any
    :ivar copy_command_settings: Specifies Copy Command related settings when allowCopyCommand is
     true.
    :vartype copy_command_settings: ~azure.mgmt.datafactory.models.DWCopyCommandSettings
    :ivar table_option: The option to handle sink table, such as autoCreate. For now only
     'autoCreate' value is supported. Type: string (or Expression with resultType string).
    :vartype table_option: any
    :ivar sql_writer_use_table_lock: Whether to use table lock during bulk copy. Type: boolean (or
     Expression with resultType boolean).
    :vartype sql_writer_use_table_lock: any
    :ivar write_behavior: Write behavior when copying data into azure SQL DW. Type:
     SqlDWWriteBehaviorEnum (or Expression with resultType SqlDWWriteBehaviorEnum).
    :vartype write_behavior: any
    :ivar upsert_settings: SQL DW upsert settings.
    :vartype upsert_settings: ~azure.mgmt.datafactory.models.SqlDWUpsertSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'object'},
        'allow_poly_base': {'key': 'allowPolyBase', 'type': 'object'},
        'poly_base_settings': {'key': 'polyBaseSettings', 'type': 'PolybaseSettings'},
        'allow_copy_command': {'key': 'allowCopyCommand', 'type': 'object'},
        'copy_command_settings': {'key': 'copyCommandSettings', 'type': 'DWCopyCommandSettings'},
        'table_option': {'key': 'tableOption', 'type': 'object'},
        'sql_writer_use_table_lock': {'key': 'sqlWriterUseTableLock', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'object'},
        'upsert_settings': {'key': 'upsertSettings', 'type': 'SqlDWUpsertSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        pre_copy_script: Optional[Any] = None,
        allow_poly_base: Optional[Any] = None,
        poly_base_settings: Optional["PolybaseSettings"] = None,
        allow_copy_command: Optional[Any] = None,
        copy_command_settings: Optional["DWCopyCommandSettings"] = None,
        table_option: Optional[Any] = None,
        sql_writer_use_table_lock: Optional[Any] = None,
        write_behavior: Optional[Any] = None,
        upsert_settings: Optional["SqlDWUpsertSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
         string).
        :paramtype pre_copy_script: any
        :keyword allow_poly_base: Indicates to use PolyBase to copy data into SQL Data Warehouse when
         applicable. Type: boolean (or Expression with resultType boolean).
        :paramtype allow_poly_base: any
        :keyword poly_base_settings: Specifies PolyBase-related settings when allowPolyBase is true.
        :paramtype poly_base_settings: ~azure.mgmt.datafactory.models.PolybaseSettings
        :keyword allow_copy_command: Indicates to use Copy Command to copy data into SQL Data
         Warehouse. Type: boolean (or Expression with resultType boolean).
        :paramtype allow_copy_command: any
        :keyword copy_command_settings: Specifies Copy Command related settings when allowCopyCommand
         is true.
        :paramtype copy_command_settings: ~azure.mgmt.datafactory.models.DWCopyCommandSettings
        :keyword table_option: The option to handle sink table, such as autoCreate. For now only
         'autoCreate' value is supported. Type: string (or Expression with resultType string).
        :paramtype table_option: any
        :keyword sql_writer_use_table_lock: Whether to use table lock during bulk copy. Type: boolean
         (or Expression with resultType boolean).
        :paramtype sql_writer_use_table_lock: any
        :keyword write_behavior: Write behavior when copying data into azure SQL DW. Type:
         SqlDWWriteBehaviorEnum (or Expression with resultType SqlDWWriteBehaviorEnum).
        :paramtype write_behavior: any
        :keyword upsert_settings: SQL DW upsert settings.
        :paramtype upsert_settings: ~azure.mgmt.datafactory.models.SqlDWUpsertSettings
        """
        super(SqlDWSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'SqlDWSink'  # type: str
        self.pre_copy_script = pre_copy_script
        self.allow_poly_base = allow_poly_base
        self.poly_base_settings = poly_base_settings
        self.allow_copy_command = allow_copy_command
        self.copy_command_settings = copy_command_settings
        self.table_option = table_option
        self.sql_writer_use_table_lock = sql_writer_use_table_lock
        self.write_behavior = write_behavior
        self.upsert_settings = upsert_settings


class SqlDWSource(TabularSource):
    """A copy activity SQL Data Warehouse source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar sql_reader_query: SQL Data Warehouse reader query. Type: string (or Expression with
     resultType string).
    :vartype sql_reader_query: any
    :ivar sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Data Warehouse
     source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression
     with resultType string).
    :vartype sql_reader_stored_procedure_name: any
    :ivar stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}". Type: object (or Expression with resultType
     object), itemType: StoredProcedureParameter.
    :vartype stored_procedure_parameters: any
    :ivar partition_option: The partition mechanism that will be used for Sql read in parallel.
     Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
    :vartype partition_option: any
    :ivar partition_settings: The settings that will be leveraged for Sql source partitioning.
    :vartype partition_settings: ~azure.mgmt.datafactory.models.SqlPartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'sql_reader_query': {'key': 'sqlReaderQuery', 'type': 'object'},
        'sql_reader_stored_procedure_name': {'key': 'sqlReaderStoredProcedureName', 'type': 'object'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': 'object'},
        'partition_option': {'key': 'partitionOption', 'type': 'object'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'SqlPartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        sql_reader_query: Optional[Any] = None,
        sql_reader_stored_procedure_name: Optional[Any] = None,
        stored_procedure_parameters: Optional[Any] = None,
        partition_option: Optional[Any] = None,
        partition_settings: Optional["SqlPartitionSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword sql_reader_query: SQL Data Warehouse reader query. Type: string (or Expression with
         resultType string).
        :paramtype sql_reader_query: any
        :keyword sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Data
         Warehouse source. This cannot be used at the same time as SqlReaderQuery. Type: string (or
         Expression with resultType string).
        :paramtype sql_reader_stored_procedure_name: any
        :keyword stored_procedure_parameters: Value and type setting for stored procedure parameters.
         Example: "{Parameter1: {value: "1", type: "int"}}". Type: object (or Expression with resultType
         object), itemType: StoredProcedureParameter.
        :paramtype stored_procedure_parameters: any
        :keyword partition_option: The partition mechanism that will be used for Sql read in parallel.
         Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
        :paramtype partition_option: any
        :keyword partition_settings: The settings that will be leveraged for Sql source partitioning.
        :paramtype partition_settings: ~azure.mgmt.datafactory.models.SqlPartitionSettings
        """
        super(SqlDWSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SqlDWSource'  # type: str
        self.sql_reader_query = sql_reader_query
        self.sql_reader_stored_procedure_name = sql_reader_stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class SqlDWUpsertSettings(msrest.serialization.Model):
    """Sql DW upsert option settings.

    :ivar interim_schema_name: Schema name for interim table. Type: string (or Expression with
     resultType string).
    :vartype interim_schema_name: any
    :ivar keys: Key column names for unique row identification. Type: array of strings (or
     Expression with resultType array of strings).
    :vartype keys: any
    """

    _attribute_map = {
        'interim_schema_name': {'key': 'interimSchemaName', 'type': 'object'},
        'keys': {'key': 'keys', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        interim_schema_name: Optional[Any] = None,
        keys: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword interim_schema_name: Schema name for interim table. Type: string (or Expression with
         resultType string).
        :paramtype interim_schema_name: any
        :keyword keys: Key column names for unique row identification. Type: array of strings (or
         Expression with resultType array of strings).
        :paramtype keys: any
        """
        super(SqlDWUpsertSettings, self).__init__(**kwargs)
        self.interim_schema_name = interim_schema_name
        self.keys = keys


class SqlMISink(CopySink):
    """A copy activity Azure SQL Managed Instance sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar sql_writer_stored_procedure_name: SQL writer stored procedure name. Type: string (or
     Expression with resultType string).
    :vartype sql_writer_stored_procedure_name: any
    :ivar sql_writer_table_type: SQL writer table type. Type: string (or Expression with resultType
     string).
    :vartype sql_writer_table_type: any
    :ivar pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :vartype pre_copy_script: any
    :ivar stored_procedure_parameters: SQL stored procedure parameters.
    :vartype stored_procedure_parameters: dict[str,
     ~azure.mgmt.datafactory.models.StoredProcedureParameter]
    :ivar stored_procedure_table_type_parameter_name: The stored procedure parameter name of the
     table type. Type: string (or Expression with resultType string).
    :vartype stored_procedure_table_type_parameter_name: any
    :ivar table_option: The option to handle sink table, such as autoCreate. For now only
     'autoCreate' value is supported. Type: string (or Expression with resultType string).
    :vartype table_option: any
    :ivar sql_writer_use_table_lock: Whether to use table lock during bulk copy. Type: boolean (or
     Expression with resultType boolean).
    :vartype sql_writer_use_table_lock: any
    :ivar write_behavior: White behavior when copying data into azure SQL MI. Type:
     SqlWriteBehaviorEnum (or Expression with resultType SqlWriteBehaviorEnum).
    :vartype write_behavior: any
    :ivar upsert_settings: SQL upsert settings.
    :vartype upsert_settings: ~azure.mgmt.datafactory.models.SqlUpsertSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'sql_writer_stored_procedure_name': {'key': 'sqlWriterStoredProcedureName', 'type': 'object'},
        'sql_writer_table_type': {'key': 'sqlWriterTableType', 'type': 'object'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'object'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'stored_procedure_table_type_parameter_name': {'key': 'storedProcedureTableTypeParameterName', 'type': 'object'},
        'table_option': {'key': 'tableOption', 'type': 'object'},
        'sql_writer_use_table_lock': {'key': 'sqlWriterUseTableLock', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'object'},
        'upsert_settings': {'key': 'upsertSettings', 'type': 'SqlUpsertSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        sql_writer_stored_procedure_name: Optional[Any] = None,
        sql_writer_table_type: Optional[Any] = None,
        pre_copy_script: Optional[Any] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        stored_procedure_table_type_parameter_name: Optional[Any] = None,
        table_option: Optional[Any] = None,
        sql_writer_use_table_lock: Optional[Any] = None,
        write_behavior: Optional[Any] = None,
        upsert_settings: Optional["SqlUpsertSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword sql_writer_stored_procedure_name: SQL writer stored procedure name. Type: string (or
         Expression with resultType string).
        :paramtype sql_writer_stored_procedure_name: any
        :keyword sql_writer_table_type: SQL writer table type. Type: string (or Expression with
         resultType string).
        :paramtype sql_writer_table_type: any
        :keyword pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
         string).
        :paramtype pre_copy_script: any
        :keyword stored_procedure_parameters: SQL stored procedure parameters.
        :paramtype stored_procedure_parameters: dict[str,
         ~azure.mgmt.datafactory.models.StoredProcedureParameter]
        :keyword stored_procedure_table_type_parameter_name: The stored procedure parameter name of the
         table type. Type: string (or Expression with resultType string).
        :paramtype stored_procedure_table_type_parameter_name: any
        :keyword table_option: The option to handle sink table, such as autoCreate. For now only
         'autoCreate' value is supported. Type: string (or Expression with resultType string).
        :paramtype table_option: any
        :keyword sql_writer_use_table_lock: Whether to use table lock during bulk copy. Type: boolean
         (or Expression with resultType boolean).
        :paramtype sql_writer_use_table_lock: any
        :keyword write_behavior: White behavior when copying data into azure SQL MI. Type:
         SqlWriteBehaviorEnum (or Expression with resultType SqlWriteBehaviorEnum).
        :paramtype write_behavior: any
        :keyword upsert_settings: SQL upsert settings.
        :paramtype upsert_settings: ~azure.mgmt.datafactory.models.SqlUpsertSettings
        """
        super(SqlMISink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'SqlMISink'  # type: str
        self.sql_writer_stored_procedure_name = sql_writer_stored_procedure_name
        self.sql_writer_table_type = sql_writer_table_type
        self.pre_copy_script = pre_copy_script
        self.stored_procedure_parameters = stored_procedure_parameters
        self.stored_procedure_table_type_parameter_name = stored_procedure_table_type_parameter_name
        self.table_option = table_option
        self.sql_writer_use_table_lock = sql_writer_use_table_lock
        self.write_behavior = write_behavior
        self.upsert_settings = upsert_settings


class SqlMISource(TabularSource):
    """A copy activity Azure SQL Managed Instance source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar sql_reader_query: SQL reader query. Type: string (or Expression with resultType string).
    :vartype sql_reader_query: any
    :ivar sql_reader_stored_procedure_name: Name of the stored procedure for a Azure SQL Managed
     Instance source. This cannot be used at the same time as SqlReaderQuery. Type: string (or
     Expression with resultType string).
    :vartype sql_reader_stored_procedure_name: any
    :ivar stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}".
    :vartype stored_procedure_parameters: dict[str,
     ~azure.mgmt.datafactory.models.StoredProcedureParameter]
    :ivar produce_additional_types: Which additional types to produce.
    :vartype produce_additional_types: any
    :ivar partition_option: The partition mechanism that will be used for Sql read in parallel.
     Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
    :vartype partition_option: any
    :ivar partition_settings: The settings that will be leveraged for Sql source partitioning.
    :vartype partition_settings: ~azure.mgmt.datafactory.models.SqlPartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'sql_reader_query': {'key': 'sqlReaderQuery', 'type': 'object'},
        'sql_reader_stored_procedure_name': {'key': 'sqlReaderStoredProcedureName', 'type': 'object'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'produce_additional_types': {'key': 'produceAdditionalTypes', 'type': 'object'},
        'partition_option': {'key': 'partitionOption', 'type': 'object'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'SqlPartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        sql_reader_query: Optional[Any] = None,
        sql_reader_stored_procedure_name: Optional[Any] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        produce_additional_types: Optional[Any] = None,
        partition_option: Optional[Any] = None,
        partition_settings: Optional["SqlPartitionSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword sql_reader_query: SQL reader query. Type: string (or Expression with resultType
         string).
        :paramtype sql_reader_query: any
        :keyword sql_reader_stored_procedure_name: Name of the stored procedure for a Azure SQL Managed
         Instance source. This cannot be used at the same time as SqlReaderQuery. Type: string (or
         Expression with resultType string).
        :paramtype sql_reader_stored_procedure_name: any
        :keyword stored_procedure_parameters: Value and type setting for stored procedure parameters.
         Example: "{Parameter1: {value: "1", type: "int"}}".
        :paramtype stored_procedure_parameters: dict[str,
         ~azure.mgmt.datafactory.models.StoredProcedureParameter]
        :keyword produce_additional_types: Which additional types to produce.
        :paramtype produce_additional_types: any
        :keyword partition_option: The partition mechanism that will be used for Sql read in parallel.
         Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
        :paramtype partition_option: any
        :keyword partition_settings: The settings that will be leveraged for Sql source partitioning.
        :paramtype partition_settings: ~azure.mgmt.datafactory.models.SqlPartitionSettings
        """
        super(SqlMISource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SqlMISource'  # type: str
        self.sql_reader_query = sql_reader_query
        self.sql_reader_stored_procedure_name = sql_reader_stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters
        self.produce_additional_types = produce_additional_types
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class SqlPartitionSettings(msrest.serialization.Model):
    """The settings that will be leveraged for Sql source partitioning.

    :ivar partition_column_name: The name of the column in integer or datetime type that will be
     used for proceeding partitioning. If not specified, the primary key of the table is
     auto-detected and used as the partition column. Type: string (or Expression with resultType
     string).
    :vartype partition_column_name: any
    :ivar partition_upper_bound: The maximum value of the partition column for partition range
     splitting. This value is used to decide the partition stride, not for filtering the rows in
     table. All rows in the table or query result will be partitioned and copied. Type: string (or
     Expression with resultType string).
    :vartype partition_upper_bound: any
    :ivar partition_lower_bound: The minimum value of the partition column for partition range
     splitting. This value is used to decide the partition stride, not for filtering the rows in
     table. All rows in the table or query result will be partitioned and copied. Type: string (or
     Expression with resultType string).
    :vartype partition_lower_bound: any
    """

    _attribute_map = {
        'partition_column_name': {'key': 'partitionColumnName', 'type': 'object'},
        'partition_upper_bound': {'key': 'partitionUpperBound', 'type': 'object'},
        'partition_lower_bound': {'key': 'partitionLowerBound', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        partition_column_name: Optional[Any] = None,
        partition_upper_bound: Optional[Any] = None,
        partition_lower_bound: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword partition_column_name: The name of the column in integer or datetime type that will be
         used for proceeding partitioning. If not specified, the primary key of the table is
         auto-detected and used as the partition column. Type: string (or Expression with resultType
         string).
        :paramtype partition_column_name: any
        :keyword partition_upper_bound: The maximum value of the partition column for partition range
         splitting. This value is used to decide the partition stride, not for filtering the rows in
         table. All rows in the table or query result will be partitioned and copied. Type: string (or
         Expression with resultType string).
        :paramtype partition_upper_bound: any
        :keyword partition_lower_bound: The minimum value of the partition column for partition range
         splitting. This value is used to decide the partition stride, not for filtering the rows in
         table. All rows in the table or query result will be partitioned and copied. Type: string (or
         Expression with resultType string).
        :paramtype partition_lower_bound: any
        """
        super(SqlPartitionSettings, self).__init__(**kwargs)
        self.partition_column_name = partition_column_name
        self.partition_upper_bound = partition_upper_bound
        self.partition_lower_bound = partition_lower_bound


class SqlServerLinkedService(LinkedService):
    """SQL Server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Required. The connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar user_name: The on-premises Windows authentication user name. Type: string (or Expression
     with resultType string).
    :vartype user_name: any
    :ivar password: The on-premises Windows authentication password.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    :ivar always_encrypted_settings: Sql always encrypted properties.
    :vartype always_encrypted_settings: ~azure.mgmt.datafactory.models.SqlAlwaysEncryptedProperties
    """

    _validation = {
        'type': {'required': True},
        'connection_string': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
        'always_encrypted_settings': {'key': 'typeProperties.alwaysEncryptedSettings', 'type': 'SqlAlwaysEncryptedProperties'},
    }

    def __init__(
        self,
        *,
        connection_string: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        always_encrypted_settings: Optional["SqlAlwaysEncryptedProperties"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Required. The connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword user_name: The on-premises Windows authentication user name. Type: string (or
         Expression with resultType string).
        :paramtype user_name: any
        :keyword password: The on-premises Windows authentication password.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        :keyword always_encrypted_settings: Sql always encrypted properties.
        :paramtype always_encrypted_settings:
         ~azure.mgmt.datafactory.models.SqlAlwaysEncryptedProperties
        """
        super(SqlServerLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'SqlServer'  # type: str
        self.connection_string = connection_string
        self.user_name = user_name
        self.password = password
        self.encrypted_credential = encrypted_credential
        self.always_encrypted_settings = always_encrypted_settings


class SqlServerSink(CopySink):
    """A copy activity SQL server sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar sql_writer_stored_procedure_name: SQL writer stored procedure name. Type: string (or
     Expression with resultType string).
    :vartype sql_writer_stored_procedure_name: any
    :ivar sql_writer_table_type: SQL writer table type. Type: string (or Expression with resultType
     string).
    :vartype sql_writer_table_type: any
    :ivar pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :vartype pre_copy_script: any
    :ivar stored_procedure_parameters: SQL stored procedure parameters.
    :vartype stored_procedure_parameters: dict[str,
     ~azure.mgmt.datafactory.models.StoredProcedureParameter]
    :ivar stored_procedure_table_type_parameter_name: The stored procedure parameter name of the
     table type. Type: string (or Expression with resultType string).
    :vartype stored_procedure_table_type_parameter_name: any
    :ivar table_option: The option to handle sink table, such as autoCreate. For now only
     'autoCreate' value is supported. Type: string (or Expression with resultType string).
    :vartype table_option: any
    :ivar sql_writer_use_table_lock: Whether to use table lock during bulk copy. Type: boolean (or
     Expression with resultType boolean).
    :vartype sql_writer_use_table_lock: any
    :ivar write_behavior: Write behavior when copying data into sql server. Type:
     SqlWriteBehaviorEnum (or Expression with resultType SqlWriteBehaviorEnum).
    :vartype write_behavior: any
    :ivar upsert_settings: SQL upsert settings.
    :vartype upsert_settings: ~azure.mgmt.datafactory.models.SqlUpsertSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'sql_writer_stored_procedure_name': {'key': 'sqlWriterStoredProcedureName', 'type': 'object'},
        'sql_writer_table_type': {'key': 'sqlWriterTableType', 'type': 'object'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'object'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'stored_procedure_table_type_parameter_name': {'key': 'storedProcedureTableTypeParameterName', 'type': 'object'},
        'table_option': {'key': 'tableOption', 'type': 'object'},
        'sql_writer_use_table_lock': {'key': 'sqlWriterUseTableLock', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'object'},
        'upsert_settings': {'key': 'upsertSettings', 'type': 'SqlUpsertSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        sql_writer_stored_procedure_name: Optional[Any] = None,
        sql_writer_table_type: Optional[Any] = None,
        pre_copy_script: Optional[Any] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        stored_procedure_table_type_parameter_name: Optional[Any] = None,
        table_option: Optional[Any] = None,
        sql_writer_use_table_lock: Optional[Any] = None,
        write_behavior: Optional[Any] = None,
        upsert_settings: Optional["SqlUpsertSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword sql_writer_stored_procedure_name: SQL writer stored procedure name. Type: string (or
         Expression with resultType string).
        :paramtype sql_writer_stored_procedure_name: any
        :keyword sql_writer_table_type: SQL writer table type. Type: string (or Expression with
         resultType string).
        :paramtype sql_writer_table_type: any
        :keyword pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
         string).
        :paramtype pre_copy_script: any
        :keyword stored_procedure_parameters: SQL stored procedure parameters.
        :paramtype stored_procedure_parameters: dict[str,
         ~azure.mgmt.datafactory.models.StoredProcedureParameter]
        :keyword stored_procedure_table_type_parameter_name: The stored procedure parameter name of the
         table type. Type: string (or Expression with resultType string).
        :paramtype stored_procedure_table_type_parameter_name: any
        :keyword table_option: The option to handle sink table, such as autoCreate. For now only
         'autoCreate' value is supported. Type: string (or Expression with resultType string).
        :paramtype table_option: any
        :keyword sql_writer_use_table_lock: Whether to use table lock during bulk copy. Type: boolean
         (or Expression with resultType boolean).
        :paramtype sql_writer_use_table_lock: any
        :keyword write_behavior: Write behavior when copying data into sql server. Type:
         SqlWriteBehaviorEnum (or Expression with resultType SqlWriteBehaviorEnum).
        :paramtype write_behavior: any
        :keyword upsert_settings: SQL upsert settings.
        :paramtype upsert_settings: ~azure.mgmt.datafactory.models.SqlUpsertSettings
        """
        super(SqlServerSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'SqlServerSink'  # type: str
        self.sql_writer_stored_procedure_name = sql_writer_stored_procedure_name
        self.sql_writer_table_type = sql_writer_table_type
        self.pre_copy_script = pre_copy_script
        self.stored_procedure_parameters = stored_procedure_parameters
        self.stored_procedure_table_type_parameter_name = stored_procedure_table_type_parameter_name
        self.table_option = table_option
        self.sql_writer_use_table_lock = sql_writer_use_table_lock
        self.write_behavior = write_behavior
        self.upsert_settings = upsert_settings


class SqlServerSource(TabularSource):
    """A copy activity SQL server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar sql_reader_query: SQL reader query. Type: string (or Expression with resultType string).
    :vartype sql_reader_query: any
    :ivar sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Database source.
     This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression with
     resultType string).
    :vartype sql_reader_stored_procedure_name: any
    :ivar stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}".
    :vartype stored_procedure_parameters: dict[str,
     ~azure.mgmt.datafactory.models.StoredProcedureParameter]
    :ivar produce_additional_types: Which additional types to produce.
    :vartype produce_additional_types: any
    :ivar partition_option: The partition mechanism that will be used for Sql read in parallel.
     Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
    :vartype partition_option: any
    :ivar partition_settings: The settings that will be leveraged for Sql source partitioning.
    :vartype partition_settings: ~azure.mgmt.datafactory.models.SqlPartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'sql_reader_query': {'key': 'sqlReaderQuery', 'type': 'object'},
        'sql_reader_stored_procedure_name': {'key': 'sqlReaderStoredProcedureName', 'type': 'object'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'produce_additional_types': {'key': 'produceAdditionalTypes', 'type': 'object'},
        'partition_option': {'key': 'partitionOption', 'type': 'object'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'SqlPartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        sql_reader_query: Optional[Any] = None,
        sql_reader_stored_procedure_name: Optional[Any] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        produce_additional_types: Optional[Any] = None,
        partition_option: Optional[Any] = None,
        partition_settings: Optional["SqlPartitionSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword sql_reader_query: SQL reader query. Type: string (or Expression with resultType
         string).
        :paramtype sql_reader_query: any
        :keyword sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Database
         source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression
         with resultType string).
        :paramtype sql_reader_stored_procedure_name: any
        :keyword stored_procedure_parameters: Value and type setting for stored procedure parameters.
         Example: "{Parameter1: {value: "1", type: "int"}}".
        :paramtype stored_procedure_parameters: dict[str,
         ~azure.mgmt.datafactory.models.StoredProcedureParameter]
        :keyword produce_additional_types: Which additional types to produce.
        :paramtype produce_additional_types: any
        :keyword partition_option: The partition mechanism that will be used for Sql read in parallel.
         Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
        :paramtype partition_option: any
        :keyword partition_settings: The settings that will be leveraged for Sql source partitioning.
        :paramtype partition_settings: ~azure.mgmt.datafactory.models.SqlPartitionSettings
        """
        super(SqlServerSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SqlServerSource'  # type: str
        self.sql_reader_query = sql_reader_query
        self.sql_reader_stored_procedure_name = sql_reader_stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters
        self.produce_additional_types = produce_additional_types
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class SqlServerStoredProcedureActivity(ExecutionActivity):
    """SQL stored procedure activity type.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar stored_procedure_name: Required. Stored procedure name. Type: string (or Expression with
     resultType string).
    :vartype stored_procedure_name: any
    :ivar stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}".
    :vartype stored_procedure_parameters: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'stored_procedure_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'stored_procedure_name': {'key': 'typeProperties.storedProcedureName', 'type': 'object'},
        'stored_procedure_parameters': {'key': 'typeProperties.storedProcedureParameters', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        stored_procedure_name: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        stored_procedure_parameters: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword stored_procedure_name: Required. Stored procedure name. Type: string (or Expression
         with resultType string).
        :paramtype stored_procedure_name: any
        :keyword stored_procedure_parameters: Value and type setting for stored procedure parameters.
         Example: "{Parameter1: {value: "1", type: "int"}}".
        :paramtype stored_procedure_parameters: any
        """
        super(SqlServerStoredProcedureActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'SqlServerStoredProcedure'  # type: str
        self.stored_procedure_name = stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters


class SqlServerTableDataset(Dataset):
    """The on-premises SQL Server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar schema_type_properties_schema: The schema name of the SQL Server dataset. Type: string
     (or Expression with resultType string).
    :vartype schema_type_properties_schema: any
    :ivar table: The table name of the SQL Server dataset. Type: string (or Expression with
     resultType string).
    :vartype table: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        table: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword schema_type_properties_schema: The schema name of the SQL Server dataset. Type: string
         (or Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        :keyword table: The table name of the SQL Server dataset. Type: string (or Expression with
         resultType string).
        :paramtype table: any
        """
        super(SqlServerTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SqlServerTable'  # type: str
        self.table_name = table_name
        self.schema_type_properties_schema = schema_type_properties_schema
        self.table = table


class SqlSink(CopySink):
    """A copy activity SQL sink.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy sink type.Constant filled by server.
    :vartype type: str
    :ivar write_batch_size: Write batch size. Type: integer (or Expression with resultType
     integer), minimum: 0.
    :vartype write_batch_size: any
    :ivar write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype write_batch_timeout: any
    :ivar sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
     integer).
    :vartype sink_retry_count: any
    :ivar sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype sink_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the sink data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar sql_writer_stored_procedure_name: SQL writer stored procedure name. Type: string (or
     Expression with resultType string).
    :vartype sql_writer_stored_procedure_name: any
    :ivar sql_writer_table_type: SQL writer table type. Type: string (or Expression with resultType
     string).
    :vartype sql_writer_table_type: any
    :ivar pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
     string).
    :vartype pre_copy_script: any
    :ivar stored_procedure_parameters: SQL stored procedure parameters.
    :vartype stored_procedure_parameters: dict[str,
     ~azure.mgmt.datafactory.models.StoredProcedureParameter]
    :ivar stored_procedure_table_type_parameter_name: The stored procedure parameter name of the
     table type. Type: string (or Expression with resultType string).
    :vartype stored_procedure_table_type_parameter_name: any
    :ivar table_option: The option to handle sink table, such as autoCreate. For now only
     'autoCreate' value is supported. Type: string (or Expression with resultType string).
    :vartype table_option: any
    :ivar sql_writer_use_table_lock: Whether to use table lock during bulk copy. Type: boolean (or
     Expression with resultType boolean).
    :vartype sql_writer_use_table_lock: any
    :ivar write_behavior: Write behavior when copying data into sql. Type: SqlWriteBehaviorEnum (or
     Expression with resultType SqlWriteBehaviorEnum).
    :vartype write_behavior: any
    :ivar upsert_settings: SQL upsert settings.
    :vartype upsert_settings: ~azure.mgmt.datafactory.models.SqlUpsertSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'write_batch_size': {'key': 'writeBatchSize', 'type': 'object'},
        'write_batch_timeout': {'key': 'writeBatchTimeout', 'type': 'object'},
        'sink_retry_count': {'key': 'sinkRetryCount', 'type': 'object'},
        'sink_retry_wait': {'key': 'sinkRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'sql_writer_stored_procedure_name': {'key': 'sqlWriterStoredProcedureName', 'type': 'object'},
        'sql_writer_table_type': {'key': 'sqlWriterTableType', 'type': 'object'},
        'pre_copy_script': {'key': 'preCopyScript', 'type': 'object'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'stored_procedure_table_type_parameter_name': {'key': 'storedProcedureTableTypeParameterName', 'type': 'object'},
        'table_option': {'key': 'tableOption', 'type': 'object'},
        'sql_writer_use_table_lock': {'key': 'sqlWriterUseTableLock', 'type': 'object'},
        'write_behavior': {'key': 'writeBehavior', 'type': 'object'},
        'upsert_settings': {'key': 'upsertSettings', 'type': 'SqlUpsertSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        write_batch_size: Optional[Any] = None,
        write_batch_timeout: Optional[Any] = None,
        sink_retry_count: Optional[Any] = None,
        sink_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        sql_writer_stored_procedure_name: Optional[Any] = None,
        sql_writer_table_type: Optional[Any] = None,
        pre_copy_script: Optional[Any] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        stored_procedure_table_type_parameter_name: Optional[Any] = None,
        table_option: Optional[Any] = None,
        sql_writer_use_table_lock: Optional[Any] = None,
        write_behavior: Optional[Any] = None,
        upsert_settings: Optional["SqlUpsertSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword write_batch_size: Write batch size. Type: integer (or Expression with resultType
         integer), minimum: 0.
        :paramtype write_batch_size: any
        :keyword write_batch_timeout: Write batch timeout. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype write_batch_timeout: any
        :keyword sink_retry_count: Sink retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype sink_retry_count: any
        :keyword sink_retry_wait: Sink retry wait. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype sink_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the sink data
         store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword sql_writer_stored_procedure_name: SQL writer stored procedure name. Type: string (or
         Expression with resultType string).
        :paramtype sql_writer_stored_procedure_name: any
        :keyword sql_writer_table_type: SQL writer table type. Type: string (or Expression with
         resultType string).
        :paramtype sql_writer_table_type: any
        :keyword pre_copy_script: SQL pre-copy script. Type: string (or Expression with resultType
         string).
        :paramtype pre_copy_script: any
        :keyword stored_procedure_parameters: SQL stored procedure parameters.
        :paramtype stored_procedure_parameters: dict[str,
         ~azure.mgmt.datafactory.models.StoredProcedureParameter]
        :keyword stored_procedure_table_type_parameter_name: The stored procedure parameter name of the
         table type. Type: string (or Expression with resultType string).
        :paramtype stored_procedure_table_type_parameter_name: any
        :keyword table_option: The option to handle sink table, such as autoCreate. For now only
         'autoCreate' value is supported. Type: string (or Expression with resultType string).
        :paramtype table_option: any
        :keyword sql_writer_use_table_lock: Whether to use table lock during bulk copy. Type: boolean
         (or Expression with resultType boolean).
        :paramtype sql_writer_use_table_lock: any
        :keyword write_behavior: Write behavior when copying data into sql. Type: SqlWriteBehaviorEnum
         (or Expression with resultType SqlWriteBehaviorEnum).
        :paramtype write_behavior: any
        :keyword upsert_settings: SQL upsert settings.
        :paramtype upsert_settings: ~azure.mgmt.datafactory.models.SqlUpsertSettings
        """
        super(SqlSink, self).__init__(additional_properties=additional_properties, write_batch_size=write_batch_size, write_batch_timeout=write_batch_timeout, sink_retry_count=sink_retry_count, sink_retry_wait=sink_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'SqlSink'  # type: str
        self.sql_writer_stored_procedure_name = sql_writer_stored_procedure_name
        self.sql_writer_table_type = sql_writer_table_type
        self.pre_copy_script = pre_copy_script
        self.stored_procedure_parameters = stored_procedure_parameters
        self.stored_procedure_table_type_parameter_name = stored_procedure_table_type_parameter_name
        self.table_option = table_option
        self.sql_writer_use_table_lock = sql_writer_use_table_lock
        self.write_behavior = write_behavior
        self.upsert_settings = upsert_settings


class SqlSource(TabularSource):
    """A copy activity SQL source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar sql_reader_query: SQL reader query. Type: string (or Expression with resultType string).
    :vartype sql_reader_query: any
    :ivar sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Database source.
     This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression with
     resultType string).
    :vartype sql_reader_stored_procedure_name: any
    :ivar stored_procedure_parameters: Value and type setting for stored procedure parameters.
     Example: "{Parameter1: {value: "1", type: "int"}}".
    :vartype stored_procedure_parameters: dict[str,
     ~azure.mgmt.datafactory.models.StoredProcedureParameter]
    :ivar isolation_level: Specifies the transaction locking behavior for the SQL source. Allowed
     values: ReadCommitted/ReadUncommitted/RepeatableRead/Serializable/Snapshot. The default value
     is ReadCommitted. Type: string (or Expression with resultType string).
    :vartype isolation_level: any
    :ivar partition_option: The partition mechanism that will be used for Sql read in parallel.
     Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
    :vartype partition_option: any
    :ivar partition_settings: The settings that will be leveraged for Sql source partitioning.
    :vartype partition_settings: ~azure.mgmt.datafactory.models.SqlPartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'sql_reader_query': {'key': 'sqlReaderQuery', 'type': 'object'},
        'sql_reader_stored_procedure_name': {'key': 'sqlReaderStoredProcedureName', 'type': 'object'},
        'stored_procedure_parameters': {'key': 'storedProcedureParameters', 'type': '{StoredProcedureParameter}'},
        'isolation_level': {'key': 'isolationLevel', 'type': 'object'},
        'partition_option': {'key': 'partitionOption', 'type': 'object'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'SqlPartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        sql_reader_query: Optional[Any] = None,
        sql_reader_stored_procedure_name: Optional[Any] = None,
        stored_procedure_parameters: Optional[Dict[str, "StoredProcedureParameter"]] = None,
        isolation_level: Optional[Any] = None,
        partition_option: Optional[Any] = None,
        partition_settings: Optional["SqlPartitionSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword sql_reader_query: SQL reader query. Type: string (or Expression with resultType
         string).
        :paramtype sql_reader_query: any
        :keyword sql_reader_stored_procedure_name: Name of the stored procedure for a SQL Database
         source. This cannot be used at the same time as SqlReaderQuery. Type: string (or Expression
         with resultType string).
        :paramtype sql_reader_stored_procedure_name: any
        :keyword stored_procedure_parameters: Value and type setting for stored procedure parameters.
         Example: "{Parameter1: {value: "1", type: "int"}}".
        :paramtype stored_procedure_parameters: dict[str,
         ~azure.mgmt.datafactory.models.StoredProcedureParameter]
        :keyword isolation_level: Specifies the transaction locking behavior for the SQL source.
         Allowed values: ReadCommitted/ReadUncommitted/RepeatableRead/Serializable/Snapshot. The default
         value is ReadCommitted. Type: string (or Expression with resultType string).
        :paramtype isolation_level: any
        :keyword partition_option: The partition mechanism that will be used for Sql read in parallel.
         Possible values include: "None", "PhysicalPartitionsOfTable", "DynamicRange".
        :paramtype partition_option: any
        :keyword partition_settings: The settings that will be leveraged for Sql source partitioning.
        :paramtype partition_settings: ~azure.mgmt.datafactory.models.SqlPartitionSettings
        """
        super(SqlSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SqlSource'  # type: str
        self.sql_reader_query = sql_reader_query
        self.sql_reader_stored_procedure_name = sql_reader_stored_procedure_name
        self.stored_procedure_parameters = stored_procedure_parameters
        self.isolation_level = isolation_level
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class SqlUpsertSettings(msrest.serialization.Model):
    """Sql upsert option settings.

    :ivar use_temp_db: Specifies whether to use temp db for upsert interim table. Type: boolean (or
     Expression with resultType boolean).
    :vartype use_temp_db: any
    :ivar interim_schema_name: Schema name for interim table. Type: string (or Expression with
     resultType string).
    :vartype interim_schema_name: any
    :ivar keys: Key column names for unique row identification. Type: array of strings (or
     Expression with resultType array of strings).
    :vartype keys: any
    """

    _attribute_map = {
        'use_temp_db': {'key': 'useTempDB', 'type': 'object'},
        'interim_schema_name': {'key': 'interimSchemaName', 'type': 'object'},
        'keys': {'key': 'keys', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        use_temp_db: Optional[Any] = None,
        interim_schema_name: Optional[Any] = None,
        keys: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword use_temp_db: Specifies whether to use temp db for upsert interim table. Type: boolean
         (or Expression with resultType boolean).
        :paramtype use_temp_db: any
        :keyword interim_schema_name: Schema name for interim table. Type: string (or Expression with
         resultType string).
        :paramtype interim_schema_name: any
        :keyword keys: Key column names for unique row identification. Type: array of strings (or
         Expression with resultType array of strings).
        :paramtype keys: any
        """
        super(SqlUpsertSettings, self).__init__(**kwargs)
        self.use_temp_db = use_temp_db
        self.interim_schema_name = interim_schema_name
        self.keys = keys


class SquareLinkedService(LinkedService):
    """Square Service linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_properties: Properties used to connect to Square. It is mutually exclusive
     with any other properties in the linked service. Type: object.
    :vartype connection_properties: any
    :ivar host: The URLof the Square instance. (i.e. mystore.mysquare.com).
    :vartype host: any
    :ivar client_id: The client ID associated with your Square application.
    :vartype client_id: any
    :ivar client_secret: The client secret associated with your Square application.
    :vartype client_secret: ~azure.mgmt.datafactory.models.SecretBase
    :ivar redirect_uri: The redirect URL assigned in the Square application dashboard. (i.e.
     http://localhost:2500).
    :vartype redirect_uri: any
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_properties': {'key': 'typeProperties.connectionProperties', 'type': 'object'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'client_id': {'key': 'typeProperties.clientId', 'type': 'object'},
        'client_secret': {'key': 'typeProperties.clientSecret', 'type': 'SecretBase'},
        'redirect_uri': {'key': 'typeProperties.redirectUri', 'type': 'object'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_properties: Optional[Any] = None,
        host: Optional[Any] = None,
        client_id: Optional[Any] = None,
        client_secret: Optional["SecretBase"] = None,
        redirect_uri: Optional[Any] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_properties: Properties used to connect to Square. It is mutually exclusive
         with any other properties in the linked service. Type: object.
        :paramtype connection_properties: any
        :keyword host: The URLof the Square instance. (i.e. mystore.mysquare.com).
        :paramtype host: any
        :keyword client_id: The client ID associated with your Square application.
        :paramtype client_id: any
        :keyword client_secret: The client secret associated with your Square application.
        :paramtype client_secret: ~azure.mgmt.datafactory.models.SecretBase
        :keyword redirect_uri: The redirect URL assigned in the Square application dashboard. (i.e.
         http://localhost:2500).
        :paramtype redirect_uri: any
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true.
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true.
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SquareLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Square'  # type: str
        self.connection_properties = connection_properties
        self.host = host
        self.client_id = client_id
        self.client_secret = client_secret
        self.redirect_uri = redirect_uri
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class SquareObjectDataset(Dataset):
    """Square Service dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(SquareObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SquareObject'  # type: str
        self.table_name = table_name


class SquareSource(TabularSource):
    """A copy activity Square Service source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(SquareSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SquareSource'  # type: str
        self.query = query


class SSISAccessCredential(msrest.serialization.Model):
    """SSIS access credential.

    All required parameters must be populated in order to send to Azure.

    :ivar domain: Required. Domain for windows authentication.
    :vartype domain: any
    :ivar user_name: Required. UseName for windows authentication.
    :vartype user_name: any
    :ivar password: Required. Password for windows authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    """

    _validation = {
        'domain': {'required': True},
        'user_name': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'domain': {'key': 'domain', 'type': 'object'},
        'user_name': {'key': 'userName', 'type': 'object'},
        'password': {'key': 'password', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        domain: Any,
        user_name: Any,
        password: "SecretBase",
        **kwargs
    ):
        """
        :keyword domain: Required. Domain for windows authentication.
        :paramtype domain: any
        :keyword user_name: Required. UseName for windows authentication.
        :paramtype user_name: any
        :keyword password: Required. Password for windows authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        """
        super(SSISAccessCredential, self).__init__(**kwargs)
        self.domain = domain
        self.user_name = user_name
        self.password = password


class SSISChildPackage(msrest.serialization.Model):
    """SSIS embedded child package.

    All required parameters must be populated in order to send to Azure.

    :ivar package_path: Required. Path for embedded child package. Type: string (or Expression with
     resultType string).
    :vartype package_path: any
    :ivar package_name: Name for embedded child package.
    :vartype package_name: str
    :ivar package_content: Required. Content for embedded child package. Type: string (or
     Expression with resultType string).
    :vartype package_content: any
    :ivar package_last_modified_date: Last modified date for embedded child package.
    :vartype package_last_modified_date: str
    """

    _validation = {
        'package_path': {'required': True},
        'package_content': {'required': True},
    }

    _attribute_map = {
        'package_path': {'key': 'packagePath', 'type': 'object'},
        'package_name': {'key': 'packageName', 'type': 'str'},
        'package_content': {'key': 'packageContent', 'type': 'object'},
        'package_last_modified_date': {'key': 'packageLastModifiedDate', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        package_path: Any,
        package_content: Any,
        package_name: Optional[str] = None,
        package_last_modified_date: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword package_path: Required. Path for embedded child package. Type: string (or Expression
         with resultType string).
        :paramtype package_path: any
        :keyword package_name: Name for embedded child package.
        :paramtype package_name: str
        :keyword package_content: Required. Content for embedded child package. Type: string (or
         Expression with resultType string).
        :paramtype package_content: any
        :keyword package_last_modified_date: Last modified date for embedded child package.
        :paramtype package_last_modified_date: str
        """
        super(SSISChildPackage, self).__init__(**kwargs)
        self.package_path = package_path
        self.package_name = package_name
        self.package_content = package_content
        self.package_last_modified_date = package_last_modified_date


class SsisObjectMetadata(msrest.serialization.Model):
    """SSIS object metadata.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: SsisEnvironment, SsisFolder, SsisPackage, SsisProject.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of metadata.Constant filled by server. Possible values include:
     "Folder", "Project", "Package", "Environment".
    :vartype type: str or ~azure.mgmt.datafactory.models.SsisObjectMetadataType
    :ivar id: Metadata id.
    :vartype id: long
    :ivar name: Metadata name.
    :vartype name: str
    :ivar description: Metadata description.
    :vartype description: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
    }

    _subtype_map = {
        'type': {'Environment': 'SsisEnvironment', 'Folder': 'SsisFolder', 'Package': 'SsisPackage', 'Project': 'SsisProject'}
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword id: Metadata id.
        :paramtype id: long
        :keyword name: Metadata name.
        :paramtype name: str
        :keyword description: Metadata description.
        :paramtype description: str
        """
        super(SsisObjectMetadata, self).__init__(**kwargs)
        self.type = None  # type: Optional[str]
        self.id = id
        self.name = name
        self.description = description


class SsisEnvironment(SsisObjectMetadata):
    """Ssis environment.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of metadata.Constant filled by server. Possible values include:
     "Folder", "Project", "Package", "Environment".
    :vartype type: str or ~azure.mgmt.datafactory.models.SsisObjectMetadataType
    :ivar id: Metadata id.
    :vartype id: long
    :ivar name: Metadata name.
    :vartype name: str
    :ivar description: Metadata description.
    :vartype description: str
    :ivar folder_id: Folder id which contains environment.
    :vartype folder_id: long
    :ivar variables: Variable in environment.
    :vartype variables: list[~azure.mgmt.datafactory.models.SsisVariable]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'folder_id': {'key': 'folderId', 'type': 'long'},
        'variables': {'key': 'variables', 'type': '[SsisVariable]'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        folder_id: Optional[int] = None,
        variables: Optional[List["SsisVariable"]] = None,
        **kwargs
    ):
        """
        :keyword id: Metadata id.
        :paramtype id: long
        :keyword name: Metadata name.
        :paramtype name: str
        :keyword description: Metadata description.
        :paramtype description: str
        :keyword folder_id: Folder id which contains environment.
        :paramtype folder_id: long
        :keyword variables: Variable in environment.
        :paramtype variables: list[~azure.mgmt.datafactory.models.SsisVariable]
        """
        super(SsisEnvironment, self).__init__(id=id, name=name, description=description, **kwargs)
        self.type = 'Environment'  # type: str
        self.folder_id = folder_id
        self.variables = variables


class SsisEnvironmentReference(msrest.serialization.Model):
    """Ssis environment reference.

    :ivar id: Environment reference id.
    :vartype id: long
    :ivar environment_folder_name: Environment folder name.
    :vartype environment_folder_name: str
    :ivar environment_name: Environment name.
    :vartype environment_name: str
    :ivar reference_type: Reference type.
    :vartype reference_type: str
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'long'},
        'environment_folder_name': {'key': 'environmentFolderName', 'type': 'str'},
        'environment_name': {'key': 'environmentName', 'type': 'str'},
        'reference_type': {'key': 'referenceType', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        environment_folder_name: Optional[str] = None,
        environment_name: Optional[str] = None,
        reference_type: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword id: Environment reference id.
        :paramtype id: long
        :keyword environment_folder_name: Environment folder name.
        :paramtype environment_folder_name: str
        :keyword environment_name: Environment name.
        :paramtype environment_name: str
        :keyword reference_type: Reference type.
        :paramtype reference_type: str
        """
        super(SsisEnvironmentReference, self).__init__(**kwargs)
        self.id = id
        self.environment_folder_name = environment_folder_name
        self.environment_name = environment_name
        self.reference_type = reference_type


class SSISExecutionCredential(msrest.serialization.Model):
    """SSIS package execution credential.

    All required parameters must be populated in order to send to Azure.

    :ivar domain: Required. Domain for windows authentication.
    :vartype domain: any
    :ivar user_name: Required. UseName for windows authentication.
    :vartype user_name: any
    :ivar password: Required. Password for windows authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecureString
    """

    _validation = {
        'domain': {'required': True},
        'user_name': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'domain': {'key': 'domain', 'type': 'object'},
        'user_name': {'key': 'userName', 'type': 'object'},
        'password': {'key': 'password', 'type': 'SecureString'},
    }

    def __init__(
        self,
        *,
        domain: Any,
        user_name: Any,
        password: "SecureString",
        **kwargs
    ):
        """
        :keyword domain: Required. Domain for windows authentication.
        :paramtype domain: any
        :keyword user_name: Required. UseName for windows authentication.
        :paramtype user_name: any
        :keyword password: Required. Password for windows authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecureString
        """
        super(SSISExecutionCredential, self).__init__(**kwargs)
        self.domain = domain
        self.user_name = user_name
        self.password = password


class SSISExecutionParameter(msrest.serialization.Model):
    """SSIS execution parameter.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. SSIS package execution parameter value. Type: string (or Expression with
     resultType string).
    :vartype value: any
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        value: Any,
        **kwargs
    ):
        """
        :keyword value: Required. SSIS package execution parameter value. Type: string (or Expression
         with resultType string).
        :paramtype value: any
        """
        super(SSISExecutionParameter, self).__init__(**kwargs)
        self.value = value


class SsisFolder(SsisObjectMetadata):
    """Ssis folder.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of metadata.Constant filled by server. Possible values include:
     "Folder", "Project", "Package", "Environment".
    :vartype type: str or ~azure.mgmt.datafactory.models.SsisObjectMetadataType
    :ivar id: Metadata id.
    :vartype id: long
    :ivar name: Metadata name.
    :vartype name: str
    :ivar description: Metadata description.
    :vartype description: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword id: Metadata id.
        :paramtype id: long
        :keyword name: Metadata name.
        :paramtype name: str
        :keyword description: Metadata description.
        :paramtype description: str
        """
        super(SsisFolder, self).__init__(id=id, name=name, description=description, **kwargs)
        self.type = 'Folder'  # type: str


class SSISLogLocation(msrest.serialization.Model):
    """SSIS package execution log location.

    All required parameters must be populated in order to send to Azure.

    :ivar log_path: Required. The SSIS package execution log path. Type: string (or Expression with
     resultType string).
    :vartype log_path: any
    :ivar type: Required. The type of SSIS log location. Possible values include: "File".
    :vartype type: str or ~azure.mgmt.datafactory.models.SsisLogLocationType
    :ivar access_credential: The package execution log access credential.
    :vartype access_credential: ~azure.mgmt.datafactory.models.SSISAccessCredential
    :ivar log_refresh_interval: Specifies the interval to refresh log. The default interval is 5
     minutes. Type: string (or Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype log_refresh_interval: any
    """

    _validation = {
        'log_path': {'required': True},
        'type': {'required': True},
    }

    _attribute_map = {
        'log_path': {'key': 'logPath', 'type': 'object'},
        'type': {'key': 'type', 'type': 'str'},
        'access_credential': {'key': 'typeProperties.accessCredential', 'type': 'SSISAccessCredential'},
        'log_refresh_interval': {'key': 'typeProperties.logRefreshInterval', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        log_path: Any,
        type: Union[str, "SsisLogLocationType"],
        access_credential: Optional["SSISAccessCredential"] = None,
        log_refresh_interval: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword log_path: Required. The SSIS package execution log path. Type: string (or Expression
         with resultType string).
        :paramtype log_path: any
        :keyword type: Required. The type of SSIS log location. Possible values include: "File".
        :paramtype type: str or ~azure.mgmt.datafactory.models.SsisLogLocationType
        :keyword access_credential: The package execution log access credential.
        :paramtype access_credential: ~azure.mgmt.datafactory.models.SSISAccessCredential
        :keyword log_refresh_interval: Specifies the interval to refresh log. The default interval is 5
         minutes. Type: string (or Expression with resultType string), pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype log_refresh_interval: any
        """
        super(SSISLogLocation, self).__init__(**kwargs)
        self.log_path = log_path
        self.type = type
        self.access_credential = access_credential
        self.log_refresh_interval = log_refresh_interval


class SsisObjectMetadataListResponse(msrest.serialization.Model):
    """A list of SSIS object metadata.

    :ivar value: List of SSIS object metadata.
    :vartype value: list[~azure.mgmt.datafactory.models.SsisObjectMetadata]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _attribute_map = {
        'value': {'key': 'value', 'type': '[SsisObjectMetadata]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: Optional[List["SsisObjectMetadata"]] = None,
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: List of SSIS object metadata.
        :paramtype value: list[~azure.mgmt.datafactory.models.SsisObjectMetadata]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(SsisObjectMetadataListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class SsisObjectMetadataStatusResponse(msrest.serialization.Model):
    """The status of the operation.

    :ivar status: The status of the operation.
    :vartype status: str
    :ivar name: The operation name.
    :vartype name: str
    :ivar properties: The operation properties.
    :vartype properties: str
    :ivar error: The operation error message.
    :vartype error: str
    """

    _attribute_map = {
        'status': {'key': 'status', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'str'},
        'error': {'key': 'error', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        status: Optional[str] = None,
        name: Optional[str] = None,
        properties: Optional[str] = None,
        error: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword status: The status of the operation.
        :paramtype status: str
        :keyword name: The operation name.
        :paramtype name: str
        :keyword properties: The operation properties.
        :paramtype properties: str
        :keyword error: The operation error message.
        :paramtype error: str
        """
        super(SsisObjectMetadataStatusResponse, self).__init__(**kwargs)
        self.status = status
        self.name = name
        self.properties = properties
        self.error = error


class SsisPackage(SsisObjectMetadata):
    """Ssis Package.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of metadata.Constant filled by server. Possible values include:
     "Folder", "Project", "Package", "Environment".
    :vartype type: str or ~azure.mgmt.datafactory.models.SsisObjectMetadataType
    :ivar id: Metadata id.
    :vartype id: long
    :ivar name: Metadata name.
    :vartype name: str
    :ivar description: Metadata description.
    :vartype description: str
    :ivar folder_id: Folder id which contains package.
    :vartype folder_id: long
    :ivar project_version: Project version which contains package.
    :vartype project_version: long
    :ivar project_id: Project id which contains package.
    :vartype project_id: long
    :ivar parameters: Parameters in package.
    :vartype parameters: list[~azure.mgmt.datafactory.models.SsisParameter]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'folder_id': {'key': 'folderId', 'type': 'long'},
        'project_version': {'key': 'projectVersion', 'type': 'long'},
        'project_id': {'key': 'projectId', 'type': 'long'},
        'parameters': {'key': 'parameters', 'type': '[SsisParameter]'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        folder_id: Optional[int] = None,
        project_version: Optional[int] = None,
        project_id: Optional[int] = None,
        parameters: Optional[List["SsisParameter"]] = None,
        **kwargs
    ):
        """
        :keyword id: Metadata id.
        :paramtype id: long
        :keyword name: Metadata name.
        :paramtype name: str
        :keyword description: Metadata description.
        :paramtype description: str
        :keyword folder_id: Folder id which contains package.
        :paramtype folder_id: long
        :keyword project_version: Project version which contains package.
        :paramtype project_version: long
        :keyword project_id: Project id which contains package.
        :paramtype project_id: long
        :keyword parameters: Parameters in package.
        :paramtype parameters: list[~azure.mgmt.datafactory.models.SsisParameter]
        """
        super(SsisPackage, self).__init__(id=id, name=name, description=description, **kwargs)
        self.type = 'Package'  # type: str
        self.folder_id = folder_id
        self.project_version = project_version
        self.project_id = project_id
        self.parameters = parameters


class SSISPackageLocation(msrest.serialization.Model):
    """SSIS package location.

    :ivar package_path: The SSIS package path. Type: string (or Expression with resultType string).
    :vartype package_path: any
    :ivar type: The type of SSIS package location. Possible values include: "SSISDB", "File",
     "InlinePackage", "PackageStore".
    :vartype type: str or ~azure.mgmt.datafactory.models.SsisPackageLocationType
    :ivar package_password: Password of the package.
    :vartype package_password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar access_credential: The package access credential.
    :vartype access_credential: ~azure.mgmt.datafactory.models.SSISAccessCredential
    :ivar configuration_path: The configuration file of the package execution. Type: string (or
     Expression with resultType string).
    :vartype configuration_path: any
    :ivar configuration_access_credential: The configuration file access credential.
    :vartype configuration_access_credential: ~azure.mgmt.datafactory.models.SSISAccessCredential
    :ivar package_name: The package name.
    :vartype package_name: str
    :ivar package_content: The embedded package content. Type: string (or Expression with
     resultType string).
    :vartype package_content: any
    :ivar package_last_modified_date: The embedded package last modified date.
    :vartype package_last_modified_date: str
    :ivar child_packages: The embedded child package list.
    :vartype child_packages: list[~azure.mgmt.datafactory.models.SSISChildPackage]
    """

    _attribute_map = {
        'package_path': {'key': 'packagePath', 'type': 'object'},
        'type': {'key': 'type', 'type': 'str'},
        'package_password': {'key': 'typeProperties.packagePassword', 'type': 'SecretBase'},
        'access_credential': {'key': 'typeProperties.accessCredential', 'type': 'SSISAccessCredential'},
        'configuration_path': {'key': 'typeProperties.configurationPath', 'type': 'object'},
        'configuration_access_credential': {'key': 'typeProperties.configurationAccessCredential', 'type': 'SSISAccessCredential'},
        'package_name': {'key': 'typeProperties.packageName', 'type': 'str'},
        'package_content': {'key': 'typeProperties.packageContent', 'type': 'object'},
        'package_last_modified_date': {'key': 'typeProperties.packageLastModifiedDate', 'type': 'str'},
        'child_packages': {'key': 'typeProperties.childPackages', 'type': '[SSISChildPackage]'},
    }

    def __init__(
        self,
        *,
        package_path: Optional[Any] = None,
        type: Optional[Union[str, "SsisPackageLocationType"]] = None,
        package_password: Optional["SecretBase"] = None,
        access_credential: Optional["SSISAccessCredential"] = None,
        configuration_path: Optional[Any] = None,
        configuration_access_credential: Optional["SSISAccessCredential"] = None,
        package_name: Optional[str] = None,
        package_content: Optional[Any] = None,
        package_last_modified_date: Optional[str] = None,
        child_packages: Optional[List["SSISChildPackage"]] = None,
        **kwargs
    ):
        """
        :keyword package_path: The SSIS package path. Type: string (or Expression with resultType
         string).
        :paramtype package_path: any
        :keyword type: The type of SSIS package location. Possible values include: "SSISDB", "File",
         "InlinePackage", "PackageStore".
        :paramtype type: str or ~azure.mgmt.datafactory.models.SsisPackageLocationType
        :keyword package_password: Password of the package.
        :paramtype package_password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword access_credential: The package access credential.
        :paramtype access_credential: ~azure.mgmt.datafactory.models.SSISAccessCredential
        :keyword configuration_path: The configuration file of the package execution. Type: string (or
         Expression with resultType string).
        :paramtype configuration_path: any
        :keyword configuration_access_credential: The configuration file access credential.
        :paramtype configuration_access_credential: ~azure.mgmt.datafactory.models.SSISAccessCredential
        :keyword package_name: The package name.
        :paramtype package_name: str
        :keyword package_content: The embedded package content. Type: string (or Expression with
         resultType string).
        :paramtype package_content: any
        :keyword package_last_modified_date: The embedded package last modified date.
        :paramtype package_last_modified_date: str
        :keyword child_packages: The embedded child package list.
        :paramtype child_packages: list[~azure.mgmt.datafactory.models.SSISChildPackage]
        """
        super(SSISPackageLocation, self).__init__(**kwargs)
        self.package_path = package_path
        self.type = type
        self.package_password = package_password
        self.access_credential = access_credential
        self.configuration_path = configuration_path
        self.configuration_access_credential = configuration_access_credential
        self.package_name = package_name
        self.package_content = package_content
        self.package_last_modified_date = package_last_modified_date
        self.child_packages = child_packages


class SsisParameter(msrest.serialization.Model):
    """Ssis parameter.

    :ivar id: Parameter id.
    :vartype id: long
    :ivar name: Parameter name.
    :vartype name: str
    :ivar description: Parameter description.
    :vartype description: str
    :ivar data_type: Parameter type.
    :vartype data_type: str
    :ivar required: Whether parameter is required.
    :vartype required: bool
    :ivar sensitive: Whether parameter is sensitive.
    :vartype sensitive: bool
    :ivar design_default_value: Design default value of parameter.
    :vartype design_default_value: str
    :ivar default_value: Default value of parameter.
    :vartype default_value: str
    :ivar sensitive_default_value: Default sensitive value of parameter.
    :vartype sensitive_default_value: str
    :ivar value_type: Parameter value type.
    :vartype value_type: str
    :ivar value_set: Parameter value set.
    :vartype value_set: bool
    :ivar variable: Parameter reference variable.
    :vartype variable: str
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'data_type': {'key': 'dataType', 'type': 'str'},
        'required': {'key': 'required', 'type': 'bool'},
        'sensitive': {'key': 'sensitive', 'type': 'bool'},
        'design_default_value': {'key': 'designDefaultValue', 'type': 'str'},
        'default_value': {'key': 'defaultValue', 'type': 'str'},
        'sensitive_default_value': {'key': 'sensitiveDefaultValue', 'type': 'str'},
        'value_type': {'key': 'valueType', 'type': 'str'},
        'value_set': {'key': 'valueSet', 'type': 'bool'},
        'variable': {'key': 'variable', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        data_type: Optional[str] = None,
        required: Optional[bool] = None,
        sensitive: Optional[bool] = None,
        design_default_value: Optional[str] = None,
        default_value: Optional[str] = None,
        sensitive_default_value: Optional[str] = None,
        value_type: Optional[str] = None,
        value_set: Optional[bool] = None,
        variable: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword id: Parameter id.
        :paramtype id: long
        :keyword name: Parameter name.
        :paramtype name: str
        :keyword description: Parameter description.
        :paramtype description: str
        :keyword data_type: Parameter type.
        :paramtype data_type: str
        :keyword required: Whether parameter is required.
        :paramtype required: bool
        :keyword sensitive: Whether parameter is sensitive.
        :paramtype sensitive: bool
        :keyword design_default_value: Design default value of parameter.
        :paramtype design_default_value: str
        :keyword default_value: Default value of parameter.
        :paramtype default_value: str
        :keyword sensitive_default_value: Default sensitive value of parameter.
        :paramtype sensitive_default_value: str
        :keyword value_type: Parameter value type.
        :paramtype value_type: str
        :keyword value_set: Parameter value set.
        :paramtype value_set: bool
        :keyword variable: Parameter reference variable.
        :paramtype variable: str
        """
        super(SsisParameter, self).__init__(**kwargs)
        self.id = id
        self.name = name
        self.description = description
        self.data_type = data_type
        self.required = required
        self.sensitive = sensitive
        self.design_default_value = design_default_value
        self.default_value = default_value
        self.sensitive_default_value = sensitive_default_value
        self.value_type = value_type
        self.value_set = value_set
        self.variable = variable


class SsisProject(SsisObjectMetadata):
    """Ssis project.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of metadata.Constant filled by server. Possible values include:
     "Folder", "Project", "Package", "Environment".
    :vartype type: str or ~azure.mgmt.datafactory.models.SsisObjectMetadataType
    :ivar id: Metadata id.
    :vartype id: long
    :ivar name: Metadata name.
    :vartype name: str
    :ivar description: Metadata description.
    :vartype description: str
    :ivar folder_id: Folder id which contains project.
    :vartype folder_id: long
    :ivar version: Project version.
    :vartype version: long
    :ivar environment_refs: Environment reference in project.
    :vartype environment_refs: list[~azure.mgmt.datafactory.models.SsisEnvironmentReference]
    :ivar parameters: Parameters in project.
    :vartype parameters: list[~azure.mgmt.datafactory.models.SsisParameter]
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'folder_id': {'key': 'folderId', 'type': 'long'},
        'version': {'key': 'version', 'type': 'long'},
        'environment_refs': {'key': 'environmentRefs', 'type': '[SsisEnvironmentReference]'},
        'parameters': {'key': 'parameters', 'type': '[SsisParameter]'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        folder_id: Optional[int] = None,
        version: Optional[int] = None,
        environment_refs: Optional[List["SsisEnvironmentReference"]] = None,
        parameters: Optional[List["SsisParameter"]] = None,
        **kwargs
    ):
        """
        :keyword id: Metadata id.
        :paramtype id: long
        :keyword name: Metadata name.
        :paramtype name: str
        :keyword description: Metadata description.
        :paramtype description: str
        :keyword folder_id: Folder id which contains project.
        :paramtype folder_id: long
        :keyword version: Project version.
        :paramtype version: long
        :keyword environment_refs: Environment reference in project.
        :paramtype environment_refs: list[~azure.mgmt.datafactory.models.SsisEnvironmentReference]
        :keyword parameters: Parameters in project.
        :paramtype parameters: list[~azure.mgmt.datafactory.models.SsisParameter]
        """
        super(SsisProject, self).__init__(id=id, name=name, description=description, **kwargs)
        self.type = 'Project'  # type: str
        self.folder_id = folder_id
        self.version = version
        self.environment_refs = environment_refs
        self.parameters = parameters


class SSISPropertyOverride(msrest.serialization.Model):
    """SSIS property override.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. SSIS package property override value. Type: string (or Expression with
     resultType string).
    :vartype value: any
    :ivar is_sensitive: Whether SSIS package property override value is sensitive data. Value will
     be encrypted in SSISDB if it is true.
    :vartype is_sensitive: bool
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': 'object'},
        'is_sensitive': {'key': 'isSensitive', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        value: Any,
        is_sensitive: Optional[bool] = None,
        **kwargs
    ):
        """
        :keyword value: Required. SSIS package property override value. Type: string (or Expression
         with resultType string).
        :paramtype value: any
        :keyword is_sensitive: Whether SSIS package property override value is sensitive data. Value
         will be encrypted in SSISDB if it is true.
        :paramtype is_sensitive: bool
        """
        super(SSISPropertyOverride, self).__init__(**kwargs)
        self.value = value
        self.is_sensitive = is_sensitive


class SsisVariable(msrest.serialization.Model):
    """Ssis variable.

    :ivar id: Variable id.
    :vartype id: long
    :ivar name: Variable name.
    :vartype name: str
    :ivar description: Variable description.
    :vartype description: str
    :ivar data_type: Variable type.
    :vartype data_type: str
    :ivar sensitive: Whether variable is sensitive.
    :vartype sensitive: bool
    :ivar value: Variable value.
    :vartype value: str
    :ivar sensitive_value: Variable sensitive value.
    :vartype sensitive_value: str
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'long'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'data_type': {'key': 'dataType', 'type': 'str'},
        'sensitive': {'key': 'sensitive', 'type': 'bool'},
        'value': {'key': 'value', 'type': 'str'},
        'sensitive_value': {'key': 'sensitiveValue', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        id: Optional[int] = None,
        name: Optional[str] = None,
        description: Optional[str] = None,
        data_type: Optional[str] = None,
        sensitive: Optional[bool] = None,
        value: Optional[str] = None,
        sensitive_value: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword id: Variable id.
        :paramtype id: long
        :keyword name: Variable name.
        :paramtype name: str
        :keyword description: Variable description.
        :paramtype description: str
        :keyword data_type: Variable type.
        :paramtype data_type: str
        :keyword sensitive: Whether variable is sensitive.
        :paramtype sensitive: bool
        :keyword value: Variable value.
        :paramtype value: str
        :keyword sensitive_value: Variable sensitive value.
        :paramtype sensitive_value: str
        """
        super(SsisVariable, self).__init__(**kwargs)
        self.id = id
        self.name = name
        self.description = description
        self.data_type = data_type
        self.sensitive = sensitive
        self.value = value
        self.sensitive_value = sensitive_value


class StagingSettings(msrest.serialization.Model):
    """Staging settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar linked_service_name: Required. Staging linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar path: The path to storage for storing the interim data. Type: string (or Expression with
     resultType string).
    :vartype path: any
    :ivar enable_compression: Specifies whether to use compression when copying data via an interim
     staging. Default value is false. Type: boolean (or Expression with resultType boolean).
    :vartype enable_compression: any
    """

    _validation = {
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'path': {'key': 'path', 'type': 'object'},
        'enable_compression': {'key': 'enableCompression', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        path: Optional[Any] = None,
        enable_compression: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword linked_service_name: Required. Staging linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword path: The path to storage for storing the interim data. Type: string (or Expression
         with resultType string).
        :paramtype path: any
        :keyword enable_compression: Specifies whether to use compression when copying data via an
         interim staging. Default value is false. Type: boolean (or Expression with resultType boolean).
        :paramtype enable_compression: any
        """
        super(StagingSettings, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.linked_service_name = linked_service_name
        self.path = path
        self.enable_compression = enable_compression


class StoredProcedureParameter(msrest.serialization.Model):
    """SQL stored procedure parameter.

    :ivar value: Stored procedure parameter value. Type: string (or Expression with resultType
     string).
    :vartype value: any
    :ivar type: Stored procedure parameter type. Possible values include: "String", "Int", "Int64",
     "Decimal", "Guid", "Boolean", "Date".
    :vartype type: str or ~azure.mgmt.datafactory.models.StoredProcedureParameterType
    """

    _attribute_map = {
        'value': {'key': 'value', 'type': 'object'},
        'type': {'key': 'type', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: Optional[Any] = None,
        type: Optional[Union[str, "StoredProcedureParameterType"]] = None,
        **kwargs
    ):
        """
        :keyword value: Stored procedure parameter value. Type: string (or Expression with resultType
         string).
        :paramtype value: any
        :keyword type: Stored procedure parameter type. Possible values include: "String", "Int",
         "Int64", "Decimal", "Guid", "Boolean", "Date".
        :paramtype type: str or ~azure.mgmt.datafactory.models.StoredProcedureParameterType
        """
        super(StoredProcedureParameter, self).__init__(**kwargs)
        self.value = value
        self.type = type


class SwitchActivity(ControlActivity):
    """This activity evaluates an expression and executes activities under the cases property that correspond to the expression evaluation expected in the equals property.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar on: Required. An expression that would evaluate to a string or integer. This is used to
     determine the block of activities in cases that will be executed.
    :vartype on: ~azure.mgmt.datafactory.models.Expression
    :ivar cases: List of cases that correspond to expected values of the 'on' property. This is an
     optional property and if not provided, the activity will execute activities provided in
     defaultActivities.
    :vartype cases: list[~azure.mgmt.datafactory.models.SwitchCase]
    :ivar default_activities: List of activities to execute if no case condition is satisfied. This
     is an optional property and if not provided, the activity will exit without any action.
    :vartype default_activities: list[~azure.mgmt.datafactory.models.Activity]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'on': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'on': {'key': 'typeProperties.on', 'type': 'Expression'},
        'cases': {'key': 'typeProperties.cases', 'type': '[SwitchCase]'},
        'default_activities': {'key': 'typeProperties.defaultActivities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        name: str,
        on: "Expression",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        cases: Optional[List["SwitchCase"]] = None,
        default_activities: Optional[List["Activity"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword on: Required. An expression that would evaluate to a string or integer. This is used
         to determine the block of activities in cases that will be executed.
        :paramtype on: ~azure.mgmt.datafactory.models.Expression
        :keyword cases: List of cases that correspond to expected values of the 'on' property. This is
         an optional property and if not provided, the activity will execute activities provided in
         defaultActivities.
        :paramtype cases: list[~azure.mgmt.datafactory.models.SwitchCase]
        :keyword default_activities: List of activities to execute if no case condition is satisfied.
         This is an optional property and if not provided, the activity will exit without any action.
        :paramtype default_activities: list[~azure.mgmt.datafactory.models.Activity]
        """
        super(SwitchActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Switch'  # type: str
        self.on = on
        self.cases = cases
        self.default_activities = default_activities


class SwitchCase(msrest.serialization.Model):
    """Switch cases with have a value and corresponding activities.

    :ivar value: Expected value that satisfies the expression result of the 'on' property.
    :vartype value: str
    :ivar activities: List of activities to execute for satisfied case condition.
    :vartype activities: list[~azure.mgmt.datafactory.models.Activity]
    """

    _attribute_map = {
        'value': {'key': 'value', 'type': 'str'},
        'activities': {'key': 'activities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        value: Optional[str] = None,
        activities: Optional[List["Activity"]] = None,
        **kwargs
    ):
        """
        :keyword value: Expected value that satisfies the expression result of the 'on' property.
        :paramtype value: str
        :keyword activities: List of activities to execute for satisfied case condition.
        :paramtype activities: list[~azure.mgmt.datafactory.models.Activity]
        """
        super(SwitchCase, self).__init__(**kwargs)
        self.value = value
        self.activities = activities


class SybaseLinkedService(LinkedService):
    """Linked service for Sybase data source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar server: Required. Server name for connection. Type: string (or Expression with resultType
     string).
    :vartype server: any
    :ivar database: Required. Database name for connection. Type: string (or Expression with
     resultType string).
    :vartype database: any
    :ivar schema: Schema name for connection. Type: string (or Expression with resultType string).
    :vartype schema: any
    :ivar authentication_type: AuthenticationType to be used for connection. Possible values
     include: "Basic", "Windows".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.SybaseAuthenticationType
    :ivar username: Username for authentication. Type: string (or Expression with resultType
     string).
    :vartype username: any
    :ivar password: Password for authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'server': {'required': True},
        'database': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'server': {'key': 'typeProperties.server', 'type': 'object'},
        'database': {'key': 'typeProperties.database', 'type': 'object'},
        'schema': {'key': 'typeProperties.schema', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        server: Any,
        database: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        schema: Optional[Any] = None,
        authentication_type: Optional[Union[str, "SybaseAuthenticationType"]] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword server: Required. Server name for connection. Type: string (or Expression with
         resultType string).
        :paramtype server: any
        :keyword database: Required. Database name for connection. Type: string (or Expression with
         resultType string).
        :paramtype database: any
        :keyword schema: Schema name for connection. Type: string (or Expression with resultType
         string).
        :paramtype schema: any
        :keyword authentication_type: AuthenticationType to be used for connection. Possible values
         include: "Basic", "Windows".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.SybaseAuthenticationType
        :keyword username: Username for authentication. Type: string (or Expression with resultType
         string).
        :paramtype username: any
        :keyword password: Password for authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(SybaseLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Sybase'  # type: str
        self.server = server
        self.database = database
        self.schema = schema
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class SybaseSource(TabularSource):
    """A copy activity source for Sybase databases.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: Database query. Type: string (or Expression with resultType string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: Database query. Type: string (or Expression with resultType string).
        :paramtype query: any
        """
        super(SybaseSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'SybaseSource'  # type: str
        self.query = query


class SybaseTableDataset(Dataset):
    """The Sybase table dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The Sybase table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The Sybase table name. Type: string (or Expression with resultType
         string).
        :paramtype table_name: any
        """
        super(SybaseTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'SybaseTable'  # type: str
        self.table_name = table_name


class TabularTranslator(CopyTranslator):
    """A copy activity tabular translator.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy translator type.Constant filled by server.
    :vartype type: str
    :ivar column_mappings: Column mappings. Example: "UserId: MyUserId, Group: MyGroup, Name:
     MyName" Type: string (or Expression with resultType string). This property will be retired.
     Please use mappings property.
    :vartype column_mappings: any
    :ivar schema_mapping: The schema mapping to map between tabular data and hierarchical data.
     Example: {"Column1": "$.Column1", "Column2": "$.Column2.Property1", "Column3":
     "$.Column2.Property2"}. Type: object (or Expression with resultType object). This property will
     be retired. Please use mappings property.
    :vartype schema_mapping: any
    :ivar collection_reference: The JSON Path of the Nested Array that is going to do cross-apply.
     Type: object (or Expression with resultType object).
    :vartype collection_reference: any
    :ivar map_complex_values_to_string: Whether to map complex (array and object) values to simple
     strings in json format. Type: boolean (or Expression with resultType boolean).
    :vartype map_complex_values_to_string: any
    :ivar mappings: Column mappings with logical types. Tabular->tabular example:
     [{"source":{"name":"CustomerName","type":"String"},"sink":{"name":"ClientName","type":"String"}},{"source":{"name":"CustomerAddress","type":"String"},"sink":{"name":"ClientAddress","type":"String"}}].
     Hierarchical->tabular example:
     [{"source":{"path":"$.CustomerName","type":"String"},"sink":{"name":"ClientName","type":"String"}},{"source":{"path":"$.CustomerAddress","type":"String"},"sink":{"name":"ClientAddress","type":"String"}}].
     Type: object (or Expression with resultType object).
    :vartype mappings: any
    :ivar type_conversion: Whether to enable the advanced type conversion feature in the Copy
     activity. Type: boolean (or Expression with resultType boolean).
    :vartype type_conversion: any
    :ivar type_conversion_settings: Type conversion settings.
    :vartype type_conversion_settings: ~azure.mgmt.datafactory.models.TypeConversionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'column_mappings': {'key': 'columnMappings', 'type': 'object'},
        'schema_mapping': {'key': 'schemaMapping', 'type': 'object'},
        'collection_reference': {'key': 'collectionReference', 'type': 'object'},
        'map_complex_values_to_string': {'key': 'mapComplexValuesToString', 'type': 'object'},
        'mappings': {'key': 'mappings', 'type': 'object'},
        'type_conversion': {'key': 'typeConversion', 'type': 'object'},
        'type_conversion_settings': {'key': 'typeConversionSettings', 'type': 'TypeConversionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        column_mappings: Optional[Any] = None,
        schema_mapping: Optional[Any] = None,
        collection_reference: Optional[Any] = None,
        map_complex_values_to_string: Optional[Any] = None,
        mappings: Optional[Any] = None,
        type_conversion: Optional[Any] = None,
        type_conversion_settings: Optional["TypeConversionSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword column_mappings: Column mappings. Example: "UserId: MyUserId, Group: MyGroup, Name:
         MyName" Type: string (or Expression with resultType string). This property will be retired.
         Please use mappings property.
        :paramtype column_mappings: any
        :keyword schema_mapping: The schema mapping to map between tabular data and hierarchical data.
         Example: {"Column1": "$.Column1", "Column2": "$.Column2.Property1", "Column3":
         "$.Column2.Property2"}. Type: object (or Expression with resultType object). This property will
         be retired. Please use mappings property.
        :paramtype schema_mapping: any
        :keyword collection_reference: The JSON Path of the Nested Array that is going to do
         cross-apply. Type: object (or Expression with resultType object).
        :paramtype collection_reference: any
        :keyword map_complex_values_to_string: Whether to map complex (array and object) values to
         simple strings in json format. Type: boolean (or Expression with resultType boolean).
        :paramtype map_complex_values_to_string: any
        :keyword mappings: Column mappings with logical types. Tabular->tabular example:
         [{"source":{"name":"CustomerName","type":"String"},"sink":{"name":"ClientName","type":"String"}},{"source":{"name":"CustomerAddress","type":"String"},"sink":{"name":"ClientAddress","type":"String"}}].
         Hierarchical->tabular example:
         [{"source":{"path":"$.CustomerName","type":"String"},"sink":{"name":"ClientName","type":"String"}},{"source":{"path":"$.CustomerAddress","type":"String"},"sink":{"name":"ClientAddress","type":"String"}}].
         Type: object (or Expression with resultType object).
        :paramtype mappings: any
        :keyword type_conversion: Whether to enable the advanced type conversion feature in the Copy
         activity. Type: boolean (or Expression with resultType boolean).
        :paramtype type_conversion: any
        :keyword type_conversion_settings: Type conversion settings.
        :paramtype type_conversion_settings: ~azure.mgmt.datafactory.models.TypeConversionSettings
        """
        super(TabularTranslator, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'TabularTranslator'  # type: str
        self.column_mappings = column_mappings
        self.schema_mapping = schema_mapping
        self.collection_reference = collection_reference
        self.map_complex_values_to_string = map_complex_values_to_string
        self.mappings = mappings
        self.type_conversion = type_conversion
        self.type_conversion_settings = type_conversion_settings


class TarGZipReadSettings(CompressionReadSettings):
    """The TarGZip compression read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The Compression setting type.Constant filled by server.
    :vartype type: str
    :ivar preserve_compression_file_name_as_folder: Preserve the compression file name as folder
     path. Type: boolean (or Expression with resultType boolean).
    :vartype preserve_compression_file_name_as_folder: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'preserve_compression_file_name_as_folder': {'key': 'preserveCompressionFileNameAsFolder', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        preserve_compression_file_name_as_folder: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword preserve_compression_file_name_as_folder: Preserve the compression file name as folder
         path. Type: boolean (or Expression with resultType boolean).
        :paramtype preserve_compression_file_name_as_folder: any
        """
        super(TarGZipReadSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'TarGZipReadSettings'  # type: str
        self.preserve_compression_file_name_as_folder = preserve_compression_file_name_as_folder


class TarReadSettings(CompressionReadSettings):
    """The Tar compression read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The Compression setting type.Constant filled by server.
    :vartype type: str
    :ivar preserve_compression_file_name_as_folder: Preserve the compression file name as folder
     path. Type: boolean (or Expression with resultType boolean).
    :vartype preserve_compression_file_name_as_folder: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'preserve_compression_file_name_as_folder': {'key': 'preserveCompressionFileNameAsFolder', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        preserve_compression_file_name_as_folder: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword preserve_compression_file_name_as_folder: Preserve the compression file name as folder
         path. Type: boolean (or Expression with resultType boolean).
        :paramtype preserve_compression_file_name_as_folder: any
        """
        super(TarReadSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'TarReadSettings'  # type: str
        self.preserve_compression_file_name_as_folder = preserve_compression_file_name_as_folder


class TeamDeskLinkedService(LinkedService):
    """Linked service for TeamDesk.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar authentication_type: Required. The authentication type to use. Possible values include:
     "Basic", "Token".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.TeamDeskAuthenticationType
    :ivar url: Required. The url to connect TeamDesk source. Type: string (or Expression with
     resultType string).
    :vartype url: any
    :ivar user_name: The username of the TeamDesk source. Type: string (or Expression with
     resultType string).
    :vartype user_name: any
    :ivar password: The password of the TeamDesk source.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar api_token: The api token for the TeamDesk source.
    :vartype api_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'authentication_type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'url': {'key': 'typeProperties.url', 'type': 'object'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'api_token': {'key': 'typeProperties.apiToken', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        authentication_type: Union[str, "TeamDeskAuthenticationType"],
        url: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        api_token: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword authentication_type: Required. The authentication type to use. Possible values
         include: "Basic", "Token".
        :paramtype authentication_type: str or
         ~azure.mgmt.datafactory.models.TeamDeskAuthenticationType
        :keyword url: Required. The url to connect TeamDesk source. Type: string (or Expression with
         resultType string).
        :paramtype url: any
        :keyword user_name: The username of the TeamDesk source. Type: string (or Expression with
         resultType string).
        :paramtype user_name: any
        :keyword password: The password of the TeamDesk source.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword api_token: The api token for the TeamDesk source.
        :paramtype api_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(TeamDeskLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'TeamDesk'  # type: str
        self.authentication_type = authentication_type
        self.url = url
        self.user_name = user_name
        self.password = password
        self.api_token = api_token
        self.encrypted_credential = encrypted_credential


class TeradataLinkedService(LinkedService):
    """Linked service for Teradata data source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: Teradata ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar server: Server name for connection. Type: string (or Expression with resultType string).
    :vartype server: any
    :ivar authentication_type: AuthenticationType to be used for connection. Possible values
     include: "Basic", "Windows".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.TeradataAuthenticationType
    :ivar username: Username for authentication. Type: string (or Expression with resultType
     string).
    :vartype username: any
    :ivar password: Password for authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'server': {'key': 'typeProperties.server', 'type': 'object'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'username': {'key': 'typeProperties.username', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        server: Optional[Any] = None,
        authentication_type: Optional[Union[str, "TeradataAuthenticationType"]] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: Teradata ODBC connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword server: Server name for connection. Type: string (or Expression with resultType
         string).
        :paramtype server: any
        :keyword authentication_type: AuthenticationType to be used for connection. Possible values
         include: "Basic", "Windows".
        :paramtype authentication_type: str or
         ~azure.mgmt.datafactory.models.TeradataAuthenticationType
        :keyword username: Username for authentication. Type: string (or Expression with resultType
         string).
        :paramtype username: any
        :keyword password: Password for authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(TeradataLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Teradata'  # type: str
        self.connection_string = connection_string
        self.server = server
        self.authentication_type = authentication_type
        self.username = username
        self.password = password
        self.encrypted_credential = encrypted_credential


class TeradataPartitionSettings(msrest.serialization.Model):
    """The settings that will be leveraged for teradata source partitioning.

    :ivar partition_column_name: The name of the column that will be used for proceeding range or
     hash partitioning. Type: string (or Expression with resultType string).
    :vartype partition_column_name: any
    :ivar partition_upper_bound: The maximum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :vartype partition_upper_bound: any
    :ivar partition_lower_bound: The minimum value of column specified in partitionColumnName that
     will be used for proceeding range partitioning. Type: string (or Expression with resultType
     string).
    :vartype partition_lower_bound: any
    """

    _attribute_map = {
        'partition_column_name': {'key': 'partitionColumnName', 'type': 'object'},
        'partition_upper_bound': {'key': 'partitionUpperBound', 'type': 'object'},
        'partition_lower_bound': {'key': 'partitionLowerBound', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        partition_column_name: Optional[Any] = None,
        partition_upper_bound: Optional[Any] = None,
        partition_lower_bound: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword partition_column_name: The name of the column that will be used for proceeding range
         or hash partitioning. Type: string (or Expression with resultType string).
        :paramtype partition_column_name: any
        :keyword partition_upper_bound: The maximum value of column specified in partitionColumnName
         that will be used for proceeding range partitioning. Type: string (or Expression with
         resultType string).
        :paramtype partition_upper_bound: any
        :keyword partition_lower_bound: The minimum value of column specified in partitionColumnName
         that will be used for proceeding range partitioning. Type: string (or Expression with
         resultType string).
        :paramtype partition_lower_bound: any
        """
        super(TeradataPartitionSettings, self).__init__(**kwargs)
        self.partition_column_name = partition_column_name
        self.partition_upper_bound = partition_upper_bound
        self.partition_lower_bound = partition_lower_bound


class TeradataSource(TabularSource):
    """A copy activity Teradata source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: Teradata query. Type: string (or Expression with resultType string).
    :vartype query: any
    :ivar partition_option: The partition mechanism that will be used for teradata read in
     parallel. Possible values include: "None", "Hash", "DynamicRange".
    :vartype partition_option: any
    :ivar partition_settings: The settings that will be leveraged for teradata source partitioning.
    :vartype partition_settings: ~azure.mgmt.datafactory.models.TeradataPartitionSettings
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
        'partition_option': {'key': 'partitionOption', 'type': 'object'},
        'partition_settings': {'key': 'partitionSettings', 'type': 'TeradataPartitionSettings'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        partition_option: Optional[Any] = None,
        partition_settings: Optional["TeradataPartitionSettings"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: Teradata query. Type: string (or Expression with resultType string).
        :paramtype query: any
        :keyword partition_option: The partition mechanism that will be used for teradata read in
         parallel. Possible values include: "None", "Hash", "DynamicRange".
        :paramtype partition_option: any
        :keyword partition_settings: The settings that will be leveraged for teradata source
         partitioning.
        :paramtype partition_settings: ~azure.mgmt.datafactory.models.TeradataPartitionSettings
        """
        super(TeradataSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'TeradataSource'  # type: str
        self.query = query
        self.partition_option = partition_option
        self.partition_settings = partition_settings


class TeradataTableDataset(Dataset):
    """The Teradata database dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar database: The database name of Teradata. Type: string (or Expression with resultType
     string).
    :vartype database: any
    :ivar table: The table name of Teradata. Type: string (or Expression with resultType string).
    :vartype table: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'database': {'key': 'typeProperties.database', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        database: Optional[Any] = None,
        table: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword database: The database name of Teradata. Type: string (or Expression with resultType
         string).
        :paramtype database: any
        :keyword table: The table name of Teradata. Type: string (or Expression with resultType
         string).
        :paramtype table: any
        """
        super(TeradataTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'TeradataTable'  # type: str
        self.database = database
        self.table = table


class TextFormat(DatasetStorageFormat):
    """The data stored in text format.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset storage format.Constant filled by server.
    :vartype type: str
    :ivar serializer: Serializer. Type: string (or Expression with resultType string).
    :vartype serializer: any
    :ivar deserializer: Deserializer. Type: string (or Expression with resultType string).
    :vartype deserializer: any
    :ivar column_delimiter: The column delimiter. Type: string (or Expression with resultType
     string).
    :vartype column_delimiter: any
    :ivar row_delimiter: The row delimiter. Type: string (or Expression with resultType string).
    :vartype row_delimiter: any
    :ivar escape_char: The escape character. Type: string (or Expression with resultType string).
    :vartype escape_char: any
    :ivar quote_char: The quote character. Type: string (or Expression with resultType string).
    :vartype quote_char: any
    :ivar null_value: The null value string. Type: string (or Expression with resultType string).
    :vartype null_value: any
    :ivar encoding_name: The code page name of the preferred encoding. If miss, the default value
     is utf-8, unless BOM denotes another Unicode encoding. Refer to the Name column of
     the table in the following link to set supported values:
     https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
     resultType string).
    :vartype encoding_name: any
    :ivar treat_empty_as_null: Treat empty column values in the text file as null. The default
     value is true. Type: boolean (or Expression with resultType boolean).
    :vartype treat_empty_as_null: any
    :ivar skip_line_count: The number of lines/rows to be skipped when parsing text files. The
     default value is 0. Type: integer (or Expression with resultType integer).
    :vartype skip_line_count: any
    :ivar first_row_as_header: When used as input, treat the first row of data as headers. When
     used as output,write the headers into the output as the first row of data. The default value is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype first_row_as_header: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'serializer': {'key': 'serializer', 'type': 'object'},
        'deserializer': {'key': 'deserializer', 'type': 'object'},
        'column_delimiter': {'key': 'columnDelimiter', 'type': 'object'},
        'row_delimiter': {'key': 'rowDelimiter', 'type': 'object'},
        'escape_char': {'key': 'escapeChar', 'type': 'object'},
        'quote_char': {'key': 'quoteChar', 'type': 'object'},
        'null_value': {'key': 'nullValue', 'type': 'object'},
        'encoding_name': {'key': 'encodingName', 'type': 'object'},
        'treat_empty_as_null': {'key': 'treatEmptyAsNull', 'type': 'object'},
        'skip_line_count': {'key': 'skipLineCount', 'type': 'object'},
        'first_row_as_header': {'key': 'firstRowAsHeader', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        serializer: Optional[Any] = None,
        deserializer: Optional[Any] = None,
        column_delimiter: Optional[Any] = None,
        row_delimiter: Optional[Any] = None,
        escape_char: Optional[Any] = None,
        quote_char: Optional[Any] = None,
        null_value: Optional[Any] = None,
        encoding_name: Optional[Any] = None,
        treat_empty_as_null: Optional[Any] = None,
        skip_line_count: Optional[Any] = None,
        first_row_as_header: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword serializer: Serializer. Type: string (or Expression with resultType string).
        :paramtype serializer: any
        :keyword deserializer: Deserializer. Type: string (or Expression with resultType string).
        :paramtype deserializer: any
        :keyword column_delimiter: The column delimiter. Type: string (or Expression with resultType
         string).
        :paramtype column_delimiter: any
        :keyword row_delimiter: The row delimiter. Type: string (or Expression with resultType string).
        :paramtype row_delimiter: any
        :keyword escape_char: The escape character. Type: string (or Expression with resultType
         string).
        :paramtype escape_char: any
        :keyword quote_char: The quote character. Type: string (or Expression with resultType string).
        :paramtype quote_char: any
        :keyword null_value: The null value string. Type: string (or Expression with resultType
         string).
        :paramtype null_value: any
        :keyword encoding_name: The code page name of the preferred encoding. If miss, the default
         value is utf-8, unless BOM denotes another Unicode encoding. Refer to the Name
         column of the table in the following link to set supported values:
         https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
         resultType string).
        :paramtype encoding_name: any
        :keyword treat_empty_as_null: Treat empty column values in the text file as null. The default
         value is true. Type: boolean (or Expression with resultType boolean).
        :paramtype treat_empty_as_null: any
        :keyword skip_line_count: The number of lines/rows to be skipped when parsing text files. The
         default value is 0. Type: integer (or Expression with resultType integer).
        :paramtype skip_line_count: any
        :keyword first_row_as_header: When used as input, treat the first row of data as headers. When
         used as output,write the headers into the output as the first row of data. The default value is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype first_row_as_header: any
        """
        super(TextFormat, self).__init__(additional_properties=additional_properties, serializer=serializer, deserializer=deserializer, **kwargs)
        self.type = 'TextFormat'  # type: str
        self.column_delimiter = column_delimiter
        self.row_delimiter = row_delimiter
        self.escape_char = escape_char
        self.quote_char = quote_char
        self.null_value = null_value
        self.encoding_name = encoding_name
        self.treat_empty_as_null = treat_empty_as_null
        self.skip_line_count = skip_line_count
        self.first_row_as_header = first_row_as_header


class TriggerDependencyReference(DependencyReference):
    """Trigger referenced dependency.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: TumblingWindowTriggerDependencyReference.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. The type of dependency reference.Constant filled by server.
    :vartype type: str
    :ivar reference_trigger: Required. Referenced trigger.
    :vartype reference_trigger: ~azure.mgmt.datafactory.models.TriggerReference
    """

    _validation = {
        'type': {'required': True},
        'reference_trigger': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_trigger': {'key': 'referenceTrigger', 'type': 'TriggerReference'},
    }

    _subtype_map = {
        'type': {'TumblingWindowTriggerDependencyReference': 'TumblingWindowTriggerDependencyReference'}
    }

    def __init__(
        self,
        *,
        reference_trigger: "TriggerReference",
        **kwargs
    ):
        """
        :keyword reference_trigger: Required. Referenced trigger.
        :paramtype reference_trigger: ~azure.mgmt.datafactory.models.TriggerReference
        """
        super(TriggerDependencyReference, self).__init__(**kwargs)
        self.type = 'TriggerDependencyReference'  # type: str
        self.reference_trigger = reference_trigger


class TriggerFilterParameters(msrest.serialization.Model):
    """Query parameters for triggers.

    :ivar continuation_token: The continuation token for getting the next page of results. Null for
     first page.
    :vartype continuation_token: str
    :ivar parent_trigger_name: The name of the parent TumblingWindowTrigger to get the child rerun
     triggers.
    :vartype parent_trigger_name: str
    """

    _attribute_map = {
        'continuation_token': {'key': 'continuationToken', 'type': 'str'},
        'parent_trigger_name': {'key': 'parentTriggerName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        continuation_token: Optional[str] = None,
        parent_trigger_name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword continuation_token: The continuation token for getting the next page of results. Null
         for first page.
        :paramtype continuation_token: str
        :keyword parent_trigger_name: The name of the parent TumblingWindowTrigger to get the child
         rerun triggers.
        :paramtype parent_trigger_name: str
        """
        super(TriggerFilterParameters, self).__init__(**kwargs)
        self.continuation_token = continuation_token
        self.parent_trigger_name = parent_trigger_name


class TriggerListResponse(msrest.serialization.Model):
    """A list of trigger resources.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of triggers.
    :vartype value: list[~azure.mgmt.datafactory.models.TriggerResource]
    :ivar next_link: The link to the next page of results, if any remaining results exist.
    :vartype next_link: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[TriggerResource]'},
        'next_link': {'key': 'nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["TriggerResource"],
        next_link: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of triggers.
        :paramtype value: list[~azure.mgmt.datafactory.models.TriggerResource]
        :keyword next_link: The link to the next page of results, if any remaining results exist.
        :paramtype next_link: str
        """
        super(TriggerListResponse, self).__init__(**kwargs)
        self.value = value
        self.next_link = next_link


class TriggerPipelineReference(msrest.serialization.Model):
    """Pipeline that needs to be triggered with the given parameters.

    :ivar pipeline_reference: Pipeline reference.
    :vartype pipeline_reference: ~azure.mgmt.datafactory.models.PipelineReference
    :ivar parameters: Pipeline parameters.
    :vartype parameters: dict[str, any]
    """

    _attribute_map = {
        'pipeline_reference': {'key': 'pipelineReference', 'type': 'PipelineReference'},
        'parameters': {'key': 'parameters', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        pipeline_reference: Optional["PipelineReference"] = None,
        parameters: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword pipeline_reference: Pipeline reference.
        :paramtype pipeline_reference: ~azure.mgmt.datafactory.models.PipelineReference
        :keyword parameters: Pipeline parameters.
        :paramtype parameters: dict[str, any]
        """
        super(TriggerPipelineReference, self).__init__(**kwargs)
        self.pipeline_reference = pipeline_reference
        self.parameters = parameters


class TriggerQueryResponse(msrest.serialization.Model):
    """A query of triggers.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of triggers.
    :vartype value: list[~azure.mgmt.datafactory.models.TriggerResource]
    :ivar continuation_token: The continuation token for getting the next page of results, if any
     remaining results exist, null otherwise.
    :vartype continuation_token: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[TriggerResource]'},
        'continuation_token': {'key': 'continuationToken', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["TriggerResource"],
        continuation_token: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of triggers.
        :paramtype value: list[~azure.mgmt.datafactory.models.TriggerResource]
        :keyword continuation_token: The continuation token for getting the next page of results, if
         any remaining results exist, null otherwise.
        :paramtype continuation_token: str
        """
        super(TriggerQueryResponse, self).__init__(**kwargs)
        self.value = value
        self.continuation_token = continuation_token


class TriggerReference(msrest.serialization.Model):
    """Trigger reference type.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Trigger reference type. Possible values include: "TriggerReference".
    :vartype type: str or ~azure.mgmt.datafactory.models.TriggerReferenceType
    :ivar reference_name: Required. Reference trigger name.
    :vartype reference_name: str
    """

    _validation = {
        'type': {'required': True},
        'reference_name': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_name': {'key': 'referenceName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        type: Union[str, "TriggerReferenceType"],
        reference_name: str,
        **kwargs
    ):
        """
        :keyword type: Required. Trigger reference type. Possible values include: "TriggerReference".
        :paramtype type: str or ~azure.mgmt.datafactory.models.TriggerReferenceType
        :keyword reference_name: Required. Reference trigger name.
        :paramtype reference_name: str
        """
        super(TriggerReference, self).__init__(**kwargs)
        self.type = type
        self.reference_name = reference_name


class TriggerResource(SubResource):
    """Trigger resource type.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar id: The resource identifier.
    :vartype id: str
    :ivar name: The resource name.
    :vartype name: str
    :ivar type: The resource type.
    :vartype type: str
    :ivar etag: Etag identifies change in the resource.
    :vartype etag: str
    :ivar properties: Required. Properties of the trigger.
    :vartype properties: ~azure.mgmt.datafactory.models.Trigger
    """

    _validation = {
        'id': {'readonly': True},
        'name': {'readonly': True},
        'type': {'readonly': True},
        'etag': {'readonly': True},
        'properties': {'required': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'etag': {'key': 'etag', 'type': 'str'},
        'properties': {'key': 'properties', 'type': 'Trigger'},
    }

    def __init__(
        self,
        *,
        properties: "Trigger",
        **kwargs
    ):
        """
        :keyword properties: Required. Properties of the trigger.
        :paramtype properties: ~azure.mgmt.datafactory.models.Trigger
        """
        super(TriggerResource, self).__init__(**kwargs)
        self.properties = properties


class TriggerRun(msrest.serialization.Model):
    """Trigger runs.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar trigger_run_id: Trigger run id.
    :vartype trigger_run_id: str
    :ivar trigger_name: Trigger name.
    :vartype trigger_name: str
    :ivar trigger_type: Trigger type.
    :vartype trigger_type: str
    :ivar trigger_run_timestamp: Trigger run start time.
    :vartype trigger_run_timestamp: ~datetime.datetime
    :ivar status: Trigger run status. Possible values include: "Succeeded", "Failed", "Inprogress".
    :vartype status: str or ~azure.mgmt.datafactory.models.TriggerRunStatus
    :ivar message: Trigger error message.
    :vartype message: str
    :ivar properties: List of property name and value related to trigger run. Name, value pair
     depends on type of trigger.
    :vartype properties: dict[str, str]
    :ivar triggered_pipelines: List of pipeline name and run Id triggered by the trigger run.
    :vartype triggered_pipelines: dict[str, str]
    :ivar run_dimension: Run dimension for which trigger was fired.
    :vartype run_dimension: dict[str, str]
    :ivar dependency_status: Status of the upstream pipelines.
    :vartype dependency_status: dict[str, any]
    """

    _validation = {
        'trigger_run_id': {'readonly': True},
        'trigger_name': {'readonly': True},
        'trigger_type': {'readonly': True},
        'trigger_run_timestamp': {'readonly': True},
        'status': {'readonly': True},
        'message': {'readonly': True},
        'properties': {'readonly': True},
        'triggered_pipelines': {'readonly': True},
        'run_dimension': {'readonly': True},
        'dependency_status': {'readonly': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'trigger_run_id': {'key': 'triggerRunId', 'type': 'str'},
        'trigger_name': {'key': 'triggerName', 'type': 'str'},
        'trigger_type': {'key': 'triggerType', 'type': 'str'},
        'trigger_run_timestamp': {'key': 'triggerRunTimestamp', 'type': 'iso-8601'},
        'status': {'key': 'status', 'type': 'str'},
        'message': {'key': 'message', 'type': 'str'},
        'properties': {'key': 'properties', 'type': '{str}'},
        'triggered_pipelines': {'key': 'triggeredPipelines', 'type': '{str}'},
        'run_dimension': {'key': 'runDimension', 'type': '{str}'},
        'dependency_status': {'key': 'dependencyStatus', 'type': '{object}'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        """
        super(TriggerRun, self).__init__(**kwargs)
        self.additional_properties = additional_properties
        self.trigger_run_id = None
        self.trigger_name = None
        self.trigger_type = None
        self.trigger_run_timestamp = None
        self.status = None
        self.message = None
        self.properties = None
        self.triggered_pipelines = None
        self.run_dimension = None
        self.dependency_status = None


class TriggerRunsQueryResponse(msrest.serialization.Model):
    """A list of trigger runs.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required. List of trigger runs.
    :vartype value: list[~azure.mgmt.datafactory.models.TriggerRun]
    :ivar continuation_token: The continuation token for getting the next page of results, if any
     remaining results exist, null otherwise.
    :vartype continuation_token: str
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[TriggerRun]'},
        'continuation_token': {'key': 'continuationToken', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        value: List["TriggerRun"],
        continuation_token: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword value: Required. List of trigger runs.
        :paramtype value: list[~azure.mgmt.datafactory.models.TriggerRun]
        :keyword continuation_token: The continuation token for getting the next page of results, if
         any remaining results exist, null otherwise.
        :paramtype continuation_token: str
        """
        super(TriggerRunsQueryResponse, self).__init__(**kwargs)
        self.value = value
        self.continuation_token = continuation_token


class TriggerSubscriptionOperationStatus(msrest.serialization.Model):
    """Defines the response of a trigger subscription operation.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar trigger_name: Trigger name.
    :vartype trigger_name: str
    :ivar status: Event Subscription Status. Possible values include: "Enabled", "Provisioning",
     "Deprovisioning", "Disabled", "Unknown".
    :vartype status: str or ~azure.mgmt.datafactory.models.EventSubscriptionStatus
    """

    _validation = {
        'trigger_name': {'readonly': True},
        'status': {'readonly': True},
    }

    _attribute_map = {
        'trigger_name': {'key': 'triggerName', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(TriggerSubscriptionOperationStatus, self).__init__(**kwargs)
        self.trigger_name = None
        self.status = None


class TumblingWindowTrigger(Trigger):
    """Trigger that schedules pipeline runs for all fixed time interval windows from a start time without gaps and also supports backfill scenarios (when start time is in the past).

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Trigger type.Constant filled by server.
    :vartype type: str
    :ivar description: Trigger description.
    :vartype description: str
    :ivar runtime_state: Indicates if trigger is running or not. Updated when Start/Stop APIs are
     called on the Trigger. Possible values include: "Started", "Stopped", "Disabled".
    :vartype runtime_state: str or ~azure.mgmt.datafactory.models.TriggerRuntimeState
    :ivar annotations: List of tags that can be used for describing the trigger.
    :vartype annotations: list[any]
    :ivar pipeline: Required. Pipeline for which runs are created when an event is fired for
     trigger window that is ready.
    :vartype pipeline: ~azure.mgmt.datafactory.models.TriggerPipelineReference
    :ivar frequency: Required. The frequency of the time windows. Possible values include:
     "Minute", "Hour", "Month".
    :vartype frequency: str or ~azure.mgmt.datafactory.models.TumblingWindowFrequency
    :ivar interval: Required. The interval of the time windows. The minimum interval allowed is 15
     Minutes.
    :vartype interval: int
    :ivar start_time: Required. The start time for the time period for the trigger during which
     events are fired for windows that are ready. Only UTC time is currently supported.
    :vartype start_time: ~datetime.datetime
    :ivar end_time: The end time for the time period for the trigger during which events are fired
     for windows that are ready. Only UTC time is currently supported.
    :vartype end_time: ~datetime.datetime
    :ivar delay: Specifies how long the trigger waits past due time before triggering new run. It
     doesn't alter window start and end time. The default is 0. Type: string (or Expression with
     resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype delay: any
    :ivar max_concurrency: Required. The max number of parallel time windows (ready for execution)
     for which a new run is triggered.
    :vartype max_concurrency: int
    :ivar retry_policy: Retry policy that will be applied for failed pipeline runs.
    :vartype retry_policy: ~azure.mgmt.datafactory.models.RetryPolicy
    :ivar depends_on: Triggers that this trigger depends on. Only tumbling window triggers are
     supported.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.DependencyReference]
    """

    _validation = {
        'type': {'required': True},
        'runtime_state': {'readonly': True},
        'pipeline': {'required': True},
        'frequency': {'required': True},
        'interval': {'required': True},
        'start_time': {'required': True},
        'max_concurrency': {'required': True, 'maximum': 50, 'minimum': 1},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'runtime_state': {'key': 'runtimeState', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'pipeline': {'key': 'pipeline', 'type': 'TriggerPipelineReference'},
        'frequency': {'key': 'typeProperties.frequency', 'type': 'str'},
        'interval': {'key': 'typeProperties.interval', 'type': 'int'},
        'start_time': {'key': 'typeProperties.startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'typeProperties.endTime', 'type': 'iso-8601'},
        'delay': {'key': 'typeProperties.delay', 'type': 'object'},
        'max_concurrency': {'key': 'typeProperties.maxConcurrency', 'type': 'int'},
        'retry_policy': {'key': 'typeProperties.retryPolicy', 'type': 'RetryPolicy'},
        'depends_on': {'key': 'typeProperties.dependsOn', 'type': '[DependencyReference]'},
    }

    def __init__(
        self,
        *,
        pipeline: "TriggerPipelineReference",
        frequency: Union[str, "TumblingWindowFrequency"],
        interval: int,
        start_time: datetime.datetime,
        max_concurrency: int,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        end_time: Optional[datetime.datetime] = None,
        delay: Optional[Any] = None,
        retry_policy: Optional["RetryPolicy"] = None,
        depends_on: Optional[List["DependencyReference"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Trigger description.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the trigger.
        :paramtype annotations: list[any]
        :keyword pipeline: Required. Pipeline for which runs are created when an event is fired for
         trigger window that is ready.
        :paramtype pipeline: ~azure.mgmt.datafactory.models.TriggerPipelineReference
        :keyword frequency: Required. The frequency of the time windows. Possible values include:
         "Minute", "Hour", "Month".
        :paramtype frequency: str or ~azure.mgmt.datafactory.models.TumblingWindowFrequency
        :keyword interval: Required. The interval of the time windows. The minimum interval allowed is
         15 Minutes.
        :paramtype interval: int
        :keyword start_time: Required. The start time for the time period for the trigger during which
         events are fired for windows that are ready. Only UTC time is currently supported.
        :paramtype start_time: ~datetime.datetime
        :keyword end_time: The end time for the time period for the trigger during which events are
         fired for windows that are ready. Only UTC time is currently supported.
        :paramtype end_time: ~datetime.datetime
        :keyword delay: Specifies how long the trigger waits past due time before triggering new run.
         It doesn't alter window start and end time. The default is 0. Type: string (or Expression with
         resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype delay: any
        :keyword max_concurrency: Required. The max number of parallel time windows (ready for
         execution) for which a new run is triggered.
        :paramtype max_concurrency: int
        :keyword retry_policy: Retry policy that will be applied for failed pipeline runs.
        :paramtype retry_policy: ~azure.mgmt.datafactory.models.RetryPolicy
        :keyword depends_on: Triggers that this trigger depends on. Only tumbling window triggers are
         supported.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.DependencyReference]
        """
        super(TumblingWindowTrigger, self).__init__(additional_properties=additional_properties, description=description, annotations=annotations, **kwargs)
        self.type = 'TumblingWindowTrigger'  # type: str
        self.pipeline = pipeline
        self.frequency = frequency
        self.interval = interval
        self.start_time = start_time
        self.end_time = end_time
        self.delay = delay
        self.max_concurrency = max_concurrency
        self.retry_policy = retry_policy
        self.depends_on = depends_on


class TumblingWindowTriggerDependencyReference(TriggerDependencyReference):
    """Referenced tumbling window trigger dependency.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. The type of dependency reference.Constant filled by server.
    :vartype type: str
    :ivar reference_trigger: Required. Referenced trigger.
    :vartype reference_trigger: ~azure.mgmt.datafactory.models.TriggerReference
    :ivar offset: Timespan applied to the start time of a tumbling window when evaluating
     dependency.
    :vartype offset: str
    :ivar size: The size of the window when evaluating the dependency. If undefined the frequency
     of the tumbling window will be used.
    :vartype size: str
    """

    _validation = {
        'type': {'required': True},
        'reference_trigger': {'required': True},
        'offset': {'max_length': 15, 'min_length': 8, 'pattern': r'-?((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9]))'},
        'size': {'max_length': 15, 'min_length': 8, 'pattern': r'((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9]))'},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'reference_trigger': {'key': 'referenceTrigger', 'type': 'TriggerReference'},
        'offset': {'key': 'offset', 'type': 'str'},
        'size': {'key': 'size', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        reference_trigger: "TriggerReference",
        offset: Optional[str] = None,
        size: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword reference_trigger: Required. Referenced trigger.
        :paramtype reference_trigger: ~azure.mgmt.datafactory.models.TriggerReference
        :keyword offset: Timespan applied to the start time of a tumbling window when evaluating
         dependency.
        :paramtype offset: str
        :keyword size: The size of the window when evaluating the dependency. If undefined the
         frequency of the tumbling window will be used.
        :paramtype size: str
        """
        super(TumblingWindowTriggerDependencyReference, self).__init__(reference_trigger=reference_trigger, **kwargs)
        self.type = 'TumblingWindowTriggerDependencyReference'  # type: str
        self.offset = offset
        self.size = size


class TwilioLinkedService(LinkedService):
    """Linked service for Twilio.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar user_name: Required. The Account SID of Twilio service.
    :vartype user_name: any
    :ivar password: Required. The auth token of Twilio service.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    """

    _validation = {
        'type': {'required': True},
        'user_name': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        user_name: Any,
        password: "SecretBase",
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword user_name: Required. The Account SID of Twilio service.
        :paramtype user_name: any
        :keyword password: Required. The auth token of Twilio service.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        """
        super(TwilioLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Twilio'  # type: str
        self.user_name = user_name
        self.password = password


class TypeConversionSettings(msrest.serialization.Model):
    """Type conversion settings.

    :ivar allow_data_truncation: Whether to allow data truncation when converting the data. Type:
     boolean (or Expression with resultType boolean).
    :vartype allow_data_truncation: any
    :ivar treat_boolean_as_number: Whether to treat boolean values as numbers. Type: boolean (or
     Expression with resultType boolean).
    :vartype treat_boolean_as_number: any
    :ivar date_time_format: The format for DateTime values. Type: string (or Expression with
     resultType string).
    :vartype date_time_format: any
    :ivar date_time_offset_format: The format for DateTimeOffset values. Type: string (or
     Expression with resultType string).
    :vartype date_time_offset_format: any
    :ivar time_span_format: The format for TimeSpan values. Type: string (or Expression with
     resultType string).
    :vartype time_span_format: any
    :ivar culture: The culture used to convert data from/to string. Type: string (or Expression
     with resultType string).
    :vartype culture: any
    """

    _attribute_map = {
        'allow_data_truncation': {'key': 'allowDataTruncation', 'type': 'object'},
        'treat_boolean_as_number': {'key': 'treatBooleanAsNumber', 'type': 'object'},
        'date_time_format': {'key': 'dateTimeFormat', 'type': 'object'},
        'date_time_offset_format': {'key': 'dateTimeOffsetFormat', 'type': 'object'},
        'time_span_format': {'key': 'timeSpanFormat', 'type': 'object'},
        'culture': {'key': 'culture', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        allow_data_truncation: Optional[Any] = None,
        treat_boolean_as_number: Optional[Any] = None,
        date_time_format: Optional[Any] = None,
        date_time_offset_format: Optional[Any] = None,
        time_span_format: Optional[Any] = None,
        culture: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword allow_data_truncation: Whether to allow data truncation when converting the data.
         Type: boolean (or Expression with resultType boolean).
        :paramtype allow_data_truncation: any
        :keyword treat_boolean_as_number: Whether to treat boolean values as numbers. Type: boolean (or
         Expression with resultType boolean).
        :paramtype treat_boolean_as_number: any
        :keyword date_time_format: The format for DateTime values. Type: string (or Expression with
         resultType string).
        :paramtype date_time_format: any
        :keyword date_time_offset_format: The format for DateTimeOffset values. Type: string (or
         Expression with resultType string).
        :paramtype date_time_offset_format: any
        :keyword time_span_format: The format for TimeSpan values. Type: string (or Expression with
         resultType string).
        :paramtype time_span_format: any
        :keyword culture: The culture used to convert data from/to string. Type: string (or Expression
         with resultType string).
        :paramtype culture: any
        """
        super(TypeConversionSettings, self).__init__(**kwargs)
        self.allow_data_truncation = allow_data_truncation
        self.treat_boolean_as_number = treat_boolean_as_number
        self.date_time_format = date_time_format
        self.date_time_offset_format = date_time_offset_format
        self.time_span_format = time_span_format
        self.culture = culture


class UntilActivity(ControlActivity):
    """This activity executes inner activities until the specified boolean expression results to true or timeout is reached, whichever is earlier.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar expression: Required. An expression that would evaluate to Boolean. The loop will
     continue until this expression evaluates to true.
    :vartype expression: ~azure.mgmt.datafactory.models.Expression
    :ivar timeout: Specifies the timeout for the activity to run. If there is no value specified,
     it takes the value of TimeSpan.FromDays(7) which is 1 week as default. Type: string (or
     Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])). Type: string (or Expression with
     resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype timeout: any
    :ivar activities: Required. List of activities to execute.
    :vartype activities: list[~azure.mgmt.datafactory.models.Activity]
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'expression': {'required': True},
        'activities': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'expression': {'key': 'typeProperties.expression', 'type': 'Expression'},
        'timeout': {'key': 'typeProperties.timeout', 'type': 'object'},
        'activities': {'key': 'typeProperties.activities', 'type': '[Activity]'},
    }

    def __init__(
        self,
        *,
        name: str,
        expression: "Expression",
        activities: List["Activity"],
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        timeout: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword expression: Required. An expression that would evaluate to Boolean. The loop will
         continue until this expression evaluates to true.
        :paramtype expression: ~azure.mgmt.datafactory.models.Expression
        :keyword timeout: Specifies the timeout for the activity to run. If there is no value
         specified, it takes the value of TimeSpan.FromDays(7) which is 1 week as default. Type: string
         (or Expression with resultType string), pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])). Type: string (or Expression with
         resultType string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype timeout: any
        :keyword activities: Required. List of activities to execute.
        :paramtype activities: list[~azure.mgmt.datafactory.models.Activity]
        """
        super(UntilActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Until'  # type: str
        self.expression = expression
        self.timeout = timeout
        self.activities = activities


class UpdateIntegrationRuntimeNodeRequest(msrest.serialization.Model):
    """Update integration runtime node request.

    :ivar concurrent_jobs_limit: The number of concurrent jobs permitted to run on the integration
     runtime node. Values between 1 and maxConcurrentJobs(inclusive) are allowed.
    :vartype concurrent_jobs_limit: int
    """

    _validation = {
        'concurrent_jobs_limit': {'minimum': 1},
    }

    _attribute_map = {
        'concurrent_jobs_limit': {'key': 'concurrentJobsLimit', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        concurrent_jobs_limit: Optional[int] = None,
        **kwargs
    ):
        """
        :keyword concurrent_jobs_limit: The number of concurrent jobs permitted to run on the
         integration runtime node. Values between 1 and maxConcurrentJobs(inclusive) are allowed.
        :paramtype concurrent_jobs_limit: int
        """
        super(UpdateIntegrationRuntimeNodeRequest, self).__init__(**kwargs)
        self.concurrent_jobs_limit = concurrent_jobs_limit


class UpdateIntegrationRuntimeRequest(msrest.serialization.Model):
    """Update integration runtime request.

    :ivar auto_update: Enables or disables the auto-update feature of the self-hosted integration
     runtime. See https://go.microsoft.com/fwlink/?linkid=854189. Possible values include: "On",
     "Off".
    :vartype auto_update: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeAutoUpdate
    :ivar update_delay_offset: The time offset (in hours) in the day, e.g., PT03H is 3 hours. The
     integration runtime auto update will happen on that time.
    :vartype update_delay_offset: str
    """

    _attribute_map = {
        'auto_update': {'key': 'autoUpdate', 'type': 'str'},
        'update_delay_offset': {'key': 'updateDelayOffset', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        auto_update: Optional[Union[str, "IntegrationRuntimeAutoUpdate"]] = None,
        update_delay_offset: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword auto_update: Enables or disables the auto-update feature of the self-hosted
         integration runtime. See https://go.microsoft.com/fwlink/?linkid=854189. Possible values
         include: "On", "Off".
        :paramtype auto_update: str or ~azure.mgmt.datafactory.models.IntegrationRuntimeAutoUpdate
        :keyword update_delay_offset: The time offset (in hours) in the day, e.g., PT03H is 3 hours.
         The integration runtime auto update will happen on that time.
        :paramtype update_delay_offset: str
        """
        super(UpdateIntegrationRuntimeRequest, self).__init__(**kwargs)
        self.auto_update = auto_update
        self.update_delay_offset = update_delay_offset


class UserAccessPolicy(msrest.serialization.Model):
    """Get Data Plane read only token request definition.

    :ivar permissions: The string with permissions for Data Plane access. Currently only 'r' is
     supported which grants read only access.
    :vartype permissions: str
    :ivar access_resource_path: The resource path to get access relative to factory. Currently only
     empty string is supported which corresponds to the factory resource.
    :vartype access_resource_path: str
    :ivar profile_name: The name of the profile. Currently only the default is supported. The
     default value is DefaultProfile.
    :vartype profile_name: str
    :ivar start_time: Start time for the token. If not specified the current time will be used.
    :vartype start_time: str
    :ivar expire_time: Expiration time for the token. Maximum duration for the token is eight hours
     and by default the token will expire in eight hours.
    :vartype expire_time: str
    """

    _attribute_map = {
        'permissions': {'key': 'permissions', 'type': 'str'},
        'access_resource_path': {'key': 'accessResourcePath', 'type': 'str'},
        'profile_name': {'key': 'profileName', 'type': 'str'},
        'start_time': {'key': 'startTime', 'type': 'str'},
        'expire_time': {'key': 'expireTime', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        permissions: Optional[str] = None,
        access_resource_path: Optional[str] = None,
        profile_name: Optional[str] = None,
        start_time: Optional[str] = None,
        expire_time: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword permissions: The string with permissions for Data Plane access. Currently only 'r' is
         supported which grants read only access.
        :paramtype permissions: str
        :keyword access_resource_path: The resource path to get access relative to factory. Currently
         only empty string is supported which corresponds to the factory resource.
        :paramtype access_resource_path: str
        :keyword profile_name: The name of the profile. Currently only the default is supported. The
         default value is DefaultProfile.
        :paramtype profile_name: str
        :keyword start_time: Start time for the token. If not specified the current time will be used.
        :paramtype start_time: str
        :keyword expire_time: Expiration time for the token. Maximum duration for the token is eight
         hours and by default the token will expire in eight hours.
        :paramtype expire_time: str
        """
        super(UserAccessPolicy, self).__init__(**kwargs)
        self.permissions = permissions
        self.access_resource_path = access_resource_path
        self.profile_name = profile_name
        self.start_time = start_time
        self.expire_time = expire_time


class UserProperty(msrest.serialization.Model):
    """User property.

    All required parameters must be populated in order to send to Azure.

    :ivar name: Required. User property name.
    :vartype name: str
    :ivar value: Required. User property value. Type: string (or Expression with resultType
     string).
    :vartype value: any
    """

    _validation = {
        'name': {'required': True},
        'value': {'required': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'value': {'key': 'value', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        value: Any,
        **kwargs
    ):
        """
        :keyword name: Required. User property name.
        :paramtype name: str
        :keyword value: Required. User property value. Type: string (or Expression with resultType
         string).
        :paramtype value: any
        """
        super(UserProperty, self).__init__(**kwargs)
        self.name = name
        self.value = value


class ValidationActivity(ControlActivity):
    """This activity verifies that an external resource exists.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar timeout: Specifies the timeout for the activity to run. If there is no value specified,
     it takes the value of TimeSpan.FromDays(7) which is 1 week as default. Type: string (or
     Expression with resultType string), pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype timeout: any
    :ivar sleep: A delay in seconds between validation attempts. If no value is specified, 10
     seconds will be used as the default. Type: integer (or Expression with resultType integer).
    :vartype sleep: any
    :ivar minimum_size: Can be used if dataset points to a file. The file must be greater than or
     equal in size to the value specified. Type: integer (or Expression with resultType integer).
    :vartype minimum_size: any
    :ivar child_items: Can be used if dataset points to a folder. If set to true, the folder must
     have at least one file. If set to false, the folder must be empty. Type: boolean (or Expression
     with resultType boolean).
    :vartype child_items: any
    :ivar dataset: Required. Validation activity dataset reference.
    :vartype dataset: ~azure.mgmt.datafactory.models.DatasetReference
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'dataset': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'timeout': {'key': 'typeProperties.timeout', 'type': 'object'},
        'sleep': {'key': 'typeProperties.sleep', 'type': 'object'},
        'minimum_size': {'key': 'typeProperties.minimumSize', 'type': 'object'},
        'child_items': {'key': 'typeProperties.childItems', 'type': 'object'},
        'dataset': {'key': 'typeProperties.dataset', 'type': 'DatasetReference'},
    }

    def __init__(
        self,
        *,
        name: str,
        dataset: "DatasetReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        timeout: Optional[Any] = None,
        sleep: Optional[Any] = None,
        minimum_size: Optional[Any] = None,
        child_items: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword timeout: Specifies the timeout for the activity to run. If there is no value
         specified, it takes the value of TimeSpan.FromDays(7) which is 1 week as default. Type: string
         (or Expression with resultType string), pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype timeout: any
        :keyword sleep: A delay in seconds between validation attempts. If no value is specified, 10
         seconds will be used as the default. Type: integer (or Expression with resultType integer).
        :paramtype sleep: any
        :keyword minimum_size: Can be used if dataset points to a file. The file must be greater than
         or equal in size to the value specified. Type: integer (or Expression with resultType integer).
        :paramtype minimum_size: any
        :keyword child_items: Can be used if dataset points to a folder. If set to true, the folder
         must have at least one file. If set to false, the folder must be empty. Type: boolean (or
         Expression with resultType boolean).
        :paramtype child_items: any
        :keyword dataset: Required. Validation activity dataset reference.
        :paramtype dataset: ~azure.mgmt.datafactory.models.DatasetReference
        """
        super(ValidationActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Validation'  # type: str
        self.timeout = timeout
        self.sleep = sleep
        self.minimum_size = minimum_size
        self.child_items = child_items
        self.dataset = dataset


class VariableSpecification(msrest.serialization.Model):
    """Definition of a single variable for a Pipeline.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Variable type. Possible values include: "String", "Bool", "Array".
    :vartype type: str or ~azure.mgmt.datafactory.models.VariableType
    :ivar default_value: Default value of variable.
    :vartype default_value: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'default_value': {'key': 'defaultValue', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        type: Union[str, "VariableType"],
        default_value: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword type: Required. Variable type. Possible values include: "String", "Bool", "Array".
        :paramtype type: str or ~azure.mgmt.datafactory.models.VariableType
        :keyword default_value: Default value of variable.
        :paramtype default_value: any
        """
        super(VariableSpecification, self).__init__(**kwargs)
        self.type = type
        self.default_value = default_value


class VerticaLinkedService(LinkedService):
    """Vertica linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_string: An ODBC connection string. Type: string, SecureString or
     AzureKeyVaultSecretReference.
    :vartype connection_string: any
    :ivar pwd: The Azure key vault secret reference of password in connection string.
    :vartype pwd: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_string': {'key': 'typeProperties.connectionString', 'type': 'object'},
        'pwd': {'key': 'typeProperties.pwd', 'type': 'AzureKeyVaultSecretReference'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_string: Optional[Any] = None,
        pwd: Optional["AzureKeyVaultSecretReference"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_string: An ODBC connection string. Type: string, SecureString or
         AzureKeyVaultSecretReference.
        :paramtype connection_string: any
        :keyword pwd: The Azure key vault secret reference of password in connection string.
        :paramtype pwd: ~azure.mgmt.datafactory.models.AzureKeyVaultSecretReference
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(VerticaLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Vertica'  # type: str
        self.connection_string = connection_string
        self.pwd = pwd
        self.encrypted_credential = encrypted_credential


class VerticaSource(TabularSource):
    """A copy activity Vertica source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(VerticaSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'VerticaSource'  # type: str
        self.query = query


class VerticaTableDataset(Dataset):
    """Vertica dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: This property will be retired. Please consider using schema + table
     properties instead.
    :vartype table_name: any
    :ivar table: The table name of the Vertica. Type: string (or Expression with resultType
     string).
    :vartype table: any
    :ivar schema_type_properties_schema: The schema name of the Vertica. Type: string (or
     Expression with resultType string).
    :vartype schema_type_properties_schema: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
        'table': {'key': 'typeProperties.table', 'type': 'object'},
        'schema_type_properties_schema': {'key': 'typeProperties.schema', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        table: Optional[Any] = None,
        schema_type_properties_schema: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: This property will be retired. Please consider using schema + table
         properties instead.
        :paramtype table_name: any
        :keyword table: The table name of the Vertica. Type: string (or Expression with resultType
         string).
        :paramtype table: any
        :keyword schema_type_properties_schema: The schema name of the Vertica. Type: string (or
         Expression with resultType string).
        :paramtype schema_type_properties_schema: any
        """
        super(VerticaTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'VerticaTable'  # type: str
        self.table_name = table_name
        self.table = table
        self.schema_type_properties_schema = schema_type_properties_schema


class WaitActivity(ControlActivity):
    """This activity suspends pipeline execution for the specified interval.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar wait_time_in_seconds: Required. Duration in seconds.
    :vartype wait_time_in_seconds: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'wait_time_in_seconds': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'wait_time_in_seconds': {'key': 'typeProperties.waitTimeInSeconds', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        wait_time_in_seconds: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword wait_time_in_seconds: Required. Duration in seconds.
        :paramtype wait_time_in_seconds: any
        """
        super(WaitActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'Wait'  # type: str
        self.wait_time_in_seconds = wait_time_in_seconds


class WebActivity(ExecutionActivity):
    """Web activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar linked_service_name: Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar policy: Activity policy.
    :vartype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
    :ivar method: Required. Rest API method for target endpoint. Possible values include: "GET",
     "POST", "PUT", "DELETE".
    :vartype method: str or ~azure.mgmt.datafactory.models.WebActivityMethod
    :ivar url: Required. Web activity target endpoint and path. Type: string (or Expression with
     resultType string).
    :vartype url: any
    :ivar headers: Represents the headers that will be sent to the request. For example, to set the
     language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type":
     "application/json" }. Type: string (or Expression with resultType string).
    :vartype headers: any
    :ivar body: Represents the payload that will be sent to the endpoint. Required for POST/PUT
     method, not allowed for GET method Type: string (or Expression with resultType string).
    :vartype body: any
    :ivar authentication: Authentication method used for calling the endpoint.
    :vartype authentication: ~azure.mgmt.datafactory.models.WebActivityAuthentication
    :ivar disable_cert_validation: When set to true, Certificate validation will be disabled.
    :vartype disable_cert_validation: bool
    :ivar datasets: List of datasets passed to web endpoint.
    :vartype datasets: list[~azure.mgmt.datafactory.models.DatasetReference]
    :ivar linked_services: List of linked services passed to web endpoint.
    :vartype linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceReference]
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'method': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'policy': {'key': 'policy', 'type': 'ActivityPolicy'},
        'method': {'key': 'typeProperties.method', 'type': 'str'},
        'url': {'key': 'typeProperties.url', 'type': 'object'},
        'headers': {'key': 'typeProperties.headers', 'type': 'object'},
        'body': {'key': 'typeProperties.body', 'type': 'object'},
        'authentication': {'key': 'typeProperties.authentication', 'type': 'WebActivityAuthentication'},
        'disable_cert_validation': {'key': 'typeProperties.disableCertValidation', 'type': 'bool'},
        'datasets': {'key': 'typeProperties.datasets', 'type': '[DatasetReference]'},
        'linked_services': {'key': 'typeProperties.linkedServices', 'type': '[LinkedServiceReference]'},
        'connect_via': {'key': 'typeProperties.connectVia', 'type': 'IntegrationRuntimeReference'},
    }

    def __init__(
        self,
        *,
        name: str,
        method: Union[str, "WebActivityMethod"],
        url: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        linked_service_name: Optional["LinkedServiceReference"] = None,
        policy: Optional["ActivityPolicy"] = None,
        headers: Optional[Any] = None,
        body: Optional[Any] = None,
        authentication: Optional["WebActivityAuthentication"] = None,
        disable_cert_validation: Optional[bool] = None,
        datasets: Optional[List["DatasetReference"]] = None,
        linked_services: Optional[List["LinkedServiceReference"]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword linked_service_name: Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword policy: Activity policy.
        :paramtype policy: ~azure.mgmt.datafactory.models.ActivityPolicy
        :keyword method: Required. Rest API method for target endpoint. Possible values include: "GET",
         "POST", "PUT", "DELETE".
        :paramtype method: str or ~azure.mgmt.datafactory.models.WebActivityMethod
        :keyword url: Required. Web activity target endpoint and path. Type: string (or Expression with
         resultType string).
        :paramtype url: any
        :keyword headers: Represents the headers that will be sent to the request. For example, to set
         the language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type":
         "application/json" }. Type: string (or Expression with resultType string).
        :paramtype headers: any
        :keyword body: Represents the payload that will be sent to the endpoint. Required for POST/PUT
         method, not allowed for GET method Type: string (or Expression with resultType string).
        :paramtype body: any
        :keyword authentication: Authentication method used for calling the endpoint.
        :paramtype authentication: ~azure.mgmt.datafactory.models.WebActivityAuthentication
        :keyword disable_cert_validation: When set to true, Certificate validation will be disabled.
        :paramtype disable_cert_validation: bool
        :keyword datasets: List of datasets passed to web endpoint.
        :paramtype datasets: list[~azure.mgmt.datafactory.models.DatasetReference]
        :keyword linked_services: List of linked services passed to web endpoint.
        :paramtype linked_services: list[~azure.mgmt.datafactory.models.LinkedServiceReference]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        """
        super(WebActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, linked_service_name=linked_service_name, policy=policy, **kwargs)
        self.type = 'WebActivity'  # type: str
        self.method = method
        self.url = url
        self.headers = headers
        self.body = body
        self.authentication = authentication
        self.disable_cert_validation = disable_cert_validation
        self.datasets = datasets
        self.linked_services = linked_services
        self.connect_via = connect_via


class WebActivityAuthentication(msrest.serialization.Model):
    """Web activity authentication properties.

    :ivar type: Web activity authentication (Basic/ClientCertificate/MSI/ServicePrincipal).
    :vartype type: str
    :ivar pfx: Base64-encoded contents of a PFX file or Certificate when used for ServicePrincipal.
    :vartype pfx: ~azure.mgmt.datafactory.models.SecretBase
    :ivar username: Web activity authentication user name for basic authentication or ClientID when
     used for ServicePrincipal. Type: string (or Expression with resultType string).
    :vartype username: any
    :ivar password: Password for the PFX file or basic authentication / Secret when used for
     ServicePrincipal.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar resource: Resource for which Azure Auth token will be requested when using MSI
     Authentication. Type: string (or Expression with resultType string).
    :vartype resource: any
    :ivar user_tenant: TenantId for which Azure Auth token will be requested when using
     ServicePrincipal Authentication. Type: string (or Expression with resultType string).
    :vartype user_tenant: any
    :ivar credential: The credential reference containing authentication information.
    :vartype credential: ~azure.mgmt.datafactory.models.CredentialReference
    """

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'pfx': {'key': 'pfx', 'type': 'SecretBase'},
        'username': {'key': 'username', 'type': 'object'},
        'password': {'key': 'password', 'type': 'SecretBase'},
        'resource': {'key': 'resource', 'type': 'object'},
        'user_tenant': {'key': 'userTenant', 'type': 'object'},
        'credential': {'key': 'credential', 'type': 'CredentialReference'},
    }

    def __init__(
        self,
        *,
        type: Optional[str] = None,
        pfx: Optional["SecretBase"] = None,
        username: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        resource: Optional[Any] = None,
        user_tenant: Optional[Any] = None,
        credential: Optional["CredentialReference"] = None,
        **kwargs
    ):
        """
        :keyword type: Web activity authentication (Basic/ClientCertificate/MSI/ServicePrincipal).
        :paramtype type: str
        :keyword pfx: Base64-encoded contents of a PFX file or Certificate when used for
         ServicePrincipal.
        :paramtype pfx: ~azure.mgmt.datafactory.models.SecretBase
        :keyword username: Web activity authentication user name for basic authentication or ClientID
         when used for ServicePrincipal. Type: string (or Expression with resultType string).
        :paramtype username: any
        :keyword password: Password for the PFX file or basic authentication / Secret when used for
         ServicePrincipal.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword resource: Resource for which Azure Auth token will be requested when using MSI
         Authentication. Type: string (or Expression with resultType string).
        :paramtype resource: any
        :keyword user_tenant: TenantId for which Azure Auth token will be requested when using
         ServicePrincipal Authentication. Type: string (or Expression with resultType string).
        :paramtype user_tenant: any
        :keyword credential: The credential reference containing authentication information.
        :paramtype credential: ~azure.mgmt.datafactory.models.CredentialReference
        """
        super(WebActivityAuthentication, self).__init__(**kwargs)
        self.type = type
        self.pfx = pfx
        self.username = username
        self.password = password
        self.resource = resource
        self.user_tenant = user_tenant
        self.credential = credential


class WebLinkedServiceTypeProperties(msrest.serialization.Model):
    """Base definition of WebLinkedServiceTypeProperties, this typeProperties is polymorphic based on authenticationType, so not flattened in SDK models.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: WebAnonymousAuthentication, WebBasicAuthentication, WebClientCertificateAuthentication.

    All required parameters must be populated in order to send to Azure.

    :ivar url: Required. The URL of the web service endpoint, e.g. http://www.microsoft.com . Type:
     string (or Expression with resultType string).
    :vartype url: any
    :ivar authentication_type: Required. Type of authentication used to connect to the web table
     source.Constant filled by server. Possible values include: "Basic", "Anonymous",
     "ClientCertificate".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.WebAuthenticationType
    """

    _validation = {
        'url': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'object'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
    }

    _subtype_map = {
        'authentication_type': {'Anonymous': 'WebAnonymousAuthentication', 'Basic': 'WebBasicAuthentication', 'ClientCertificate': 'WebClientCertificateAuthentication'}
    }

    def __init__(
        self,
        *,
        url: Any,
        **kwargs
    ):
        """
        :keyword url: Required. The URL of the web service endpoint, e.g. http://www.microsoft.com .
         Type: string (or Expression with resultType string).
        :paramtype url: any
        """
        super(WebLinkedServiceTypeProperties, self).__init__(**kwargs)
        self.url = url
        self.authentication_type = None  # type: Optional[str]


class WebAnonymousAuthentication(WebLinkedServiceTypeProperties):
    """A WebLinkedService that uses anonymous authentication to communicate with an HTTP endpoint.

    All required parameters must be populated in order to send to Azure.

    :ivar url: Required. The URL of the web service endpoint, e.g. http://www.microsoft.com . Type:
     string (or Expression with resultType string).
    :vartype url: any
    :ivar authentication_type: Required. Type of authentication used to connect to the web table
     source.Constant filled by server. Possible values include: "Basic", "Anonymous",
     "ClientCertificate".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.WebAuthenticationType
    """

    _validation = {
        'url': {'required': True},
        'authentication_type': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'object'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        url: Any,
        **kwargs
    ):
        """
        :keyword url: Required. The URL of the web service endpoint, e.g. http://www.microsoft.com .
         Type: string (or Expression with resultType string).
        :paramtype url: any
        """
        super(WebAnonymousAuthentication, self).__init__(url=url, **kwargs)
        self.authentication_type = 'Anonymous'  # type: str


class WebBasicAuthentication(WebLinkedServiceTypeProperties):
    """A WebLinkedService that uses basic authentication to communicate with an HTTP endpoint.

    All required parameters must be populated in order to send to Azure.

    :ivar url: Required. The URL of the web service endpoint, e.g. http://www.microsoft.com . Type:
     string (or Expression with resultType string).
    :vartype url: any
    :ivar authentication_type: Required. Type of authentication used to connect to the web table
     source.Constant filled by server. Possible values include: "Basic", "Anonymous",
     "ClientCertificate".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.WebAuthenticationType
    :ivar username: Required. User name for Basic authentication. Type: string (or Expression with
     resultType string).
    :vartype username: any
    :ivar password: Required. The password for Basic authentication.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    """

    _validation = {
        'url': {'required': True},
        'authentication_type': {'required': True},
        'username': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'object'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'username': {'key': 'username', 'type': 'object'},
        'password': {'key': 'password', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        url: Any,
        username: Any,
        password: "SecretBase",
        **kwargs
    ):
        """
        :keyword url: Required. The URL of the web service endpoint, e.g. http://www.microsoft.com .
         Type: string (or Expression with resultType string).
        :paramtype url: any
        :keyword username: Required. User name for Basic authentication. Type: string (or Expression
         with resultType string).
        :paramtype username: any
        :keyword password: Required. The password for Basic authentication.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        """
        super(WebBasicAuthentication, self).__init__(url=url, **kwargs)
        self.authentication_type = 'Basic'  # type: str
        self.username = username
        self.password = password


class WebClientCertificateAuthentication(WebLinkedServiceTypeProperties):
    """A WebLinkedService that uses client certificate based authentication to communicate with an HTTP endpoint. This scheme follows mutual authentication; the server must also provide valid credentials to the client.

    All required parameters must be populated in order to send to Azure.

    :ivar url: Required. The URL of the web service endpoint, e.g. http://www.microsoft.com . Type:
     string (or Expression with resultType string).
    :vartype url: any
    :ivar authentication_type: Required. Type of authentication used to connect to the web table
     source.Constant filled by server. Possible values include: "Basic", "Anonymous",
     "ClientCertificate".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.WebAuthenticationType
    :ivar pfx: Required. Base64-encoded contents of a PFX file.
    :vartype pfx: ~azure.mgmt.datafactory.models.SecretBase
    :ivar password: Required. Password for the PFX file.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    """

    _validation = {
        'url': {'required': True},
        'authentication_type': {'required': True},
        'pfx': {'required': True},
        'password': {'required': True},
    }

    _attribute_map = {
        'url': {'key': 'url', 'type': 'object'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'pfx': {'key': 'pfx', 'type': 'SecretBase'},
        'password': {'key': 'password', 'type': 'SecretBase'},
    }

    def __init__(
        self,
        *,
        url: Any,
        pfx: "SecretBase",
        password: "SecretBase",
        **kwargs
    ):
        """
        :keyword url: Required. The URL of the web service endpoint, e.g. http://www.microsoft.com .
         Type: string (or Expression with resultType string).
        :paramtype url: any
        :keyword pfx: Required. Base64-encoded contents of a PFX file.
        :paramtype pfx: ~azure.mgmt.datafactory.models.SecretBase
        :keyword password: Required. Password for the PFX file.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        """
        super(WebClientCertificateAuthentication, self).__init__(url=url, **kwargs)
        self.authentication_type = 'ClientCertificate'  # type: str
        self.pfx = pfx
        self.password = password


class WebHookActivity(ControlActivity):
    """WebHook activity.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar name: Required. Activity name.
    :vartype name: str
    :ivar type: Required. Type of activity.Constant filled by server.
    :vartype type: str
    :ivar description: Activity description.
    :vartype description: str
    :ivar depends_on: Activity depends on condition.
    :vartype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
    :ivar user_properties: Activity user properties.
    :vartype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
    :ivar method: Required. Rest API method for target endpoint. Possible values include: "POST".
    :vartype method: str or ~azure.mgmt.datafactory.models.WebHookActivityMethod
    :ivar url: Required. WebHook activity target endpoint and path. Type: string (or Expression
     with resultType string).
    :vartype url: any
    :ivar timeout: The timeout within which the webhook should be called back. If there is no value
     specified, it defaults to 10 minutes. Type: string. Pattern:
     ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype timeout: str
    :ivar headers: Represents the headers that will be sent to the request. For example, to set the
     language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type":
     "application/json" }. Type: string (or Expression with resultType string).
    :vartype headers: any
    :ivar body: Represents the payload that will be sent to the endpoint. Required for POST/PUT
     method, not allowed for GET method Type: string (or Expression with resultType string).
    :vartype body: any
    :ivar authentication: Authentication method used for calling the endpoint.
    :vartype authentication: ~azure.mgmt.datafactory.models.WebActivityAuthentication
    :ivar report_status_on_call_back: When set to true, statusCode, output and error in callback
     request body will be consumed by activity. The activity can be marked as failed by setting
     statusCode >= 400 in callback request. Default is false. Type: boolean (or Expression with
     resultType boolean).
    :vartype report_status_on_call_back: any
    """

    _validation = {
        'name': {'required': True},
        'type': {'required': True},
        'method': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'name': {'key': 'name', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'depends_on': {'key': 'dependsOn', 'type': '[ActivityDependency]'},
        'user_properties': {'key': 'userProperties', 'type': '[UserProperty]'},
        'method': {'key': 'typeProperties.method', 'type': 'str'},
        'url': {'key': 'typeProperties.url', 'type': 'object'},
        'timeout': {'key': 'typeProperties.timeout', 'type': 'str'},
        'headers': {'key': 'typeProperties.headers', 'type': 'object'},
        'body': {'key': 'typeProperties.body', 'type': 'object'},
        'authentication': {'key': 'typeProperties.authentication', 'type': 'WebActivityAuthentication'},
        'report_status_on_call_back': {'key': 'typeProperties.reportStatusOnCallBack', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        name: str,
        method: Union[str, "WebHookActivityMethod"],
        url: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        depends_on: Optional[List["ActivityDependency"]] = None,
        user_properties: Optional[List["UserProperty"]] = None,
        timeout: Optional[str] = None,
        headers: Optional[Any] = None,
        body: Optional[Any] = None,
        authentication: Optional["WebActivityAuthentication"] = None,
        report_status_on_call_back: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword name: Required. Activity name.
        :paramtype name: str
        :keyword description: Activity description.
        :paramtype description: str
        :keyword depends_on: Activity depends on condition.
        :paramtype depends_on: list[~azure.mgmt.datafactory.models.ActivityDependency]
        :keyword user_properties: Activity user properties.
        :paramtype user_properties: list[~azure.mgmt.datafactory.models.UserProperty]
        :keyword method: Required. Rest API method for target endpoint. Possible values include:
         "POST".
        :paramtype method: str or ~azure.mgmt.datafactory.models.WebHookActivityMethod
        :keyword url: Required. WebHook activity target endpoint and path. Type: string (or Expression
         with resultType string).
        :paramtype url: any
        :keyword timeout: The timeout within which the webhook should be called back. If there is no
         value specified, it defaults to 10 minutes. Type: string. Pattern:
         ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype timeout: str
        :keyword headers: Represents the headers that will be sent to the request. For example, to set
         the language and type on a request: "headers" : { "Accept-Language": "en-us", "Content-Type":
         "application/json" }. Type: string (or Expression with resultType string).
        :paramtype headers: any
        :keyword body: Represents the payload that will be sent to the endpoint. Required for POST/PUT
         method, not allowed for GET method Type: string (or Expression with resultType string).
        :paramtype body: any
        :keyword authentication: Authentication method used for calling the endpoint.
        :paramtype authentication: ~azure.mgmt.datafactory.models.WebActivityAuthentication
        :keyword report_status_on_call_back: When set to true, statusCode, output and error in callback
         request body will be consumed by activity. The activity can be marked as failed by setting
         statusCode >= 400 in callback request. Default is false. Type: boolean (or Expression with
         resultType boolean).
        :paramtype report_status_on_call_back: any
        """
        super(WebHookActivity, self).__init__(additional_properties=additional_properties, name=name, description=description, depends_on=depends_on, user_properties=user_properties, **kwargs)
        self.type = 'WebHook'  # type: str
        self.method = method
        self.url = url
        self.timeout = timeout
        self.headers = headers
        self.body = body
        self.authentication = authentication
        self.report_status_on_call_back = report_status_on_call_back


class WebLinkedService(LinkedService):
    """Web linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar type_properties: Required. Web linked service properties.
    :vartype type_properties: ~azure.mgmt.datafactory.models.WebLinkedServiceTypeProperties
    """

    _validation = {
        'type': {'required': True},
        'type_properties': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'type_properties': {'key': 'typeProperties', 'type': 'WebLinkedServiceTypeProperties'},
    }

    def __init__(
        self,
        *,
        type_properties: "WebLinkedServiceTypeProperties",
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword type_properties: Required. Web linked service properties.
        :paramtype type_properties: ~azure.mgmt.datafactory.models.WebLinkedServiceTypeProperties
        """
        super(WebLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Web'  # type: str
        self.type_properties = type_properties


class WebSource(CopySource):
    """A copy activity source for web page table.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(WebSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'WebSource'  # type: str
        self.additional_columns = additional_columns


class WebTableDataset(Dataset):
    """The dataset points to a HTML table in the web page.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar index: Required. The zero-based index of the table in the web page. Type: integer (or
     Expression with resultType integer), minimum: 0.
    :vartype index: any
    :ivar path: The relative URL to the web page from the linked service URL. Type: string (or
     Expression with resultType string).
    :vartype path: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
        'index': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'index': {'key': 'typeProperties.index', 'type': 'object'},
        'path': {'key': 'typeProperties.path', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        index: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        path: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword index: Required. The zero-based index of the table in the web page. Type: integer (or
         Expression with resultType integer), minimum: 0.
        :paramtype index: any
        :keyword path: The relative URL to the web page from the linked service URL. Type: string (or
         Expression with resultType string).
        :paramtype path: any
        """
        super(WebTableDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'WebTable'  # type: str
        self.index = index
        self.path = path


class WranglingDataFlow(DataFlow):
    """Power Query data flow.

    All required parameters must be populated in order to send to Azure.

    :ivar type: Required. Type of data flow.Constant filled by server.
    :vartype type: str
    :ivar description: The description of the data flow.
    :vartype description: str
    :ivar annotations: List of tags that can be used for describing the data flow.
    :vartype annotations: list[any]
    :ivar folder: The folder that this data flow is in. If not specified, Data flow will appear at
     the root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DataFlowFolder
    :ivar sources: List of sources in Power Query.
    :vartype sources: list[~azure.mgmt.datafactory.models.PowerQuerySource]
    :ivar script: Power query mashup script.
    :vartype script: str
    :ivar document_locale: Locale of the Power query mashup document.
    :vartype document_locale: str
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DataFlowFolder'},
        'sources': {'key': 'typeProperties.sources', 'type': '[PowerQuerySource]'},
        'script': {'key': 'typeProperties.script', 'type': 'str'},
        'document_locale': {'key': 'typeProperties.documentLocale', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        description: Optional[str] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DataFlowFolder"] = None,
        sources: Optional[List["PowerQuerySource"]] = None,
        script: Optional[str] = None,
        document_locale: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword description: The description of the data flow.
        :paramtype description: str
        :keyword annotations: List of tags that can be used for describing the data flow.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this data flow is in. If not specified, Data flow will appear
         at the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DataFlowFolder
        :keyword sources: List of sources in Power Query.
        :paramtype sources: list[~azure.mgmt.datafactory.models.PowerQuerySource]
        :keyword script: Power query mashup script.
        :paramtype script: str
        :keyword document_locale: Locale of the Power query mashup document.
        :paramtype document_locale: str
        """
        super(WranglingDataFlow, self).__init__(description=description, annotations=annotations, folder=folder, **kwargs)
        self.type = 'WranglingDataFlow'  # type: str
        self.sources = sources
        self.script = script
        self.document_locale = document_locale


class XeroLinkedService(LinkedService):
    """Xero Service linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_properties: Properties used to connect to Xero. It is mutually exclusive with
     any other properties in the linked service. Type: object.
    :vartype connection_properties: any
    :ivar host: The endpoint of the Xero server. (i.e. api.xero.com).
    :vartype host: any
    :ivar consumer_key: The consumer key associated with the Xero application.
    :vartype consumer_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar private_key: The private key from the .pem file that was generated for your Xero private
     application. You must include all the text from the .pem file, including the Unix line endings(
     ).
    :vartype private_key: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_properties': {'key': 'typeProperties.connectionProperties', 'type': 'object'},
        'host': {'key': 'typeProperties.host', 'type': 'object'},
        'consumer_key': {'key': 'typeProperties.consumerKey', 'type': 'SecretBase'},
        'private_key': {'key': 'typeProperties.privateKey', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_properties: Optional[Any] = None,
        host: Optional[Any] = None,
        consumer_key: Optional["SecretBase"] = None,
        private_key: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_properties: Properties used to connect to Xero. It is mutually exclusive
         with any other properties in the linked service. Type: object.
        :paramtype connection_properties: any
        :keyword host: The endpoint of the Xero server. (i.e. api.xero.com).
        :paramtype host: any
        :keyword consumer_key: The consumer key associated with the Xero application.
        :paramtype consumer_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword private_key: The private key from the .pem file that was generated for your Xero
         private application. You must include all the text from the .pem file, including the Unix line
         endings(
         ).
        :paramtype private_key: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true.
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true.
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(XeroLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Xero'  # type: str
        self.connection_properties = connection_properties
        self.host = host
        self.consumer_key = consumer_key
        self.private_key = private_key
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class XeroObjectDataset(Dataset):
    """Xero Service dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(XeroObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'XeroObject'  # type: str
        self.table_name = table_name


class XeroSource(TabularSource):
    """A copy activity Xero Service source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(XeroSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'XeroSource'  # type: str
        self.query = query


class XmlDataset(Dataset):
    """Xml dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar location: The location of the json data storage.
    :vartype location: ~azure.mgmt.datafactory.models.DatasetLocation
    :ivar encoding_name: The code page name of the preferred encoding. If not specified, the
     default value is UTF-8, unless BOM denotes another Unicode encoding. Refer to the name column
     of the table in the following link to set supported values:
     https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
     resultType string).
    :vartype encoding_name: any
    :ivar null_value: The null value string. Type: string (or Expression with resultType string).
    :vartype null_value: any
    :ivar compression: The data compression method used for the json dataset.
    :vartype compression: ~azure.mgmt.datafactory.models.DatasetCompression
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'location': {'key': 'typeProperties.location', 'type': 'DatasetLocation'},
        'encoding_name': {'key': 'typeProperties.encodingName', 'type': 'object'},
        'null_value': {'key': 'typeProperties.nullValue', 'type': 'object'},
        'compression': {'key': 'typeProperties.compression', 'type': 'DatasetCompression'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        location: Optional["DatasetLocation"] = None,
        encoding_name: Optional[Any] = None,
        null_value: Optional[Any] = None,
        compression: Optional["DatasetCompression"] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword location: The location of the json data storage.
        :paramtype location: ~azure.mgmt.datafactory.models.DatasetLocation
        :keyword encoding_name: The code page name of the preferred encoding. If not specified, the
         default value is UTF-8, unless BOM denotes another Unicode encoding. Refer to the name column
         of the table in the following link to set supported values:
         https://msdn.microsoft.com/library/system.text.encoding.aspx. Type: string (or Expression with
         resultType string).
        :paramtype encoding_name: any
        :keyword null_value: The null value string. Type: string (or Expression with resultType
         string).
        :paramtype null_value: any
        :keyword compression: The data compression method used for the json dataset.
        :paramtype compression: ~azure.mgmt.datafactory.models.DatasetCompression
        """
        super(XmlDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'Xml'  # type: str
        self.location = location
        self.encoding_name = encoding_name
        self.null_value = null_value
        self.compression = compression


class XmlReadSettings(FormatReadSettings):
    """Xml read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The read setting type.Constant filled by server.
    :vartype type: str
    :ivar compression_properties: Compression settings.
    :vartype compression_properties: ~azure.mgmt.datafactory.models.CompressionReadSettings
    :ivar validation_mode: Indicates what validation method is used when reading the xml files.
     Allowed values: 'none', 'xsd', or 'dtd'. Type: string (or Expression with resultType string).
    :vartype validation_mode: any
    :ivar detect_data_type: Indicates whether type detection is enabled when reading the xml files.
     Type: boolean (or Expression with resultType boolean).
    :vartype detect_data_type: any
    :ivar namespaces: Indicates whether namespace is enabled when reading the xml files. Type:
     boolean (or Expression with resultType boolean).
    :vartype namespaces: any
    :ivar namespace_prefixes: Namespace uri to prefix mappings to override the prefixes in column
     names when namespace is enabled, if no prefix is defined for a namespace uri, the prefix of xml
     element/attribute name in the xml data file will be used. Example:
     "{"http://www.example.com/xml":"prefix"}" Type: object (or Expression with resultType object).
    :vartype namespace_prefixes: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'compression_properties': {'key': 'compressionProperties', 'type': 'CompressionReadSettings'},
        'validation_mode': {'key': 'validationMode', 'type': 'object'},
        'detect_data_type': {'key': 'detectDataType', 'type': 'object'},
        'namespaces': {'key': 'namespaces', 'type': 'object'},
        'namespace_prefixes': {'key': 'namespacePrefixes', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        compression_properties: Optional["CompressionReadSettings"] = None,
        validation_mode: Optional[Any] = None,
        detect_data_type: Optional[Any] = None,
        namespaces: Optional[Any] = None,
        namespace_prefixes: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword compression_properties: Compression settings.
        :paramtype compression_properties: ~azure.mgmt.datafactory.models.CompressionReadSettings
        :keyword validation_mode: Indicates what validation method is used when reading the xml files.
         Allowed values: 'none', 'xsd', or 'dtd'. Type: string (or Expression with resultType string).
        :paramtype validation_mode: any
        :keyword detect_data_type: Indicates whether type detection is enabled when reading the xml
         files. Type: boolean (or Expression with resultType boolean).
        :paramtype detect_data_type: any
        :keyword namespaces: Indicates whether namespace is enabled when reading the xml files. Type:
         boolean (or Expression with resultType boolean).
        :paramtype namespaces: any
        :keyword namespace_prefixes: Namespace uri to prefix mappings to override the prefixes in
         column names when namespace is enabled, if no prefix is defined for a namespace uri, the prefix
         of xml element/attribute name in the xml data file will be used. Example:
         "{"http://www.example.com/xml":"prefix"}" Type: object (or Expression with resultType object).
        :paramtype namespace_prefixes: any
        """
        super(XmlReadSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'XmlReadSettings'  # type: str
        self.compression_properties = compression_properties
        self.validation_mode = validation_mode
        self.detect_data_type = detect_data_type
        self.namespaces = namespaces
        self.namespace_prefixes = namespace_prefixes


class XmlSource(CopySource):
    """A copy activity Xml source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar store_settings: Xml store settings.
    :vartype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
    :ivar format_settings: Xml format settings.
    :vartype format_settings: ~azure.mgmt.datafactory.models.XmlReadSettings
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'store_settings': {'key': 'storeSettings', 'type': 'StoreReadSettings'},
        'format_settings': {'key': 'formatSettings', 'type': 'XmlReadSettings'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        store_settings: Optional["StoreReadSettings"] = None,
        format_settings: Optional["XmlReadSettings"] = None,
        additional_columns: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword store_settings: Xml store settings.
        :paramtype store_settings: ~azure.mgmt.datafactory.models.StoreReadSettings
        :keyword format_settings: Xml format settings.
        :paramtype format_settings: ~azure.mgmt.datafactory.models.XmlReadSettings
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        """
        super(XmlSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, **kwargs)
        self.type = 'XmlSource'  # type: str
        self.store_settings = store_settings
        self.format_settings = format_settings
        self.additional_columns = additional_columns


class ZendeskLinkedService(LinkedService):
    """Linked service for Zendesk.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar authentication_type: Required. The authentication type to use. Possible values include:
     "Basic", "Token".
    :vartype authentication_type: str or ~azure.mgmt.datafactory.models.ZendeskAuthenticationType
    :ivar url: Required. The url to connect Zendesk source. Type: string (or Expression with
     resultType string).
    :vartype url: any
    :ivar user_name: The username of the Zendesk source. Type: string (or Expression with
     resultType string).
    :vartype user_name: any
    :ivar password: The password of the Zendesk source.
    :vartype password: ~azure.mgmt.datafactory.models.SecretBase
    :ivar api_token: The api token for the Zendesk source.
    :vartype api_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
        'authentication_type': {'required': True},
        'url': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'authentication_type': {'key': 'typeProperties.authenticationType', 'type': 'str'},
        'url': {'key': 'typeProperties.url', 'type': 'object'},
        'user_name': {'key': 'typeProperties.userName', 'type': 'object'},
        'password': {'key': 'typeProperties.password', 'type': 'SecretBase'},
        'api_token': {'key': 'typeProperties.apiToken', 'type': 'SecretBase'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        authentication_type: Union[str, "ZendeskAuthenticationType"],
        url: Any,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        user_name: Optional[Any] = None,
        password: Optional["SecretBase"] = None,
        api_token: Optional["SecretBase"] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword authentication_type: Required. The authentication type to use. Possible values
         include: "Basic", "Token".
        :paramtype authentication_type: str or ~azure.mgmt.datafactory.models.ZendeskAuthenticationType
        :keyword url: Required. The url to connect Zendesk source. Type: string (or Expression with
         resultType string).
        :paramtype url: any
        :keyword user_name: The username of the Zendesk source. Type: string (or Expression with
         resultType string).
        :paramtype user_name: any
        :keyword password: The password of the Zendesk source.
        :paramtype password: ~azure.mgmt.datafactory.models.SecretBase
        :keyword api_token: The api token for the Zendesk source.
        :paramtype api_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(ZendeskLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Zendesk'  # type: str
        self.authentication_type = authentication_type
        self.url = url
        self.user_name = user_name
        self.password = password
        self.api_token = api_token
        self.encrypted_credential = encrypted_credential


class ZipDeflateReadSettings(CompressionReadSettings):
    """The ZipDeflate compression read settings.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. The Compression setting type.Constant filled by server.
    :vartype type: str
    :ivar preserve_zip_file_name_as_folder: Preserve the zip file name as folder path. Type:
     boolean (or Expression with resultType boolean).
    :vartype preserve_zip_file_name_as_folder: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'preserve_zip_file_name_as_folder': {'key': 'preserveZipFileNameAsFolder', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        preserve_zip_file_name_as_folder: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword preserve_zip_file_name_as_folder: Preserve the zip file name as folder path. Type:
         boolean (or Expression with resultType boolean).
        :paramtype preserve_zip_file_name_as_folder: any
        """
        super(ZipDeflateReadSettings, self).__init__(additional_properties=additional_properties, **kwargs)
        self.type = 'ZipDeflateReadSettings'  # type: str
        self.preserve_zip_file_name_as_folder = preserve_zip_file_name_as_folder


class ZohoLinkedService(LinkedService):
    """Zoho server linked service.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of linked service.Constant filled by server.
    :vartype type: str
    :ivar connect_via: The integration runtime reference.
    :vartype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
    :ivar description: Linked service description.
    :vartype description: str
    :ivar parameters: Parameters for linked service.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the linked service.
    :vartype annotations: list[any]
    :ivar connection_properties: Properties used to connect to Zoho. It is mutually exclusive with
     any other properties in the linked service. Type: object.
    :vartype connection_properties: any
    :ivar endpoint: The endpoint of the Zoho server. (i.e. crm.zoho.com/crm/private).
    :vartype endpoint: any
    :ivar access_token: The access token for Zoho authentication.
    :vartype access_token: ~azure.mgmt.datafactory.models.SecretBase
    :ivar use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted using
     HTTPS. The default value is true.
    :vartype use_encrypted_endpoints: any
    :ivar use_host_verification: Specifies whether to require the host name in the server's
     certificate to match the host name of the server when connecting over SSL. The default value is
     true.
    :vartype use_host_verification: any
    :ivar use_peer_verification: Specifies whether to verify the identity of the server when
     connecting over SSL. The default value is true.
    :vartype use_peer_verification: any
    :ivar encrypted_credential: The encrypted credential used for authentication. Credentials are
     encrypted using the integration runtime credential manager. Type: string (or Expression with
     resultType string).
    :vartype encrypted_credential: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'connect_via': {'key': 'connectVia', 'type': 'IntegrationRuntimeReference'},
        'description': {'key': 'description', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'connection_properties': {'key': 'typeProperties.connectionProperties', 'type': 'object'},
        'endpoint': {'key': 'typeProperties.endpoint', 'type': 'object'},
        'access_token': {'key': 'typeProperties.accessToken', 'type': 'SecretBase'},
        'use_encrypted_endpoints': {'key': 'typeProperties.useEncryptedEndpoints', 'type': 'object'},
        'use_host_verification': {'key': 'typeProperties.useHostVerification', 'type': 'object'},
        'use_peer_verification': {'key': 'typeProperties.usePeerVerification', 'type': 'object'},
        'encrypted_credential': {'key': 'typeProperties.encryptedCredential', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        connect_via: Optional["IntegrationRuntimeReference"] = None,
        description: Optional[str] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        connection_properties: Optional[Any] = None,
        endpoint: Optional[Any] = None,
        access_token: Optional["SecretBase"] = None,
        use_encrypted_endpoints: Optional[Any] = None,
        use_host_verification: Optional[Any] = None,
        use_peer_verification: Optional[Any] = None,
        encrypted_credential: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword connect_via: The integration runtime reference.
        :paramtype connect_via: ~azure.mgmt.datafactory.models.IntegrationRuntimeReference
        :keyword description: Linked service description.
        :paramtype description: str
        :keyword parameters: Parameters for linked service.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the linked service.
        :paramtype annotations: list[any]
        :keyword connection_properties: Properties used to connect to Zoho. It is mutually exclusive
         with any other properties in the linked service. Type: object.
        :paramtype connection_properties: any
        :keyword endpoint: The endpoint of the Zoho server. (i.e. crm.zoho.com/crm/private).
        :paramtype endpoint: any
        :keyword access_token: The access token for Zoho authentication.
        :paramtype access_token: ~azure.mgmt.datafactory.models.SecretBase
        :keyword use_encrypted_endpoints: Specifies whether the data source endpoints are encrypted
         using HTTPS. The default value is true.
        :paramtype use_encrypted_endpoints: any
        :keyword use_host_verification: Specifies whether to require the host name in the server's
         certificate to match the host name of the server when connecting over SSL. The default value is
         true.
        :paramtype use_host_verification: any
        :keyword use_peer_verification: Specifies whether to verify the identity of the server when
         connecting over SSL. The default value is true.
        :paramtype use_peer_verification: any
        :keyword encrypted_credential: The encrypted credential used for authentication. Credentials
         are encrypted using the integration runtime credential manager. Type: string (or Expression
         with resultType string).
        :paramtype encrypted_credential: any
        """
        super(ZohoLinkedService, self).__init__(additional_properties=additional_properties, connect_via=connect_via, description=description, parameters=parameters, annotations=annotations, **kwargs)
        self.type = 'Zoho'  # type: str
        self.connection_properties = connection_properties
        self.endpoint = endpoint
        self.access_token = access_token
        self.use_encrypted_endpoints = use_encrypted_endpoints
        self.use_host_verification = use_host_verification
        self.use_peer_verification = use_peer_verification
        self.encrypted_credential = encrypted_credential


class ZohoObjectDataset(Dataset):
    """Zoho server dataset.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Type of dataset.Constant filled by server.
    :vartype type: str
    :ivar description: Dataset description.
    :vartype description: str
    :ivar structure: Columns that define the structure of the dataset. Type: array (or Expression
     with resultType array), itemType: DatasetDataElement.
    :vartype structure: any
    :ivar schema: Columns that define the physical type schema of the dataset. Type: array (or
     Expression with resultType array), itemType: DatasetSchemaDataElement.
    :vartype schema: any
    :ivar linked_service_name: Required. Linked service reference.
    :vartype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
    :ivar parameters: Parameters for dataset.
    :vartype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
    :ivar annotations: List of tags that can be used for describing the Dataset.
    :vartype annotations: list[any]
    :ivar folder: The folder that this Dataset is in. If not specified, Dataset will appear at the
     root level.
    :vartype folder: ~azure.mgmt.datafactory.models.DatasetFolder
    :ivar table_name: The table name. Type: string (or Expression with resultType string).
    :vartype table_name: any
    """

    _validation = {
        'type': {'required': True},
        'linked_service_name': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'structure': {'key': 'structure', 'type': 'object'},
        'schema': {'key': 'schema', 'type': 'object'},
        'linked_service_name': {'key': 'linkedServiceName', 'type': 'LinkedServiceReference'},
        'parameters': {'key': 'parameters', 'type': '{ParameterSpecification}'},
        'annotations': {'key': 'annotations', 'type': '[object]'},
        'folder': {'key': 'folder', 'type': 'DatasetFolder'},
        'table_name': {'key': 'typeProperties.tableName', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        linked_service_name: "LinkedServiceReference",
        additional_properties: Optional[Dict[str, Any]] = None,
        description: Optional[str] = None,
        structure: Optional[Any] = None,
        schema: Optional[Any] = None,
        parameters: Optional[Dict[str, "ParameterSpecification"]] = None,
        annotations: Optional[List[Any]] = None,
        folder: Optional["DatasetFolder"] = None,
        table_name: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword description: Dataset description.
        :paramtype description: str
        :keyword structure: Columns that define the structure of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetDataElement.
        :paramtype structure: any
        :keyword schema: Columns that define the physical type schema of the dataset. Type: array (or
         Expression with resultType array), itemType: DatasetSchemaDataElement.
        :paramtype schema: any
        :keyword linked_service_name: Required. Linked service reference.
        :paramtype linked_service_name: ~azure.mgmt.datafactory.models.LinkedServiceReference
        :keyword parameters: Parameters for dataset.
        :paramtype parameters: dict[str, ~azure.mgmt.datafactory.models.ParameterSpecification]
        :keyword annotations: List of tags that can be used for describing the Dataset.
        :paramtype annotations: list[any]
        :keyword folder: The folder that this Dataset is in. If not specified, Dataset will appear at
         the root level.
        :paramtype folder: ~azure.mgmt.datafactory.models.DatasetFolder
        :keyword table_name: The table name. Type: string (or Expression with resultType string).
        :paramtype table_name: any
        """
        super(ZohoObjectDataset, self).__init__(additional_properties=additional_properties, description=description, structure=structure, schema=schema, linked_service_name=linked_service_name, parameters=parameters, annotations=annotations, folder=folder, **kwargs)
        self.type = 'ZohoObject'  # type: str
        self.table_name = table_name


class ZohoSource(TabularSource):
    """A copy activity Zoho server source.

    All required parameters must be populated in order to send to Azure.

    :ivar additional_properties: Unmatched properties from the message are deserialized to this
     collection.
    :vartype additional_properties: dict[str, any]
    :ivar type: Required. Copy source type.Constant filled by server.
    :vartype type: str
    :ivar source_retry_count: Source retry count. Type: integer (or Expression with resultType
     integer).
    :vartype source_retry_count: any
    :ivar source_retry_wait: Source retry wait. Type: string (or Expression with resultType
     string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype source_retry_wait: any
    :ivar max_concurrent_connections: The maximum concurrent connection count for the source data
     store. Type: integer (or Expression with resultType integer).
    :vartype max_concurrent_connections: any
    :ivar disable_metrics_collection: If true, disable data store metrics collection. Default is
     false. Type: boolean (or Expression with resultType boolean).
    :vartype disable_metrics_collection: any
    :ivar query_timeout: Query timeout. Type: string (or Expression with resultType string),
     pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
    :vartype query_timeout: any
    :ivar additional_columns: Specifies the additional columns to be added to source data. Type:
     array of objects(AdditionalColumns) (or Expression with resultType array of objects).
    :vartype additional_columns: any
    :ivar query: A query to retrieve data from source. Type: string (or Expression with resultType
     string).
    :vartype query: any
    """

    _validation = {
        'type': {'required': True},
    }

    _attribute_map = {
        'additional_properties': {'key': '', 'type': '{object}'},
        'type': {'key': 'type', 'type': 'str'},
        'source_retry_count': {'key': 'sourceRetryCount', 'type': 'object'},
        'source_retry_wait': {'key': 'sourceRetryWait', 'type': 'object'},
        'max_concurrent_connections': {'key': 'maxConcurrentConnections', 'type': 'object'},
        'disable_metrics_collection': {'key': 'disableMetricsCollection', 'type': 'object'},
        'query_timeout': {'key': 'queryTimeout', 'type': 'object'},
        'additional_columns': {'key': 'additionalColumns', 'type': 'object'},
        'query': {'key': 'query', 'type': 'object'},
    }

    def __init__(
        self,
        *,
        additional_properties: Optional[Dict[str, Any]] = None,
        source_retry_count: Optional[Any] = None,
        source_retry_wait: Optional[Any] = None,
        max_concurrent_connections: Optional[Any] = None,
        disable_metrics_collection: Optional[Any] = None,
        query_timeout: Optional[Any] = None,
        additional_columns: Optional[Any] = None,
        query: Optional[Any] = None,
        **kwargs
    ):
        """
        :keyword additional_properties: Unmatched properties from the message are deserialized to this
         collection.
        :paramtype additional_properties: dict[str, any]
        :keyword source_retry_count: Source retry count. Type: integer (or Expression with resultType
         integer).
        :paramtype source_retry_count: any
        :keyword source_retry_wait: Source retry wait. Type: string (or Expression with resultType
         string), pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype source_retry_wait: any
        :keyword max_concurrent_connections: The maximum concurrent connection count for the source
         data store. Type: integer (or Expression with resultType integer).
        :paramtype max_concurrent_connections: any
        :keyword disable_metrics_collection: If true, disable data store metrics collection. Default is
         false. Type: boolean (or Expression with resultType boolean).
        :paramtype disable_metrics_collection: any
        :keyword query_timeout: Query timeout. Type: string (or Expression with resultType string),
         pattern: ((\d+).)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
        :paramtype query_timeout: any
        :keyword additional_columns: Specifies the additional columns to be added to source data. Type:
         array of objects(AdditionalColumns) (or Expression with resultType array of objects).
        :paramtype additional_columns: any
        :keyword query: A query to retrieve data from source. Type: string (or Expression with
         resultType string).
        :paramtype query: any
        """
        super(ZohoSource, self).__init__(additional_properties=additional_properties, source_retry_count=source_retry_count, source_retry_wait=source_retry_wait, max_concurrent_connections=max_concurrent_connections, disable_metrics_collection=disable_metrics_collection, query_timeout=query_timeout, additional_columns=additional_columns, **kwargs)
        self.type = 'ZohoSource'  # type: str
        self.query = query
