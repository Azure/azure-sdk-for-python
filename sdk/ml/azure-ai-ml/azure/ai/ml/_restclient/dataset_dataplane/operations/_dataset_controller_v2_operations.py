# pylint: disable=too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
from typing import Any, Callable, Dict, IO, Iterable, List, Optional, TypeVar, Union, overload

from azure.core.exceptions import (
    ClientAuthenticationError,
    HttpResponseError,
    ResourceExistsError,
    ResourceNotFoundError,
    ResourceNotModifiedError,
    map_error,
)
from azure.core.paging import ItemPaged
from azure.core.pipeline import PipelineResponse
from azure.core.pipeline.transport import HttpResponse
from azure.core.rest import HttpRequest
from azure.core.tracing.decorator import distributed_trace
from azure.core.utils import case_insensitive_dict
from azure.mgmt.core.exceptions import ARMErrorFormat

from .. import models as _models
from ..._serialization import Serializer
from .._vendor import _convert_request, _format_url_section

T = TypeVar("T")
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]

_SERIALIZER = Serializer()
_SERIALIZER.client_side_validation = False


def build_get_dataset_definition_request(
    subscription_id: str, resource_group_name: str, workspace_name: str, dataset_id: str, version: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = kwargs.pop(
        "template_url",
        "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/{datasetId}/definitions/{version}",
    )  # pylint: disable=line-too-long
    path_format_arguments = {
        "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, "str"),
        "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, "str"),
        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, "str"),
        "datasetId": _SERIALIZER.url("dataset_id", dataset_id, "str"),
        "version": _SERIALIZER.url("version", version, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, headers=_headers, **kwargs)


def build_get_all_dataset_definitions_request(
    subscription_id: str,
    resource_group_name: str,
    workspace_name: str,
    dataset_id: str,
    *,
    continuation_token_parameter: Optional[str] = None,
    page_size: Optional[int] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = kwargs.pop(
        "template_url",
        "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/{datasetId}/definitions",
    )  # pylint: disable=line-too-long
    path_format_arguments = {
        "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, "str"),
        "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, "str"),
        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, "str"),
        "datasetId": _SERIALIZER.url("dataset_id", dataset_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    if continuation_token_parameter is not None:
        _params["continuationToken"] = _SERIALIZER.query(
            "continuation_token_parameter", continuation_token_parameter, "str"
        )
    if page_size is not None:
        _params["pageSize"] = _SERIALIZER.query("page_size", page_size, "int")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_update_definition_request(
    subscription_id: str,
    resource_group_name: str,
    workspace_name: str,
    dataset_id: str,
    *,
    register_as_pending: bool = False,
    force_update: bool = False,
    dataset_type: Optional[str] = None,
    user_version_id: Optional[str] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = kwargs.pop(
        "template_url",
        "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/{datasetId}/definitions",
    )  # pylint: disable=line-too-long
    path_format_arguments = {
        "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, "str"),
        "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, "str"),
        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, "str"),
        "datasetId": _SERIALIZER.url("dataset_id", dataset_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    if register_as_pending is not None:
        _params["registerAsPending"] = _SERIALIZER.query("register_as_pending", register_as_pending, "bool")
    if force_update is not None:
        _params["forceUpdate"] = _SERIALIZER.query("force_update", force_update, "bool")
    if dataset_type is not None:
        _params["datasetType"] = _SERIALIZER.query("dataset_type", dataset_type, "str")
    if user_version_id is not None:
        _params["userVersionId"] = _SERIALIZER.query("user_version_id", user_version_id, "str")

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_get_all_dataset_versions_request(
    subscription_id: str,
    resource_group_name: str,
    workspace_name: str,
    dataset_id: str,
    *,
    continuation_token_parameter: Optional[str] = None,
    page_size: Optional[int] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = kwargs.pop(
        "template_url",
        "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/{datasetId}/versions",
    )  # pylint: disable=line-too-long
    path_format_arguments = {
        "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, "str"),
        "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, "str"),
        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, "str"),
        "datasetId": _SERIALIZER.url("dataset_id", dataset_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    if continuation_token_parameter is not None:
        _params["continuationToken"] = _SERIALIZER.query(
            "continuation_token_parameter", continuation_token_parameter, "str"
        )
    if page_size is not None:
        _params["pageSize"] = _SERIALIZER.query("page_size", page_size, "int")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_get_dataset_by_name_request(
    subscription_id: str,
    resource_group_name: str,
    workspace_name: str,
    dataset_name: str,
    *,
    version_id: Optional[str] = None,
    include_latest_definition: bool = True,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = kwargs.pop(
        "template_url",
        "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/query/name={datasetName}",
    )  # pylint: disable=line-too-long
    path_format_arguments = {
        "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, "str"),
        "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, "str"),
        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, "str"),
        "datasetName": _SERIALIZER.url("dataset_name", dataset_name, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    if version_id is not None:
        _params["versionId"] = _SERIALIZER.query("version_id", version_id, "str")
    if include_latest_definition is not None:
        _params["includeLatestDefinition"] = _SERIALIZER.query(
            "include_latest_definition", include_latest_definition, "bool"
        )

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_list_request(
    subscription_id: str,
    resource_group_name: str,
    workspace_name: str,
    *,
    dataset_names: Optional[List[str]] = None,
    search_text: Optional[str] = None,
    include_invisible: bool = False,
    status: Optional[str] = None,
    continuation_token_parameter: Optional[str] = None,
    page_size: Optional[int] = None,
    include_latest_definition: bool = False,
    order_by: Optional[str] = None,
    order_by_asc: bool = False,
    dataset_types: Optional[List[str]] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = kwargs.pop(
        "template_url",
        "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets",
    )  # pylint: disable=line-too-long
    path_format_arguments = {
        "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, "str"),
        "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, "str"),
        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    if dataset_names is not None:
        _params["datasetNames"] = _SERIALIZER.query("dataset_names", dataset_names, "[str]")
    if search_text is not None:
        _params["searchText"] = _SERIALIZER.query("search_text", search_text, "str")
    if include_invisible is not None:
        _params["includeInvisible"] = _SERIALIZER.query("include_invisible", include_invisible, "bool")
    if status is not None:
        _params["status"] = _SERIALIZER.query("status", status, "str")
    if continuation_token_parameter is not None:
        _params["continuationToken"] = _SERIALIZER.query(
            "continuation_token_parameter", continuation_token_parameter, "str"
        )
    if page_size is not None:
        _params["pageSize"] = _SERIALIZER.query("page_size", page_size, "int")
    if include_latest_definition is not None:
        _params["includeLatestDefinition"] = _SERIALIZER.query(
            "include_latest_definition", include_latest_definition, "bool"
        )
    if order_by is not None:
        _params["orderBy"] = _SERIALIZER.query("order_by", order_by, "str")
    if order_by_asc is not None:
        _params["orderByAsc"] = _SERIALIZER.query("order_by_asc", order_by_asc, "bool")
    if dataset_types is not None:
        _params["datasetTypes"] = _SERIALIZER.query("dataset_types", dataset_types, "[str]")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_register_request(
    subscription_id: str,
    resource_group_name: str,
    workspace_name: str,
    *,
    register_as_pending: bool = False,
    if_exists_ok: bool = True,
    update_definition_if_exists: bool = False,
    with_data_hash: bool = False,
    user_version_id: Optional[str] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = kwargs.pop(
        "template_url",
        "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets",
    )  # pylint: disable=line-too-long
    path_format_arguments = {
        "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, "str"),
        "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, "str"),
        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    if register_as_pending is not None:
        _params["registerAsPending"] = _SERIALIZER.query("register_as_pending", register_as_pending, "bool")
    if if_exists_ok is not None:
        _params["ifExistsOk"] = _SERIALIZER.query("if_exists_ok", if_exists_ok, "bool")
    if update_definition_if_exists is not None:
        _params["updateDefinitionIfExists"] = _SERIALIZER.query(
            "update_definition_if_exists", update_definition_if_exists, "bool"
        )
    if with_data_hash is not None:
        _params["withDataHash"] = _SERIALIZER.query("with_data_hash", with_data_hash, "bool")
    if user_version_id is not None:
        _params["userVersionId"] = _SERIALIZER.query("user_version_id", user_version_id, "str")

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_delete_all_datasets_request(
    subscription_id: str, resource_group_name: str, workspace_name: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = kwargs.pop(
        "template_url",
        "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets",
    )  # pylint: disable=line-too-long
    path_format_arguments = {
        "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, "str"),
        "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, "str"),
        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="DELETE", url=_url, headers=_headers, **kwargs)


def build_update_dataset_request(
    subscription_id: str,
    resource_group_name: str,
    workspace_name: str,
    dataset_id: str,
    *,
    force_update: bool = False,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = kwargs.pop(
        "template_url",
        "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/{datasetId}",
    )  # pylint: disable=line-too-long
    path_format_arguments = {
        "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, "str"),
        "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, "str"),
        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, "str"),
        "datasetId": _SERIALIZER.url("dataset_id", dataset_id, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct parameters
    if force_update is not None:
        _params["forceUpdate"] = _SERIALIZER.query("force_update", force_update, "bool")

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="PUT", url=_url, params=_params, headers=_headers, **kwargs)


def build_unregister_dataset_request(
    subscription_id: str, resource_group_name: str, workspace_name: str, name: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = kwargs.pop(
        "template_url",
        "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/{name}",
    )  # pylint: disable=line-too-long
    path_format_arguments = {
        "subscriptionId": _SERIALIZER.url("subscription_id", subscription_id, "str"),
        "resourceGroupName": _SERIALIZER.url("resource_group_name", resource_group_name, "str"),
        "workspaceName": _SERIALIZER.url("workspace_name", workspace_name, "str"),
        "name": _SERIALIZER.url("name", name, "str"),
    }

    _url: str = _format_url_section(_url, **path_format_arguments)  # type: ignore

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="DELETE", url=_url, headers=_headers, **kwargs)


class DatasetControllerV2Operations:
    """
    .. warning::
        **DO NOT** instantiate this class directly.

        Instead, you should access the following operations through
        :class:`~azure.mgmt.machinelearningservices.AzureMachineLearningWorkspaces`'s
        :attr:`dataset_controller_v2` attribute.
    """

    models = _models

    def __init__(self, *args, **kwargs):
        input_args = list(args)
        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")

    @distributed_trace
    def get_dataset_definition(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        dataset_id: str,
        version: str,
        **kwargs: Any
    ) -> _models.DatasetDefinition:
        """Get a specific dataset definition.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param dataset_id: Required.
        :type dataset_id: str
        :param version: Required.
        :type version: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: DatasetDefinition or the result of cls(response)
        :rtype: ~azure.mgmt.machinelearningservices.models.DatasetDefinition
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.DatasetDefinition] = kwargs.pop("cls", None)

        request = build_get_dataset_definition_request(
            subscription_id=subscription_id,
            resource_group_name=resource_group_name,
            workspace_name=workspace_name,
            dataset_id=dataset_id,
            version=version,
            template_url=self.get_dataset_definition.metadata["url"],
            headers=_headers,
            params=_params,
        )
        request = _convert_request(request)
        request.url = self._client.format_url(request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)

        deserialized = self._deserialize("DatasetDefinition", pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized

    get_dataset_definition.metadata = {
        "url": "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/{datasetId}/definitions/{version}"
    }

    @distributed_trace
    def get_all_dataset_definitions(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        dataset_id: str,
        continuation_token_parameter: Optional[str] = None,
        page_size: Optional[int] = None,
        **kwargs: Any
    ) -> Iterable["_models.DatasetDefinition"]:
        """Get all dataset definitions for a given dataset.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param dataset_id: Required.
        :type dataset_id: str
        :param continuation_token_parameter: Default value is None.
        :type continuation_token_parameter: str
        :param page_size: Default value is None.
        :type page_size: int
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: An iterator like instance of either DatasetDefinition or the result of cls(response)
        :rtype:
         ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.DatasetDefinition]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.PaginatedDatasetDefinitionList] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_get_all_dataset_definitions_request(
                    subscription_id=subscription_id,
                    resource_group_name=resource_group_name,
                    workspace_name=workspace_name,
                    dataset_id=dataset_id,
                    continuation_token_parameter=continuation_token_parameter,
                    page_size=page_size,
                    template_url=self.get_all_dataset_definitions.metadata["url"],
                    headers=_headers,
                    params=_params,
                )
                request = _convert_request(request)
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request = _convert_request(request)
                request.url = self._client.format_url(request.url)
                request.method = "GET"
            return request

        def extract_data(pipeline_response):
            deserialized = self._deserialize("PaginatedDatasetDefinitionList", pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    get_all_dataset_definitions.metadata = {
        "url": "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/{datasetId}/definitions"
    }

    @overload
    def update_definition(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        dataset_id: str,
        register_as_pending: bool = False,
        force_update: bool = False,
        dataset_type: Optional[str] = None,
        user_version_id: Optional[str] = None,
        body: Optional[_models.DatasetDefinition] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.Dataset:
        """Update a dataset definition.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param dataset_id: Required.
        :type dataset_id: str
        :param register_as_pending: Default value is False.
        :type register_as_pending: bool
        :param force_update: Default value is False.
        :type force_update: bool
        :param dataset_type: Default value is None.
        :type dataset_type: str
        :param user_version_id: Default value is None.
        :type user_version_id: str
        :param body: Default value is None.
        :type body: ~azure.mgmt.machinelearningservices.models.DatasetDefinition
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: Dataset or the result of cls(response)
        :rtype: ~azure.mgmt.machinelearningservices.models.Dataset
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def update_definition(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        dataset_id: str,
        register_as_pending: bool = False,
        force_update: bool = False,
        dataset_type: Optional[str] = None,
        user_version_id: Optional[str] = None,
        body: Optional[IO] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.Dataset:
        """Update a dataset definition.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param dataset_id: Required.
        :type dataset_id: str
        :param register_as_pending: Default value is False.
        :type register_as_pending: bool
        :param force_update: Default value is False.
        :type force_update: bool
        :param dataset_type: Default value is None.
        :type dataset_type: str
        :param user_version_id: Default value is None.
        :type user_version_id: str
        :param body: Default value is None.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: Dataset or the result of cls(response)
        :rtype: ~azure.mgmt.machinelearningservices.models.Dataset
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def update_definition(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        dataset_id: str,
        register_as_pending: bool = False,
        force_update: bool = False,
        dataset_type: Optional[str] = None,
        user_version_id: Optional[str] = None,
        body: Optional[Union[_models.DatasetDefinition, IO]] = None,
        **kwargs: Any
    ) -> _models.Dataset:
        """Update a dataset definition.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param dataset_id: Required.
        :type dataset_id: str
        :param register_as_pending: Default value is False.
        :type register_as_pending: bool
        :param force_update: Default value is False.
        :type force_update: bool
        :param dataset_type: Default value is None.
        :type dataset_type: str
        :param user_version_id: Default value is None.
        :type user_version_id: str
        :param body: Is either a DatasetDefinition type or a IO type. Default value is None.
        :type body: ~azure.mgmt.machinelearningservices.models.DatasetDefinition or IO
        :keyword content_type: Body Parameter content-type. Known values are: 'application/json'.
         Default value is None.
        :paramtype content_type: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: Dataset or the result of cls(response)
        :rtype: ~azure.mgmt.machinelearningservices.models.Dataset
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.Dataset] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _json = self._serialize.body(body, "DatasetDefinition")
            else:
                _json = None

        request = build_update_definition_request(
            subscription_id=subscription_id,
            resource_group_name=resource_group_name,
            workspace_name=workspace_name,
            dataset_id=dataset_id,
            register_as_pending=register_as_pending,
            force_update=force_update,
            dataset_type=dataset_type,
            user_version_id=user_version_id,
            content_type=content_type,
            json=_json,
            content=_content,
            template_url=self.update_definition.metadata["url"],
            headers=_headers,
            params=_params,
        )
        request = _convert_request(request)
        request.url = self._client.format_url(request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)

        deserialized = self._deserialize("Dataset", pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized

    update_definition.metadata = {
        "url": "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/{datasetId}/definitions"
    }

    @distributed_trace
    def get_all_dataset_versions(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        dataset_id: str,
        continuation_token_parameter: Optional[str] = None,
        page_size: Optional[int] = None,
        **kwargs: Any
    ) -> Iterable[str]:
        """Get all dataset versions for a given dataset.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param dataset_id: Required.
        :type dataset_id: str
        :param continuation_token_parameter: Default value is None.
        :type continuation_token_parameter: str
        :param page_size: Default value is None.
        :type page_size: int
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: An iterator like instance of either str or the result of cls(response)
        :rtype: ~azure.core.paging.ItemPaged[str]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.PaginatedStringList] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_get_all_dataset_versions_request(
                    subscription_id=subscription_id,
                    resource_group_name=resource_group_name,
                    workspace_name=workspace_name,
                    dataset_id=dataset_id,
                    continuation_token_parameter=continuation_token_parameter,
                    page_size=page_size,
                    template_url=self.get_all_dataset_versions.metadata["url"],
                    headers=_headers,
                    params=_params,
                )
                request = _convert_request(request)
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request = _convert_request(request)
                request.url = self._client.format_url(request.url)
                request.method = "GET"
            return request

        def extract_data(pipeline_response):
            deserialized = self._deserialize("PaginatedStringList", pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    get_all_dataset_versions.metadata = {
        "url": "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/{datasetId}/versions"
    }

    @distributed_trace
    def get_dataset_by_name(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        dataset_name: str,
        version_id: Optional[str] = None,
        include_latest_definition: bool = True,
        **kwargs: Any
    ) -> _models.Dataset:
        """Get a dataset for a given dataset name.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param dataset_name: Required.
        :type dataset_name: str
        :param version_id: Default value is None.
        :type version_id: str
        :param include_latest_definition: Default value is True.
        :type include_latest_definition: bool
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: Dataset or the result of cls(response)
        :rtype: ~azure.mgmt.machinelearningservices.models.Dataset
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.Dataset] = kwargs.pop("cls", None)

        request = build_get_dataset_by_name_request(
            subscription_id=subscription_id,
            resource_group_name=resource_group_name,
            workspace_name=workspace_name,
            dataset_name=dataset_name,
            version_id=version_id,
            include_latest_definition=include_latest_definition,
            template_url=self.get_dataset_by_name.metadata["url"],
            headers=_headers,
            params=_params,
        )
        request = _convert_request(request)
        request.url = self._client.format_url(request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)

        deserialized = self._deserialize("Dataset", pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized

    get_dataset_by_name.metadata = {
        "url": "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/query/name={datasetName}"
    }

    @distributed_trace
    def list(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        dataset_names: Optional[List[str]] = None,
        search_text: Optional[str] = None,
        include_invisible: bool = False,
        status: Optional[str] = None,
        continuation_token_parameter: Optional[str] = None,
        page_size: Optional[int] = None,
        include_latest_definition: bool = False,
        order_by: Optional[str] = None,
        order_by_asc: bool = False,
        dataset_types: Optional[List[str]] = None,
        **kwargs: Any
    ) -> Iterable["_models.Dataset"]:
        """Get a list of datasets.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param dataset_names: Default value is None.
        :type dataset_names: list[str]
        :param search_text: Default value is None.
        :type search_text: str
        :param include_invisible: Default value is False.
        :type include_invisible: bool
        :param status: Default value is None.
        :type status: str
        :param continuation_token_parameter: Default value is None.
        :type continuation_token_parameter: str
        :param page_size: Default value is None.
        :type page_size: int
        :param include_latest_definition: Default value is False.
        :type include_latest_definition: bool
        :param order_by: Default value is None.
        :type order_by: str
        :param order_by_asc: Default value is False.
        :type order_by_asc: bool
        :param dataset_types: Default value is None.
        :type dataset_types: list[str]
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: An iterator like instance of either Dataset or the result of cls(response)
        :rtype: ~azure.core.paging.ItemPaged[~azure.mgmt.machinelearningservices.models.Dataset]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.PaginatedDatasetList] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                request = build_list_request(
                    subscription_id=subscription_id,
                    resource_group_name=resource_group_name,
                    workspace_name=workspace_name,
                    dataset_names=dataset_names,
                    search_text=search_text,
                    include_invisible=include_invisible,
                    status=status,
                    continuation_token_parameter=continuation_token_parameter,
                    page_size=page_size,
                    include_latest_definition=include_latest_definition,
                    order_by=order_by,
                    order_by_asc=order_by_asc,
                    dataset_types=dataset_types,
                    template_url=self.list.metadata["url"],
                    headers=_headers,
                    params=_params,
                )
                request = _convert_request(request)
                request.url = self._client.format_url(request.url)

            else:
                request = HttpRequest("GET", next_link)
                request = _convert_request(request)
                request.url = self._client.format_url(request.url)
                request.method = "GET"
            return request

        def extract_data(pipeline_response):
            deserialized = self._deserialize("PaginatedDatasetList", pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.next_link or None, iter(list_of_elem)

        def get_next(next_link=None):
            request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    list.metadata = {
        "url": "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets"
    }

    @overload
    def register(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        register_as_pending: bool = False,
        if_exists_ok: bool = True,
        update_definition_if_exists: bool = False,
        with_data_hash: bool = False,
        user_version_id: Optional[str] = None,
        body: Optional[_models.Dataset] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.Dataset:
        """Register new dataset.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param register_as_pending: Default value is False.
        :type register_as_pending: bool
        :param if_exists_ok: Default value is True.
        :type if_exists_ok: bool
        :param update_definition_if_exists: Default value is False.
        :type update_definition_if_exists: bool
        :param with_data_hash: Default value is False.
        :type with_data_hash: bool
        :param user_version_id: Default value is None.
        :type user_version_id: str
        :param body: Default value is None.
        :type body: ~azure.mgmt.machinelearningservices.models.Dataset
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: Dataset or the result of cls(response)
        :rtype: ~azure.mgmt.machinelearningservices.models.Dataset
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def register(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        register_as_pending: bool = False,
        if_exists_ok: bool = True,
        update_definition_if_exists: bool = False,
        with_data_hash: bool = False,
        user_version_id: Optional[str] = None,
        body: Optional[IO] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.Dataset:
        """Register new dataset.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param register_as_pending: Default value is False.
        :type register_as_pending: bool
        :param if_exists_ok: Default value is True.
        :type if_exists_ok: bool
        :param update_definition_if_exists: Default value is False.
        :type update_definition_if_exists: bool
        :param with_data_hash: Default value is False.
        :type with_data_hash: bool
        :param user_version_id: Default value is None.
        :type user_version_id: str
        :param body: Default value is None.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: Dataset or the result of cls(response)
        :rtype: ~azure.mgmt.machinelearningservices.models.Dataset
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def register(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        register_as_pending: bool = False,
        if_exists_ok: bool = True,
        update_definition_if_exists: bool = False,
        with_data_hash: bool = False,
        user_version_id: Optional[str] = None,
        body: Optional[Union[_models.Dataset, IO]] = None,
        **kwargs: Any
    ) -> _models.Dataset:
        """Register new dataset.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param register_as_pending: Default value is False.
        :type register_as_pending: bool
        :param if_exists_ok: Default value is True.
        :type if_exists_ok: bool
        :param update_definition_if_exists: Default value is False.
        :type update_definition_if_exists: bool
        :param with_data_hash: Default value is False.
        :type with_data_hash: bool
        :param user_version_id: Default value is None.
        :type user_version_id: str
        :param body: Is either a Dataset type or a IO type. Default value is None.
        :type body: ~azure.mgmt.machinelearningservices.models.Dataset or IO
        :keyword content_type: Body Parameter content-type. Known values are: 'application/json'.
         Default value is None.
        :paramtype content_type: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: Dataset or the result of cls(response)
        :rtype: ~azure.mgmt.machinelearningservices.models.Dataset
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.Dataset] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _json = self._serialize.body(body, "Dataset")
            else:
                _json = None

        request = build_register_request(
            subscription_id=subscription_id,
            resource_group_name=resource_group_name,
            workspace_name=workspace_name,
            register_as_pending=register_as_pending,
            if_exists_ok=if_exists_ok,
            update_definition_if_exists=update_definition_if_exists,
            with_data_hash=with_data_hash,
            user_version_id=user_version_id,
            content_type=content_type,
            json=_json,
            content=_content,
            template_url=self.register.metadata["url"],
            headers=_headers,
            params=_params,
        )
        request = _convert_request(request)
        request.url = self._client.format_url(request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)

        deserialized = self._deserialize("Dataset", pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized

    register.metadata = {
        "url": "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets"
    }

    @distributed_trace
    def delete_all_datasets(  # pylint: disable=inconsistent-return-statements
        self, subscription_id: str, resource_group_name: str, workspace_name: str, **kwargs: Any
    ) -> None:
        """Unregister all datasets in the workspace.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: None or the result of cls(response)
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        request = build_delete_all_datasets_request(
            subscription_id=subscription_id,
            resource_group_name=resource_group_name,
            workspace_name=workspace_name,
            template_url=self.delete_all_datasets.metadata["url"],
            headers=_headers,
            params=_params,
        )
        request = _convert_request(request)
        request.url = self._client.format_url(request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in []:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)

        if cls:
            return cls(pipeline_response, None, {})

    delete_all_datasets.metadata = {
        "url": "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets"
    }

    @overload
    def update_dataset(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        dataset_id: str,
        force_update: bool = False,
        body: Optional[_models.Dataset] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.Dataset:
        """Update a dataset.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param dataset_id: Required.
        :type dataset_id: str
        :param force_update: Default value is False.
        :type force_update: bool
        :param body: Default value is None.
        :type body: ~azure.mgmt.machinelearningservices.models.Dataset
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: Dataset or the result of cls(response)
        :rtype: ~azure.mgmt.machinelearningservices.models.Dataset
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def update_dataset(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        dataset_id: str,
        force_update: bool = False,
        body: Optional[IO] = None,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.Dataset:
        """Update a dataset.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param dataset_id: Required.
        :type dataset_id: str
        :param force_update: Default value is False.
        :type force_update: bool
        :param body: Default value is None.
        :type body: IO
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: Dataset or the result of cls(response)
        :rtype: ~azure.mgmt.machinelearningservices.models.Dataset
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def update_dataset(
        self,
        subscription_id: str,
        resource_group_name: str,
        workspace_name: str,
        dataset_id: str,
        force_update: bool = False,
        body: Optional[Union[_models.Dataset, IO]] = None,
        **kwargs: Any
    ) -> _models.Dataset:
        """Update a dataset.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param dataset_id: Required.
        :type dataset_id: str
        :param force_update: Default value is False.
        :type force_update: bool
        :param body: Is either a Dataset type or a IO type. Default value is None.
        :type body: ~azure.mgmt.machinelearningservices.models.Dataset or IO
        :keyword content_type: Body Parameter content-type. Known values are: 'application/json'.
         Default value is None.
        :paramtype content_type: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: Dataset or the result of cls(response)
        :rtype: ~azure.mgmt.machinelearningservices.models.Dataset
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.Dataset] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(body, (IO, bytes)):
            _content = body
        else:
            if body is not None:
                _json = self._serialize.body(body, "Dataset")
            else:
                _json = None

        request = build_update_dataset_request(
            subscription_id=subscription_id,
            resource_group_name=resource_group_name,
            workspace_name=workspace_name,
            dataset_id=dataset_id,
            force_update=force_update,
            content_type=content_type,
            json=_json,
            content=_content,
            template_url=self.update_dataset.metadata["url"],
            headers=_headers,
            params=_params,
        )
        request = _convert_request(request)
        request.url = self._client.format_url(request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)

        deserialized = self._deserialize("Dataset", pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized

    update_dataset.metadata = {
        "url": "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/{datasetId}"
    }

    @distributed_trace
    def unregister_dataset(  # pylint: disable=inconsistent-return-statements
        self, subscription_id: str, resource_group_name: str, workspace_name: str, name: str, **kwargs: Any
    ) -> None:
        """Unregister a dataset.

        :param subscription_id: The Azure Subscription ID. Required.
        :type subscription_id: str
        :param resource_group_name: The Name of the resource group in which the workspace is located.
         Required.
        :type resource_group_name: str
        :param workspace_name: The name of the workspace. Required.
        :type workspace_name: str
        :param name: Required.
        :type name: str
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: None or the result of cls(response)
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        request = build_unregister_dataset_request(
            subscription_id=subscription_id,
            resource_group_name=resource_group_name,
            workspace_name=workspace_name,
            name=name,
            template_url=self.unregister_dataset.metadata["url"],
            headers=_headers,
            params=_params,
        )
        request = _convert_request(request)
        request.url = self._client.format_url(request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in []:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)

        if cls:
            return cls(pipeline_response, None, {})

    unregister_dataset.metadata = {
        "url": "/dataset/v1.2/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/datasets/{name}"
    }
