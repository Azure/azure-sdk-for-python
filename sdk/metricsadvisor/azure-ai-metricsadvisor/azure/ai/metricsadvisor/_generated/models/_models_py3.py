# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------

import datetime
from typing import Dict, List, Optional, TYPE_CHECKING, Union

from azure.core.exceptions import HttpResponseError
import msrest.serialization

from ._metrics_advisor_client_enums import *

if TYPE_CHECKING:
    # pylint: disable=unused-import,ungrouped-imports
    from .._patch import MetricFeedbackCustomization
    from ..._patch import AlertResultCustomization, AlertResultListCustomization, AlertSnoozeConditionCustomization, AlertingResultQueryCustomization, AnomalyAlertingConfigurationCustomization, AnomalyAlertingConfigurationListCustomization, AnomalyAlertingConfigurationPatchCustomization, AnomalyDetectionConfigurationCustomization, AnomalyDetectionConfigurationListCustomization, AnomalyDetectionConfigurationPatchCustomization, AnomalyDimensionListCustomization, AnomalyDimensionQueryCustomization, AnomalyFeedbackCustomization, AnomalyFeedbackValueCustomization, AnomalyPropertyCustomization, AnomalyResultCustomization, AnomalyResultListCustomization, AzureApplicationInsightsDataFeedCustomization, AzureApplicationInsightsDataFeedPatchCustomization, AzureApplicationInsightsParameterCustomization, AzureApplicationInsightsParameterPatchCustomization, AzureBlobDataFeedCustomization, AzureBlobDataFeedPatchCustomization, AzureBlobParameterCustomization, AzureBlobParameterPatchCustomization, AzureCosmosDBDataFeedCustomization, AzureCosmosDBDataFeedPatchCustomization, AzureCosmosDBParameterCustomization, AzureCosmosDBParameterPatchCustomization, AzureDataExplorerDataFeedCustomization, AzureDataExplorerDataFeedPatchCustomization, AzureDataLakeStorageGen2DataFeedCustomization, AzureDataLakeStorageGen2DataFeedPatchCustomization, AzureDataLakeStorageGen2ParameterCustomization, AzureDataLakeStorageGen2ParameterPatchCustomization, AzureEventHubsDataFeedCustomization, AzureEventHubsDataFeedPatchCustomization, AzureEventHubsParameterCustomization, AzureEventHubsParameterPatchCustomization, AzureLogAnalyticsDataFeedCustomization, AzureLogAnalyticsDataFeedPatchCustomization, AzureLogAnalyticsParameterCustomization, AzureLogAnalyticsParameterPatchCustomization, AzureSQLConnectionStringCredentialCustomization, AzureSQLConnectionStringCredentialPatchCustomization, AzureSQLConnectionStringParamCustomization, AzureSQLConnectionStringParamPatchCustomization, AzureTableDataFeedCustomization, AzureTableDataFeedPatchCustomization, AzureTableParameterCustomization, AzureTableParameterPatchCustomization, ChangePointFeedbackCustomization, ChangePointFeedbackValueCustomization, ChangeThresholdConditionCustomization, ChangeThresholdConditionPatchCustomization, CommentFeedbackCustomization, CommentFeedbackValueCustomization, DataFeedCustomization, DataFeedPatchCustomization, DataFeedIngestionProgressCustomization, DataFeedListCustomization, DataLakeGen2SharedKeyCredentialCustomization, DataLakeGen2SharedKeyCredentialPatchCustomization, DataLakeGen2SharedKeyParamCustomization, DataLakeGen2SharedKeyParamPatchCustomization, DataSourceCredentialCustomization, DataSourceCredentialListCustomization, DataSourceCredentialPatchCustomization, DetectionAnomalyFilterConditionCustomization, DetectionAnomalyResultQueryCustomization, DetectionIncidentFilterConditionCustomization, DetectionIncidentResultQueryCustomization, DetectionSeriesQueryCustomization, DimensionCustomization, DimensionGroupConfigurationCustomization, DimensionGroupIdentityCustomization, EmailHookInfoCustomization, EmailHookInfoPatchCustomization, EmailHookParameterCustomization, EmailHookParameterPatchCustomization, EnrichmentStatusCustomization, EnrichmentStatusListCustomization, EnrichmentStatusQueryOptionCustomization, ErrorCodeCustomization, FeedbackDimensionFilterCustomization, HardThresholdConditionCustomization, HardThresholdConditionPatchCustomization, HookInfoCustomization, HookInfoPatchCustomization, HookListCustomization, IncidentPropertyCustomization, IncidentResultCustomization, IncidentResultListCustomization, InfluxDBDataFeedCustomization, InfluxDBDataFeedPatchCustomization, InfluxDBParameterCustomization, InfluxDBParameterPatchCustomization, IngestionProgressResetOptionsCustomization, DataFeedIngestionStatusCustomization, IngestionStatusListCustomization, IngestionStatusQueryOptionsCustomization, MetricAlertConfigurationCustomization, MetricCustomization, MetricDataItemCustomization, MetricDataListCustomization, MetricDataQueryOptionsCustomization, MetricDimensionListCustomization, MetricDimensionQueryOptionsCustomization, MetricFeedbackCustomization, MetricFeedbackFilterCustomization, MetricFeedbackListCustomization, MetricSeriesDefinitionCustomization, MetricSeriesListCustomization, MetricSeriesQueryOptionsCustomization, MongoDBDataFeedCustomization, MongoDBDataFeedPatchCustomization, MongoDBParameterCustomization, MongoDBParameterPatchCustomization, MySqlDataFeedCustomization, MySqlDataFeedPatchCustomization, PeriodFeedbackCustomization, PeriodFeedbackValueCustomization, PostgreSqlDataFeedCustomization, PostgreSqlDataFeedPatchCustomization, RootCauseCustomization, RootCauseListCustomization, SQLServerDataFeedCustomization, SQLServerDataFeedPatchCustomization, SQLSourceParameterPatchCustomization, SeriesConfigurationCustomization, SeriesIdentityCustomization, SeriesResultCustomization, SeriesResultListCustomization, ServicePrincipalCredentialCustomization, ServicePrincipalCredentialPatchCustomization, ServicePrincipalInKVCredentialCustomization, ServicePrincipalInKVCredentialPatchCustomization, ServicePrincipalInKVParamCustomization, ServicePrincipalInKVParamPatchCustomization, ServicePrincipalParamCustomization, ServicePrincipalParamPatchCustomization, SeverityConditionCustomization, SeverityFilterConditionCustomization, SmartDetectionConditionCustomization, SmartDetectionConditionPatchCustomization, SqlSourceParameterCustomization, SuppressConditionCustomization, SuppressConditionPatchCustomization, TopNGroupScopeCustomization, UsageStatsCustomization, ValueConditionCustomization, WebhookHookInfoCustomization, WebhookHookInfoPatchCustomization, WebhookHookParameterCustomization, WebhookHookParameterPatchCustomization, WholeMetricConfigurationCustomization, WholeMetricConfigurationPatchCustomization
else:
    try:
        from ..._patch import AlertingResultQueryCustomization
    except ImportError:
        class AlertingResultQueryCustomization(object):
            pass
    try:
        from ..._patch import AlertResultCustomization
    except ImportError:
        class AlertResultCustomization(object):
            pass
    try:
        from ..._patch import AlertResultListCustomization
    except ImportError:
        class AlertResultListCustomization(object):
            pass
    try:
        from ..._patch import AlertSnoozeConditionCustomization
    except ImportError:
        class AlertSnoozeConditionCustomization(object):
            pass
    try:
        from ..._patch import AnomalyAlertingConfigurationCustomization
    except ImportError:
        class AnomalyAlertingConfigurationCustomization(object):
            pass
    try:
        from ..._patch import AnomalyAlertingConfigurationListCustomization
    except ImportError:
        class AnomalyAlertingConfigurationListCustomization(object):
            pass
    try:
        from ..._patch import AnomalyAlertingConfigurationPatchCustomization
    except ImportError:
        class AnomalyAlertingConfigurationPatchCustomization(object):
            pass
    try:
        from ..._patch import AnomalyDetectionConfigurationCustomization
    except ImportError:
        class AnomalyDetectionConfigurationCustomization(object):
            pass
    try:
        from ..._patch import AnomalyDetectionConfigurationListCustomization
    except ImportError:
        class AnomalyDetectionConfigurationListCustomization(object):
            pass
    try:
        from ..._patch import AnomalyDetectionConfigurationPatchCustomization
    except ImportError:
        class AnomalyDetectionConfigurationPatchCustomization(object):
            pass
    try:
        from ..._patch import AnomalyDimensionListCustomization
    except ImportError:
        class AnomalyDimensionListCustomization(object):
            pass
    try:
        from ..._patch import AnomalyDimensionQueryCustomization
    except ImportError:
        class AnomalyDimensionQueryCustomization(object):
            pass
    try:
        from .._patch import MetricFeedbackCustomization
    except ImportError:
        class MetricFeedbackCustomization(object):
            pass
    try:
        from ..._patch import AnomalyFeedbackCustomization
    except ImportError:
        class AnomalyFeedbackCustomization(object):
            pass
    try:
        from ..._patch import AnomalyFeedbackValueCustomization
    except ImportError:
        class AnomalyFeedbackValueCustomization(object):
            pass
    try:
        from ..._patch import AnomalyPropertyCustomization
    except ImportError:
        class AnomalyPropertyCustomization(object):
            pass
    try:
        from ..._patch import AnomalyResultCustomization
    except ImportError:
        class AnomalyResultCustomization(object):
            pass
    try:
        from ..._patch import AnomalyResultListCustomization
    except ImportError:
        class AnomalyResultListCustomization(object):
            pass
    try:
        from ..._patch import DataFeedCustomization
    except ImportError:
        class DataFeedCustomization(object):
            pass
    try:
        from ..._patch import AzureApplicationInsightsDataFeedCustomization
    except ImportError:
        class AzureApplicationInsightsDataFeedCustomization(object):
            pass
    try:
        from ..._patch import DataFeedPatchCustomization
    except ImportError:
        class DataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureApplicationInsightsDataFeedPatchCustomization
    except ImportError:
        class AzureApplicationInsightsDataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureApplicationInsightsParameterCustomization
    except ImportError:
        class AzureApplicationInsightsParameterCustomization(object):
            pass
    try:
        from ..._patch import AzureApplicationInsightsParameterPatchCustomization
    except ImportError:
        class AzureApplicationInsightsParameterPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureBlobDataFeedCustomization
    except ImportError:
        class AzureBlobDataFeedCustomization(object):
            pass
    try:
        from ..._patch import AzureBlobDataFeedPatchCustomization
    except ImportError:
        class AzureBlobDataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureBlobParameterCustomization
    except ImportError:
        class AzureBlobParameterCustomization(object):
            pass
    try:
        from ..._patch import AzureBlobParameterPatchCustomization
    except ImportError:
        class AzureBlobParameterPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureCosmosDBDataFeedCustomization
    except ImportError:
        class AzureCosmosDBDataFeedCustomization(object):
            pass
    try:
        from ..._patch import AzureCosmosDBDataFeedPatchCustomization
    except ImportError:
        class AzureCosmosDBDataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureCosmosDBParameterCustomization
    except ImportError:
        class AzureCosmosDBParameterCustomization(object):
            pass
    try:
        from ..._patch import AzureCosmosDBParameterPatchCustomization
    except ImportError:
        class AzureCosmosDBParameterPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureDataExplorerDataFeedCustomization
    except ImportError:
        class AzureDataExplorerDataFeedCustomization(object):
            pass
    try:
        from ..._patch import AzureDataExplorerDataFeedPatchCustomization
    except ImportError:
        class AzureDataExplorerDataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureDataLakeStorageGen2DataFeedCustomization
    except ImportError:
        class AzureDataLakeStorageGen2DataFeedCustomization(object):
            pass
    try:
        from ..._patch import AzureDataLakeStorageGen2DataFeedPatchCustomization
    except ImportError:
        class AzureDataLakeStorageGen2DataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureDataLakeStorageGen2ParameterCustomization
    except ImportError:
        class AzureDataLakeStorageGen2ParameterCustomization(object):
            pass
    try:
        from ..._patch import AzureDataLakeStorageGen2ParameterPatchCustomization
    except ImportError:
        class AzureDataLakeStorageGen2ParameterPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureEventHubsDataFeedCustomization
    except ImportError:
        class AzureEventHubsDataFeedCustomization(object):
            pass
    try:
        from ..._patch import AzureEventHubsDataFeedPatchCustomization
    except ImportError:
        class AzureEventHubsDataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureEventHubsParameterCustomization
    except ImportError:
        class AzureEventHubsParameterCustomization(object):
            pass
    try:
        from ..._patch import AzureEventHubsParameterPatchCustomization
    except ImportError:
        class AzureEventHubsParameterPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureLogAnalyticsDataFeedCustomization
    except ImportError:
        class AzureLogAnalyticsDataFeedCustomization(object):
            pass
    try:
        from ..._patch import AzureLogAnalyticsDataFeedPatchCustomization
    except ImportError:
        class AzureLogAnalyticsDataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureLogAnalyticsParameterCustomization
    except ImportError:
        class AzureLogAnalyticsParameterCustomization(object):
            pass
    try:
        from ..._patch import AzureLogAnalyticsParameterPatchCustomization
    except ImportError:
        class AzureLogAnalyticsParameterPatchCustomization(object):
            pass
    try:
        from ..._patch import DataSourceCredentialCustomization
    except ImportError:
        class DataSourceCredentialCustomization(object):
            pass
    try:
        from ..._patch import AzureSQLConnectionStringCredentialCustomization
    except ImportError:
        class AzureSQLConnectionStringCredentialCustomization(object):
            pass
    try:
        from ..._patch import DataSourceCredentialPatchCustomization
    except ImportError:
        class DataSourceCredentialPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureSQLConnectionStringCredentialPatchCustomization
    except ImportError:
        class AzureSQLConnectionStringCredentialPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureSQLConnectionStringParamCustomization
    except ImportError:
        class AzureSQLConnectionStringParamCustomization(object):
            pass
    try:
        from ..._patch import AzureSQLConnectionStringParamPatchCustomization
    except ImportError:
        class AzureSQLConnectionStringParamPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureTableDataFeedCustomization
    except ImportError:
        class AzureTableDataFeedCustomization(object):
            pass
    try:
        from ..._patch import AzureTableDataFeedPatchCustomization
    except ImportError:
        class AzureTableDataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import AzureTableParameterCustomization
    except ImportError:
        class AzureTableParameterCustomization(object):
            pass
    try:
        from ..._patch import AzureTableParameterPatchCustomization
    except ImportError:
        class AzureTableParameterPatchCustomization(object):
            pass
    try:
        from ..._patch import ChangePointFeedbackCustomization
    except ImportError:
        class ChangePointFeedbackCustomization(object):
            pass
    try:
        from ..._patch import ChangePointFeedbackValueCustomization
    except ImportError:
        class ChangePointFeedbackValueCustomization(object):
            pass
    try:
        from ..._patch import ChangeThresholdConditionCustomization
    except ImportError:
        class ChangeThresholdConditionCustomization(object):
            pass
    try:
        from ..._patch import ChangeThresholdConditionPatchCustomization
    except ImportError:
        class ChangeThresholdConditionPatchCustomization(object):
            pass
    try:
        from ..._patch import CommentFeedbackCustomization
    except ImportError:
        class CommentFeedbackCustomization(object):
            pass
    try:
        from ..._patch import CommentFeedbackValueCustomization
    except ImportError:
        class CommentFeedbackValueCustomization(object):
            pass
    try:
        from ..._patch import DataFeedIngestionProgressCustomization
    except ImportError:
        class DataFeedIngestionProgressCustomization(object):
            pass
    try:
        from ..._patch import DataFeedListCustomization
    except ImportError:
        class DataFeedListCustomization(object):
            pass
    try:
        from ..._patch import DataLakeGen2SharedKeyCredentialCustomization
    except ImportError:
        class DataLakeGen2SharedKeyCredentialCustomization(object):
            pass
    try:
        from ..._patch import DataLakeGen2SharedKeyCredentialPatchCustomization
    except ImportError:
        class DataLakeGen2SharedKeyCredentialPatchCustomization(object):
            pass
    try:
        from ..._patch import DataLakeGen2SharedKeyParamCustomization
    except ImportError:
        class DataLakeGen2SharedKeyParamCustomization(object):
            pass
    try:
        from ..._patch import DataLakeGen2SharedKeyParamPatchCustomization
    except ImportError:
        class DataLakeGen2SharedKeyParamPatchCustomization(object):
            pass
    try:
        from ..._patch import DataSourceCredentialListCustomization
    except ImportError:
        class DataSourceCredentialListCustomization(object):
            pass
    try:
        from ..._patch import DetectionAnomalyFilterConditionCustomization
    except ImportError:
        class DetectionAnomalyFilterConditionCustomization(object):
            pass
    try:
        from ..._patch import DetectionAnomalyResultQueryCustomization
    except ImportError:
        class DetectionAnomalyResultQueryCustomization(object):
            pass
    try:
        from ..._patch import DetectionIncidentFilterConditionCustomization
    except ImportError:
        class DetectionIncidentFilterConditionCustomization(object):
            pass
    try:
        from ..._patch import DetectionIncidentResultQueryCustomization
    except ImportError:
        class DetectionIncidentResultQueryCustomization(object):
            pass
    try:
        from ..._patch import DetectionSeriesQueryCustomization
    except ImportError:
        class DetectionSeriesQueryCustomization(object):
            pass
    try:
        from ..._patch import DimensionCustomization
    except ImportError:
        class DimensionCustomization(object):
            pass
    try:
        from ..._patch import DimensionGroupConfigurationCustomization
    except ImportError:
        class DimensionGroupConfigurationCustomization(object):
            pass
    try:
        from ..._patch import DimensionGroupIdentityCustomization
    except ImportError:
        class DimensionGroupIdentityCustomization(object):
            pass
    try:
        from ..._patch import HookInfoCustomization
    except ImportError:
        class HookInfoCustomization(object):
            pass
    try:
        from ..._patch import EmailHookInfoCustomization
    except ImportError:
        class EmailHookInfoCustomization(object):
            pass
    try:
        from ..._patch import HookInfoPatchCustomization
    except ImportError:
        class HookInfoPatchCustomization(object):
            pass
    try:
        from ..._patch import EmailHookInfoPatchCustomization
    except ImportError:
        class EmailHookInfoPatchCustomization(object):
            pass
    try:
        from ..._patch import EmailHookParameterCustomization
    except ImportError:
        class EmailHookParameterCustomization(object):
            pass
    try:
        from ..._patch import EmailHookParameterPatchCustomization
    except ImportError:
        class EmailHookParameterPatchCustomization(object):
            pass
    try:
        from ..._patch import EnrichmentStatusCustomization
    except ImportError:
        class EnrichmentStatusCustomization(object):
            pass
    try:
        from ..._patch import EnrichmentStatusListCustomization
    except ImportError:
        class EnrichmentStatusListCustomization(object):
            pass
    try:
        from ..._patch import EnrichmentStatusQueryOptionCustomization
    except ImportError:
        class EnrichmentStatusQueryOptionCustomization(object):
            pass
    try:
        from ..._patch import ErrorCodeCustomization
    except ImportError:
        class ErrorCodeCustomization(object):
            pass
    try:
        from ..._patch import FeedbackDimensionFilterCustomization
    except ImportError:
        class FeedbackDimensionFilterCustomization(object):
            pass
    try:
        from ..._patch import HardThresholdConditionCustomization
    except ImportError:
        class HardThresholdConditionCustomization(object):
            pass
    try:
        from ..._patch import HardThresholdConditionPatchCustomization
    except ImportError:
        class HardThresholdConditionPatchCustomization(object):
            pass
    try:
        from ..._patch import HookListCustomization
    except ImportError:
        class HookListCustomization(object):
            pass
    try:
        from ..._patch import IncidentPropertyCustomization
    except ImportError:
        class IncidentPropertyCustomization(object):
            pass
    try:
        from ..._patch import IncidentResultCustomization
    except ImportError:
        class IncidentResultCustomization(object):
            pass
    try:
        from ..._patch import IncidentResultListCustomization
    except ImportError:
        class IncidentResultListCustomization(object):
            pass
    try:
        from ..._patch import InfluxDBDataFeedCustomization
    except ImportError:
        class InfluxDBDataFeedCustomization(object):
            pass
    try:
        from ..._patch import InfluxDBDataFeedPatchCustomization
    except ImportError:
        class InfluxDBDataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import InfluxDBParameterCustomization
    except ImportError:
        class InfluxDBParameterCustomization(object):
            pass
    try:
        from ..._patch import InfluxDBParameterPatchCustomization
    except ImportError:
        class InfluxDBParameterPatchCustomization(object):
            pass
    try:
        from ..._patch import IngestionProgressResetOptionsCustomization
    except ImportError:
        class IngestionProgressResetOptionsCustomization(object):
            pass
    try:
        from ..._patch import DataFeedIngestionStatusCustomization
    except ImportError:
        class DataFeedIngestionStatusCustomization(object):
            pass
    try:
        from ..._patch import IngestionStatusListCustomization
    except ImportError:
        class IngestionStatusListCustomization(object):
            pass
    try:
        from ..._patch import IngestionStatusQueryOptionsCustomization
    except ImportError:
        class IngestionStatusQueryOptionsCustomization(object):
            pass
    try:
        from ..._patch import MetricCustomization
    except ImportError:
        class MetricCustomization(object):
            pass
    try:
        from ..._patch import MetricAlertConfigurationCustomization
    except ImportError:
        class MetricAlertConfigurationCustomization(object):
            pass
    try:
        from ..._patch import MetricDataItemCustomization
    except ImportError:
        class MetricDataItemCustomization(object):
            pass
    try:
        from ..._patch import MetricDataListCustomization
    except ImportError:
        class MetricDataListCustomization(object):
            pass
    try:
        from ..._patch import MetricDataQueryOptionsCustomization
    except ImportError:
        class MetricDataQueryOptionsCustomization(object):
            pass
    try:
        from ..._patch import MetricDimensionListCustomization
    except ImportError:
        class MetricDimensionListCustomization(object):
            pass
    try:
        from ..._patch import MetricDimensionQueryOptionsCustomization
    except ImportError:
        class MetricDimensionQueryOptionsCustomization(object):
            pass
    try:
        from ..._patch import MetricFeedbackFilterCustomization
    except ImportError:
        class MetricFeedbackFilterCustomization(object):
            pass
    try:
        from ..._patch import MetricFeedbackListCustomization
    except ImportError:
        class MetricFeedbackListCustomization(object):
            pass
    try:
        from ..._patch import MetricSeriesDefinitionCustomization
    except ImportError:
        class MetricSeriesDefinitionCustomization(object):
            pass
    try:
        from ..._patch import MetricSeriesListCustomization
    except ImportError:
        class MetricSeriesListCustomization(object):
            pass
    try:
        from ..._patch import MetricSeriesQueryOptionsCustomization
    except ImportError:
        class MetricSeriesQueryOptionsCustomization(object):
            pass
    try:
        from ..._patch import MongoDBDataFeedCustomization
    except ImportError:
        class MongoDBDataFeedCustomization(object):
            pass
    try:
        from ..._patch import MongoDBDataFeedPatchCustomization
    except ImportError:
        class MongoDBDataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import MongoDBParameterCustomization
    except ImportError:
        class MongoDBParameterCustomization(object):
            pass
    try:
        from ..._patch import MongoDBParameterPatchCustomization
    except ImportError:
        class MongoDBParameterPatchCustomization(object):
            pass
    try:
        from ..._patch import MySqlDataFeedCustomization
    except ImportError:
        class MySqlDataFeedCustomization(object):
            pass
    try:
        from ..._patch import MySqlDataFeedPatchCustomization
    except ImportError:
        class MySqlDataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import PeriodFeedbackCustomization
    except ImportError:
        class PeriodFeedbackCustomization(object):
            pass
    try:
        from ..._patch import PeriodFeedbackValueCustomization
    except ImportError:
        class PeriodFeedbackValueCustomization(object):
            pass
    try:
        from ..._patch import PostgreSqlDataFeedCustomization
    except ImportError:
        class PostgreSqlDataFeedCustomization(object):
            pass
    try:
        from ..._patch import PostgreSqlDataFeedPatchCustomization
    except ImportError:
        class PostgreSqlDataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import RootCauseCustomization
    except ImportError:
        class RootCauseCustomization(object):
            pass
    try:
        from ..._patch import RootCauseListCustomization
    except ImportError:
        class RootCauseListCustomization(object):
            pass
    try:
        from ..._patch import SeriesConfigurationCustomization
    except ImportError:
        class SeriesConfigurationCustomization(object):
            pass
    try:
        from ..._patch import SeriesIdentityCustomization
    except ImportError:
        class SeriesIdentityCustomization(object):
            pass
    try:
        from ..._patch import SeriesResultCustomization
    except ImportError:
        class SeriesResultCustomization(object):
            pass
    try:
        from ..._patch import SeriesResultListCustomization
    except ImportError:
        class SeriesResultListCustomization(object):
            pass
    try:
        from ..._patch import ServicePrincipalCredentialCustomization
    except ImportError:
        class ServicePrincipalCredentialCustomization(object):
            pass
    try:
        from ..._patch import ServicePrincipalCredentialPatchCustomization
    except ImportError:
        class ServicePrincipalCredentialPatchCustomization(object):
            pass
    try:
        from ..._patch import ServicePrincipalInKVCredentialCustomization
    except ImportError:
        class ServicePrincipalInKVCredentialCustomization(object):
            pass
    try:
        from ..._patch import ServicePrincipalInKVCredentialPatchCustomization
    except ImportError:
        class ServicePrincipalInKVCredentialPatchCustomization(object):
            pass
    try:
        from ..._patch import ServicePrincipalInKVParamCustomization
    except ImportError:
        class ServicePrincipalInKVParamCustomization(object):
            pass
    try:
        from ..._patch import ServicePrincipalInKVParamPatchCustomization
    except ImportError:
        class ServicePrincipalInKVParamPatchCustomization(object):
            pass
    try:
        from ..._patch import ServicePrincipalParamCustomization
    except ImportError:
        class ServicePrincipalParamCustomization(object):
            pass
    try:
        from ..._patch import ServicePrincipalParamPatchCustomization
    except ImportError:
        class ServicePrincipalParamPatchCustomization(object):
            pass
    try:
        from ..._patch import SeverityConditionCustomization
    except ImportError:
        class SeverityConditionCustomization(object):
            pass
    try:
        from ..._patch import SeverityFilterConditionCustomization
    except ImportError:
        class SeverityFilterConditionCustomization(object):
            pass
    try:
        from ..._patch import SmartDetectionConditionCustomization
    except ImportError:
        class SmartDetectionConditionCustomization(object):
            pass
    try:
        from ..._patch import SmartDetectionConditionPatchCustomization
    except ImportError:
        class SmartDetectionConditionPatchCustomization(object):
            pass
    try:
        from ..._patch import SQLServerDataFeedCustomization
    except ImportError:
        class SQLServerDataFeedCustomization(object):
            pass
    try:
        from ..._patch import SQLServerDataFeedPatchCustomization
    except ImportError:
        class SQLServerDataFeedPatchCustomization(object):
            pass
    try:
        from ..._patch import SqlSourceParameterCustomization
    except ImportError:
        class SqlSourceParameterCustomization(object):
            pass
    try:
        from ..._patch import SQLSourceParameterPatchCustomization
    except ImportError:
        class SQLSourceParameterPatchCustomization(object):
            pass
    try:
        from ..._patch import SuppressConditionCustomization
    except ImportError:
        class SuppressConditionCustomization(object):
            pass
    try:
        from ..._patch import SuppressConditionPatchCustomization
    except ImportError:
        class SuppressConditionPatchCustomization(object):
            pass
    try:
        from ..._patch import TopNGroupScopeCustomization
    except ImportError:
        class TopNGroupScopeCustomization(object):
            pass
    try:
        from ..._patch import UsageStatsCustomization
    except ImportError:
        class UsageStatsCustomization(object):
            pass
    try:
        from ..._patch import ValueConditionCustomization
    except ImportError:
        class ValueConditionCustomization(object):
            pass
    try:
        from ..._patch import WebhookHookInfoCustomization
    except ImportError:
        class WebhookHookInfoCustomization(object):
            pass
    try:
        from ..._patch import WebhookHookInfoPatchCustomization
    except ImportError:
        class WebhookHookInfoPatchCustomization(object):
            pass
    try:
        from ..._patch import WebhookHookParameterCustomization
    except ImportError:
        class WebhookHookParameterCustomization(object):
            pass
    try:
        from ..._patch import WebhookHookParameterPatchCustomization
    except ImportError:
        class WebhookHookParameterPatchCustomization(object):
            pass
    try:
        from ..._patch import WholeMetricConfigurationCustomization
    except ImportError:
        class WholeMetricConfigurationCustomization(object):
            pass
    try:
        from ..._patch import WholeMetricConfigurationPatchCustomization
    except ImportError:
        class WholeMetricConfigurationPatchCustomization(object):
            pass


class _AlertingResultQueryGenerated(msrest.serialization.Model):
    """AlertingResultQuery.

    All required parameters must be populated in order to send to Azure.

    :ivar start_time: Required. start time.
    :vartype start_time: ~datetime.datetime
    :ivar end_time: Required. end time.
    :vartype end_time: ~datetime.datetime
    :ivar time_mode: Required. time mode. Possible values include: "AnomalyTime", "CreatedTime",
     "ModifiedTime".
    :vartype time_mode: str or ~azure.ai.metricsadvisor.models.TimeMode
    """

    _validation = {
        'start_time': {'required': True},
        'end_time': {'required': True},
        'time_mode': {'required': True},
    }

    _attribute_map = {
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'endTime', 'type': 'iso-8601'},
        'time_mode': {'key': 'timeMode', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        start_time: datetime.datetime,
        end_time: datetime.datetime,
        time_mode: Union[str, "TimeMode"],
        **kwargs
    ):
        """
        :keyword start_time: Required. start time.
        :paramtype start_time: ~datetime.datetime
        :keyword end_time: Required. end time.
        :paramtype end_time: ~datetime.datetime
        :keyword time_mode: Required. time mode. Possible values include: "AnomalyTime", "CreatedTime",
         "ModifiedTime".
        :paramtype time_mode: str or ~azure.ai.metricsadvisor.models.TimeMode
        """
        super(_AlertingResultQueryGenerated, self).__init__(**kwargs)
        self.start_time = start_time
        self.end_time = end_time
        self.time_mode = time_mode

class AlertingResultQuery(AlertingResultQueryCustomization, _AlertingResultQueryGenerated):
    pass


class _AlertResultGenerated(msrest.serialization.Model):
    """AlertResult.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar alert_id: alert id.
    :vartype alert_id: str
    :ivar timestamp: anomaly time.
    :vartype timestamp: ~datetime.datetime
    :ivar created_time: created time.
    :vartype created_time: ~datetime.datetime
    :ivar modified_time: modified time.
    :vartype modified_time: ~datetime.datetime
    """

    _validation = {
        'alert_id': {'readonly': True},
        'timestamp': {'readonly': True},
        'created_time': {'readonly': True},
        'modified_time': {'readonly': True},
    }

    _attribute_map = {
        'alert_id': {'key': 'alertId', 'type': 'str'},
        'timestamp': {'key': 'timestamp', 'type': 'iso-8601'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'modified_time': {'key': 'modifiedTime', 'type': 'iso-8601'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_AlertResultGenerated, self).__init__(**kwargs)
        self.alert_id = None
        self.timestamp = None
        self.created_time = None
        self.modified_time = None

class AlertResult(AlertResultCustomization, _AlertResultGenerated):
    pass


class _AlertResultListGenerated(msrest.serialization.Model):
    """AlertResultList.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar next_link:
    :vartype next_link: str
    :ivar value: Required.
    :vartype value: list[~azure.ai.metricsadvisor.models.AlertResult]
    """

    _validation = {
        'next_link': {'readonly': True},
        'value': {'required': True},
    }

    _attribute_map = {
        'next_link': {'key': '@nextLink', 'type': 'str'},
        'value': {'key': 'value', 'type': '[AlertResult]'},
    }

    def __init__(
        self,
        *,
        value: List["AlertResult"],
        **kwargs
    ):
        """
        :keyword value: Required.
        :paramtype value: list[~azure.ai.metricsadvisor.models.AlertResult]
        """
        super(_AlertResultListGenerated, self).__init__(**kwargs)
        self.next_link = None
        self.value = value

class AlertResultList(AlertResultListCustomization, _AlertResultListGenerated):
    pass


class _AlertSnoozeConditionGenerated(msrest.serialization.Model):
    """AlertSnoozeCondition.

    All required parameters must be populated in order to send to Azure.

    :ivar auto_snooze: Required. snooze point count, value range : [0, +∞).
    :vartype auto_snooze: int
    :ivar snooze_scope: Required. snooze scope. Possible values include: "Metric", "Series".
    :vartype snooze_scope: str or ~azure.ai.metricsadvisor.models.SnoozeScope
    :ivar only_for_successive: Required. only snooze for successive anomalies.
    :vartype only_for_successive: bool
    """

    _validation = {
        'auto_snooze': {'required': True},
        'snooze_scope': {'required': True},
        'only_for_successive': {'required': True},
    }

    _attribute_map = {
        'auto_snooze': {'key': 'autoSnooze', 'type': 'int'},
        'snooze_scope': {'key': 'snoozeScope', 'type': 'str'},
        'only_for_successive': {'key': 'onlyForSuccessive', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        auto_snooze: int,
        snooze_scope: Union[str, "SnoozeScope"],
        only_for_successive: bool,
        **kwargs
    ):
        """
        :keyword auto_snooze: Required. snooze point count, value range : [0, +∞).
        :paramtype auto_snooze: int
        :keyword snooze_scope: Required. snooze scope. Possible values include: "Metric", "Series".
        :paramtype snooze_scope: str or ~azure.ai.metricsadvisor.models.SnoozeScope
        :keyword only_for_successive: Required. only snooze for successive anomalies.
        :paramtype only_for_successive: bool
        """
        super(_AlertSnoozeConditionGenerated, self).__init__(**kwargs)
        self.auto_snooze = auto_snooze
        self.snooze_scope = snooze_scope
        self.only_for_successive = only_for_successive

class AlertSnoozeCondition(AlertSnoozeConditionCustomization, _AlertSnoozeConditionGenerated):
    pass


class _AnomalyAlertingConfigurationGenerated(msrest.serialization.Model):
    """AnomalyAlertingConfiguration.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar anomaly_alerting_configuration_id: anomaly alerting configuration unique id.
    :vartype anomaly_alerting_configuration_id: str
    :ivar name: Required. anomaly alerting configuration name.
    :vartype name: str
    :ivar description: anomaly alerting configuration description.
    :vartype description: str
    :ivar cross_metrics_operator: cross metrics operator

     should be specified when setting up multiple metric alerting configurations. Possible values
     include: "AND", "OR", "XOR".
    :vartype cross_metrics_operator: str or
     ~azure.ai.metricsadvisor.models.AnomalyAlertingConfigurationLogicType
    :ivar split_alert_by_dimensions: dimensions used to split alert.
    :vartype split_alert_by_dimensions: list[str]
    :ivar hook_ids: Required. hook unique ids.
    :vartype hook_ids: list[str]
    :ivar metric_alerting_configurations: Required. Anomaly alerting configurations.
    :vartype metric_alerting_configurations:
     list[~azure.ai.metricsadvisor.models.MetricAlertConfiguration]
    """

    _validation = {
        'anomaly_alerting_configuration_id': {'readonly': True},
        'name': {'required': True},
        'split_alert_by_dimensions': {'unique': True},
        'hook_ids': {'required': True, 'unique': True},
        'metric_alerting_configurations': {'required': True, 'unique': True},
    }

    _attribute_map = {
        'anomaly_alerting_configuration_id': {'key': 'anomalyAlertingConfigurationId', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'cross_metrics_operator': {'key': 'crossMetricsOperator', 'type': 'str'},
        'split_alert_by_dimensions': {'key': 'splitAlertByDimensions', 'type': '[str]'},
        'hook_ids': {'key': 'hookIds', 'type': '[str]'},
        'metric_alerting_configurations': {'key': 'metricAlertingConfigurations', 'type': '[MetricAlertConfiguration]'},
    }

    def __init__(
        self,
        *,
        name: str,
        hook_ids: List[str],
        metric_alerting_configurations: List["MetricAlertConfiguration"],
        description: Optional[str] = "",
        cross_metrics_operator: Optional[Union[str, "AnomalyAlertingConfigurationLogicType"]] = None,
        split_alert_by_dimensions: Optional[List[str]] = None,
        **kwargs
    ):
        """
        :keyword name: Required. anomaly alerting configuration name.
        :paramtype name: str
        :keyword description: anomaly alerting configuration description.
        :paramtype description: str
        :keyword cross_metrics_operator: cross metrics operator

         should be specified when setting up multiple metric alerting configurations. Possible values
         include: "AND", "OR", "XOR".
        :paramtype cross_metrics_operator: str or
         ~azure.ai.metricsadvisor.models.AnomalyAlertingConfigurationLogicType
        :keyword split_alert_by_dimensions: dimensions used to split alert.
        :paramtype split_alert_by_dimensions: list[str]
        :keyword hook_ids: Required. hook unique ids.
        :paramtype hook_ids: list[str]
        :keyword metric_alerting_configurations: Required. Anomaly alerting configurations.
        :paramtype metric_alerting_configurations:
         list[~azure.ai.metricsadvisor.models.MetricAlertConfiguration]
        """
        super(_AnomalyAlertingConfigurationGenerated, self).__init__(**kwargs)
        self.anomaly_alerting_configuration_id = None
        self.name = name
        self.description = description
        self.cross_metrics_operator = cross_metrics_operator
        self.split_alert_by_dimensions = split_alert_by_dimensions
        self.hook_ids = hook_ids
        self.metric_alerting_configurations = metric_alerting_configurations

class AnomalyAlertingConfiguration(AnomalyAlertingConfigurationCustomization, _AnomalyAlertingConfigurationGenerated):
    pass


class _AnomalyAlertingConfigurationListGenerated(msrest.serialization.Model):
    """AnomalyAlertingConfigurationList.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar value:
    :vartype value: list[~azure.ai.metricsadvisor.models.AnomalyAlertingConfiguration]
    :ivar next_link:
    :vartype next_link: str
    """

    _validation = {
        'value': {'readonly': True},
        'next_link': {'readonly': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[AnomalyAlertingConfiguration]'},
        'next_link': {'key': '@nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_AnomalyAlertingConfigurationListGenerated, self).__init__(**kwargs)
        self.value = None
        self.next_link = None

class AnomalyAlertingConfigurationList(AnomalyAlertingConfigurationListCustomization, _AnomalyAlertingConfigurationListGenerated):
    pass


class _AnomalyAlertingConfigurationPatchGenerated(msrest.serialization.Model):
    """AnomalyAlertingConfigurationPatch.

    :ivar name: Anomaly alerting configuration name.
    :vartype name: str
    :ivar description: anomaly alerting configuration description.
    :vartype description: str
    :ivar cross_metrics_operator: cross metrics operator. Possible values include: "AND", "OR",
     "XOR".
    :vartype cross_metrics_operator: str or
     ~azure.ai.metricsadvisor.models.AnomalyAlertingConfigurationLogicType
    :ivar split_alert_by_dimensions: dimensions used to split alert.
    :vartype split_alert_by_dimensions: list[str]
    :ivar hook_ids: hook unique ids.
    :vartype hook_ids: list[str]
    :ivar metric_alerting_configurations: Anomaly alerting configurations.
    :vartype metric_alerting_configurations:
     list[~azure.ai.metricsadvisor.models.MetricAlertConfiguration]
    """

    _validation = {
        'split_alert_by_dimensions': {'unique': True},
        'hook_ids': {'unique': True},
        'metric_alerting_configurations': {'unique': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'cross_metrics_operator': {'key': 'crossMetricsOperator', 'type': 'str'},
        'split_alert_by_dimensions': {'key': 'splitAlertByDimensions', 'type': '[str]'},
        'hook_ids': {'key': 'hookIds', 'type': '[str]'},
        'metric_alerting_configurations': {'key': 'metricAlertingConfigurations', 'type': '[MetricAlertConfiguration]'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        description: Optional[str] = "",
        cross_metrics_operator: Optional[Union[str, "AnomalyAlertingConfigurationLogicType"]] = None,
        split_alert_by_dimensions: Optional[List[str]] = None,
        hook_ids: Optional[List[str]] = None,
        metric_alerting_configurations: Optional[List["MetricAlertConfiguration"]] = None,
        **kwargs
    ):
        """
        :keyword name: Anomaly alerting configuration name.
        :paramtype name: str
        :keyword description: anomaly alerting configuration description.
        :paramtype description: str
        :keyword cross_metrics_operator: cross metrics operator. Possible values include: "AND", "OR",
         "XOR".
        :paramtype cross_metrics_operator: str or
         ~azure.ai.metricsadvisor.models.AnomalyAlertingConfigurationLogicType
        :keyword split_alert_by_dimensions: dimensions used to split alert.
        :paramtype split_alert_by_dimensions: list[str]
        :keyword hook_ids: hook unique ids.
        :paramtype hook_ids: list[str]
        :keyword metric_alerting_configurations: Anomaly alerting configurations.
        :paramtype metric_alerting_configurations:
         list[~azure.ai.metricsadvisor.models.MetricAlertConfiguration]
        """
        super(_AnomalyAlertingConfigurationPatchGenerated, self).__init__(**kwargs)
        self.name = name
        self.description = description
        self.cross_metrics_operator = cross_metrics_operator
        self.split_alert_by_dimensions = split_alert_by_dimensions
        self.hook_ids = hook_ids
        self.metric_alerting_configurations = metric_alerting_configurations

class AnomalyAlertingConfigurationPatch(AnomalyAlertingConfigurationPatchCustomization, _AnomalyAlertingConfigurationPatchGenerated):
    pass


class _AnomalyDetectionConfigurationGenerated(msrest.serialization.Model):
    """AnomalyDetectionConfiguration.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar anomaly_detection_configuration_id: anomaly detection configuration unique id.
    :vartype anomaly_detection_configuration_id: str
    :ivar name: Required. anomaly detection configuration name.
    :vartype name: str
    :ivar description: anomaly detection configuration description.
    :vartype description: str
    :ivar metric_id: Required. metric unique id.
    :vartype metric_id: str
    :ivar whole_metric_configuration: Required.
    :vartype whole_metric_configuration: ~azure.ai.metricsadvisor.models.WholeMetricConfiguration
    :ivar dimension_group_override_configurations: detection configuration for series group.
    :vartype dimension_group_override_configurations:
     list[~azure.ai.metricsadvisor.models.DimensionGroupConfiguration]
    :ivar series_override_configurations: detection configuration for specific series.
    :vartype series_override_configurations:
     list[~azure.ai.metricsadvisor.models.SeriesConfiguration]
    """

    _validation = {
        'anomaly_detection_configuration_id': {'readonly': True},
        'name': {'required': True},
        'metric_id': {'required': True},
        'whole_metric_configuration': {'required': True},
        'dimension_group_override_configurations': {'unique': True},
        'series_override_configurations': {'unique': True},
    }

    _attribute_map = {
        'anomaly_detection_configuration_id': {'key': 'anomalyDetectionConfigurationId', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'metric_id': {'key': 'metricId', 'type': 'str'},
        'whole_metric_configuration': {'key': 'wholeMetricConfiguration', 'type': 'WholeMetricConfiguration'},
        'dimension_group_override_configurations': {'key': 'dimensionGroupOverrideConfigurations', 'type': '[DimensionGroupConfiguration]'},
        'series_override_configurations': {'key': 'seriesOverrideConfigurations', 'type': '[SeriesConfiguration]'},
    }

    def __init__(
        self,
        *,
        name: str,
        metric_id: str,
        whole_metric_configuration: "WholeMetricConfiguration",
        description: Optional[str] = "",
        dimension_group_override_configurations: Optional[List["DimensionGroupConfiguration"]] = None,
        series_override_configurations: Optional[List["SeriesConfiguration"]] = None,
        **kwargs
    ):
        """
        :keyword name: Required. anomaly detection configuration name.
        :paramtype name: str
        :keyword description: anomaly detection configuration description.
        :paramtype description: str
        :keyword metric_id: Required. metric unique id.
        :paramtype metric_id: str
        :keyword whole_metric_configuration: Required.
        :paramtype whole_metric_configuration: ~azure.ai.metricsadvisor.models.WholeMetricConfiguration
        :keyword dimension_group_override_configurations: detection configuration for series group.
        :paramtype dimension_group_override_configurations:
         list[~azure.ai.metricsadvisor.models.DimensionGroupConfiguration]
        :keyword series_override_configurations: detection configuration for specific series.
        :paramtype series_override_configurations:
         list[~azure.ai.metricsadvisor.models.SeriesConfiguration]
        """
        super(_AnomalyDetectionConfigurationGenerated, self).__init__(**kwargs)
        self.anomaly_detection_configuration_id = None
        self.name = name
        self.description = description
        self.metric_id = metric_id
        self.whole_metric_configuration = whole_metric_configuration
        self.dimension_group_override_configurations = dimension_group_override_configurations
        self.series_override_configurations = series_override_configurations

class AnomalyDetectionConfiguration(AnomalyDetectionConfigurationCustomization, _AnomalyDetectionConfigurationGenerated):
    pass


class _AnomalyDetectionConfigurationListGenerated(msrest.serialization.Model):
    """AnomalyDetectionConfigurationList.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar value:
    :vartype value: list[~azure.ai.metricsadvisor.models.AnomalyDetectionConfiguration]
    :ivar next_link:
    :vartype next_link: str
    """

    _validation = {
        'value': {'readonly': True},
        'next_link': {'readonly': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[AnomalyDetectionConfiguration]'},
        'next_link': {'key': '@nextLink', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_AnomalyDetectionConfigurationListGenerated, self).__init__(**kwargs)
        self.value = None
        self.next_link = None

class AnomalyDetectionConfigurationList(AnomalyDetectionConfigurationListCustomization, _AnomalyDetectionConfigurationListGenerated):
    pass


class _AnomalyDetectionConfigurationPatchGenerated(msrest.serialization.Model):
    """AnomalyDetectionConfigurationPatch.

    :ivar name: anomaly detection configuration name.
    :vartype name: str
    :ivar description: anomaly detection configuration description.
    :vartype description: str
    :ivar whole_metric_configuration:
    :vartype whole_metric_configuration:
     ~azure.ai.metricsadvisor.models.WholeMetricConfigurationPatch
    :ivar dimension_group_override_configurations: detection configuration for series group.
    :vartype dimension_group_override_configurations:
     list[~azure.ai.metricsadvisor.models.DimensionGroupConfiguration]
    :ivar series_override_configurations: detection configuration for specific series.
    :vartype series_override_configurations:
     list[~azure.ai.metricsadvisor.models.SeriesConfiguration]
    """

    _validation = {
        'dimension_group_override_configurations': {'unique': True},
        'series_override_configurations': {'unique': True},
    }

    _attribute_map = {
        'name': {'key': 'name', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'whole_metric_configuration': {'key': 'wholeMetricConfiguration', 'type': 'WholeMetricConfigurationPatch'},
        'dimension_group_override_configurations': {'key': 'dimensionGroupOverrideConfigurations', 'type': '[DimensionGroupConfiguration]'},
        'series_override_configurations': {'key': 'seriesOverrideConfigurations', 'type': '[SeriesConfiguration]'},
    }

    def __init__(
        self,
        *,
        name: Optional[str] = None,
        description: Optional[str] = "",
        whole_metric_configuration: Optional["WholeMetricConfigurationPatch"] = None,
        dimension_group_override_configurations: Optional[List["DimensionGroupConfiguration"]] = None,
        series_override_configurations: Optional[List["SeriesConfiguration"]] = None,
        **kwargs
    ):
        """
        :keyword name: anomaly detection configuration name.
        :paramtype name: str
        :keyword description: anomaly detection configuration description.
        :paramtype description: str
        :keyword whole_metric_configuration:
        :paramtype whole_metric_configuration:
         ~azure.ai.metricsadvisor.models.WholeMetricConfigurationPatch
        :keyword dimension_group_override_configurations: detection configuration for series group.
        :paramtype dimension_group_override_configurations:
         list[~azure.ai.metricsadvisor.models.DimensionGroupConfiguration]
        :keyword series_override_configurations: detection configuration for specific series.
        :paramtype series_override_configurations:
         list[~azure.ai.metricsadvisor.models.SeriesConfiguration]
        """
        super(_AnomalyDetectionConfigurationPatchGenerated, self).__init__(**kwargs)
        self.name = name
        self.description = description
        self.whole_metric_configuration = whole_metric_configuration
        self.dimension_group_override_configurations = dimension_group_override_configurations
        self.series_override_configurations = series_override_configurations

class AnomalyDetectionConfigurationPatch(AnomalyDetectionConfigurationPatchCustomization, _AnomalyDetectionConfigurationPatchGenerated):
    pass


class _AnomalyDimensionListGenerated(msrest.serialization.Model):
    """AnomalyDimensionList.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar next_link:
    :vartype next_link: str
    :ivar value: Required.
    :vartype value: list[str]
    """

    _validation = {
        'next_link': {'readonly': True},
        'value': {'required': True},
    }

    _attribute_map = {
        'next_link': {'key': '@nextLink', 'type': 'str'},
        'value': {'key': 'value', 'type': '[str]'},
    }

    def __init__(
        self,
        *,
        value: List[str],
        **kwargs
    ):
        """
        :keyword value: Required.
        :paramtype value: list[str]
        """
        super(_AnomalyDimensionListGenerated, self).__init__(**kwargs)
        self.next_link = None
        self.value = value

class AnomalyDimensionList(AnomalyDimensionListCustomization, _AnomalyDimensionListGenerated):
    pass


class _AnomalyDimensionQueryGenerated(msrest.serialization.Model):
    """AnomalyDimensionQuery.

    All required parameters must be populated in order to send to Azure.

    :ivar start_time: Required. start time.
    :vartype start_time: ~datetime.datetime
    :ivar end_time: Required. end time.
    :vartype end_time: ~datetime.datetime
    :ivar dimension_name: Required. dimension to query.
    :vartype dimension_name: str
    :ivar dimension_filter:
    :vartype dimension_filter: ~azure.ai.metricsadvisor.models.DimensionGroupIdentity
    """

    _validation = {
        'start_time': {'required': True},
        'end_time': {'required': True},
        'dimension_name': {'required': True},
    }

    _attribute_map = {
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'endTime', 'type': 'iso-8601'},
        'dimension_name': {'key': 'dimensionName', 'type': 'str'},
        'dimension_filter': {'key': 'dimensionFilter', 'type': 'DimensionGroupIdentity'},
    }

    def __init__(
        self,
        *,
        start_time: datetime.datetime,
        end_time: datetime.datetime,
        dimension_name: str,
        dimension_filter: Optional["DimensionGroupIdentity"] = None,
        **kwargs
    ):
        """
        :keyword start_time: Required. start time.
        :paramtype start_time: ~datetime.datetime
        :keyword end_time: Required. end time.
        :paramtype end_time: ~datetime.datetime
        :keyword dimension_name: Required. dimension to query.
        :paramtype dimension_name: str
        :keyword dimension_filter:
        :paramtype dimension_filter: ~azure.ai.metricsadvisor.models.DimensionGroupIdentity
        """
        super(_AnomalyDimensionQueryGenerated, self).__init__(**kwargs)
        self.start_time = start_time
        self.end_time = end_time
        self.dimension_name = dimension_name
        self.dimension_filter = dimension_filter

class AnomalyDimensionQuery(AnomalyDimensionQueryCustomization, _AnomalyDimensionQueryGenerated):
    pass


class _AnomalyFeedbackValueGenerated(msrest.serialization.Model):
    """AnomalyFeedbackValue.

    All required parameters must be populated in order to send to Azure.

    :ivar anomaly_value: Required. Possible values include: "AutoDetect", "Anomaly", "NotAnomaly".
    :vartype anomaly_value: str or ~azure.ai.metricsadvisor.models.AnomalyValue
    """

    _validation = {
        'anomaly_value': {'required': True},
    }

    _attribute_map = {
        'anomaly_value': {'key': 'anomalyValue', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        anomaly_value: Union[str, "AnomalyValue"],
        **kwargs
    ):
        """
        :keyword anomaly_value: Required. Possible values include: "AutoDetect", "Anomaly",
         "NotAnomaly".
        :paramtype anomaly_value: str or ~azure.ai.metricsadvisor.models.AnomalyValue
        """
        super(_AnomalyFeedbackValueGenerated, self).__init__(**kwargs)
        self.anomaly_value = anomaly_value

class AnomalyFeedbackValue(AnomalyFeedbackValueCustomization, _AnomalyFeedbackValueGenerated):
    pass


class _AnomalyPropertyGenerated(msrest.serialization.Model):
    """AnomalyProperty.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar anomaly_severity: Required. anomaly severity. Possible values include: "Low", "Medium",
     "High".
    :vartype anomaly_severity: str or ~azure.ai.metricsadvisor.models.Severity
    :ivar anomaly_status: anomaly status

     only return for alerting anomaly result. Possible values include: "Active", "Resolved".
    :vartype anomaly_status: str or ~azure.ai.metricsadvisor.models.AnomalyStatus
    :ivar value: value of the anomaly.
    :vartype value: float
    :ivar expected_value: expected value of the anomaly given by smart detector.
    :vartype expected_value: float
    """

    _validation = {
        'anomaly_severity': {'required': True},
        'anomaly_status': {'readonly': True},
        'value': {'readonly': True},
        'expected_value': {'readonly': True},
    }

    _attribute_map = {
        'anomaly_severity': {'key': 'anomalySeverity', 'type': 'str'},
        'anomaly_status': {'key': 'anomalyStatus', 'type': 'str'},
        'value': {'key': 'value', 'type': 'float'},
        'expected_value': {'key': 'expectedValue', 'type': 'float'},
    }

    def __init__(
        self,
        *,
        anomaly_severity: Union[str, "Severity"],
        **kwargs
    ):
        """
        :keyword anomaly_severity: Required. anomaly severity. Possible values include: "Low",
         "Medium", "High".
        :paramtype anomaly_severity: str or ~azure.ai.metricsadvisor.models.Severity
        """
        super(_AnomalyPropertyGenerated, self).__init__(**kwargs)
        self.anomaly_severity = anomaly_severity
        self.anomaly_status = None
        self.value = None
        self.expected_value = None

class AnomalyProperty(AnomalyPropertyCustomization, _AnomalyPropertyGenerated):
    pass


class _AnomalyResultGenerated(msrest.serialization.Model):
    """AnomalyResult.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_feed_id: data feed unique id

     only return for alerting anomaly result.
    :vartype data_feed_id: str
    :ivar metric_id: metric unique id

     only return for alerting anomaly result.
    :vartype metric_id: str
    :ivar anomaly_detection_configuration_id: anomaly detection configuration unique id

     only return for alerting anomaly result.
    :vartype anomaly_detection_configuration_id: str
    :ivar timestamp: Required. anomaly time.
    :vartype timestamp: ~datetime.datetime
    :ivar created_time: created time

     only return for alerting result.
    :vartype created_time: ~datetime.datetime
    :ivar modified_time: modified time

     only return for alerting result.
    :vartype modified_time: ~datetime.datetime
    :ivar dimension: Required. dimension specified for series.
    :vartype dimension: dict[str, str]
    :ivar property: Required.
    :vartype property: ~azure.ai.metricsadvisor.models.AnomalyProperty
    """

    _validation = {
        'data_feed_id': {'readonly': True},
        'metric_id': {'readonly': True},
        'anomaly_detection_configuration_id': {'readonly': True},
        'timestamp': {'required': True},
        'created_time': {'readonly': True},
        'modified_time': {'readonly': True},
        'dimension': {'required': True},
        'property': {'required': True},
    }

    _attribute_map = {
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'metric_id': {'key': 'metricId', 'type': 'str'},
        'anomaly_detection_configuration_id': {'key': 'anomalyDetectionConfigurationId', 'type': 'str'},
        'timestamp': {'key': 'timestamp', 'type': 'iso-8601'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'modified_time': {'key': 'modifiedTime', 'type': 'iso-8601'},
        'dimension': {'key': 'dimension', 'type': '{str}'},
        'property': {'key': 'property', 'type': 'AnomalyProperty'},
    }

    def __init__(
        self,
        *,
        timestamp: datetime.datetime,
        dimension: Dict[str, str],
        property: "AnomalyProperty",
        **kwargs
    ):
        """
        :keyword timestamp: Required. anomaly time.
        :paramtype timestamp: ~datetime.datetime
        :keyword dimension: Required. dimension specified for series.
        :paramtype dimension: dict[str, str]
        :keyword property: Required.
        :paramtype property: ~azure.ai.metricsadvisor.models.AnomalyProperty
        """
        super(_AnomalyResultGenerated, self).__init__(**kwargs)
        self.data_feed_id = None
        self.metric_id = None
        self.anomaly_detection_configuration_id = None
        self.timestamp = timestamp
        self.created_time = None
        self.modified_time = None
        self.dimension = dimension
        self.property = property

class AnomalyResult(AnomalyResultCustomization, _AnomalyResultGenerated):
    pass


class _AnomalyResultListGenerated(msrest.serialization.Model):
    """AnomalyResultList.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar next_link:
    :vartype next_link: str
    :ivar value: Required.
    :vartype value: list[~azure.ai.metricsadvisor.models.AnomalyResult]
    """

    _validation = {
        'next_link': {'readonly': True},
        'value': {'required': True},
    }

    _attribute_map = {
        'next_link': {'key': '@nextLink', 'type': 'str'},
        'value': {'key': 'value', 'type': '[AnomalyResult]'},
    }

    def __init__(
        self,
        *,
        value: List["AnomalyResult"],
        **kwargs
    ):
        """
        :keyword value: Required.
        :paramtype value: list[~azure.ai.metricsadvisor.models.AnomalyResult]
        """
        super(_AnomalyResultListGenerated, self).__init__(**kwargs)
        self.next_link = None
        self.value = value

class AnomalyResultList(AnomalyResultListCustomization, _AnomalyResultListGenerated):
    pass


class _DataFeedGenerated(msrest.serialization.Model):
    """DataFeed.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AzureApplicationInsightsDataFeed, AzureBlobDataFeed, AzureCosmosDBDataFeed, AzureDataExplorerDataFeed, AzureDataLakeStorageGen2DataFeed, AzureEventHubsDataFeed, AzureLogAnalyticsDataFeed, AzureTableDataFeed, InfluxDBDataFeed, MongoDBDataFeed, MySqlDataFeed, PostgreSqlDataFeed, SQLServerDataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
    }

    _subtype_map = {
        'data_source_type': {'AzureApplicationInsights': 'AzureApplicationInsightsDataFeed', 'AzureBlob': 'AzureBlobDataFeed', 'AzureCosmosDB': 'AzureCosmosDBDataFeed', 'AzureDataExplorer': 'AzureDataExplorerDataFeed', 'AzureDataLakeStorageGen2': 'AzureDataLakeStorageGen2DataFeed', 'AzureEventHubs': 'AzureEventHubsDataFeed', 'AzureLogAnalytics': 'AzureLogAnalyticsDataFeed', 'AzureTable': 'AzureTableDataFeed', 'InfluxDB': 'InfluxDBDataFeed', 'MongoDB': 'MongoDBDataFeed', 'MySql': 'MySqlDataFeed', 'PostgreSql': 'PostgreSqlDataFeed', 'SqlServer': 'SQLServerDataFeed'}
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        """
        super(_DataFeedGenerated, self).__init__(**kwargs)
        self.data_source_type = None  # type: Optional[str]
        self.data_feed_id = None
        self.data_feed_name = data_feed_name
        self.data_feed_description = data_feed_description
        self.granularity_name = granularity_name
        self.granularity_amount = granularity_amount
        self.metrics = metrics
        self.dimension = dimension
        self.timestamp_column = timestamp_column
        self.data_start_from = data_start_from
        self.start_offset_in_seconds = start_offset_in_seconds
        self.max_concurrency = max_concurrency
        self.min_retry_interval_in_seconds = min_retry_interval_in_seconds
        self.stop_retry_after_in_seconds = stop_retry_after_in_seconds
        self.need_rollup = need_rollup
        self.roll_up_method = roll_up_method
        self.roll_up_columns = roll_up_columns
        self.all_up_identification = all_up_identification
        self.fill_missing_point_type = fill_missing_point_type
        self.fill_missing_point_value = fill_missing_point_value
        self.view_mode = view_mode
        self.admins = admins
        self.viewers = viewers
        self.is_admin = None
        self.creator = None
        self.status = None
        self.created_time = None
        self.action_link_template = action_link_template
        self.authentication_type = authentication_type
        self.credential_id = credential_id

class DataFeed(DataFeedCustomization, _DataFeedGenerated):
    pass


class _AzureApplicationInsightsDataFeedGenerated(_DataFeedGenerated):
    """AzureApplicationInsightsDataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter: Required.
    :vartype data_source_parameter:
     ~azure.ai.metricsadvisor.models.AzureApplicationInsightsParameter
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
        'data_source_parameter': {'required': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureApplicationInsightsParameter'},
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_source_parameter: "AzureApplicationInsightsParameter",
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter: Required.
        :paramtype data_source_parameter:
         ~azure.ai.metricsadvisor.models.AzureApplicationInsightsParameter
        """
        super(_AzureApplicationInsightsDataFeedGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, granularity_name=granularity_name, granularity_amount=granularity_amount, metrics=metrics, dimension=dimension, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureApplicationInsights'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureApplicationInsightsDataFeed(AzureApplicationInsightsDataFeedCustomization, DataFeed, _AzureApplicationInsightsDataFeedGenerated):
    pass


class _DataFeedPatchGenerated(msrest.serialization.Model):
    """DataFeedPatch.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AzureApplicationInsightsDataFeedPatch, AzureBlobDataFeedPatch, AzureCosmosDBDataFeedPatch, AzureDataExplorerDataFeedPatch, AzureDataLakeStorageGen2DataFeedPatch, AzureEventHubsDataFeedPatch, AzureLogAnalyticsDataFeedPatch, AzureTableDataFeedPatch, InfluxDBDataFeedPatch, MongoDBDataFeedPatch, MySqlDataFeedPatch, PostgreSqlDataFeedPatch, SQLServerDataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
    }

    _subtype_map = {
        'data_source_type': {'AzureApplicationInsights': 'AzureApplicationInsightsDataFeedPatch', 'AzureBlob': 'AzureBlobDataFeedPatch', 'AzureCosmosDB': 'AzureCosmosDBDataFeedPatch', 'AzureDataExplorer': 'AzureDataExplorerDataFeedPatch', 'AzureDataLakeStorageGen2': 'AzureDataLakeStorageGen2DataFeedPatch', 'AzureEventHubs': 'AzureEventHubsDataFeedPatch', 'AzureLogAnalytics': 'AzureLogAnalyticsDataFeedPatch', 'AzureTable': 'AzureTableDataFeedPatch', 'InfluxDB': 'InfluxDBDataFeedPatch', 'MongoDB': 'MongoDBDataFeedPatch', 'MySql': 'MySqlDataFeedPatch', 'PostgreSql': 'PostgreSqlDataFeedPatch', 'SqlServer': 'SQLServerDataFeedPatch'}
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        """
        super(_DataFeedPatchGenerated, self).__init__(**kwargs)
        self.data_source_type = None  # type: Optional[str]
        self.data_feed_name = data_feed_name
        self.data_feed_description = data_feed_description
        self.timestamp_column = timestamp_column
        self.data_start_from = data_start_from
        self.start_offset_in_seconds = start_offset_in_seconds
        self.max_concurrency = max_concurrency
        self.min_retry_interval_in_seconds = min_retry_interval_in_seconds
        self.stop_retry_after_in_seconds = stop_retry_after_in_seconds
        self.need_rollup = need_rollup
        self.roll_up_method = roll_up_method
        self.roll_up_columns = roll_up_columns
        self.all_up_identification = all_up_identification
        self.fill_missing_point_type = fill_missing_point_type
        self.fill_missing_point_value = fill_missing_point_value
        self.view_mode = view_mode
        self.admins = admins
        self.viewers = viewers
        self.status = status
        self.action_link_template = action_link_template
        self.authentication_type = authentication_type
        self.credential_id = credential_id

class DataFeedPatch(DataFeedPatchCustomization, _DataFeedPatchGenerated):
    pass


class _AzureApplicationInsightsDataFeedPatchGenerated(_DataFeedPatchGenerated):
    """AzureApplicationInsightsDataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter:
    :vartype data_source_parameter:
     ~azure.ai.metricsadvisor.models.AzureApplicationInsightsParameterPatch
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureApplicationInsightsParameterPatch'},
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        data_source_parameter: Optional["AzureApplicationInsightsParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter:
        :paramtype data_source_parameter:
         ~azure.ai.metricsadvisor.models.AzureApplicationInsightsParameterPatch
        """
        super(_AzureApplicationInsightsDataFeedPatchGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, status=status, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureApplicationInsights'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureApplicationInsightsDataFeedPatch(AzureApplicationInsightsDataFeedPatchCustomization, DataFeedPatch, _AzureApplicationInsightsDataFeedPatchGenerated):
    pass


class _AzureApplicationInsightsParameterGenerated(msrest.serialization.Model):
    """AzureApplicationInsightsParameter.

    All required parameters must be populated in order to send to Azure.

    :ivar azure_cloud: The Azure cloud that this Azure Application Insights in.
    :vartype azure_cloud: str
    :ivar application_id: The application id of this Azure Application Insights.
    :vartype application_id: str
    :ivar api_key: The API Key that can access this Azure Application Insights.
    :vartype api_key: str
    :ivar query: Required. The statement to query this Azure Application Insights.
    :vartype query: str
    """

    _validation = {
        'query': {'required': True},
    }

    _attribute_map = {
        'azure_cloud': {'key': 'azureCloud', 'type': 'str'},
        'application_id': {'key': 'applicationId', 'type': 'str'},
        'api_key': {'key': 'apiKey', 'type': 'str'},
        'query': {'key': 'query', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        query: str,
        azure_cloud: Optional[str] = None,
        application_id: Optional[str] = None,
        api_key: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword azure_cloud: The Azure cloud that this Azure Application Insights in.
        :paramtype azure_cloud: str
        :keyword application_id: The application id of this Azure Application Insights.
        :paramtype application_id: str
        :keyword api_key: The API Key that can access this Azure Application Insights.
        :paramtype api_key: str
        :keyword query: Required. The statement to query this Azure Application Insights.
        :paramtype query: str
        """
        super(_AzureApplicationInsightsParameterGenerated, self).__init__(**kwargs)
        self.azure_cloud = azure_cloud
        self.application_id = application_id
        self.api_key = api_key
        self.query = query

class AzureApplicationInsightsParameter(AzureApplicationInsightsParameterCustomization, _AzureApplicationInsightsParameterGenerated):
    pass


class _AzureApplicationInsightsParameterPatchGenerated(msrest.serialization.Model):
    """AzureApplicationInsightsParameterPatch.

    :ivar azure_cloud: The Azure cloud that this Azure Application Insights in.
    :vartype azure_cloud: str
    :ivar application_id: The application id of this Azure Application Insights.
    :vartype application_id: str
    :ivar api_key: The API Key that can access this Azure Application Insights.
    :vartype api_key: str
    :ivar query: The statement to query this Azure Application Insights.
    :vartype query: str
    """

    _attribute_map = {
        'azure_cloud': {'key': 'azureCloud', 'type': 'str'},
        'application_id': {'key': 'applicationId', 'type': 'str'},
        'api_key': {'key': 'apiKey', 'type': 'str'},
        'query': {'key': 'query', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        azure_cloud: Optional[str] = None,
        application_id: Optional[str] = None,
        api_key: Optional[str] = None,
        query: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword azure_cloud: The Azure cloud that this Azure Application Insights in.
        :paramtype azure_cloud: str
        :keyword application_id: The application id of this Azure Application Insights.
        :paramtype application_id: str
        :keyword api_key: The API Key that can access this Azure Application Insights.
        :paramtype api_key: str
        :keyword query: The statement to query this Azure Application Insights.
        :paramtype query: str
        """
        super(_AzureApplicationInsightsParameterPatchGenerated, self).__init__(**kwargs)
        self.azure_cloud = azure_cloud
        self.application_id = application_id
        self.api_key = api_key
        self.query = query

class AzureApplicationInsightsParameterPatch(AzureApplicationInsightsParameterPatchCustomization, _AzureApplicationInsightsParameterPatchGenerated):
    pass


class _AzureBlobDataFeedGenerated(_DataFeedGenerated):
    """AzureBlobDataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter: Required.
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureBlobParameter
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
        'data_source_parameter': {'required': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureBlobParameter'},
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_source_parameter: "AzureBlobParameter",
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter: Required.
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureBlobParameter
        """
        super(_AzureBlobDataFeedGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, granularity_name=granularity_name, granularity_amount=granularity_amount, metrics=metrics, dimension=dimension, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureBlob'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureBlobDataFeed(AzureBlobDataFeedCustomization, DataFeed, _AzureBlobDataFeedGenerated):
    pass


class _AzureBlobDataFeedPatchGenerated(_DataFeedPatchGenerated):
    """AzureBlobDataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter:
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureBlobParameterPatch
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureBlobParameterPatch'},
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        data_source_parameter: Optional["AzureBlobParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter:
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureBlobParameterPatch
        """
        super(_AzureBlobDataFeedPatchGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, status=status, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureBlob'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureBlobDataFeedPatch(AzureBlobDataFeedPatchCustomization, DataFeedPatch, _AzureBlobDataFeedPatchGenerated):
    pass


class _AzureBlobParameterGenerated(msrest.serialization.Model):
    """AzureBlobParameter.

    All required parameters must be populated in order to send to Azure.

    :ivar connection_string: The connection string of this Azure Blob.
    :vartype connection_string: str
    :ivar container: Required. The container name in this Azure Blob.
    :vartype container: str
    :ivar blob_template: Required. The path template in this container.
    :vartype blob_template: str
    """

    _validation = {
        'container': {'required': True},
        'blob_template': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'container': {'key': 'container', 'type': 'str'},
        'blob_template': {'key': 'blobTemplate', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        container: str,
        blob_template: str,
        connection_string: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this Azure Blob.
        :paramtype connection_string: str
        :keyword container: Required. The container name in this Azure Blob.
        :paramtype container: str
        :keyword blob_template: Required. The path template in this container.
        :paramtype blob_template: str
        """
        super(_AzureBlobParameterGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.container = container
        self.blob_template = blob_template

class AzureBlobParameter(AzureBlobParameterCustomization, _AzureBlobParameterGenerated):
    pass


class _AzureBlobParameterPatchGenerated(msrest.serialization.Model):
    """AzureBlobParameterPatch.

    :ivar connection_string: The connection string of this Azure Blob.
    :vartype connection_string: str
    :ivar container: The container name in this Azure Blob.
    :vartype container: str
    :ivar blob_template: The path template in this container.
    :vartype blob_template: str
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'container': {'key': 'container', 'type': 'str'},
        'blob_template': {'key': 'blobTemplate', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional[str] = None,
        container: Optional[str] = None,
        blob_template: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this Azure Blob.
        :paramtype connection_string: str
        :keyword container: The container name in this Azure Blob.
        :paramtype container: str
        :keyword blob_template: The path template in this container.
        :paramtype blob_template: str
        """
        super(_AzureBlobParameterPatchGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.container = container
        self.blob_template = blob_template

class AzureBlobParameterPatch(AzureBlobParameterPatchCustomization, _AzureBlobParameterPatchGenerated):
    pass


class _AzureCosmosDBDataFeedGenerated(_DataFeedGenerated):
    """AzureCosmosDBDataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter: Required.
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureCosmosDBParameter
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
        'data_source_parameter': {'required': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureCosmosDBParameter'},
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_source_parameter: "AzureCosmosDBParameter",
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter: Required.
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureCosmosDBParameter
        """
        super(_AzureCosmosDBDataFeedGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, granularity_name=granularity_name, granularity_amount=granularity_amount, metrics=metrics, dimension=dimension, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureCosmosDB'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureCosmosDBDataFeed(AzureCosmosDBDataFeedCustomization, DataFeed, _AzureCosmosDBDataFeedGenerated):
    pass


class _AzureCosmosDBDataFeedPatchGenerated(_DataFeedPatchGenerated):
    """AzureCosmosDBDataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter:
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureCosmosDBParameterPatch
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureCosmosDBParameterPatch'},
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        data_source_parameter: Optional["AzureCosmosDBParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter:
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureCosmosDBParameterPatch
        """
        super(_AzureCosmosDBDataFeedPatchGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, status=status, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureCosmosDB'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureCosmosDBDataFeedPatch(AzureCosmosDBDataFeedPatchCustomization, DataFeedPatch, _AzureCosmosDBDataFeedPatchGenerated):
    pass


class _AzureCosmosDBParameterGenerated(msrest.serialization.Model):
    """AzureCosmosDBParameter.

    All required parameters must be populated in order to send to Azure.

    :ivar connection_string: The connection string of this Azure CosmosDB.
    :vartype connection_string: str
    :ivar sql_query: Required. The statement to query this collection.
    :vartype sql_query: str
    :ivar database: Required. A database name in this Azure CosmosDB.
    :vartype database: str
    :ivar collection_id: Required. A collection id in this database.
    :vartype collection_id: str
    """

    _validation = {
        'sql_query': {'required': True},
        'database': {'required': True},
        'collection_id': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'sql_query': {'key': 'sqlQuery', 'type': 'str'},
        'database': {'key': 'database', 'type': 'str'},
        'collection_id': {'key': 'collectionId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        sql_query: str,
        database: str,
        collection_id: str,
        connection_string: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this Azure CosmosDB.
        :paramtype connection_string: str
        :keyword sql_query: Required. The statement to query this collection.
        :paramtype sql_query: str
        :keyword database: Required. A database name in this Azure CosmosDB.
        :paramtype database: str
        :keyword collection_id: Required. A collection id in this database.
        :paramtype collection_id: str
        """
        super(_AzureCosmosDBParameterGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.sql_query = sql_query
        self.database = database
        self.collection_id = collection_id

class AzureCosmosDBParameter(AzureCosmosDBParameterCustomization, _AzureCosmosDBParameterGenerated):
    pass


class _AzureCosmosDBParameterPatchGenerated(msrest.serialization.Model):
    """AzureCosmosDBParameterPatch.

    :ivar connection_string: The connection string of this Azure CosmosDB.
    :vartype connection_string: str
    :ivar sql_query: The statement to query this collection.
    :vartype sql_query: str
    :ivar database: A database name in this Azure CosmosDB.
    :vartype database: str
    :ivar collection_id: A collection id in this database.
    :vartype collection_id: str
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'sql_query': {'key': 'sqlQuery', 'type': 'str'},
        'database': {'key': 'database', 'type': 'str'},
        'collection_id': {'key': 'collectionId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional[str] = None,
        sql_query: Optional[str] = None,
        database: Optional[str] = None,
        collection_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this Azure CosmosDB.
        :paramtype connection_string: str
        :keyword sql_query: The statement to query this collection.
        :paramtype sql_query: str
        :keyword database: A database name in this Azure CosmosDB.
        :paramtype database: str
        :keyword collection_id: A collection id in this database.
        :paramtype collection_id: str
        """
        super(_AzureCosmosDBParameterPatchGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.sql_query = sql_query
        self.database = database
        self.collection_id = collection_id

class AzureCosmosDBParameterPatch(AzureCosmosDBParameterPatchCustomization, _AzureCosmosDBParameterPatchGenerated):
    pass


class _AzureDataExplorerDataFeedGenerated(_DataFeedGenerated):
    """AzureDataExplorerDataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter: Required.
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.SqlSourceParameter
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
        'data_source_parameter': {'required': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'SqlSourceParameter'},
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_source_parameter: "SqlSourceParameter",
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter: Required.
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.SqlSourceParameter
        """
        super(_AzureDataExplorerDataFeedGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, granularity_name=granularity_name, granularity_amount=granularity_amount, metrics=metrics, dimension=dimension, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureDataExplorer'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureDataExplorerDataFeed(AzureDataExplorerDataFeedCustomization, DataFeed, _AzureDataExplorerDataFeedGenerated):
    pass


class _AzureDataExplorerDataFeedPatchGenerated(_DataFeedPatchGenerated):
    """AzureDataExplorerDataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter:
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.SQLSourceParameterPatch
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'SQLSourceParameterPatch'},
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        data_source_parameter: Optional["SQLSourceParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter:
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.SQLSourceParameterPatch
        """
        super(_AzureDataExplorerDataFeedPatchGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, status=status, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureDataExplorer'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureDataExplorerDataFeedPatch(AzureDataExplorerDataFeedPatchCustomization, DataFeedPatch, _AzureDataExplorerDataFeedPatchGenerated):
    pass


class _AzureDataLakeStorageGen2DataFeedGenerated(_DataFeedGenerated):
    """AzureDataLakeStorageGen2DataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter: Required.
    :vartype data_source_parameter:
     ~azure.ai.metricsadvisor.models.AzureDataLakeStorageGen2Parameter
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
        'data_source_parameter': {'required': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureDataLakeStorageGen2Parameter'},
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_source_parameter: "AzureDataLakeStorageGen2Parameter",
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter: Required.
        :paramtype data_source_parameter:
         ~azure.ai.metricsadvisor.models.AzureDataLakeStorageGen2Parameter
        """
        super(_AzureDataLakeStorageGen2DataFeedGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, granularity_name=granularity_name, granularity_amount=granularity_amount, metrics=metrics, dimension=dimension, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureDataLakeStorageGen2'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureDataLakeStorageGen2DataFeed(AzureDataLakeStorageGen2DataFeedCustomization, DataFeed, _AzureDataLakeStorageGen2DataFeedGenerated):
    pass


class _AzureDataLakeStorageGen2DataFeedPatchGenerated(_DataFeedPatchGenerated):
    """AzureDataLakeStorageGen2DataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter:
    :vartype data_source_parameter:
     ~azure.ai.metricsadvisor.models.AzureDataLakeStorageGen2ParameterPatch
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureDataLakeStorageGen2ParameterPatch'},
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        data_source_parameter: Optional["AzureDataLakeStorageGen2ParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter:
        :paramtype data_source_parameter:
         ~azure.ai.metricsadvisor.models.AzureDataLakeStorageGen2ParameterPatch
        """
        super(_AzureDataLakeStorageGen2DataFeedPatchGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, status=status, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureDataLakeStorageGen2'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureDataLakeStorageGen2DataFeedPatch(AzureDataLakeStorageGen2DataFeedPatchCustomization, DataFeedPatch, _AzureDataLakeStorageGen2DataFeedPatchGenerated):
    pass


class _AzureDataLakeStorageGen2ParameterGenerated(msrest.serialization.Model):
    """AzureDataLakeStorageGen2Parameter.

    All required parameters must be populated in order to send to Azure.

    :ivar account_name: The account name of this Azure Data Lake.
    :vartype account_name: str
    :ivar account_key: The account key that can access this Azure Data Lake.
    :vartype account_key: str
    :ivar file_system_name: Required. The file system (container) name in this Azure Data Lake.
    :vartype file_system_name: str
    :ivar directory_template: Required. The directory template under this file system.
    :vartype directory_template: str
    :ivar file_template: Required. The file template.
    :vartype file_template: str
    """

    _validation = {
        'file_system_name': {'required': True},
        'directory_template': {'required': True},
        'file_template': {'required': True},
    }

    _attribute_map = {
        'account_name': {'key': 'accountName', 'type': 'str'},
        'account_key': {'key': 'accountKey', 'type': 'str'},
        'file_system_name': {'key': 'fileSystemName', 'type': 'str'},
        'directory_template': {'key': 'directoryTemplate', 'type': 'str'},
        'file_template': {'key': 'fileTemplate', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        file_system_name: str,
        directory_template: str,
        file_template: str,
        account_name: Optional[str] = None,
        account_key: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword account_name: The account name of this Azure Data Lake.
        :paramtype account_name: str
        :keyword account_key: The account key that can access this Azure Data Lake.
        :paramtype account_key: str
        :keyword file_system_name: Required. The file system (container) name in this Azure Data Lake.
        :paramtype file_system_name: str
        :keyword directory_template: Required. The directory template under this file system.
        :paramtype directory_template: str
        :keyword file_template: Required. The file template.
        :paramtype file_template: str
        """
        super(_AzureDataLakeStorageGen2ParameterGenerated, self).__init__(**kwargs)
        self.account_name = account_name
        self.account_key = account_key
        self.file_system_name = file_system_name
        self.directory_template = directory_template
        self.file_template = file_template

class AzureDataLakeStorageGen2Parameter(AzureDataLakeStorageGen2ParameterCustomization, _AzureDataLakeStorageGen2ParameterGenerated):
    pass


class _AzureDataLakeStorageGen2ParameterPatchGenerated(msrest.serialization.Model):
    """AzureDataLakeStorageGen2ParameterPatch.

    :ivar account_name: The account name of this Azure Data Lake.
    :vartype account_name: str
    :ivar account_key: The account key that can access this Azure Data Lake.
    :vartype account_key: str
    :ivar file_system_name: The file system (container) name in this Azure Data Lake.
    :vartype file_system_name: str
    :ivar directory_template: The directory template under this file system.
    :vartype directory_template: str
    :ivar file_template: The file template.
    :vartype file_template: str
    """

    _attribute_map = {
        'account_name': {'key': 'accountName', 'type': 'str'},
        'account_key': {'key': 'accountKey', 'type': 'str'},
        'file_system_name': {'key': 'fileSystemName', 'type': 'str'},
        'directory_template': {'key': 'directoryTemplate', 'type': 'str'},
        'file_template': {'key': 'fileTemplate', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        account_name: Optional[str] = None,
        account_key: Optional[str] = None,
        file_system_name: Optional[str] = None,
        directory_template: Optional[str] = None,
        file_template: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword account_name: The account name of this Azure Data Lake.
        :paramtype account_name: str
        :keyword account_key: The account key that can access this Azure Data Lake.
        :paramtype account_key: str
        :keyword file_system_name: The file system (container) name in this Azure Data Lake.
        :paramtype file_system_name: str
        :keyword directory_template: The directory template under this file system.
        :paramtype directory_template: str
        :keyword file_template: The file template.
        :paramtype file_template: str
        """
        super(_AzureDataLakeStorageGen2ParameterPatchGenerated, self).__init__(**kwargs)
        self.account_name = account_name
        self.account_key = account_key
        self.file_system_name = file_system_name
        self.directory_template = directory_template
        self.file_template = file_template

class AzureDataLakeStorageGen2ParameterPatch(AzureDataLakeStorageGen2ParameterPatchCustomization, _AzureDataLakeStorageGen2ParameterPatchGenerated):
    pass


class _AzureEventHubsDataFeedGenerated(_DataFeedGenerated):
    """AzureEventHubsDataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter: Required.
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureEventHubsParameter
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
        'data_source_parameter': {'required': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureEventHubsParameter'},
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_source_parameter: "AzureEventHubsParameter",
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter: Required.
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureEventHubsParameter
        """
        super(_AzureEventHubsDataFeedGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, granularity_name=granularity_name, granularity_amount=granularity_amount, metrics=metrics, dimension=dimension, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureEventHubs'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureEventHubsDataFeed(AzureEventHubsDataFeedCustomization, DataFeed, _AzureEventHubsDataFeedGenerated):
    pass


class _AzureEventHubsDataFeedPatchGenerated(_DataFeedPatchGenerated):
    """AzureEventHubsDataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter:
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureEventHubsParameterPatch
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureEventHubsParameterPatch'},
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        data_source_parameter: Optional["AzureEventHubsParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter:
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureEventHubsParameterPatch
        """
        super(_AzureEventHubsDataFeedPatchGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, status=status, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureEventHubs'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureEventHubsDataFeedPatch(AzureEventHubsDataFeedPatchCustomization, DataFeedPatch, _AzureEventHubsDataFeedPatchGenerated):
    pass


class _AzureEventHubsParameterGenerated(msrest.serialization.Model):
    """AzureEventHubsParameter.

    All required parameters must be populated in order to send to Azure.

    :ivar connection_string: The connection string of this Azure Event Hubs.
    :vartype connection_string: str
    :ivar consumer_group: Required. The consumer group to be used in this data feed.
    :vartype consumer_group: str
    """

    _validation = {
        'consumer_group': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'consumer_group': {'key': 'consumerGroup', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        consumer_group: str,
        connection_string: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this Azure Event Hubs.
        :paramtype connection_string: str
        :keyword consumer_group: Required. The consumer group to be used in this data feed.
        :paramtype consumer_group: str
        """
        super(_AzureEventHubsParameterGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.consumer_group = consumer_group

class AzureEventHubsParameter(AzureEventHubsParameterCustomization, _AzureEventHubsParameterGenerated):
    pass


class _AzureEventHubsParameterPatchGenerated(msrest.serialization.Model):
    """AzureEventHubsParameterPatch.

    :ivar connection_string: The connection string of this Azure Event Hubs.
    :vartype connection_string: str
    :ivar consumer_group: The consumer group to be used in this data feed.
    :vartype consumer_group: str
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'consumer_group': {'key': 'consumerGroup', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional[str] = None,
        consumer_group: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this Azure Event Hubs.
        :paramtype connection_string: str
        :keyword consumer_group: The consumer group to be used in this data feed.
        :paramtype consumer_group: str
        """
        super(_AzureEventHubsParameterPatchGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.consumer_group = consumer_group

class AzureEventHubsParameterPatch(AzureEventHubsParameterPatchCustomization, _AzureEventHubsParameterPatchGenerated):
    pass


class _AzureLogAnalyticsDataFeedGenerated(_DataFeedGenerated):
    """AzureLogAnalyticsDataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter: Required.
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureLogAnalyticsParameter
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
        'data_source_parameter': {'required': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureLogAnalyticsParameter'},
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_source_parameter: "AzureLogAnalyticsParameter",
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter: Required.
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureLogAnalyticsParameter
        """
        super(_AzureLogAnalyticsDataFeedGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, granularity_name=granularity_name, granularity_amount=granularity_amount, metrics=metrics, dimension=dimension, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureLogAnalytics'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureLogAnalyticsDataFeed(AzureLogAnalyticsDataFeedCustomization, DataFeed, _AzureLogAnalyticsDataFeedGenerated):
    pass


class _AzureLogAnalyticsDataFeedPatchGenerated(_DataFeedPatchGenerated):
    """AzureLogAnalyticsDataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter:
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureLogAnalyticsParameterPatch
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureLogAnalyticsParameterPatch'},
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        data_source_parameter: Optional["AzureLogAnalyticsParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter:
        :paramtype data_source_parameter:
         ~azure.ai.metricsadvisor.models.AzureLogAnalyticsParameterPatch
        """
        super(_AzureLogAnalyticsDataFeedPatchGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, status=status, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureLogAnalytics'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureLogAnalyticsDataFeedPatch(AzureLogAnalyticsDataFeedPatchCustomization, DataFeedPatch, _AzureLogAnalyticsDataFeedPatchGenerated):
    pass


class _AzureLogAnalyticsParameterGenerated(msrest.serialization.Model):
    """AzureLogAnalyticsParameter.

    All required parameters must be populated in order to send to Azure.

    :ivar tenant_id: The tenant id of service principal that have access to this Log Analytics.
    :vartype tenant_id: str
    :ivar client_id: The client id of service principal that have access to this Log Analytics.
    :vartype client_id: str
    :ivar client_secret: The client secret of service principal that have access to this Log
     Analytics.
    :vartype client_secret: str
    :ivar workspace_id: Required. The workspace id of this Log Analytics.
    :vartype workspace_id: str
    :ivar query: Required. The KQL (Kusto Query Language) query to fetch data from this Log
     Analytics.
    :vartype query: str
    """

    _validation = {
        'workspace_id': {'required': True},
        'query': {'required': True},
    }

    _attribute_map = {
        'tenant_id': {'key': 'tenantId', 'type': 'str'},
        'client_id': {'key': 'clientId', 'type': 'str'},
        'client_secret': {'key': 'clientSecret', 'type': 'str'},
        'workspace_id': {'key': 'workspaceId', 'type': 'str'},
        'query': {'key': 'query', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        workspace_id: str,
        query: str,
        tenant_id: Optional[str] = None,
        client_id: Optional[str] = None,
        client_secret: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword tenant_id: The tenant id of service principal that have access to this Log Analytics.
        :paramtype tenant_id: str
        :keyword client_id: The client id of service principal that have access to this Log Analytics.
        :paramtype client_id: str
        :keyword client_secret: The client secret of service principal that have access to this Log
         Analytics.
        :paramtype client_secret: str
        :keyword workspace_id: Required. The workspace id of this Log Analytics.
        :paramtype workspace_id: str
        :keyword query: Required. The KQL (Kusto Query Language) query to fetch data from this Log
         Analytics.
        :paramtype query: str
        """
        super(_AzureLogAnalyticsParameterGenerated, self).__init__(**kwargs)
        self.tenant_id = tenant_id
        self.client_id = client_id
        self.client_secret = client_secret
        self.workspace_id = workspace_id
        self.query = query

class AzureLogAnalyticsParameter(AzureLogAnalyticsParameterCustomization, _AzureLogAnalyticsParameterGenerated):
    pass


class _AzureLogAnalyticsParameterPatchGenerated(msrest.serialization.Model):
    """AzureLogAnalyticsParameterPatch.

    :ivar tenant_id: The tenant id of service principal that have access to this Log Analytics.
    :vartype tenant_id: str
    :ivar client_id: The client id of service principal that have access to this Log Analytics.
    :vartype client_id: str
    :ivar client_secret: The client secret of service principal that have access to this Log
     Analytics.
    :vartype client_secret: str
    :ivar workspace_id: The workspace id of this Log Analytics.
    :vartype workspace_id: str
    :ivar query: The KQL (Kusto Query Language) query to fetch data from this Log Analytics.
    :vartype query: str
    """

    _attribute_map = {
        'tenant_id': {'key': 'tenantId', 'type': 'str'},
        'client_id': {'key': 'clientId', 'type': 'str'},
        'client_secret': {'key': 'clientSecret', 'type': 'str'},
        'workspace_id': {'key': 'workspaceId', 'type': 'str'},
        'query': {'key': 'query', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        tenant_id: Optional[str] = None,
        client_id: Optional[str] = None,
        client_secret: Optional[str] = None,
        workspace_id: Optional[str] = None,
        query: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword tenant_id: The tenant id of service principal that have access to this Log Analytics.
        :paramtype tenant_id: str
        :keyword client_id: The client id of service principal that have access to this Log Analytics.
        :paramtype client_id: str
        :keyword client_secret: The client secret of service principal that have access to this Log
         Analytics.
        :paramtype client_secret: str
        :keyword workspace_id: The workspace id of this Log Analytics.
        :paramtype workspace_id: str
        :keyword query: The KQL (Kusto Query Language) query to fetch data from this Log Analytics.
        :paramtype query: str
        """
        super(_AzureLogAnalyticsParameterPatchGenerated, self).__init__(**kwargs)
        self.tenant_id = tenant_id
        self.client_id = client_id
        self.client_secret = client_secret
        self.workspace_id = workspace_id
        self.query = query

class AzureLogAnalyticsParameterPatch(AzureLogAnalyticsParameterPatchCustomization, _AzureLogAnalyticsParameterPatchGenerated):
    pass


class _DataSourceCredentialGenerated(msrest.serialization.Model):
    """DataSourceCredential.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AzureSQLConnectionStringCredential, DataLakeGen2SharedKeyCredential, ServicePrincipalCredential, ServicePrincipalInKVCredential.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_credential_type: Required. Type of data source credential.Constant filled by
     server. Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype data_source_credential_type: str or
     ~azure.ai.metricsadvisor.models.DataSourceCredentialType
    :ivar data_source_credential_id: Unique id of data source credential.
    :vartype data_source_credential_id: str
    :ivar data_source_credential_name: Required. Name of data source credential.
    :vartype data_source_credential_name: str
    :ivar data_source_credential_description: Description of data source credential.
    :vartype data_source_credential_description: str
    """

    _validation = {
        'data_source_credential_type': {'required': True},
        'data_source_credential_id': {'readonly': True},
        'data_source_credential_name': {'required': True},
    }

    _attribute_map = {
        'data_source_credential_type': {'key': 'dataSourceCredentialType', 'type': 'str'},
        'data_source_credential_id': {'key': 'dataSourceCredentialId', 'type': 'str'},
        'data_source_credential_name': {'key': 'dataSourceCredentialName', 'type': 'str'},
        'data_source_credential_description': {'key': 'dataSourceCredentialDescription', 'type': 'str'},
    }

    _subtype_map = {
        'data_source_credential_type': {'AzureSQLConnectionString': 'AzureSQLConnectionStringCredential', 'DataLakeGen2SharedKey': 'DataLakeGen2SharedKeyCredential', 'ServicePrincipal': 'ServicePrincipalCredential', 'ServicePrincipalInKV': 'ServicePrincipalInKVCredential'}
    }

    def __init__(
        self,
        *,
        data_source_credential_name: str,
        data_source_credential_description: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_source_credential_name: Required. Name of data source credential.
        :paramtype data_source_credential_name: str
        :keyword data_source_credential_description: Description of data source credential.
        :paramtype data_source_credential_description: str
        """
        super(_DataSourceCredentialGenerated, self).__init__(**kwargs)
        self.data_source_credential_type = None  # type: Optional[str]
        self.data_source_credential_id = None
        self.data_source_credential_name = data_source_credential_name
        self.data_source_credential_description = data_source_credential_description

class DataSourceCredential(DataSourceCredentialCustomization, _DataSourceCredentialGenerated):
    pass


class _AzureSQLConnectionStringCredentialGenerated(_DataSourceCredentialGenerated):
    """AzureSQLConnectionStringCredential.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_credential_type: Required. Type of data source credential.Constant filled by
     server. Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype data_source_credential_type: str or
     ~azure.ai.metricsadvisor.models.DataSourceCredentialType
    :ivar data_source_credential_id: Unique id of data source credential.
    :vartype data_source_credential_id: str
    :ivar data_source_credential_name: Required. Name of data source credential.
    :vartype data_source_credential_name: str
    :ivar data_source_credential_description: Description of data source credential.
    :vartype data_source_credential_description: str
    :ivar parameters: Required.
    :vartype parameters: ~azure.ai.metricsadvisor.models.AzureSQLConnectionStringParam
    """

    _validation = {
        'data_source_credential_type': {'required': True},
        'data_source_credential_id': {'readonly': True},
        'data_source_credential_name': {'required': True},
        'parameters': {'required': True},
    }

    _attribute_map = {
        'data_source_credential_type': {'key': 'dataSourceCredentialType', 'type': 'str'},
        'data_source_credential_id': {'key': 'dataSourceCredentialId', 'type': 'str'},
        'data_source_credential_name': {'key': 'dataSourceCredentialName', 'type': 'str'},
        'data_source_credential_description': {'key': 'dataSourceCredentialDescription', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': 'AzureSQLConnectionStringParam'},
    }

    def __init__(
        self,
        *,
        data_source_credential_name: str,
        parameters: "AzureSQLConnectionStringParam",
        data_source_credential_description: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_source_credential_name: Required. Name of data source credential.
        :paramtype data_source_credential_name: str
        :keyword data_source_credential_description: Description of data source credential.
        :paramtype data_source_credential_description: str
        :keyword parameters: Required.
        :paramtype parameters: ~azure.ai.metricsadvisor.models.AzureSQLConnectionStringParam
        """
        super(_AzureSQLConnectionStringCredentialGenerated, self).__init__(data_source_credential_name=data_source_credential_name, data_source_credential_description=data_source_credential_description, **kwargs)
        self.data_source_credential_type = 'AzureSQLConnectionString'  # type: str
        self.parameters = parameters

class AzureSQLConnectionStringCredential(AzureSQLConnectionStringCredentialCustomization, DataSourceCredential, _AzureSQLConnectionStringCredentialGenerated):
    pass


class _DataSourceCredentialPatchGenerated(msrest.serialization.Model):
    """DataSourceCredentialPatch.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: AzureSQLConnectionStringCredentialPatch, DataLakeGen2SharedKeyCredentialPatch, ServicePrincipalCredentialPatch, ServicePrincipalInKVCredentialPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_credential_type: Required. Type of data source credential.Constant filled by
     server. Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype data_source_credential_type: str or
     ~azure.ai.metricsadvisor.models.DataSourceCredentialType
    :ivar data_source_credential_name: Name of data source credential.
    :vartype data_source_credential_name: str
    :ivar data_source_credential_description: Description of data source credential.
    :vartype data_source_credential_description: str
    """

    _validation = {
        'data_source_credential_type': {'required': True},
    }

    _attribute_map = {
        'data_source_credential_type': {'key': 'dataSourceCredentialType', 'type': 'str'},
        'data_source_credential_name': {'key': 'dataSourceCredentialName', 'type': 'str'},
        'data_source_credential_description': {'key': 'dataSourceCredentialDescription', 'type': 'str'},
    }

    _subtype_map = {
        'data_source_credential_type': {'AzureSQLConnectionString': 'AzureSQLConnectionStringCredentialPatch', 'DataLakeGen2SharedKey': 'DataLakeGen2SharedKeyCredentialPatch', 'ServicePrincipal': 'ServicePrincipalCredentialPatch', 'ServicePrincipalInKV': 'ServicePrincipalInKVCredentialPatch'}
    }

    def __init__(
        self,
        *,
        data_source_credential_name: Optional[str] = None,
        data_source_credential_description: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_source_credential_name: Name of data source credential.
        :paramtype data_source_credential_name: str
        :keyword data_source_credential_description: Description of data source credential.
        :paramtype data_source_credential_description: str
        """
        super(_DataSourceCredentialPatchGenerated, self).__init__(**kwargs)
        self.data_source_credential_type = None  # type: Optional[str]
        self.data_source_credential_name = data_source_credential_name
        self.data_source_credential_description = data_source_credential_description

class DataSourceCredentialPatch(DataSourceCredentialPatchCustomization, _DataSourceCredentialPatchGenerated):
    pass


class _AzureSQLConnectionStringCredentialPatchGenerated(_DataSourceCredentialPatchGenerated):
    """AzureSQLConnectionStringCredentialPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_credential_type: Required. Type of data source credential.Constant filled by
     server. Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype data_source_credential_type: str or
     ~azure.ai.metricsadvisor.models.DataSourceCredentialType
    :ivar data_source_credential_name: Name of data source credential.
    :vartype data_source_credential_name: str
    :ivar data_source_credential_description: Description of data source credential.
    :vartype data_source_credential_description: str
    :ivar parameters:
    :vartype parameters: ~azure.ai.metricsadvisor.models.AzureSQLConnectionStringParamPatch
    """

    _validation = {
        'data_source_credential_type': {'required': True},
    }

    _attribute_map = {
        'data_source_credential_type': {'key': 'dataSourceCredentialType', 'type': 'str'},
        'data_source_credential_name': {'key': 'dataSourceCredentialName', 'type': 'str'},
        'data_source_credential_description': {'key': 'dataSourceCredentialDescription', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': 'AzureSQLConnectionStringParamPatch'},
    }

    def __init__(
        self,
        *,
        data_source_credential_name: Optional[str] = None,
        data_source_credential_description: Optional[str] = None,
        parameters: Optional["AzureSQLConnectionStringParamPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_source_credential_name: Name of data source credential.
        :paramtype data_source_credential_name: str
        :keyword data_source_credential_description: Description of data source credential.
        :paramtype data_source_credential_description: str
        :keyword parameters:
        :paramtype parameters: ~azure.ai.metricsadvisor.models.AzureSQLConnectionStringParamPatch
        """
        super(_AzureSQLConnectionStringCredentialPatchGenerated, self).__init__(data_source_credential_name=data_source_credential_name, data_source_credential_description=data_source_credential_description, **kwargs)
        self.data_source_credential_type = 'AzureSQLConnectionString'  # type: str
        self.parameters = parameters

class AzureSQLConnectionStringCredentialPatch(AzureSQLConnectionStringCredentialPatchCustomization, DataSourceCredentialPatch, _AzureSQLConnectionStringCredentialPatchGenerated):
    pass


class _AzureSQLConnectionStringParamGenerated(msrest.serialization.Model):
    """AzureSQLConnectionStringParam.

    :ivar connection_string: The connection string to access the Azure SQL.
    :vartype connection_string: str
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string to access the Azure SQL.
        :paramtype connection_string: str
        """
        super(_AzureSQLConnectionStringParamGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string

class AzureSQLConnectionStringParam(AzureSQLConnectionStringParamCustomization, _AzureSQLConnectionStringParamGenerated):
    pass


class _AzureSQLConnectionStringParamPatchGenerated(msrest.serialization.Model):
    """AzureSQLConnectionStringParamPatch.

    :ivar connection_string: The connection string to access the Azure SQL.
    :vartype connection_string: str
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string to access the Azure SQL.
        :paramtype connection_string: str
        """
        super(_AzureSQLConnectionStringParamPatchGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string

class AzureSQLConnectionStringParamPatch(AzureSQLConnectionStringParamPatchCustomization, _AzureSQLConnectionStringParamPatchGenerated):
    pass


class _AzureTableDataFeedGenerated(_DataFeedGenerated):
    """AzureTableDataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter: Required.
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureTableParameter
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
        'data_source_parameter': {'required': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureTableParameter'},
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_source_parameter: "AzureTableParameter",
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter: Required.
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureTableParameter
        """
        super(_AzureTableDataFeedGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, granularity_name=granularity_name, granularity_amount=granularity_amount, metrics=metrics, dimension=dimension, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureTable'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureTableDataFeed(AzureTableDataFeedCustomization, DataFeed, _AzureTableDataFeedGenerated):
    pass


class _AzureTableDataFeedPatchGenerated(_DataFeedPatchGenerated):
    """AzureTableDataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter:
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureTableParameterPatch
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'AzureTableParameterPatch'},
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        data_source_parameter: Optional["AzureTableParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter:
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.AzureTableParameterPatch
        """
        super(_AzureTableDataFeedPatchGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, status=status, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'AzureTable'  # type: str
        self.data_source_parameter = data_source_parameter

class AzureTableDataFeedPatch(AzureTableDataFeedPatchCustomization, DataFeedPatch, _AzureTableDataFeedPatchGenerated):
    pass


class _AzureTableParameterGenerated(msrest.serialization.Model):
    """AzureTableParameter.

    All required parameters must be populated in order to send to Azure.

    :ivar connection_string: The connection string of this Azure Table.
    :vartype connection_string: str
    :ivar table: Required. A table name in this Azure Table.
    :vartype table: str
    :ivar query: Required. The statement to query this table. Please find syntax and details from
     Azure Table documents.
    :vartype query: str
    """

    _validation = {
        'table': {'required': True},
        'query': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'table': {'key': 'table', 'type': 'str'},
        'query': {'key': 'query', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        table: str,
        query: str,
        connection_string: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this Azure Table.
        :paramtype connection_string: str
        :keyword table: Required. A table name in this Azure Table.
        :paramtype table: str
        :keyword query: Required. The statement to query this table. Please find syntax and details
         from Azure Table documents.
        :paramtype query: str
        """
        super(_AzureTableParameterGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.table = table
        self.query = query

class AzureTableParameter(AzureTableParameterCustomization, _AzureTableParameterGenerated):
    pass


class _AzureTableParameterPatchGenerated(msrest.serialization.Model):
    """AzureTableParameterPatch.

    :ivar connection_string: The connection string of this Azure Table.
    :vartype connection_string: str
    :ivar table: A table name in this Azure Table.
    :vartype table: str
    :ivar query: The statement to query this table. Please find syntax and details from Azure Table
     documents.
    :vartype query: str
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'table': {'key': 'table', 'type': 'str'},
        'query': {'key': 'query', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional[str] = None,
        table: Optional[str] = None,
        query: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this Azure Table.
        :paramtype connection_string: str
        :keyword table: A table name in this Azure Table.
        :paramtype table: str
        :keyword query: The statement to query this table. Please find syntax and details from Azure
         Table documents.
        :paramtype query: str
        """
        super(_AzureTableParameterPatchGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.table = table
        self.query = query

class AzureTableParameterPatch(AzureTableParameterPatchCustomization, _AzureTableParameterPatchGenerated):
    pass


class _ChangePointFeedbackValueGenerated(msrest.serialization.Model):
    """ChangePointFeedbackValue.

    All required parameters must be populated in order to send to Azure.

    :ivar change_point_value: Required. Possible values include: "AutoDetect", "ChangePoint",
     "NotChangePoint".
    :vartype change_point_value: str or ~azure.ai.metricsadvisor.models.ChangePointValue
    """

    _validation = {
        'change_point_value': {'required': True},
    }

    _attribute_map = {
        'change_point_value': {'key': 'changePointValue', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        change_point_value: Union[str, "ChangePointValue"],
        **kwargs
    ):
        """
        :keyword change_point_value: Required. Possible values include: "AutoDetect", "ChangePoint",
         "NotChangePoint".
        :paramtype change_point_value: str or ~azure.ai.metricsadvisor.models.ChangePointValue
        """
        super(_ChangePointFeedbackValueGenerated, self).__init__(**kwargs)
        self.change_point_value = change_point_value

class ChangePointFeedbackValue(ChangePointFeedbackValueCustomization, _ChangePointFeedbackValueGenerated):
    pass


class _ChangeThresholdConditionGenerated(msrest.serialization.Model):
    """ChangeThresholdCondition.

    All required parameters must be populated in order to send to Azure.

    :ivar change_percentage: Required. change percentage, value range : [0, +∞).
    :vartype change_percentage: float
    :ivar shift_point: Required. shift point, value range : [1, +∞).
    :vartype shift_point: int
    :ivar within_range: Required. if the withinRange = true, detected data is abnormal when the
     value falls in the range, in this case anomalyDetectorDirection must be Both
     if the withinRange = false, detected data is abnormal when the value falls out of the range.
    :vartype within_range: bool
    :ivar anomaly_detector_direction: Required. detection direction. Possible values include:
     "Both", "Down", "Up".
    :vartype anomaly_detector_direction: str or
     ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
    :ivar suppress_condition: Required.
    :vartype suppress_condition: ~azure.ai.metricsadvisor.models.SuppressCondition
    """

    _validation = {
        'change_percentage': {'required': True},
        'shift_point': {'required': True},
        'within_range': {'required': True},
        'anomaly_detector_direction': {'required': True},
        'suppress_condition': {'required': True},
    }

    _attribute_map = {
        'change_percentage': {'key': 'changePercentage', 'type': 'float'},
        'shift_point': {'key': 'shiftPoint', 'type': 'int'},
        'within_range': {'key': 'withinRange', 'type': 'bool'},
        'anomaly_detector_direction': {'key': 'anomalyDetectorDirection', 'type': 'str'},
        'suppress_condition': {'key': 'suppressCondition', 'type': 'SuppressCondition'},
    }

    def __init__(
        self,
        *,
        change_percentage: float,
        shift_point: int,
        within_range: bool,
        anomaly_detector_direction: Union[str, "AnomalyDetectorDirection"],
        suppress_condition: "SuppressCondition",
        **kwargs
    ):
        """
        :keyword change_percentage: Required. change percentage, value range : [0, +∞).
        :paramtype change_percentage: float
        :keyword shift_point: Required. shift point, value range : [1, +∞).
        :paramtype shift_point: int
        :keyword within_range: Required. if the withinRange = true, detected data is abnormal when the
         value falls in the range, in this case anomalyDetectorDirection must be Both
         if the withinRange = false, detected data is abnormal when the value falls out of the range.
        :paramtype within_range: bool
        :keyword anomaly_detector_direction: Required. detection direction. Possible values include:
         "Both", "Down", "Up".
        :paramtype anomaly_detector_direction: str or
         ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
        :keyword suppress_condition: Required.
        :paramtype suppress_condition: ~azure.ai.metricsadvisor.models.SuppressCondition
        """
        super(_ChangeThresholdConditionGenerated, self).__init__(**kwargs)
        self.change_percentage = change_percentage
        self.shift_point = shift_point
        self.within_range = within_range
        self.anomaly_detector_direction = anomaly_detector_direction
        self.suppress_condition = suppress_condition

class ChangeThresholdCondition(ChangeThresholdConditionCustomization, _ChangeThresholdConditionGenerated):
    pass


class _ChangeThresholdConditionPatchGenerated(msrest.serialization.Model):
    """ChangeThresholdConditionPatch.

    :ivar change_percentage: change percentage, value range : [0, +∞).
    :vartype change_percentage: float
    :ivar shift_point: shift point, value range : [1, +∞).
    :vartype shift_point: int
    :ivar within_range: if the withinRange = true, detected data is abnormal when the value falls
     in the range, in this case anomalyDetectorDirection must be Both
     if the withinRange = false, detected data is abnormal when the value falls out of the range.
    :vartype within_range: bool
    :ivar anomaly_detector_direction: detection direction. Possible values include: "Both", "Down",
     "Up".
    :vartype anomaly_detector_direction: str or
     ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
    :ivar suppress_condition:
    :vartype suppress_condition: ~azure.ai.metricsadvisor.models.SuppressConditionPatch
    """

    _attribute_map = {
        'change_percentage': {'key': 'changePercentage', 'type': 'float'},
        'shift_point': {'key': 'shiftPoint', 'type': 'int'},
        'within_range': {'key': 'withinRange', 'type': 'bool'},
        'anomaly_detector_direction': {'key': 'anomalyDetectorDirection', 'type': 'str'},
        'suppress_condition': {'key': 'suppressCondition', 'type': 'SuppressConditionPatch'},
    }

    def __init__(
        self,
        *,
        change_percentage: Optional[float] = None,
        shift_point: Optional[int] = None,
        within_range: Optional[bool] = None,
        anomaly_detector_direction: Optional[Union[str, "AnomalyDetectorDirection"]] = None,
        suppress_condition: Optional["SuppressConditionPatch"] = None,
        **kwargs
    ):
        """
        :keyword change_percentage: change percentage, value range : [0, +∞).
        :paramtype change_percentage: float
        :keyword shift_point: shift point, value range : [1, +∞).
        :paramtype shift_point: int
        :keyword within_range: if the withinRange = true, detected data is abnormal when the value
         falls in the range, in this case anomalyDetectorDirection must be Both
         if the withinRange = false, detected data is abnormal when the value falls out of the range.
        :paramtype within_range: bool
        :keyword anomaly_detector_direction: detection direction. Possible values include: "Both",
         "Down", "Up".
        :paramtype anomaly_detector_direction: str or
         ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
        :keyword suppress_condition:
        :paramtype suppress_condition: ~azure.ai.metricsadvisor.models.SuppressConditionPatch
        """
        super(_ChangeThresholdConditionPatchGenerated, self).__init__(**kwargs)
        self.change_percentage = change_percentage
        self.shift_point = shift_point
        self.within_range = within_range
        self.anomaly_detector_direction = anomaly_detector_direction
        self.suppress_condition = suppress_condition

class ChangeThresholdConditionPatch(ChangeThresholdConditionPatchCustomization, _ChangeThresholdConditionPatchGenerated):
    pass


class _CommentFeedbackValueGenerated(msrest.serialization.Model):
    """CommentFeedbackValue.

    All required parameters must be populated in order to send to Azure.

    :ivar comment_value: Required. the comment string.
    :vartype comment_value: str
    """

    _validation = {
        'comment_value': {'required': True},
    }

    _attribute_map = {
        'comment_value': {'key': 'commentValue', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        comment_value: str,
        **kwargs
    ):
        """
        :keyword comment_value: Required. the comment string.
        :paramtype comment_value: str
        """
        super(_CommentFeedbackValueGenerated, self).__init__(**kwargs)
        self.comment_value = comment_value

class CommentFeedbackValue(CommentFeedbackValueCustomization, _CommentFeedbackValueGenerated):
    pass


class _DataFeedIngestionProgressGenerated(msrest.serialization.Model):
    """DataFeedIngestionProgress.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar latest_success_timestamp: the timestamp of latest success ingestion job.
     null indicates not available.
    :vartype latest_success_timestamp: ~datetime.datetime
    :ivar latest_active_timestamp: the timestamp of latest ingestion job with status update.
     null indicates not available.
    :vartype latest_active_timestamp: ~datetime.datetime
    """

    _validation = {
        'latest_success_timestamp': {'readonly': True},
        'latest_active_timestamp': {'readonly': True},
    }

    _attribute_map = {
        'latest_success_timestamp': {'key': 'latestSuccessTimestamp', 'type': 'iso-8601'},
        'latest_active_timestamp': {'key': 'latestActiveTimestamp', 'type': 'iso-8601'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_DataFeedIngestionProgressGenerated, self).__init__(**kwargs)
        self.latest_success_timestamp = None
        self.latest_active_timestamp = None

class DataFeedIngestionProgress(DataFeedIngestionProgressCustomization, _DataFeedIngestionProgressGenerated):
    pass


class _DataFeedListGenerated(msrest.serialization.Model):
    """DataFeedList.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar next_link:
    :vartype next_link: str
    :ivar value:
    :vartype value: list[~azure.ai.metricsadvisor.models.DataFeed]
    """

    _validation = {
        'next_link': {'readonly': True},
        'value': {'readonly': True},
    }

    _attribute_map = {
        'next_link': {'key': '@nextLink', 'type': 'str'},
        'value': {'key': 'value', 'type': '[DataFeed]'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_DataFeedListGenerated, self).__init__(**kwargs)
        self.next_link = None
        self.value = None

class DataFeedList(DataFeedListCustomization, _DataFeedListGenerated):
    pass


class _DataLakeGen2SharedKeyCredentialGenerated(_DataSourceCredentialGenerated):
    """DataLakeGen2SharedKeyCredential.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_credential_type: Required. Type of data source credential.Constant filled by
     server. Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype data_source_credential_type: str or
     ~azure.ai.metricsadvisor.models.DataSourceCredentialType
    :ivar data_source_credential_id: Unique id of data source credential.
    :vartype data_source_credential_id: str
    :ivar data_source_credential_name: Required. Name of data source credential.
    :vartype data_source_credential_name: str
    :ivar data_source_credential_description: Description of data source credential.
    :vartype data_source_credential_description: str
    :ivar parameters: Required.
    :vartype parameters: ~azure.ai.metricsadvisor.models.DataLakeGen2SharedKeyParam
    """

    _validation = {
        'data_source_credential_type': {'required': True},
        'data_source_credential_id': {'readonly': True},
        'data_source_credential_name': {'required': True},
        'parameters': {'required': True},
    }

    _attribute_map = {
        'data_source_credential_type': {'key': 'dataSourceCredentialType', 'type': 'str'},
        'data_source_credential_id': {'key': 'dataSourceCredentialId', 'type': 'str'},
        'data_source_credential_name': {'key': 'dataSourceCredentialName', 'type': 'str'},
        'data_source_credential_description': {'key': 'dataSourceCredentialDescription', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': 'DataLakeGen2SharedKeyParam'},
    }

    def __init__(
        self,
        *,
        data_source_credential_name: str,
        parameters: "DataLakeGen2SharedKeyParam",
        data_source_credential_description: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_source_credential_name: Required. Name of data source credential.
        :paramtype data_source_credential_name: str
        :keyword data_source_credential_description: Description of data source credential.
        :paramtype data_source_credential_description: str
        :keyword parameters: Required.
        :paramtype parameters: ~azure.ai.metricsadvisor.models.DataLakeGen2SharedKeyParam
        """
        super(_DataLakeGen2SharedKeyCredentialGenerated, self).__init__(data_source_credential_name=data_source_credential_name, data_source_credential_description=data_source_credential_description, **kwargs)
        self.data_source_credential_type = 'DataLakeGen2SharedKey'  # type: str
        self.parameters = parameters

class DataLakeGen2SharedKeyCredential(DataLakeGen2SharedKeyCredentialCustomization, DataSourceCredential, _DataLakeGen2SharedKeyCredentialGenerated):
    pass


class _DataLakeGen2SharedKeyCredentialPatchGenerated(_DataSourceCredentialPatchGenerated):
    """DataLakeGen2SharedKeyCredentialPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_credential_type: Required. Type of data source credential.Constant filled by
     server. Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype data_source_credential_type: str or
     ~azure.ai.metricsadvisor.models.DataSourceCredentialType
    :ivar data_source_credential_name: Name of data source credential.
    :vartype data_source_credential_name: str
    :ivar data_source_credential_description: Description of data source credential.
    :vartype data_source_credential_description: str
    :ivar parameters:
    :vartype parameters: ~azure.ai.metricsadvisor.models.DataLakeGen2SharedKeyParamPatch
    """

    _validation = {
        'data_source_credential_type': {'required': True},
    }

    _attribute_map = {
        'data_source_credential_type': {'key': 'dataSourceCredentialType', 'type': 'str'},
        'data_source_credential_name': {'key': 'dataSourceCredentialName', 'type': 'str'},
        'data_source_credential_description': {'key': 'dataSourceCredentialDescription', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': 'DataLakeGen2SharedKeyParamPatch'},
    }

    def __init__(
        self,
        *,
        data_source_credential_name: Optional[str] = None,
        data_source_credential_description: Optional[str] = None,
        parameters: Optional["DataLakeGen2SharedKeyParamPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_source_credential_name: Name of data source credential.
        :paramtype data_source_credential_name: str
        :keyword data_source_credential_description: Description of data source credential.
        :paramtype data_source_credential_description: str
        :keyword parameters:
        :paramtype parameters: ~azure.ai.metricsadvisor.models.DataLakeGen2SharedKeyParamPatch
        """
        super(_DataLakeGen2SharedKeyCredentialPatchGenerated, self).__init__(data_source_credential_name=data_source_credential_name, data_source_credential_description=data_source_credential_description, **kwargs)
        self.data_source_credential_type = 'DataLakeGen2SharedKey'  # type: str
        self.parameters = parameters

class DataLakeGen2SharedKeyCredentialPatch(DataLakeGen2SharedKeyCredentialPatchCustomization, DataSourceCredentialPatch, _DataLakeGen2SharedKeyCredentialPatchGenerated):
    pass


class _DataLakeGen2SharedKeyParamGenerated(msrest.serialization.Model):
    """DataLakeGen2SharedKeyParam.

    :ivar account_key: The account key to access the Azure Data Lake Storage Gen2.
    :vartype account_key: str
    """

    _attribute_map = {
        'account_key': {'key': 'accountKey', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        account_key: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword account_key: The account key to access the Azure Data Lake Storage Gen2.
        :paramtype account_key: str
        """
        super(_DataLakeGen2SharedKeyParamGenerated, self).__init__(**kwargs)
        self.account_key = account_key

class DataLakeGen2SharedKeyParam(DataLakeGen2SharedKeyParamCustomization, _DataLakeGen2SharedKeyParamGenerated):
    pass


class _DataLakeGen2SharedKeyParamPatchGenerated(msrest.serialization.Model):
    """DataLakeGen2SharedKeyParamPatch.

    :ivar account_key: The account key to access the Azure Data Lake Storage Gen2.
    :vartype account_key: str
    """

    _attribute_map = {
        'account_key': {'key': 'accountKey', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        account_key: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword account_key: The account key to access the Azure Data Lake Storage Gen2.
        :paramtype account_key: str
        """
        super(_DataLakeGen2SharedKeyParamPatchGenerated, self).__init__(**kwargs)
        self.account_key = account_key

class DataLakeGen2SharedKeyParamPatch(DataLakeGen2SharedKeyParamPatchCustomization, _DataLakeGen2SharedKeyParamPatchGenerated):
    pass


class _DataSourceCredentialListGenerated(msrest.serialization.Model):
    """DataSourceCredentialList.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar next_link:
    :vartype next_link: str
    :ivar value:
    :vartype value: list[~azure.ai.metricsadvisor.models.DataSourceCredential]
    """

    _validation = {
        'next_link': {'readonly': True},
        'value': {'readonly': True, 'unique': True},
    }

    _attribute_map = {
        'next_link': {'key': '@nextLink', 'type': 'str'},
        'value': {'key': 'value', 'type': '[DataSourceCredential]'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_DataSourceCredentialListGenerated, self).__init__(**kwargs)
        self.next_link = None
        self.value = None

class DataSourceCredentialList(DataSourceCredentialListCustomization, _DataSourceCredentialListGenerated):
    pass


class _DetectionAnomalyFilterConditionGenerated(msrest.serialization.Model):
    """DetectionAnomalyFilterCondition.

    :ivar dimension_filter: dimension filter.
    :vartype dimension_filter: list[~azure.ai.metricsadvisor.models.DimensionGroupIdentity]
    :ivar severity_filter:
    :vartype severity_filter: ~azure.ai.metricsadvisor.models.SeverityFilterCondition
    """

    _validation = {
        'dimension_filter': {'unique': True},
    }

    _attribute_map = {
        'dimension_filter': {'key': 'dimensionFilter', 'type': '[DimensionGroupIdentity]'},
        'severity_filter': {'key': 'severityFilter', 'type': 'SeverityFilterCondition'},
    }

    def __init__(
        self,
        *,
        dimension_filter: Optional[List["DimensionGroupIdentity"]] = None,
        severity_filter: Optional["SeverityFilterCondition"] = None,
        **kwargs
    ):
        """
        :keyword dimension_filter: dimension filter.
        :paramtype dimension_filter: list[~azure.ai.metricsadvisor.models.DimensionGroupIdentity]
        :keyword severity_filter:
        :paramtype severity_filter: ~azure.ai.metricsadvisor.models.SeverityFilterCondition
        """
        super(_DetectionAnomalyFilterConditionGenerated, self).__init__(**kwargs)
        self.dimension_filter = dimension_filter
        self.severity_filter = severity_filter

class DetectionAnomalyFilterCondition(DetectionAnomalyFilterConditionCustomization, _DetectionAnomalyFilterConditionGenerated):
    pass


class _DetectionAnomalyResultQueryGenerated(msrest.serialization.Model):
    """DetectionAnomalyResultQuery.

    All required parameters must be populated in order to send to Azure.

    :ivar start_time: Required. start time.
    :vartype start_time: ~datetime.datetime
    :ivar end_time: Required. end time.
    :vartype end_time: ~datetime.datetime
    :ivar filter:
    :vartype filter: ~azure.ai.metricsadvisor.models.DetectionAnomalyFilterCondition
    """

    _validation = {
        'start_time': {'required': True},
        'end_time': {'required': True},
    }

    _attribute_map = {
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'endTime', 'type': 'iso-8601'},
        'filter': {'key': 'filter', 'type': 'DetectionAnomalyFilterCondition'},
    }

    def __init__(
        self,
        *,
        start_time: datetime.datetime,
        end_time: datetime.datetime,
        filter: Optional["DetectionAnomalyFilterCondition"] = None,
        **kwargs
    ):
        """
        :keyword start_time: Required. start time.
        :paramtype start_time: ~datetime.datetime
        :keyword end_time: Required. end time.
        :paramtype end_time: ~datetime.datetime
        :keyword filter:
        :paramtype filter: ~azure.ai.metricsadvisor.models.DetectionAnomalyFilterCondition
        """
        super(_DetectionAnomalyResultQueryGenerated, self).__init__(**kwargs)
        self.start_time = start_time
        self.end_time = end_time
        self.filter = filter

class DetectionAnomalyResultQuery(DetectionAnomalyResultQueryCustomization, _DetectionAnomalyResultQueryGenerated):
    pass


class _DetectionIncidentFilterConditionGenerated(msrest.serialization.Model):
    """DetectionIncidentFilterCondition.

    :ivar dimension_filter: dimension filter.
    :vartype dimension_filter: list[~azure.ai.metricsadvisor.models.DimensionGroupIdentity]
    """

    _validation = {
        'dimension_filter': {'unique': True},
    }

    _attribute_map = {
        'dimension_filter': {'key': 'dimensionFilter', 'type': '[DimensionGroupIdentity]'},
    }

    def __init__(
        self,
        *,
        dimension_filter: Optional[List["DimensionGroupIdentity"]] = None,
        **kwargs
    ):
        """
        :keyword dimension_filter: dimension filter.
        :paramtype dimension_filter: list[~azure.ai.metricsadvisor.models.DimensionGroupIdentity]
        """
        super(_DetectionIncidentFilterConditionGenerated, self).__init__(**kwargs)
        self.dimension_filter = dimension_filter

class DetectionIncidentFilterCondition(DetectionIncidentFilterConditionCustomization, _DetectionIncidentFilterConditionGenerated):
    pass


class _DetectionIncidentResultQueryGenerated(msrest.serialization.Model):
    """DetectionIncidentResultQuery.

    All required parameters must be populated in order to send to Azure.

    :ivar start_time: Required. start time.
    :vartype start_time: ~datetime.datetime
    :ivar end_time: Required. end time.
    :vartype end_time: ~datetime.datetime
    :ivar filter:
    :vartype filter: ~azure.ai.metricsadvisor.models.DetectionIncidentFilterCondition
    """

    _validation = {
        'start_time': {'required': True},
        'end_time': {'required': True},
    }

    _attribute_map = {
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'endTime', 'type': 'iso-8601'},
        'filter': {'key': 'filter', 'type': 'DetectionIncidentFilterCondition'},
    }

    def __init__(
        self,
        *,
        start_time: datetime.datetime,
        end_time: datetime.datetime,
        filter: Optional["DetectionIncidentFilterCondition"] = None,
        **kwargs
    ):
        """
        :keyword start_time: Required. start time.
        :paramtype start_time: ~datetime.datetime
        :keyword end_time: Required. end time.
        :paramtype end_time: ~datetime.datetime
        :keyword filter:
        :paramtype filter: ~azure.ai.metricsadvisor.models.DetectionIncidentFilterCondition
        """
        super(_DetectionIncidentResultQueryGenerated, self).__init__(**kwargs)
        self.start_time = start_time
        self.end_time = end_time
        self.filter = filter

class DetectionIncidentResultQuery(DetectionIncidentResultQueryCustomization, _DetectionIncidentResultQueryGenerated):
    pass


class _DetectionSeriesQueryGenerated(msrest.serialization.Model):
    """DetectionSeriesQuery.

    All required parameters must be populated in order to send to Azure.

    :ivar start_time: Required. This is inclusive. The maximum number of data points (series number
     * time range) is 10000.
    :vartype start_time: ~datetime.datetime
    :ivar end_time: Required. This is exclusive. The maximum number of data points (series number *
     time range) is 10000.
    :vartype end_time: ~datetime.datetime
    :ivar series: Required. The series to be queried. The identity must be able to define one
     single time series instead of a group of time series. The maximum number of series is 100.
    :vartype series: list[~azure.ai.metricsadvisor.models.SeriesIdentity]
    """

    _validation = {
        'start_time': {'required': True},
        'end_time': {'required': True},
        'series': {'required': True, 'unique': True},
    }

    _attribute_map = {
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'endTime', 'type': 'iso-8601'},
        'series': {'key': 'series', 'type': '[SeriesIdentity]'},
    }

    def __init__(
        self,
        *,
        start_time: datetime.datetime,
        end_time: datetime.datetime,
        series: List["SeriesIdentity"],
        **kwargs
    ):
        """
        :keyword start_time: Required. This is inclusive. The maximum number of data points (series
         number * time range) is 10000.
        :paramtype start_time: ~datetime.datetime
        :keyword end_time: Required. This is exclusive. The maximum number of data points (series
         number * time range) is 10000.
        :paramtype end_time: ~datetime.datetime
        :keyword series: Required. The series to be queried. The identity must be able to define one
         single time series instead of a group of time series. The maximum number of series is 100.
        :paramtype series: list[~azure.ai.metricsadvisor.models.SeriesIdentity]
        """
        super(_DetectionSeriesQueryGenerated, self).__init__(**kwargs)
        self.start_time = start_time
        self.end_time = end_time
        self.series = series

class DetectionSeriesQuery(DetectionSeriesQueryCustomization, _DetectionSeriesQueryGenerated):
    pass


class _DimensionGenerated(msrest.serialization.Model):
    """Dimension.

    All required parameters must be populated in order to send to Azure.

    :ivar dimension_name: Required. dimension name.
    :vartype dimension_name: str
    :ivar dimension_display_name: dimension display name.
    :vartype dimension_display_name: str
    """

    _validation = {
        'dimension_name': {'required': True},
        'dimension_display_name': {'pattern': r'[.a-zA-Z0-9_-]+'},
    }

    _attribute_map = {
        'dimension_name': {'key': 'dimensionName', 'type': 'str'},
        'dimension_display_name': {'key': 'dimensionDisplayName', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        dimension_name: str,
        dimension_display_name: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword dimension_name: Required. dimension name.
        :paramtype dimension_name: str
        :keyword dimension_display_name: dimension display name.
        :paramtype dimension_display_name: str
        """
        super(_DimensionGenerated, self).__init__(**kwargs)
        self.dimension_name = dimension_name
        self.dimension_display_name = dimension_display_name

class Dimension(DimensionCustomization, _DimensionGenerated):
    pass


class _DimensionGroupConfigurationGenerated(msrest.serialization.Model):
    """DimensionGroupConfiguration.

    All required parameters must be populated in order to send to Azure.

    :ivar group: Required.
    :vartype group: ~azure.ai.metricsadvisor.models.DimensionGroupIdentity
    :ivar condition_operator: condition operator

     should be specified when combining multiple detection conditions. Possible values include:
     "AND", "OR".
    :vartype condition_operator: str or
     ~azure.ai.metricsadvisor.models.AnomalyDetectionConfigurationLogicType
    :ivar smart_detection_condition:
    :vartype smart_detection_condition: ~azure.ai.metricsadvisor.models.SmartDetectionCondition
    :ivar hard_threshold_condition:
    :vartype hard_threshold_condition: ~azure.ai.metricsadvisor.models.HardThresholdCondition
    :ivar change_threshold_condition:
    :vartype change_threshold_condition: ~azure.ai.metricsadvisor.models.ChangeThresholdCondition
    """

    _validation = {
        'group': {'required': True},
    }

    _attribute_map = {
        'group': {'key': 'group', 'type': 'DimensionGroupIdentity'},
        'condition_operator': {'key': 'conditionOperator', 'type': 'str'},
        'smart_detection_condition': {'key': 'smartDetectionCondition', 'type': 'SmartDetectionCondition'},
        'hard_threshold_condition': {'key': 'hardThresholdCondition', 'type': 'HardThresholdCondition'},
        'change_threshold_condition': {'key': 'changeThresholdCondition', 'type': 'ChangeThresholdCondition'},
    }

    def __init__(
        self,
        *,
        group: "DimensionGroupIdentity",
        condition_operator: Optional[Union[str, "AnomalyDetectionConfigurationLogicType"]] = None,
        smart_detection_condition: Optional["SmartDetectionCondition"] = None,
        hard_threshold_condition: Optional["HardThresholdCondition"] = None,
        change_threshold_condition: Optional["ChangeThresholdCondition"] = None,
        **kwargs
    ):
        """
        :keyword group: Required.
        :paramtype group: ~azure.ai.metricsadvisor.models.DimensionGroupIdentity
        :keyword condition_operator: condition operator

         should be specified when combining multiple detection conditions. Possible values include:
         "AND", "OR".
        :paramtype condition_operator: str or
         ~azure.ai.metricsadvisor.models.AnomalyDetectionConfigurationLogicType
        :keyword smart_detection_condition:
        :paramtype smart_detection_condition: ~azure.ai.metricsadvisor.models.SmartDetectionCondition
        :keyword hard_threshold_condition:
        :paramtype hard_threshold_condition: ~azure.ai.metricsadvisor.models.HardThresholdCondition
        :keyword change_threshold_condition:
        :paramtype change_threshold_condition: ~azure.ai.metricsadvisor.models.ChangeThresholdCondition
        """
        super(_DimensionGroupConfigurationGenerated, self).__init__(**kwargs)
        self.group = group
        self.condition_operator = condition_operator
        self.smart_detection_condition = smart_detection_condition
        self.hard_threshold_condition = hard_threshold_condition
        self.change_threshold_condition = change_threshold_condition

class DimensionGroupConfiguration(DimensionGroupConfigurationCustomization, _DimensionGroupConfigurationGenerated):
    pass


class _DimensionGroupIdentityGenerated(msrest.serialization.Model):
    """DimensionGroupIdentity.

    All required parameters must be populated in order to send to Azure.

    :ivar dimension: Required. dimension specified for series group.
    :vartype dimension: dict[str, str]
    """

    _validation = {
        'dimension': {'required': True},
    }

    _attribute_map = {
        'dimension': {'key': 'dimension', 'type': '{str}'},
    }

    def __init__(
        self,
        *,
        dimension: Dict[str, str],
        **kwargs
    ):
        """
        :keyword dimension: Required. dimension specified for series group.
        :paramtype dimension: dict[str, str]
        """
        super(_DimensionGroupIdentityGenerated, self).__init__(**kwargs)
        self.dimension = dimension

class DimensionGroupIdentity(DimensionGroupIdentityCustomization, _DimensionGroupIdentityGenerated):
    pass


class _HookInfoGenerated(msrest.serialization.Model):
    """HookInfo.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: EmailHookInfo, WebhookHookInfo.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar hook_type: Required. hook type.Constant filled by server. Possible values include:
     "Webhook", "Email".
    :vartype hook_type: str or ~azure.ai.metricsadvisor.models.HookType
    :ivar hook_id: Hook unique id.
    :vartype hook_id: str
    :ivar hook_name: Required. hook unique name.
    :vartype hook_name: str
    :ivar description: hook description.
    :vartype description: str
    :ivar external_link: hook external link.
    :vartype external_link: str
    :ivar admins: hook administrators.
    :vartype admins: list[str]
    """

    _validation = {
        'hook_type': {'required': True},
        'hook_id': {'readonly': True},
        'hook_name': {'required': True},
        'admins': {'unique': True},
    }

    _attribute_map = {
        'hook_type': {'key': 'hookType', 'type': 'str'},
        'hook_id': {'key': 'hookId', 'type': 'str'},
        'hook_name': {'key': 'hookName', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'external_link': {'key': 'externalLink', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
    }

    _subtype_map = {
        'hook_type': {'Email': 'EmailHookInfo', 'Webhook': 'WebhookHookInfo'}
    }

    def __init__(
        self,
        *,
        hook_name: str,
        description: Optional[str] = "",
        external_link: Optional[str] = "",
        admins: Optional[List[str]] = None,
        **kwargs
    ):
        """
        :keyword hook_name: Required. hook unique name.
        :paramtype hook_name: str
        :keyword description: hook description.
        :paramtype description: str
        :keyword external_link: hook external link.
        :paramtype external_link: str
        :keyword admins: hook administrators.
        :paramtype admins: list[str]
        """
        super(_HookInfoGenerated, self).__init__(**kwargs)
        self.hook_type = None  # type: Optional[str]
        self.hook_id = None
        self.hook_name = hook_name
        self.description = description
        self.external_link = external_link
        self.admins = admins

class HookInfo(HookInfoCustomization, _HookInfoGenerated):
    pass


class _EmailHookInfoGenerated(_HookInfoGenerated):
    """EmailHookInfo.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar hook_type: Required. hook type.Constant filled by server. Possible values include:
     "Webhook", "Email".
    :vartype hook_type: str or ~azure.ai.metricsadvisor.models.HookType
    :ivar hook_id: Hook unique id.
    :vartype hook_id: str
    :ivar hook_name: Required. hook unique name.
    :vartype hook_name: str
    :ivar description: hook description.
    :vartype description: str
    :ivar external_link: hook external link.
    :vartype external_link: str
    :ivar admins: hook administrators.
    :vartype admins: list[str]
    :ivar hook_parameter: Required.
    :vartype hook_parameter: ~azure.ai.metricsadvisor.models.EmailHookParameter
    """

    _validation = {
        'hook_type': {'required': True},
        'hook_id': {'readonly': True},
        'hook_name': {'required': True},
        'admins': {'unique': True},
        'hook_parameter': {'required': True},
    }

    _attribute_map = {
        'hook_type': {'key': 'hookType', 'type': 'str'},
        'hook_id': {'key': 'hookId', 'type': 'str'},
        'hook_name': {'key': 'hookName', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'external_link': {'key': 'externalLink', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'hook_parameter': {'key': 'hookParameter', 'type': 'EmailHookParameter'},
    }

    def __init__(
        self,
        *,
        hook_name: str,
        hook_parameter: "EmailHookParameter",
        description: Optional[str] = "",
        external_link: Optional[str] = "",
        admins: Optional[List[str]] = None,
        **kwargs
    ):
        """
        :keyword hook_name: Required. hook unique name.
        :paramtype hook_name: str
        :keyword description: hook description.
        :paramtype description: str
        :keyword external_link: hook external link.
        :paramtype external_link: str
        :keyword admins: hook administrators.
        :paramtype admins: list[str]
        :keyword hook_parameter: Required.
        :paramtype hook_parameter: ~azure.ai.metricsadvisor.models.EmailHookParameter
        """
        super(_EmailHookInfoGenerated, self).__init__(hook_name=hook_name, description=description, external_link=external_link, admins=admins, **kwargs)
        self.hook_type = 'Email'  # type: str
        self.hook_parameter = hook_parameter

class EmailHookInfo(EmailHookInfoCustomization, HookInfo, _EmailHookInfoGenerated):
    pass


class _HookInfoPatchGenerated(msrest.serialization.Model):
    """HookInfoPatch.

    You probably want to use the sub-classes and not this class directly. Known
    sub-classes are: EmailHookInfoPatch, WebhookHookInfoPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar hook_type: Required. hook type.Constant filled by server. Possible values include:
     "Webhook", "Email".
    :vartype hook_type: str or ~azure.ai.metricsadvisor.models.HookType
    :ivar hook_name: hook unique name.
    :vartype hook_name: str
    :ivar description: hook description.
    :vartype description: str
    :ivar external_link: hook external link.
    :vartype external_link: str
    :ivar admins: hook administrators.
    :vartype admins: list[str]
    """

    _validation = {
        'hook_type': {'required': True},
        'admins': {'unique': True},
    }

    _attribute_map = {
        'hook_type': {'key': 'hookType', 'type': 'str'},
        'hook_name': {'key': 'hookName', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'external_link': {'key': 'externalLink', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
    }

    _subtype_map = {
        'hook_type': {'Email': 'EmailHookInfoPatch', 'Webhook': 'WebhookHookInfoPatch'}
    }

    def __init__(
        self,
        *,
        hook_name: Optional[str] = None,
        description: Optional[str] = None,
        external_link: Optional[str] = None,
        admins: Optional[List[str]] = None,
        **kwargs
    ):
        """
        :keyword hook_name: hook unique name.
        :paramtype hook_name: str
        :keyword description: hook description.
        :paramtype description: str
        :keyword external_link: hook external link.
        :paramtype external_link: str
        :keyword admins: hook administrators.
        :paramtype admins: list[str]
        """
        super(_HookInfoPatchGenerated, self).__init__(**kwargs)
        self.hook_type = None  # type: Optional[str]
        self.hook_name = hook_name
        self.description = description
        self.external_link = external_link
        self.admins = admins

class HookInfoPatch(HookInfoPatchCustomization, _HookInfoPatchGenerated):
    pass


class _EmailHookInfoPatchGenerated(_HookInfoPatchGenerated):
    """EmailHookInfoPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar hook_type: Required. hook type.Constant filled by server. Possible values include:
     "Webhook", "Email".
    :vartype hook_type: str or ~azure.ai.metricsadvisor.models.HookType
    :ivar hook_name: hook unique name.
    :vartype hook_name: str
    :ivar description: hook description.
    :vartype description: str
    :ivar external_link: hook external link.
    :vartype external_link: str
    :ivar admins: hook administrators.
    :vartype admins: list[str]
    :ivar hook_parameter:
    :vartype hook_parameter: ~azure.ai.metricsadvisor.models.EmailHookParameterPatch
    """

    _validation = {
        'hook_type': {'required': True},
        'admins': {'unique': True},
    }

    _attribute_map = {
        'hook_type': {'key': 'hookType', 'type': 'str'},
        'hook_name': {'key': 'hookName', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'external_link': {'key': 'externalLink', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'hook_parameter': {'key': 'hookParameter', 'type': 'EmailHookParameterPatch'},
    }

    def __init__(
        self,
        *,
        hook_name: Optional[str] = None,
        description: Optional[str] = None,
        external_link: Optional[str] = None,
        admins: Optional[List[str]] = None,
        hook_parameter: Optional["EmailHookParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword hook_name: hook unique name.
        :paramtype hook_name: str
        :keyword description: hook description.
        :paramtype description: str
        :keyword external_link: hook external link.
        :paramtype external_link: str
        :keyword admins: hook administrators.
        :paramtype admins: list[str]
        :keyword hook_parameter:
        :paramtype hook_parameter: ~azure.ai.metricsadvisor.models.EmailHookParameterPatch
        """
        super(_EmailHookInfoPatchGenerated, self).__init__(hook_name=hook_name, description=description, external_link=external_link, admins=admins, **kwargs)
        self.hook_type = 'Email'  # type: str
        self.hook_parameter = hook_parameter

class EmailHookInfoPatch(EmailHookInfoPatchCustomization, HookInfoPatch, _EmailHookInfoPatchGenerated):
    pass


class _EmailHookParameterGenerated(msrest.serialization.Model):
    """EmailHookParameter.

    All required parameters must be populated in order to send to Azure.

    :ivar to_list: Required. Email TO: list.
    :vartype to_list: list[str]
    """

    _validation = {
        'to_list': {'required': True, 'unique': True},
    }

    _attribute_map = {
        'to_list': {'key': 'toList', 'type': '[str]'},
    }

    def __init__(
        self,
        *,
        to_list: List[str],
        **kwargs
    ):
        """
        :keyword to_list: Required. Email TO: list.
        :paramtype to_list: list[str]
        """
        super(_EmailHookParameterGenerated, self).__init__(**kwargs)
        self.to_list = to_list

class EmailHookParameter(EmailHookParameterCustomization, _EmailHookParameterGenerated):
    pass


class _EmailHookParameterPatchGenerated(msrest.serialization.Model):
    """EmailHookParameterPatch.

    :ivar to_list: Email TO: list.
    :vartype to_list: list[str]
    """

    _validation = {
        'to_list': {'unique': True},
    }

    _attribute_map = {
        'to_list': {'key': 'toList', 'type': '[str]'},
    }

    def __init__(
        self,
        *,
        to_list: Optional[List[str]] = None,
        **kwargs
    ):
        """
        :keyword to_list: Email TO: list.
        :paramtype to_list: list[str]
        """
        super(_EmailHookParameterPatchGenerated, self).__init__(**kwargs)
        self.to_list = to_list

class EmailHookParameterPatch(EmailHookParameterPatchCustomization, _EmailHookParameterPatchGenerated):
    pass


class _EnrichmentStatusGenerated(msrest.serialization.Model):
    """EnrichmentStatus.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar timestamp: data slice timestamp.
    :vartype timestamp: ~datetime.datetime
    :ivar status: latest enrichment status for this data slice.
    :vartype status: str
    :ivar message: the trimmed message describes details of the enrichment status.
    :vartype message: str
    """

    _validation = {
        'timestamp': {'readonly': True},
        'status': {'readonly': True},
        'message': {'readonly': True},
    }

    _attribute_map = {
        'timestamp': {'key': 'timestamp', 'type': 'iso-8601'},
        'status': {'key': 'status', 'type': 'str'},
        'message': {'key': 'message', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_EnrichmentStatusGenerated, self).__init__(**kwargs)
        self.timestamp = None
        self.status = None
        self.message = None

class EnrichmentStatus(EnrichmentStatusCustomization, _EnrichmentStatusGenerated):
    pass


class _EnrichmentStatusListGenerated(msrest.serialization.Model):
    """EnrichmentStatusList.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar next_link:
    :vartype next_link: str
    :ivar value:
    :vartype value: list[~azure.ai.metricsadvisor.models.EnrichmentStatus]
    """

    _validation = {
        'next_link': {'readonly': True},
        'value': {'readonly': True},
    }

    _attribute_map = {
        'next_link': {'key': '@nextLink', 'type': 'str'},
        'value': {'key': 'value', 'type': '[EnrichmentStatus]'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_EnrichmentStatusListGenerated, self).__init__(**kwargs)
        self.next_link = None
        self.value = None

class EnrichmentStatusList(EnrichmentStatusListCustomization, _EnrichmentStatusListGenerated):
    pass


class _EnrichmentStatusQueryOptionGenerated(msrest.serialization.Model):
    """EnrichmentStatusQueryOption.

    All required parameters must be populated in order to send to Azure.

    :ivar start_time: Required. the start point of time range to query anomaly detection status.
    :vartype start_time: ~datetime.datetime
    :ivar end_time: Required. the end point of time range to query anomaly detection status.
    :vartype end_time: ~datetime.datetime
    """

    _validation = {
        'start_time': {'required': True},
        'end_time': {'required': True},
    }

    _attribute_map = {
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'endTime', 'type': 'iso-8601'},
    }

    def __init__(
        self,
        *,
        start_time: datetime.datetime,
        end_time: datetime.datetime,
        **kwargs
    ):
        """
        :keyword start_time: Required. the start point of time range to query anomaly detection status.
        :paramtype start_time: ~datetime.datetime
        :keyword end_time: Required. the end point of time range to query anomaly detection status.
        :paramtype end_time: ~datetime.datetime
        """
        super(_EnrichmentStatusQueryOptionGenerated, self).__init__(**kwargs)
        self.start_time = start_time
        self.end_time = end_time

class EnrichmentStatusQueryOption(EnrichmentStatusQueryOptionCustomization, _EnrichmentStatusQueryOptionGenerated):
    pass


class _ErrorCodeGenerated(msrest.serialization.Model):
    """ErrorCode.

    :ivar message:
    :vartype message: str
    :ivar code:
    :vartype code: str
    """

    _attribute_map = {
        'message': {'key': 'message', 'type': 'str'},
        'code': {'key': 'code', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        message: Optional[str] = None,
        code: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword message:
        :paramtype message: str
        :keyword code:
        :paramtype code: str
        """
        super(_ErrorCodeGenerated, self).__init__(**kwargs)
        self.message = message
        self.code = code

class ErrorCode(ErrorCodeCustomization, _ErrorCodeGenerated):
    pass


class _FeedbackDimensionFilterGenerated(msrest.serialization.Model):
    """FeedbackDimensionFilter.

    All required parameters must be populated in order to send to Azure.

    :ivar dimension: Required. metric dimension filter.
    :vartype dimension: dict[str, str]
    """

    _validation = {
        'dimension': {'required': True},
    }

    _attribute_map = {
        'dimension': {'key': 'dimension', 'type': '{str}'},
    }

    def __init__(
        self,
        *,
        dimension: Dict[str, str],
        **kwargs
    ):
        """
        :keyword dimension: Required. metric dimension filter.
        :paramtype dimension: dict[str, str]
        """
        super(_FeedbackDimensionFilterGenerated, self).__init__(**kwargs)
        self.dimension = dimension

class FeedbackDimensionFilter(FeedbackDimensionFilterCustomization, _FeedbackDimensionFilterGenerated):
    pass


class _HardThresholdConditionGenerated(msrest.serialization.Model):
    """HardThresholdCondition.

    All required parameters must be populated in order to send to Azure.

    :ivar lower_bound: lower bound

     should be specified when anomalyDetectorDirection is Both or Down.
    :vartype lower_bound: float
    :ivar upper_bound: upper bound

     should be specified when anomalyDetectorDirection is Both or Up.
    :vartype upper_bound: float
    :ivar anomaly_detector_direction: Required. detection direction. Possible values include:
     "Both", "Down", "Up".
    :vartype anomaly_detector_direction: str or
     ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
    :ivar suppress_condition: Required.
    :vartype suppress_condition: ~azure.ai.metricsadvisor.models.SuppressCondition
    """

    _validation = {
        'anomaly_detector_direction': {'required': True},
        'suppress_condition': {'required': True},
    }

    _attribute_map = {
        'lower_bound': {'key': 'lowerBound', 'type': 'float'},
        'upper_bound': {'key': 'upperBound', 'type': 'float'},
        'anomaly_detector_direction': {'key': 'anomalyDetectorDirection', 'type': 'str'},
        'suppress_condition': {'key': 'suppressCondition', 'type': 'SuppressCondition'},
    }

    def __init__(
        self,
        *,
        anomaly_detector_direction: Union[str, "AnomalyDetectorDirection"],
        suppress_condition: "SuppressCondition",
        lower_bound: Optional[float] = None,
        upper_bound: Optional[float] = None,
        **kwargs
    ):
        """
        :keyword lower_bound: lower bound

         should be specified when anomalyDetectorDirection is Both or Down.
        :paramtype lower_bound: float
        :keyword upper_bound: upper bound

         should be specified when anomalyDetectorDirection is Both or Up.
        :paramtype upper_bound: float
        :keyword anomaly_detector_direction: Required. detection direction. Possible values include:
         "Both", "Down", "Up".
        :paramtype anomaly_detector_direction: str or
         ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
        :keyword suppress_condition: Required.
        :paramtype suppress_condition: ~azure.ai.metricsadvisor.models.SuppressCondition
        """
        super(_HardThresholdConditionGenerated, self).__init__(**kwargs)
        self.lower_bound = lower_bound
        self.upper_bound = upper_bound
        self.anomaly_detector_direction = anomaly_detector_direction
        self.suppress_condition = suppress_condition

class HardThresholdCondition(HardThresholdConditionCustomization, _HardThresholdConditionGenerated):
    pass


class _HardThresholdConditionPatchGenerated(msrest.serialization.Model):
    """HardThresholdConditionPatch.

    :ivar lower_bound: lower bound

     should be specified when anomalyDetectorDirection is Both or Down.
    :vartype lower_bound: float
    :ivar upper_bound: upper bound

     should be specified when anomalyDetectorDirection is Both or Up.
    :vartype upper_bound: float
    :ivar anomaly_detector_direction: detection direction. Possible values include: "Both", "Down",
     "Up".
    :vartype anomaly_detector_direction: str or
     ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
    :ivar suppress_condition:
    :vartype suppress_condition: ~azure.ai.metricsadvisor.models.SuppressConditionPatch
    """

    _attribute_map = {
        'lower_bound': {'key': 'lowerBound', 'type': 'float'},
        'upper_bound': {'key': 'upperBound', 'type': 'float'},
        'anomaly_detector_direction': {'key': 'anomalyDetectorDirection', 'type': 'str'},
        'suppress_condition': {'key': 'suppressCondition', 'type': 'SuppressConditionPatch'},
    }

    def __init__(
        self,
        *,
        lower_bound: Optional[float] = None,
        upper_bound: Optional[float] = None,
        anomaly_detector_direction: Optional[Union[str, "AnomalyDetectorDirection"]] = None,
        suppress_condition: Optional["SuppressConditionPatch"] = None,
        **kwargs
    ):
        """
        :keyword lower_bound: lower bound

         should be specified when anomalyDetectorDirection is Both or Down.
        :paramtype lower_bound: float
        :keyword upper_bound: upper bound

         should be specified when anomalyDetectorDirection is Both or Up.
        :paramtype upper_bound: float
        :keyword anomaly_detector_direction: detection direction. Possible values include: "Both",
         "Down", "Up".
        :paramtype anomaly_detector_direction: str or
         ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
        :keyword suppress_condition:
        :paramtype suppress_condition: ~azure.ai.metricsadvisor.models.SuppressConditionPatch
        """
        super(_HardThresholdConditionPatchGenerated, self).__init__(**kwargs)
        self.lower_bound = lower_bound
        self.upper_bound = upper_bound
        self.anomaly_detector_direction = anomaly_detector_direction
        self.suppress_condition = suppress_condition

class HardThresholdConditionPatch(HardThresholdConditionPatchCustomization, _HardThresholdConditionPatchGenerated):
    pass


class _HookListGenerated(msrest.serialization.Model):
    """HookList.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar next_link:
    :vartype next_link: str
    :ivar value:
    :vartype value: list[~azure.ai.metricsadvisor.models.HookInfo]
    """

    _validation = {
        'next_link': {'readonly': True},
        'value': {'readonly': True, 'unique': True},
    }

    _attribute_map = {
        'next_link': {'key': '@nextLink', 'type': 'str'},
        'value': {'key': 'value', 'type': '[HookInfo]'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_HookListGenerated, self).__init__(**kwargs)
        self.next_link = None
        self.value = None

class HookList(HookListCustomization, _HookListGenerated):
    pass


class _IncidentPropertyGenerated(msrest.serialization.Model):
    """IncidentProperty.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar max_severity: Required. max severity of latest anomalies in the incident. Possible values
     include: "Low", "Medium", "High".
    :vartype max_severity: str or ~azure.ai.metricsadvisor.models.Severity
    :ivar incident_status: incident status

     only return for alerting incident result. Possible values include: "Active", "Resolved".
    :vartype incident_status: str or ~azure.ai.metricsadvisor.models.IncidentStatus
    :ivar value_of_root_node: value of the root node.
    :vartype value_of_root_node: float
    :ivar expected_value_of_root_node: expected value of the root node given by smart detector.
    :vartype expected_value_of_root_node: float
    """

    _validation = {
        'max_severity': {'required': True},
        'incident_status': {'readonly': True},
        'value_of_root_node': {'readonly': True},
        'expected_value_of_root_node': {'readonly': True},
    }

    _attribute_map = {
        'max_severity': {'key': 'maxSeverity', 'type': 'str'},
        'incident_status': {'key': 'incidentStatus', 'type': 'str'},
        'value_of_root_node': {'key': 'valueOfRootNode', 'type': 'float'},
        'expected_value_of_root_node': {'key': 'expectedValueOfRootNode', 'type': 'float'},
    }

    def __init__(
        self,
        *,
        max_severity: Union[str, "Severity"],
        **kwargs
    ):
        """
        :keyword max_severity: Required. max severity of latest anomalies in the incident. Possible
         values include: "Low", "Medium", "High".
        :paramtype max_severity: str or ~azure.ai.metricsadvisor.models.Severity
        """
        super(_IncidentPropertyGenerated, self).__init__(**kwargs)
        self.max_severity = max_severity
        self.incident_status = None
        self.value_of_root_node = None
        self.expected_value_of_root_node = None

class IncidentProperty(IncidentPropertyCustomization, _IncidentPropertyGenerated):
    pass


class _IncidentResultGenerated(msrest.serialization.Model):
    """IncidentResult.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_feed_id: data feed unique id

     only return for alerting anomaly result.
    :vartype data_feed_id: str
    :ivar metric_id: metric unique id

     only return for alerting incident result.
    :vartype metric_id: str
    :ivar anomaly_detection_configuration_id: anomaly detection configuration unique id

     only return for alerting incident result.
    :vartype anomaly_detection_configuration_id: str
    :ivar incident_id: Required. incident id.
    :vartype incident_id: str
    :ivar start_time: Required. incident start time.
    :vartype start_time: ~datetime.datetime
    :ivar last_time: Required. incident last time.
    :vartype last_time: ~datetime.datetime
    :ivar root_node: Required.
    :vartype root_node: ~azure.ai.metricsadvisor.models.SeriesIdentity
    :ivar property: Required.
    :vartype property: ~azure.ai.metricsadvisor.models.IncidentProperty
    """

    _validation = {
        'data_feed_id': {'readonly': True},
        'metric_id': {'readonly': True},
        'anomaly_detection_configuration_id': {'readonly': True},
        'incident_id': {'required': True},
        'start_time': {'required': True},
        'last_time': {'required': True},
        'root_node': {'required': True},
        'property': {'required': True},
    }

    _attribute_map = {
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'metric_id': {'key': 'metricId', 'type': 'str'},
        'anomaly_detection_configuration_id': {'key': 'anomalyDetectionConfigurationId', 'type': 'str'},
        'incident_id': {'key': 'incidentId', 'type': 'str'},
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'last_time': {'key': 'lastTime', 'type': 'iso-8601'},
        'root_node': {'key': 'rootNode', 'type': 'SeriesIdentity'},
        'property': {'key': 'property', 'type': 'IncidentProperty'},
    }

    def __init__(
        self,
        *,
        incident_id: str,
        start_time: datetime.datetime,
        last_time: datetime.datetime,
        root_node: "SeriesIdentity",
        property: "IncidentProperty",
        **kwargs
    ):
        """
        :keyword incident_id: Required. incident id.
        :paramtype incident_id: str
        :keyword start_time: Required. incident start time.
        :paramtype start_time: ~datetime.datetime
        :keyword last_time: Required. incident last time.
        :paramtype last_time: ~datetime.datetime
        :keyword root_node: Required.
        :paramtype root_node: ~azure.ai.metricsadvisor.models.SeriesIdentity
        :keyword property: Required.
        :paramtype property: ~azure.ai.metricsadvisor.models.IncidentProperty
        """
        super(_IncidentResultGenerated, self).__init__(**kwargs)
        self.data_feed_id = None
        self.metric_id = None
        self.anomaly_detection_configuration_id = None
        self.incident_id = incident_id
        self.start_time = start_time
        self.last_time = last_time
        self.root_node = root_node
        self.property = property

class IncidentResult(IncidentResultCustomization, _IncidentResultGenerated):
    pass


class _IncidentResultListGenerated(msrest.serialization.Model):
    """IncidentResultList.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar next_link:
    :vartype next_link: str
    :ivar value: Required.
    :vartype value: list[~azure.ai.metricsadvisor.models.IncidentResult]
    """

    _validation = {
        'next_link': {'readonly': True},
        'value': {'required': True},
    }

    _attribute_map = {
        'next_link': {'key': '@nextLink', 'type': 'str'},
        'value': {'key': 'value', 'type': '[IncidentResult]'},
    }

    def __init__(
        self,
        *,
        value: List["IncidentResult"],
        **kwargs
    ):
        """
        :keyword value: Required.
        :paramtype value: list[~azure.ai.metricsadvisor.models.IncidentResult]
        """
        super(_IncidentResultListGenerated, self).__init__(**kwargs)
        self.next_link = None
        self.value = value

class IncidentResultList(IncidentResultListCustomization, _IncidentResultListGenerated):
    pass


class _InfluxDBDataFeedGenerated(_DataFeedGenerated):
    """InfluxDBDataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter: Required.
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.InfluxDBParameter
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
        'data_source_parameter': {'required': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'InfluxDBParameter'},
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_source_parameter: "InfluxDBParameter",
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter: Required.
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.InfluxDBParameter
        """
        super(_InfluxDBDataFeedGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, granularity_name=granularity_name, granularity_amount=granularity_amount, metrics=metrics, dimension=dimension, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'InfluxDB'  # type: str
        self.data_source_parameter = data_source_parameter

class InfluxDBDataFeed(InfluxDBDataFeedCustomization, DataFeed, _InfluxDBDataFeedGenerated):
    pass


class _InfluxDBDataFeedPatchGenerated(_DataFeedPatchGenerated):
    """InfluxDBDataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter:
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.InfluxDBParameterPatch
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'InfluxDBParameterPatch'},
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        data_source_parameter: Optional["InfluxDBParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter:
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.InfluxDBParameterPatch
        """
        super(_InfluxDBDataFeedPatchGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, status=status, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'InfluxDB'  # type: str
        self.data_source_parameter = data_source_parameter

class InfluxDBDataFeedPatch(InfluxDBDataFeedPatchCustomization, DataFeedPatch, _InfluxDBDataFeedPatchGenerated):
    pass


class _InfluxDBParameterGenerated(msrest.serialization.Model):
    """InfluxDBParameter.

    All required parameters must be populated in order to send to Azure.

    :ivar connection_string: The connection string of this InfluxDB.
    :vartype connection_string: str
    :ivar database: A database name.
    :vartype database: str
    :ivar user_name: The user name of the account that can access this database.
    :vartype user_name: str
    :ivar password: The password of the account that can access this database.
    :vartype password: str
    :ivar query: Required. The script to query this database.
    :vartype query: str
    """

    _validation = {
        'query': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'database': {'key': 'database', 'type': 'str'},
        'user_name': {'key': 'userName', 'type': 'str'},
        'password': {'key': 'password', 'type': 'str'},
        'query': {'key': 'query', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        query: str,
        connection_string: Optional[str] = None,
        database: Optional[str] = None,
        user_name: Optional[str] = None,
        password: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this InfluxDB.
        :paramtype connection_string: str
        :keyword database: A database name.
        :paramtype database: str
        :keyword user_name: The user name of the account that can access this database.
        :paramtype user_name: str
        :keyword password: The password of the account that can access this database.
        :paramtype password: str
        :keyword query: Required. The script to query this database.
        :paramtype query: str
        """
        super(_InfluxDBParameterGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.database = database
        self.user_name = user_name
        self.password = password
        self.query = query

class InfluxDBParameter(InfluxDBParameterCustomization, _InfluxDBParameterGenerated):
    pass


class _InfluxDBParameterPatchGenerated(msrest.serialization.Model):
    """InfluxDBParameterPatch.

    :ivar connection_string: The connection string of this InfluxDB.
    :vartype connection_string: str
    :ivar database: A database name.
    :vartype database: str
    :ivar user_name: The user name of the account that can access this database.
    :vartype user_name: str
    :ivar password: The password of the account that can access this database.
    :vartype password: str
    :ivar query: The script to query this database.
    :vartype query: str
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'database': {'key': 'database', 'type': 'str'},
        'user_name': {'key': 'userName', 'type': 'str'},
        'password': {'key': 'password', 'type': 'str'},
        'query': {'key': 'query', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional[str] = None,
        database: Optional[str] = None,
        user_name: Optional[str] = None,
        password: Optional[str] = None,
        query: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this InfluxDB.
        :paramtype connection_string: str
        :keyword database: A database name.
        :paramtype database: str
        :keyword user_name: The user name of the account that can access this database.
        :paramtype user_name: str
        :keyword password: The password of the account that can access this database.
        :paramtype password: str
        :keyword query: The script to query this database.
        :paramtype query: str
        """
        super(_InfluxDBParameterPatchGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.database = database
        self.user_name = user_name
        self.password = password
        self.query = query

class InfluxDBParameterPatch(InfluxDBParameterPatchCustomization, _InfluxDBParameterPatchGenerated):
    pass


class _IngestionProgressResetOptionsGenerated(msrest.serialization.Model):
    """IngestionProgressResetOptions.

    All required parameters must be populated in order to send to Azure.

    :ivar start_time: Required. the start point of time range to reset data ingestion status.
    :vartype start_time: ~datetime.datetime
    :ivar end_time: Required. the end point of time range to reset data ingestion status.
    :vartype end_time: ~datetime.datetime
    """

    _validation = {
        'start_time': {'required': True},
        'end_time': {'required': True},
    }

    _attribute_map = {
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'endTime', 'type': 'iso-8601'},
    }

    def __init__(
        self,
        *,
        start_time: datetime.datetime,
        end_time: datetime.datetime,
        **kwargs
    ):
        """
        :keyword start_time: Required. the start point of time range to reset data ingestion status.
        :paramtype start_time: ~datetime.datetime
        :keyword end_time: Required. the end point of time range to reset data ingestion status.
        :paramtype end_time: ~datetime.datetime
        """
        super(_IngestionProgressResetOptionsGenerated, self).__init__(**kwargs)
        self.start_time = start_time
        self.end_time = end_time

class IngestionProgressResetOptions(IngestionProgressResetOptionsCustomization, _IngestionProgressResetOptionsGenerated):
    pass


class _DataFeedIngestionStatusGenerated(msrest.serialization.Model):
    """DataFeedIngestionStatus.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar timestamp: data slice timestamp.
    :vartype timestamp: ~datetime.datetime
    :ivar status: latest ingestion task status for this data slice. Possible values include:
     "NotStarted", "Scheduled", "Running", "Succeeded", "Failed", "NoData", "Error", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.IngestionStatusType
    :ivar message: the trimmed message of last ingestion job.
    :vartype message: str
    """

    _validation = {
        'timestamp': {'readonly': True},
        'status': {'readonly': True},
        'message': {'readonly': True},
    }

    _attribute_map = {
        'timestamp': {'key': 'timestamp', 'type': 'iso-8601'},
        'status': {'key': 'status', 'type': 'str'},
        'message': {'key': 'message', 'type': 'str'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_DataFeedIngestionStatusGenerated, self).__init__(**kwargs)
        self.timestamp = None
        self.status = None
        self.message = None

class DataFeedIngestionStatus(DataFeedIngestionStatusCustomization, _DataFeedIngestionStatusGenerated):
    pass


class _IngestionStatusListGenerated(msrest.serialization.Model):
    """IngestionStatusList.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar next_link:
    :vartype next_link: str
    :ivar value:
    :vartype value: list[~azure.ai.metricsadvisor.models.IngestionStatus]
    """

    _validation = {
        'next_link': {'readonly': True},
        'value': {'readonly': True},
    }

    _attribute_map = {
        'next_link': {'key': '@nextLink', 'type': 'str'},
        'value': {'key': 'value', 'type': '[IngestionStatus]'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_IngestionStatusListGenerated, self).__init__(**kwargs)
        self.next_link = None
        self.value = None

class IngestionStatusList(IngestionStatusListCustomization, _IngestionStatusListGenerated):
    pass


class _IngestionStatusQueryOptionsGenerated(msrest.serialization.Model):
    """IngestionStatusQueryOptions.

    All required parameters must be populated in order to send to Azure.

    :ivar start_time: Required. the start point of time range to query data ingestion status.
    :vartype start_time: ~datetime.datetime
    :ivar end_time: Required. the end point of time range to query data ingestion status.
    :vartype end_time: ~datetime.datetime
    """

    _validation = {
        'start_time': {'required': True},
        'end_time': {'required': True},
    }

    _attribute_map = {
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'endTime', 'type': 'iso-8601'},
    }

    def __init__(
        self,
        *,
        start_time: datetime.datetime,
        end_time: datetime.datetime,
        **kwargs
    ):
        """
        :keyword start_time: Required. the start point of time range to query data ingestion status.
        :paramtype start_time: ~datetime.datetime
        :keyword end_time: Required. the end point of time range to query data ingestion status.
        :paramtype end_time: ~datetime.datetime
        """
        super(_IngestionStatusQueryOptionsGenerated, self).__init__(**kwargs)
        self.start_time = start_time
        self.end_time = end_time

class IngestionStatusQueryOptions(IngestionStatusQueryOptionsCustomization, _IngestionStatusQueryOptionsGenerated):
    pass


class _MetricGenerated(msrest.serialization.Model):
    """Metric.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar metric_id: metric id.
    :vartype metric_id: str
    :ivar metric_name: Required. metric name.
    :vartype metric_name: str
    :ivar metric_display_name: metric display name.
    :vartype metric_display_name: str
    :ivar metric_description: metric description.
    :vartype metric_description: str
    """

    _validation = {
        'metric_id': {'readonly': True},
        'metric_name': {'required': True},
        'metric_display_name': {'pattern': r'[.a-zA-Z0-9_-]+'},
    }

    _attribute_map = {
        'metric_id': {'key': 'metricId', 'type': 'str'},
        'metric_name': {'key': 'metricName', 'type': 'str'},
        'metric_display_name': {'key': 'metricDisplayName', 'type': 'str'},
        'metric_description': {'key': 'metricDescription', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        metric_name: str,
        metric_display_name: Optional[str] = None,
        metric_description: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword metric_name: Required. metric name.
        :paramtype metric_name: str
        :keyword metric_display_name: metric display name.
        :paramtype metric_display_name: str
        :keyword metric_description: metric description.
        :paramtype metric_description: str
        """
        super(_MetricGenerated, self).__init__(**kwargs)
        self.metric_id = None
        self.metric_name = metric_name
        self.metric_display_name = metric_display_name
        self.metric_description = metric_description

class Metric(MetricCustomization, _MetricGenerated):
    pass


class _MetricAlertConfigurationGenerated(msrest.serialization.Model):
    """MetricAlertConfiguration.

    All required parameters must be populated in order to send to Azure.

    :ivar anomaly_detection_configuration_id: Required. Anomaly detection configuration unique id.
    :vartype anomaly_detection_configuration_id: str
    :ivar anomaly_scope_type: Required. Anomaly scope. Possible values include: "WholeSeries",
     "SeriesGroup", "TopN".
    :vartype anomaly_scope_type: str or ~azure.ai.metricsadvisor.models.MetricAnomalyAlertScopeType
    :ivar negation_operation: Negation operation.
    :vartype negation_operation: bool
    :ivar dimension_anomaly_scope:
    :vartype dimension_anomaly_scope: ~azure.ai.metricsadvisor.models.DimensionGroupIdentity
    :ivar top_n_anomaly_scope:
    :vartype top_n_anomaly_scope: ~azure.ai.metricsadvisor.models.TopNGroupScope
    :ivar severity_filter:
    :vartype severity_filter: ~azure.ai.metricsadvisor.models.SeverityCondition
    :ivar snooze_filter:
    :vartype snooze_filter: ~azure.ai.metricsadvisor.models.AlertSnoozeCondition
    :ivar value_filter:
    :vartype value_filter: ~azure.ai.metricsadvisor.models.ValueCondition
    """

    _validation = {
        'anomaly_detection_configuration_id': {'required': True},
        'anomaly_scope_type': {'required': True},
    }

    _attribute_map = {
        'anomaly_detection_configuration_id': {'key': 'anomalyDetectionConfigurationId', 'type': 'str'},
        'anomaly_scope_type': {'key': 'anomalyScopeType', 'type': 'str'},
        'negation_operation': {'key': 'negationOperation', 'type': 'bool'},
        'dimension_anomaly_scope': {'key': 'dimensionAnomalyScope', 'type': 'DimensionGroupIdentity'},
        'top_n_anomaly_scope': {'key': 'topNAnomalyScope', 'type': 'TopNGroupScope'},
        'severity_filter': {'key': 'severityFilter', 'type': 'SeverityCondition'},
        'snooze_filter': {'key': 'snoozeFilter', 'type': 'AlertSnoozeCondition'},
        'value_filter': {'key': 'valueFilter', 'type': 'ValueCondition'},
    }

    def __init__(
        self,
        *,
        anomaly_detection_configuration_id: str,
        anomaly_scope_type: Union[str, "MetricAnomalyAlertScopeType"],
        negation_operation: Optional[bool] = False,
        dimension_anomaly_scope: Optional["DimensionGroupIdentity"] = None,
        top_n_anomaly_scope: Optional["TopNGroupScope"] = None,
        severity_filter: Optional["SeverityCondition"] = None,
        snooze_filter: Optional["AlertSnoozeCondition"] = None,
        value_filter: Optional["ValueCondition"] = None,
        **kwargs
    ):
        """
        :keyword anomaly_detection_configuration_id: Required. Anomaly detection configuration unique
         id.
        :paramtype anomaly_detection_configuration_id: str
        :keyword anomaly_scope_type: Required. Anomaly scope. Possible values include: "WholeSeries",
         "SeriesGroup", "TopN".
        :paramtype anomaly_scope_type: str or
         ~azure.ai.metricsadvisor.models.MetricAnomalyAlertScopeType
        :keyword negation_operation: Negation operation.
        :paramtype negation_operation: bool
        :keyword dimension_anomaly_scope:
        :paramtype dimension_anomaly_scope: ~azure.ai.metricsadvisor.models.DimensionGroupIdentity
        :keyword top_n_anomaly_scope:
        :paramtype top_n_anomaly_scope: ~azure.ai.metricsadvisor.models.TopNGroupScope
        :keyword severity_filter:
        :paramtype severity_filter: ~azure.ai.metricsadvisor.models.SeverityCondition
        :keyword snooze_filter:
        :paramtype snooze_filter: ~azure.ai.metricsadvisor.models.AlertSnoozeCondition
        :keyword value_filter:
        :paramtype value_filter: ~azure.ai.metricsadvisor.models.ValueCondition
        """
        super(_MetricAlertConfigurationGenerated, self).__init__(**kwargs)
        self.anomaly_detection_configuration_id = anomaly_detection_configuration_id
        self.anomaly_scope_type = anomaly_scope_type
        self.negation_operation = negation_operation
        self.dimension_anomaly_scope = dimension_anomaly_scope
        self.top_n_anomaly_scope = top_n_anomaly_scope
        self.severity_filter = severity_filter
        self.snooze_filter = snooze_filter
        self.value_filter = value_filter

class MetricAlertConfiguration(MetricAlertConfigurationCustomization, _MetricAlertConfigurationGenerated):
    pass


class _MetricDataItemGenerated(msrest.serialization.Model):
    """MetricDataItem.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar id:
    :vartype id: ~azure.ai.metricsadvisor.models.MetricSeriesDefinition
    :ivar timestamp_list: timestamps of the data related to this time series.
    :vartype timestamp_list: list[~datetime.datetime]
    :ivar value_list: values of the data related to this time series.
    :vartype value_list: list[float]
    """

    _validation = {
        'timestamp_list': {'readonly': True},
        'value_list': {'readonly': True},
    }

    _attribute_map = {
        'id': {'key': 'id', 'type': 'MetricSeriesDefinition'},
        'timestamp_list': {'key': 'timestampList', 'type': '[iso-8601]'},
        'value_list': {'key': 'valueList', 'type': '[float]'},
    }

    def __init__(
        self,
        *,
        id: Optional["MetricSeriesDefinition"] = None,
        **kwargs
    ):
        """
        :keyword id:
        :paramtype id: ~azure.ai.metricsadvisor.models.MetricSeriesDefinition
        """
        super(_MetricDataItemGenerated, self).__init__(**kwargs)
        self.id = id
        self.timestamp_list = None
        self.value_list = None

class MetricDataItem(MetricDataItemCustomization, _MetricDataItemGenerated):
    pass


class _MetricDataListGenerated(msrest.serialization.Model):
    """MetricDataList.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar value:
    :vartype value: list[~azure.ai.metricsadvisor.models.MetricDataItem]
    """

    _validation = {
        'value': {'readonly': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[MetricDataItem]'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_MetricDataListGenerated, self).__init__(**kwargs)
        self.value = None

class MetricDataList(MetricDataListCustomization, _MetricDataListGenerated):
    pass


class _MetricDataQueryOptionsGenerated(msrest.serialization.Model):
    """MetricDataQueryOptions.

    All required parameters must be populated in order to send to Azure.

    :ivar start_time: Required. start time of query a time series data, and format should be
     yyyy-MM-ddThh:mm:ssZ. The maximum number of data points (series number * time range) is 10000.
    :vartype start_time: ~datetime.datetime
    :ivar end_time: Required. start time of query a time series data, and format should be
     yyyy-MM-ddThh:mm:ssZ. The maximum number of data points (series number * time range) is 10000.
    :vartype end_time: ~datetime.datetime
    :ivar series: Required. query specific series. The maximum number of series is 100.
    :vartype series: list[dict[str, str]]
    """

    _validation = {
        'start_time': {'required': True},
        'end_time': {'required': True},
        'series': {'required': True},
    }

    _attribute_map = {
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'endTime', 'type': 'iso-8601'},
        'series': {'key': 'series', 'type': '[{str}]'},
    }

    def __init__(
        self,
        *,
        start_time: datetime.datetime,
        end_time: datetime.datetime,
        series: List[Dict[str, str]],
        **kwargs
    ):
        """
        :keyword start_time: Required. start time of query a time series data, and format should be
         yyyy-MM-ddThh:mm:ssZ. The maximum number of data points (series number * time range) is 10000.
        :paramtype start_time: ~datetime.datetime
        :keyword end_time: Required. start time of query a time series data, and format should be
         yyyy-MM-ddThh:mm:ssZ. The maximum number of data points (series number * time range) is 10000.
        :paramtype end_time: ~datetime.datetime
        :keyword series: Required. query specific series. The maximum number of series is 100.
        :paramtype series: list[dict[str, str]]
        """
        super(_MetricDataQueryOptionsGenerated, self).__init__(**kwargs)
        self.start_time = start_time
        self.end_time = end_time
        self.series = series

class MetricDataQueryOptions(MetricDataQueryOptionsCustomization, _MetricDataQueryOptionsGenerated):
    pass


class _MetricDimensionListGenerated(msrest.serialization.Model):
    """MetricDimensionList.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar next_link:
    :vartype next_link: str
    :ivar value:
    :vartype value: list[str]
    """

    _validation = {
        'next_link': {'readonly': True},
        'value': {'readonly': True, 'unique': True},
    }

    _attribute_map = {
        'next_link': {'key': '@nextLink', 'type': 'str'},
        'value': {'key': 'value', 'type': '[str]'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_MetricDimensionListGenerated, self).__init__(**kwargs)
        self.next_link = None
        self.value = None

class MetricDimensionList(MetricDimensionListCustomization, _MetricDimensionListGenerated):
    pass


class _MetricDimensionQueryOptionsGenerated(msrest.serialization.Model):
    """MetricDimensionQueryOptions.

    All required parameters must be populated in order to send to Azure.

    :ivar dimension_name: Required. dimension name.
    :vartype dimension_name: str
    :ivar dimension_value_filter: dimension value to be filtered.
    :vartype dimension_value_filter: str
    """

    _validation = {
        'dimension_name': {'required': True},
    }

    _attribute_map = {
        'dimension_name': {'key': 'dimensionName', 'type': 'str'},
        'dimension_value_filter': {'key': 'dimensionValueFilter', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        dimension_name: str,
        dimension_value_filter: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword dimension_name: Required. dimension name.
        :paramtype dimension_name: str
        :keyword dimension_value_filter: dimension value to be filtered.
        :paramtype dimension_value_filter: str
        """
        super(_MetricDimensionQueryOptionsGenerated, self).__init__(**kwargs)
        self.dimension_name = dimension_name
        self.dimension_value_filter = dimension_value_filter

class MetricDimensionQueryOptions(MetricDimensionQueryOptionsCustomization, _MetricDimensionQueryOptionsGenerated):
    pass

class MetricFeedback(dict):
    """Feedback base class
    Variables are only populated by the server, and will be ignored when sending a request.
    All required parameters must be populated in order to send to Azure.
    :ivar feedback_type: Required. feedback type.Constant filled by server.  Possible values
     include: "Anomaly", "ChangePoint", "Period", "Comment".
    :vartype feedback_type: str or ~azure.ai.metricsadvisor.models.FeedbackType
    :ivar str id: feedback unique id.
    :ivar created_time: feedback created time.
    :vartype created_time: ~datetime.datetime
    :ivar user_principal: user who gives this feedback.
    :vartype user_principal: str
    :ivar str metric_id: Required. metric unique id.
    :ivar dict[str, str] dimension_key: Required. metric dimension filter.
    """

    _attribute_map = {
        "feedback_type": {"key": "feedbackType", "type": "str"},
        "id": {"key": "id", "type": "str"},
        "created_time": {"key": "createdTime", "type": "iso-8601"},
        "user_principal": {"key": "userPrincipal", "type": "str"},
        "metric_id": {"key": "metricId", "type": "str"},
        "dimension_key": {"key": "dimensionKey", "type": "{str}"},
    }

    def __init__(self, feedback_type, metric_id, dimension_key, **kwargs):
        super(MetricFeedback, self).__init__(**kwargs)
        self.feedback_type = feedback_type  # type: str
        self.id = kwargs.get("id", None)
        self.created_time = kwargs.get("created_time", None)
        self.user_principal = kwargs.get("user_principal", None)
        self.metric_id = metric_id
        self.dimension_key = dimension_key

    def __repr__(self):
        return (
            "MetricFeedback(feedback_type={}, id={}, created_time={}, user_principal={}, metric_id={}, "
            "dimension_key={})".format(
                self.feedback_type,
                self.id,
                self.created_time,
                self.user_principal,
                self.metric_id,
                self.dimension_key,
            )[:1024]
        )

class _MetricFeedbackFilterGenerated(msrest.serialization.Model):
    """MetricFeedbackFilter.

    All required parameters must be populated in order to send to Azure.

    :ivar metric_id: Required. filter feedbacks by metric id.
    :vartype metric_id: str
    :ivar dimension_filter:
    :vartype dimension_filter: ~azure.ai.metricsadvisor.models.FeedbackDimensionFilter
    :ivar feedback_type: filter feedbacks by type. Possible values include: "Anomaly",
     "ChangePoint", "Period", "Comment".
    :vartype feedback_type: str or ~azure.ai.metricsadvisor.models.FeedbackType
    :ivar start_time: start time filter under chosen time mode.
    :vartype start_time: ~datetime.datetime
    :ivar end_time: end time filter under chosen time mode.
    :vartype end_time: ~datetime.datetime
    :ivar time_mode: time mode to filter feedback. Possible values include: "MetricTimestamp",
     "FeedbackCreatedTime".
    :vartype time_mode: str or ~azure.ai.metricsadvisor.models.FeedbackQueryTimeMode
    """

    _validation = {
        'metric_id': {'required': True},
    }

    _attribute_map = {
        'metric_id': {'key': 'metricId', 'type': 'str'},
        'dimension_filter': {'key': 'dimensionFilter', 'type': 'FeedbackDimensionFilter'},
        'feedback_type': {'key': 'feedbackType', 'type': 'str'},
        'start_time': {'key': 'startTime', 'type': 'iso-8601'},
        'end_time': {'key': 'endTime', 'type': 'iso-8601'},
        'time_mode': {'key': 'timeMode', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        metric_id: str,
        dimension_filter: Optional["FeedbackDimensionFilter"] = None,
        feedback_type: Optional[Union[str, "FeedbackType"]] = None,
        start_time: Optional[datetime.datetime] = None,
        end_time: Optional[datetime.datetime] = None,
        time_mode: Optional[Union[str, "FeedbackQueryTimeMode"]] = None,
        **kwargs
    ):
        """
        :keyword metric_id: Required. filter feedbacks by metric id.
        :paramtype metric_id: str
        :keyword dimension_filter:
        :paramtype dimension_filter: ~azure.ai.metricsadvisor.models.FeedbackDimensionFilter
        :keyword feedback_type: filter feedbacks by type. Possible values include: "Anomaly",
         "ChangePoint", "Period", "Comment".
        :paramtype feedback_type: str or ~azure.ai.metricsadvisor.models.FeedbackType
        :keyword start_time: start time filter under chosen time mode.
        :paramtype start_time: ~datetime.datetime
        :keyword end_time: end time filter under chosen time mode.
        :paramtype end_time: ~datetime.datetime
        :keyword time_mode: time mode to filter feedback. Possible values include: "MetricTimestamp",
         "FeedbackCreatedTime".
        :paramtype time_mode: str or ~azure.ai.metricsadvisor.models.FeedbackQueryTimeMode
        """
        super(_MetricFeedbackFilterGenerated, self).__init__(**kwargs)
        self.metric_id = metric_id
        self.dimension_filter = dimension_filter
        self.feedback_type = feedback_type
        self.start_time = start_time
        self.end_time = end_time
        self.time_mode = time_mode

class MetricFeedbackFilter(MetricFeedbackFilterCustomization, _MetricFeedbackFilterGenerated):
    pass


class _MetricFeedbackListGenerated(msrest.serialization.Model):
    """MetricFeedbackList.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar next_link:
    :vartype next_link: str
    :ivar value:
    :vartype value: list[~azure.ai.metricsadvisor.models.MetricFeedback]
    """

    _validation = {
        'next_link': {'readonly': True},
        'value': {'readonly': True},
    }

    _attribute_map = {
        'next_link': {'key': '@nextLink', 'type': 'str'},
        'value': {'key': 'value', 'type': '[MetricFeedback]'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_MetricFeedbackListGenerated, self).__init__(**kwargs)
        self.next_link = None
        self.value = None

class MetricFeedbackList(MetricFeedbackListCustomization, _MetricFeedbackListGenerated):
    pass


class _MetricSeriesDefinitionGenerated(msrest.serialization.Model):
    """MetricSeriesDefinition.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar metric_id: metric unique id.
    :vartype metric_id: str
    :ivar dimension: dimension name and value pair.
    :vartype dimension: dict[str, str]
    """

    _validation = {
        'metric_id': {'readonly': True},
        'dimension': {'readonly': True},
    }

    _attribute_map = {
        'metric_id': {'key': 'metricId', 'type': 'str'},
        'dimension': {'key': 'dimension', 'type': '{str}'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_MetricSeriesDefinitionGenerated, self).__init__(**kwargs)
        self.metric_id = None
        self.dimension = None

class MetricSeriesDefinition(MetricSeriesDefinitionCustomization, _MetricSeriesDefinitionGenerated):
    pass


class _MetricSeriesListGenerated(msrest.serialization.Model):
    """MetricSeriesList.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar next_link:
    :vartype next_link: str
    :ivar value:
    :vartype value: list[~azure.ai.metricsadvisor.models.MetricSeriesDefinition]
    """

    _validation = {
        'next_link': {'readonly': True},
        'value': {'readonly': True},
    }

    _attribute_map = {
        'next_link': {'key': '@nextLink', 'type': 'str'},
        'value': {'key': 'value', 'type': '[MetricSeriesDefinition]'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_MetricSeriesListGenerated, self).__init__(**kwargs)
        self.next_link = None
        self.value = None

class MetricSeriesList(MetricSeriesListCustomization, _MetricSeriesListGenerated):
    pass


class _MetricSeriesQueryOptionsGenerated(msrest.serialization.Model):
    """MetricSeriesQueryOptions.

    All required parameters must be populated in order to send to Azure.

    :ivar active_since: Required. query series ingested after this time, the format should be
     yyyy-MM-ddTHH:mm:ssZ.
    :vartype active_since: ~datetime.datetime
    :ivar dimension_filter: filter specific dimension name and values.
    :vartype dimension_filter: dict[str, list[str]]
    """

    _validation = {
        'active_since': {'required': True},
    }

    _attribute_map = {
        'active_since': {'key': 'activeSince', 'type': 'iso-8601'},
        'dimension_filter': {'key': 'dimensionFilter', 'type': '{[str]}'},
    }

    def __init__(
        self,
        *,
        active_since: datetime.datetime,
        dimension_filter: Optional[Dict[str, List[str]]] = None,
        **kwargs
    ):
        """
        :keyword active_since: Required. query series ingested after this time, the format should be
         yyyy-MM-ddTHH:mm:ssZ.
        :paramtype active_since: ~datetime.datetime
        :keyword dimension_filter: filter specific dimension name and values.
        :paramtype dimension_filter: dict[str, list[str]]
        """
        super(_MetricSeriesQueryOptionsGenerated, self).__init__(**kwargs)
        self.active_since = active_since
        self.dimension_filter = dimension_filter

class MetricSeriesQueryOptions(MetricSeriesQueryOptionsCustomization, _MetricSeriesQueryOptionsGenerated):
    pass


class _MongoDBDataFeedGenerated(_DataFeedGenerated):
    """MongoDBDataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter: Required.
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.MongoDBParameter
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
        'data_source_parameter': {'required': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'MongoDBParameter'},
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_source_parameter: "MongoDBParameter",
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter: Required.
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.MongoDBParameter
        """
        super(_MongoDBDataFeedGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, granularity_name=granularity_name, granularity_amount=granularity_amount, metrics=metrics, dimension=dimension, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'MongoDB'  # type: str
        self.data_source_parameter = data_source_parameter

class MongoDBDataFeed(MongoDBDataFeedCustomization, DataFeed, _MongoDBDataFeedGenerated):
    pass


class _MongoDBDataFeedPatchGenerated(_DataFeedPatchGenerated):
    """MongoDBDataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter:
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.MongoDBParameterPatch
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'MongoDBParameterPatch'},
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        data_source_parameter: Optional["MongoDBParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter:
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.MongoDBParameterPatch
        """
        super(_MongoDBDataFeedPatchGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, status=status, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'MongoDB'  # type: str
        self.data_source_parameter = data_source_parameter

class MongoDBDataFeedPatch(MongoDBDataFeedPatchCustomization, DataFeedPatch, _MongoDBDataFeedPatchGenerated):
    pass


class _MongoDBParameterGenerated(msrest.serialization.Model):
    """MongoDBParameter.

    All required parameters must be populated in order to send to Azure.

    :ivar connection_string: The connection string of this MongoDB.
    :vartype connection_string: str
    :ivar database: A database name in this MongoDB.
    :vartype database: str
    :ivar command: Required. The script to query this database.
    :vartype command: str
    """

    _validation = {
        'command': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'database': {'key': 'database', 'type': 'str'},
        'command': {'key': 'command', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        command: str,
        connection_string: Optional[str] = None,
        database: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this MongoDB.
        :paramtype connection_string: str
        :keyword database: A database name in this MongoDB.
        :paramtype database: str
        :keyword command: Required. The script to query this database.
        :paramtype command: str
        """
        super(_MongoDBParameterGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.database = database
        self.command = command

class MongoDBParameter(MongoDBParameterCustomization, _MongoDBParameterGenerated):
    pass


class _MongoDBParameterPatchGenerated(msrest.serialization.Model):
    """MongoDBParameterPatch.

    :ivar connection_string: The connection string of this MongoDB.
    :vartype connection_string: str
    :ivar database: A database name in this MongoDB.
    :vartype database: str
    :ivar command: The script to query this database.
    :vartype command: str
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'database': {'key': 'database', 'type': 'str'},
        'command': {'key': 'command', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional[str] = None,
        database: Optional[str] = None,
        command: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this MongoDB.
        :paramtype connection_string: str
        :keyword database: A database name in this MongoDB.
        :paramtype database: str
        :keyword command: The script to query this database.
        :paramtype command: str
        """
        super(_MongoDBParameterPatchGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.database = database
        self.command = command

class MongoDBParameterPatch(MongoDBParameterPatchCustomization, _MongoDBParameterPatchGenerated):
    pass


class _MySqlDataFeedGenerated(_DataFeedGenerated):
    """MySqlDataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter: Required.
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.SqlSourceParameter
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
        'data_source_parameter': {'required': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'SqlSourceParameter'},
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_source_parameter: "SqlSourceParameter",
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter: Required.
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.SqlSourceParameter
        """
        super(_MySqlDataFeedGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, granularity_name=granularity_name, granularity_amount=granularity_amount, metrics=metrics, dimension=dimension, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'MySql'  # type: str
        self.data_source_parameter = data_source_parameter

class MySqlDataFeed(MySqlDataFeedCustomization, DataFeed, _MySqlDataFeedGenerated):
    pass


class _MySqlDataFeedPatchGenerated(_DataFeedPatchGenerated):
    """MySqlDataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter:
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.SQLSourceParameterPatch
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'SQLSourceParameterPatch'},
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        data_source_parameter: Optional["SQLSourceParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter:
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.SQLSourceParameterPatch
        """
        super(_MySqlDataFeedPatchGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, status=status, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'MySql'  # type: str
        self.data_source_parameter = data_source_parameter

class MySqlDataFeedPatch(MySqlDataFeedPatchCustomization, DataFeedPatch, _MySqlDataFeedPatchGenerated):
    pass

class _PeriodFeedbackValueGenerated(msrest.serialization.Model):
    """PeriodFeedbackValue.

    All required parameters must be populated in order to send to Azure.

    :ivar period_type: Required. the type of setting period. Possible values include: "AutoDetect",
     "AssignValue".
    :vartype period_type: str or ~azure.ai.metricsadvisor.models.PeriodType
    :ivar period_value: Required. the number of intervals a period contains, when no period set to
     0.
    :vartype period_value: int
    """

    _validation = {
        'period_type': {'required': True},
        'period_value': {'required': True},
    }

    _attribute_map = {
        'period_type': {'key': 'periodType', 'type': 'str'},
        'period_value': {'key': 'periodValue', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        period_type: Union[str, "PeriodType"],
        period_value: int,
        **kwargs
    ):
        """
        :keyword period_type: Required. the type of setting period. Possible values include:
         "AutoDetect", "AssignValue".
        :paramtype period_type: str or ~azure.ai.metricsadvisor.models.PeriodType
        :keyword period_value: Required. the number of intervals a period contains, when no period set
         to 0.
        :paramtype period_value: int
        """
        super(_PeriodFeedbackValueGenerated, self).__init__(**kwargs)
        self.period_type = period_type
        self.period_value = period_value

class PeriodFeedbackValue(PeriodFeedbackValueCustomization, _PeriodFeedbackValueGenerated):
    pass


class _PostgreSqlDataFeedGenerated(_DataFeedGenerated):
    """PostgreSqlDataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter: Required.
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.SqlSourceParameter
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
        'data_source_parameter': {'required': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'SqlSourceParameter'},
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_source_parameter: "SqlSourceParameter",
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter: Required.
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.SqlSourceParameter
        """
        super(_PostgreSqlDataFeedGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, granularity_name=granularity_name, granularity_amount=granularity_amount, metrics=metrics, dimension=dimension, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'PostgreSql'  # type: str
        self.data_source_parameter = data_source_parameter

class PostgreSqlDataFeed(PostgreSqlDataFeedCustomization, DataFeed, _PostgreSqlDataFeedGenerated):
    pass


class _PostgreSqlDataFeedPatchGenerated(_DataFeedPatchGenerated):
    """PostgreSqlDataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter:
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.SQLSourceParameterPatch
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'SQLSourceParameterPatch'},
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        data_source_parameter: Optional["SQLSourceParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter:
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.SQLSourceParameterPatch
        """
        super(_PostgreSqlDataFeedPatchGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, status=status, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'PostgreSql'  # type: str
        self.data_source_parameter = data_source_parameter

class PostgreSqlDataFeedPatch(PostgreSqlDataFeedPatchCustomization, DataFeedPatch, _PostgreSqlDataFeedPatchGenerated):
    pass


class _RootCauseGenerated(msrest.serialization.Model):
    """RootCause.

    All required parameters must be populated in order to send to Azure.

    :ivar root_cause: Required.
    :vartype root_cause: ~azure.ai.metricsadvisor.models.DimensionGroupIdentity
    :ivar path: Required. drilling down path from query anomaly to root cause.
    :vartype path: list[str]
    :ivar score: Required. score of the root cause.
    :vartype score: float
    :ivar description: Required. description of the root cause.
    :vartype description: str
    """

    _validation = {
        'root_cause': {'required': True},
        'path': {'required': True},
        'score': {'required': True},
        'description': {'required': True},
    }

    _attribute_map = {
        'root_cause': {'key': 'rootCause', 'type': 'DimensionGroupIdentity'},
        'path': {'key': 'path', 'type': '[str]'},
        'score': {'key': 'score', 'type': 'float'},
        'description': {'key': 'description', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        root_cause: "DimensionGroupIdentity",
        path: List[str],
        score: float,
        description: str,
        **kwargs
    ):
        """
        :keyword root_cause: Required.
        :paramtype root_cause: ~azure.ai.metricsadvisor.models.DimensionGroupIdentity
        :keyword path: Required. drilling down path from query anomaly to root cause.
        :paramtype path: list[str]
        :keyword score: Required. score of the root cause.
        :paramtype score: float
        :keyword description: Required. description of the root cause.
        :paramtype description: str
        """
        super(_RootCauseGenerated, self).__init__(**kwargs)
        self.root_cause = root_cause
        self.path = path
        self.score = score
        self.description = description

class RootCause(RootCauseCustomization, _RootCauseGenerated):
    pass


class _RootCauseListGenerated(msrest.serialization.Model):
    """RootCauseList.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required.
    :vartype value: list[~azure.ai.metricsadvisor.models.RootCause]
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[RootCause]'},
    }

    def __init__(
        self,
        *,
        value: List["RootCause"],
        **kwargs
    ):
        """
        :keyword value: Required.
        :paramtype value: list[~azure.ai.metricsadvisor.models.RootCause]
        """
        super(_RootCauseListGenerated, self).__init__(**kwargs)
        self.value = value

class RootCauseList(RootCauseListCustomization, _RootCauseListGenerated):
    pass


class _SeriesConfigurationGenerated(msrest.serialization.Model):
    """SeriesConfiguration.

    All required parameters must be populated in order to send to Azure.

    :ivar series: Required.
    :vartype series: ~azure.ai.metricsadvisor.models.SeriesIdentity
    :ivar condition_operator: condition operator

     should be specified when combining multiple detection conditions. Possible values include:
     "AND", "OR".
    :vartype condition_operator: str or
     ~azure.ai.metricsadvisor.models.AnomalyDetectionConfigurationLogicType
    :ivar smart_detection_condition:
    :vartype smart_detection_condition: ~azure.ai.metricsadvisor.models.SmartDetectionCondition
    :ivar hard_threshold_condition:
    :vartype hard_threshold_condition: ~azure.ai.metricsadvisor.models.HardThresholdCondition
    :ivar change_threshold_condition:
    :vartype change_threshold_condition: ~azure.ai.metricsadvisor.models.ChangeThresholdCondition
    """

    _validation = {
        'series': {'required': True},
    }

    _attribute_map = {
        'series': {'key': 'series', 'type': 'SeriesIdentity'},
        'condition_operator': {'key': 'conditionOperator', 'type': 'str'},
        'smart_detection_condition': {'key': 'smartDetectionCondition', 'type': 'SmartDetectionCondition'},
        'hard_threshold_condition': {'key': 'hardThresholdCondition', 'type': 'HardThresholdCondition'},
        'change_threshold_condition': {'key': 'changeThresholdCondition', 'type': 'ChangeThresholdCondition'},
    }

    def __init__(
        self,
        *,
        series: "SeriesIdentity",
        condition_operator: Optional[Union[str, "AnomalyDetectionConfigurationLogicType"]] = None,
        smart_detection_condition: Optional["SmartDetectionCondition"] = None,
        hard_threshold_condition: Optional["HardThresholdCondition"] = None,
        change_threshold_condition: Optional["ChangeThresholdCondition"] = None,
        **kwargs
    ):
        """
        :keyword series: Required.
        :paramtype series: ~azure.ai.metricsadvisor.models.SeriesIdentity
        :keyword condition_operator: condition operator

         should be specified when combining multiple detection conditions. Possible values include:
         "AND", "OR".
        :paramtype condition_operator: str or
         ~azure.ai.metricsadvisor.models.AnomalyDetectionConfigurationLogicType
        :keyword smart_detection_condition:
        :paramtype smart_detection_condition: ~azure.ai.metricsadvisor.models.SmartDetectionCondition
        :keyword hard_threshold_condition:
        :paramtype hard_threshold_condition: ~azure.ai.metricsadvisor.models.HardThresholdCondition
        :keyword change_threshold_condition:
        :paramtype change_threshold_condition: ~azure.ai.metricsadvisor.models.ChangeThresholdCondition
        """
        super(_SeriesConfigurationGenerated, self).__init__(**kwargs)
        self.series = series
        self.condition_operator = condition_operator
        self.smart_detection_condition = smart_detection_condition
        self.hard_threshold_condition = hard_threshold_condition
        self.change_threshold_condition = change_threshold_condition

class SeriesConfiguration(SeriesConfigurationCustomization, _SeriesConfigurationGenerated):
    pass


class _SeriesIdentityGenerated(msrest.serialization.Model):
    """SeriesIdentity.

    All required parameters must be populated in order to send to Azure.

    :ivar dimension: Required. dimension specified for series.
    :vartype dimension: dict[str, str]
    """

    _validation = {
        'dimension': {'required': True},
    }

    _attribute_map = {
        'dimension': {'key': 'dimension', 'type': '{str}'},
    }

    def __init__(
        self,
        *,
        dimension: Dict[str, str],
        **kwargs
    ):
        """
        :keyword dimension: Required. dimension specified for series.
        :paramtype dimension: dict[str, str]
        """
        super(_SeriesIdentityGenerated, self).__init__(**kwargs)
        self.dimension = dimension

class SeriesIdentity(SeriesIdentityCustomization, _SeriesIdentityGenerated):
    pass


class _SeriesResultGenerated(msrest.serialization.Model):
    """SeriesResult.

    All required parameters must be populated in order to send to Azure.

    :ivar series: Required.
    :vartype series: ~azure.ai.metricsadvisor.models.SeriesIdentity
    :ivar timestamp_list: Required. timestamps of the series.
    :vartype timestamp_list: list[~datetime.datetime]
    :ivar value_list: Required. values of the series.
    :vartype value_list: list[float]
    :ivar is_anomaly_list: Required. whether points of the series are anomalies.
    :vartype is_anomaly_list: list[bool]
    :ivar period_list: Required. period calculated on each point of the series.
    :vartype period_list: list[int]
    :ivar expected_value_list: Required. expected values of the series given by smart detector.
    :vartype expected_value_list: list[float]
    :ivar lower_boundary_list: Required. lower boundary list of the series given by smart detector.
    :vartype lower_boundary_list: list[float]
    :ivar upper_boundary_list: Required. upper boundary list of the series given by smart detector.
    :vartype upper_boundary_list: list[float]
    """

    _validation = {
        'series': {'required': True},
        'timestamp_list': {'required': True},
        'value_list': {'required': True},
        'is_anomaly_list': {'required': True},
        'period_list': {'required': True},
        'expected_value_list': {'required': True},
        'lower_boundary_list': {'required': True},
        'upper_boundary_list': {'required': True},
    }

    _attribute_map = {
        'series': {'key': 'series', 'type': 'SeriesIdentity'},
        'timestamp_list': {'key': 'timestampList', 'type': '[iso-8601]'},
        'value_list': {'key': 'valueList', 'type': '[float]'},
        'is_anomaly_list': {'key': 'isAnomalyList', 'type': '[bool]'},
        'period_list': {'key': 'periodList', 'type': '[int]'},
        'expected_value_list': {'key': 'expectedValueList', 'type': '[float]'},
        'lower_boundary_list': {'key': 'lowerBoundaryList', 'type': '[float]'},
        'upper_boundary_list': {'key': 'upperBoundaryList', 'type': '[float]'},
    }

    def __init__(
        self,
        *,
        series: "SeriesIdentity",
        timestamp_list: List[datetime.datetime],
        value_list: List[float],
        is_anomaly_list: List[bool],
        period_list: List[int],
        expected_value_list: List[float],
        lower_boundary_list: List[float],
        upper_boundary_list: List[float],
        **kwargs
    ):
        """
        :keyword series: Required.
        :paramtype series: ~azure.ai.metricsadvisor.models.SeriesIdentity
        :keyword timestamp_list: Required. timestamps of the series.
        :paramtype timestamp_list: list[~datetime.datetime]
        :keyword value_list: Required. values of the series.
        :paramtype value_list: list[float]
        :keyword is_anomaly_list: Required. whether points of the series are anomalies.
        :paramtype is_anomaly_list: list[bool]
        :keyword period_list: Required. period calculated on each point of the series.
        :paramtype period_list: list[int]
        :keyword expected_value_list: Required. expected values of the series given by smart detector.
        :paramtype expected_value_list: list[float]
        :keyword lower_boundary_list: Required. lower boundary list of the series given by smart
         detector.
        :paramtype lower_boundary_list: list[float]
        :keyword upper_boundary_list: Required. upper boundary list of the series given by smart
         detector.
        :paramtype upper_boundary_list: list[float]
        """
        super(_SeriesResultGenerated, self).__init__(**kwargs)
        self.series = series
        self.timestamp_list = timestamp_list
        self.value_list = value_list
        self.is_anomaly_list = is_anomaly_list
        self.period_list = period_list
        self.expected_value_list = expected_value_list
        self.lower_boundary_list = lower_boundary_list
        self.upper_boundary_list = upper_boundary_list

class SeriesResult(SeriesResultCustomization, _SeriesResultGenerated):
    pass


class _SeriesResultListGenerated(msrest.serialization.Model):
    """SeriesResultList.

    All required parameters must be populated in order to send to Azure.

    :ivar value: Required.
    :vartype value: list[~azure.ai.metricsadvisor.models.SeriesResult]
    """

    _validation = {
        'value': {'required': True},
    }

    _attribute_map = {
        'value': {'key': 'value', 'type': '[SeriesResult]'},
    }

    def __init__(
        self,
        *,
        value: List["SeriesResult"],
        **kwargs
    ):
        """
        :keyword value: Required.
        :paramtype value: list[~azure.ai.metricsadvisor.models.SeriesResult]
        """
        super(_SeriesResultListGenerated, self).__init__(**kwargs)
        self.value = value

class SeriesResultList(SeriesResultListCustomization, _SeriesResultListGenerated):
    pass


class _ServicePrincipalCredentialGenerated(_DataSourceCredentialGenerated):
    """ServicePrincipalCredential.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_credential_type: Required. Type of data source credential.Constant filled by
     server. Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype data_source_credential_type: str or
     ~azure.ai.metricsadvisor.models.DataSourceCredentialType
    :ivar data_source_credential_id: Unique id of data source credential.
    :vartype data_source_credential_id: str
    :ivar data_source_credential_name: Required. Name of data source credential.
    :vartype data_source_credential_name: str
    :ivar data_source_credential_description: Description of data source credential.
    :vartype data_source_credential_description: str
    :ivar parameters: Required.
    :vartype parameters: ~azure.ai.metricsadvisor.models.ServicePrincipalParam
    """

    _validation = {
        'data_source_credential_type': {'required': True},
        'data_source_credential_id': {'readonly': True},
        'data_source_credential_name': {'required': True},
        'parameters': {'required': True},
    }

    _attribute_map = {
        'data_source_credential_type': {'key': 'dataSourceCredentialType', 'type': 'str'},
        'data_source_credential_id': {'key': 'dataSourceCredentialId', 'type': 'str'},
        'data_source_credential_name': {'key': 'dataSourceCredentialName', 'type': 'str'},
        'data_source_credential_description': {'key': 'dataSourceCredentialDescription', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': 'ServicePrincipalParam'},
    }

    def __init__(
        self,
        *,
        data_source_credential_name: str,
        parameters: "ServicePrincipalParam",
        data_source_credential_description: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_source_credential_name: Required. Name of data source credential.
        :paramtype data_source_credential_name: str
        :keyword data_source_credential_description: Description of data source credential.
        :paramtype data_source_credential_description: str
        :keyword parameters: Required.
        :paramtype parameters: ~azure.ai.metricsadvisor.models.ServicePrincipalParam
        """
        super(_ServicePrincipalCredentialGenerated, self).__init__(data_source_credential_name=data_source_credential_name, data_source_credential_description=data_source_credential_description, **kwargs)
        self.data_source_credential_type = 'ServicePrincipal'  # type: str
        self.parameters = parameters

class ServicePrincipalCredential(ServicePrincipalCredentialCustomization, DataSourceCredential, _ServicePrincipalCredentialGenerated):
    pass


class _ServicePrincipalCredentialPatchGenerated(_DataSourceCredentialPatchGenerated):
    """ServicePrincipalCredentialPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_credential_type: Required. Type of data source credential.Constant filled by
     server. Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype data_source_credential_type: str or
     ~azure.ai.metricsadvisor.models.DataSourceCredentialType
    :ivar data_source_credential_name: Name of data source credential.
    :vartype data_source_credential_name: str
    :ivar data_source_credential_description: Description of data source credential.
    :vartype data_source_credential_description: str
    :ivar parameters:
    :vartype parameters: ~azure.ai.metricsadvisor.models.ServicePrincipalParamPatch
    """

    _validation = {
        'data_source_credential_type': {'required': True},
    }

    _attribute_map = {
        'data_source_credential_type': {'key': 'dataSourceCredentialType', 'type': 'str'},
        'data_source_credential_name': {'key': 'dataSourceCredentialName', 'type': 'str'},
        'data_source_credential_description': {'key': 'dataSourceCredentialDescription', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': 'ServicePrincipalParamPatch'},
    }

    def __init__(
        self,
        *,
        data_source_credential_name: Optional[str] = None,
        data_source_credential_description: Optional[str] = None,
        parameters: Optional["ServicePrincipalParamPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_source_credential_name: Name of data source credential.
        :paramtype data_source_credential_name: str
        :keyword data_source_credential_description: Description of data source credential.
        :paramtype data_source_credential_description: str
        :keyword parameters:
        :paramtype parameters: ~azure.ai.metricsadvisor.models.ServicePrincipalParamPatch
        """
        super(_ServicePrincipalCredentialPatchGenerated, self).__init__(data_source_credential_name=data_source_credential_name, data_source_credential_description=data_source_credential_description, **kwargs)
        self.data_source_credential_type = 'ServicePrincipal'  # type: str
        self.parameters = parameters

class ServicePrincipalCredentialPatch(ServicePrincipalCredentialPatchCustomization, DataSourceCredentialPatch, _ServicePrincipalCredentialPatchGenerated):
    pass


class _ServicePrincipalInKVCredentialGenerated(_DataSourceCredentialGenerated):
    """ServicePrincipalInKVCredential.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_credential_type: Required. Type of data source credential.Constant filled by
     server. Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype data_source_credential_type: str or
     ~azure.ai.metricsadvisor.models.DataSourceCredentialType
    :ivar data_source_credential_id: Unique id of data source credential.
    :vartype data_source_credential_id: str
    :ivar data_source_credential_name: Required. Name of data source credential.
    :vartype data_source_credential_name: str
    :ivar data_source_credential_description: Description of data source credential.
    :vartype data_source_credential_description: str
    :ivar parameters: Required.
    :vartype parameters: ~azure.ai.metricsadvisor.models.ServicePrincipalInKVParam
    """

    _validation = {
        'data_source_credential_type': {'required': True},
        'data_source_credential_id': {'readonly': True},
        'data_source_credential_name': {'required': True},
        'parameters': {'required': True},
    }

    _attribute_map = {
        'data_source_credential_type': {'key': 'dataSourceCredentialType', 'type': 'str'},
        'data_source_credential_id': {'key': 'dataSourceCredentialId', 'type': 'str'},
        'data_source_credential_name': {'key': 'dataSourceCredentialName', 'type': 'str'},
        'data_source_credential_description': {'key': 'dataSourceCredentialDescription', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': 'ServicePrincipalInKVParam'},
    }

    def __init__(
        self,
        *,
        data_source_credential_name: str,
        parameters: "ServicePrincipalInKVParam",
        data_source_credential_description: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_source_credential_name: Required. Name of data source credential.
        :paramtype data_source_credential_name: str
        :keyword data_source_credential_description: Description of data source credential.
        :paramtype data_source_credential_description: str
        :keyword parameters: Required.
        :paramtype parameters: ~azure.ai.metricsadvisor.models.ServicePrincipalInKVParam
        """
        super(_ServicePrincipalInKVCredentialGenerated, self).__init__(data_source_credential_name=data_source_credential_name, data_source_credential_description=data_source_credential_description, **kwargs)
        self.data_source_credential_type = 'ServicePrincipalInKV'  # type: str
        self.parameters = parameters

class ServicePrincipalInKVCredential(ServicePrincipalInKVCredentialCustomization, DataSourceCredential, _ServicePrincipalInKVCredentialGenerated):
    pass


class _ServicePrincipalInKVCredentialPatchGenerated(_DataSourceCredentialPatchGenerated):
    """ServicePrincipalInKVCredentialPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_credential_type: Required. Type of data source credential.Constant filled by
     server. Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype data_source_credential_type: str or
     ~azure.ai.metricsadvisor.models.DataSourceCredentialType
    :ivar data_source_credential_name: Name of data source credential.
    :vartype data_source_credential_name: str
    :ivar data_source_credential_description: Description of data source credential.
    :vartype data_source_credential_description: str
    :ivar parameters:
    :vartype parameters: ~azure.ai.metricsadvisor.models.ServicePrincipalInKVParamPatch
    """

    _validation = {
        'data_source_credential_type': {'required': True},
    }

    _attribute_map = {
        'data_source_credential_type': {'key': 'dataSourceCredentialType', 'type': 'str'},
        'data_source_credential_name': {'key': 'dataSourceCredentialName', 'type': 'str'},
        'data_source_credential_description': {'key': 'dataSourceCredentialDescription', 'type': 'str'},
        'parameters': {'key': 'parameters', 'type': 'ServicePrincipalInKVParamPatch'},
    }

    def __init__(
        self,
        *,
        data_source_credential_name: Optional[str] = None,
        data_source_credential_description: Optional[str] = None,
        parameters: Optional["ServicePrincipalInKVParamPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_source_credential_name: Name of data source credential.
        :paramtype data_source_credential_name: str
        :keyword data_source_credential_description: Description of data source credential.
        :paramtype data_source_credential_description: str
        :keyword parameters:
        :paramtype parameters: ~azure.ai.metricsadvisor.models.ServicePrincipalInKVParamPatch
        """
        super(_ServicePrincipalInKVCredentialPatchGenerated, self).__init__(data_source_credential_name=data_source_credential_name, data_source_credential_description=data_source_credential_description, **kwargs)
        self.data_source_credential_type = 'ServicePrincipalInKV'  # type: str
        self.parameters = parameters

class ServicePrincipalInKVCredentialPatch(ServicePrincipalInKVCredentialPatchCustomization, DataSourceCredentialPatch, _ServicePrincipalInKVCredentialPatchGenerated):
    pass


class _ServicePrincipalInKVParamGenerated(msrest.serialization.Model):
    """ServicePrincipalInKVParam.

    All required parameters must be populated in order to send to Azure.

    :ivar key_vault_endpoint: Required. The Key Vault endpoint that storing the service principal.
    :vartype key_vault_endpoint: str
    :ivar key_vault_client_id: Required. The Client Id to access the Key Vault.
    :vartype key_vault_client_id: str
    :ivar key_vault_client_secret: The Client Secret to access the Key Vault.
    :vartype key_vault_client_secret: str
    :ivar service_principal_id_name_in_kv: Required. The secret name of the service principal's
     client Id in the Key Vault.
    :vartype service_principal_id_name_in_kv: str
    :ivar service_principal_secret_name_in_kv: Required. The secret name of the service principal's
     client secret in the Key Vault.
    :vartype service_principal_secret_name_in_kv: str
    :ivar tenant_id: Required. The tenant id of your service principal.
    :vartype tenant_id: str
    """

    _validation = {
        'key_vault_endpoint': {'required': True},
        'key_vault_client_id': {'required': True},
        'service_principal_id_name_in_kv': {'required': True},
        'service_principal_secret_name_in_kv': {'required': True},
        'tenant_id': {'required': True},
    }

    _attribute_map = {
        'key_vault_endpoint': {'key': 'keyVaultEndpoint', 'type': 'str'},
        'key_vault_client_id': {'key': 'keyVaultClientId', 'type': 'str'},
        'key_vault_client_secret': {'key': 'keyVaultClientSecret', 'type': 'str'},
        'service_principal_id_name_in_kv': {'key': 'servicePrincipalIdNameInKV', 'type': 'str'},
        'service_principal_secret_name_in_kv': {'key': 'servicePrincipalSecretNameInKV', 'type': 'str'},
        'tenant_id': {'key': 'tenantId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        key_vault_endpoint: str,
        key_vault_client_id: str,
        service_principal_id_name_in_kv: str,
        service_principal_secret_name_in_kv: str,
        tenant_id: str,
        key_vault_client_secret: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword key_vault_endpoint: Required. The Key Vault endpoint that storing the service
         principal.
        :paramtype key_vault_endpoint: str
        :keyword key_vault_client_id: Required. The Client Id to access the Key Vault.
        :paramtype key_vault_client_id: str
        :keyword key_vault_client_secret: The Client Secret to access the Key Vault.
        :paramtype key_vault_client_secret: str
        :keyword service_principal_id_name_in_kv: Required. The secret name of the service principal's
         client Id in the Key Vault.
        :paramtype service_principal_id_name_in_kv: str
        :keyword service_principal_secret_name_in_kv: Required. The secret name of the service
         principal's client secret in the Key Vault.
        :paramtype service_principal_secret_name_in_kv: str
        :keyword tenant_id: Required. The tenant id of your service principal.
        :paramtype tenant_id: str
        """
        super(_ServicePrincipalInKVParamGenerated, self).__init__(**kwargs)
        self.key_vault_endpoint = key_vault_endpoint
        self.key_vault_client_id = key_vault_client_id
        self.key_vault_client_secret = key_vault_client_secret
        self.service_principal_id_name_in_kv = service_principal_id_name_in_kv
        self.service_principal_secret_name_in_kv = service_principal_secret_name_in_kv
        self.tenant_id = tenant_id

class ServicePrincipalInKVParam(ServicePrincipalInKVParamCustomization, _ServicePrincipalInKVParamGenerated):
    pass


class _ServicePrincipalInKVParamPatchGenerated(msrest.serialization.Model):
    """ServicePrincipalInKVParamPatch.

    :ivar key_vault_endpoint: The Key Vault endpoint that storing the service principal.
    :vartype key_vault_endpoint: str
    :ivar key_vault_client_id: The Client Id to access the Key Vault.
    :vartype key_vault_client_id: str
    :ivar key_vault_client_secret: The Client Secret to access the Key Vault.
    :vartype key_vault_client_secret: str
    :ivar service_principal_id_name_in_kv: The secret name of the service principal's client Id in
     the Key Vault.
    :vartype service_principal_id_name_in_kv: str
    :ivar service_principal_secret_name_in_kv: The secret name of the service principal's client
     secret in the Key Vault.
    :vartype service_principal_secret_name_in_kv: str
    :ivar tenant_id: The tenant id of your service principal.
    :vartype tenant_id: str
    """

    _attribute_map = {
        'key_vault_endpoint': {'key': 'keyVaultEndpoint', 'type': 'str'},
        'key_vault_client_id': {'key': 'keyVaultClientId', 'type': 'str'},
        'key_vault_client_secret': {'key': 'keyVaultClientSecret', 'type': 'str'},
        'service_principal_id_name_in_kv': {'key': 'servicePrincipalIdNameInKV', 'type': 'str'},
        'service_principal_secret_name_in_kv': {'key': 'servicePrincipalSecretNameInKV', 'type': 'str'},
        'tenant_id': {'key': 'tenantId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        key_vault_endpoint: Optional[str] = None,
        key_vault_client_id: Optional[str] = None,
        key_vault_client_secret: Optional[str] = None,
        service_principal_id_name_in_kv: Optional[str] = None,
        service_principal_secret_name_in_kv: Optional[str] = None,
        tenant_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword key_vault_endpoint: The Key Vault endpoint that storing the service principal.
        :paramtype key_vault_endpoint: str
        :keyword key_vault_client_id: The Client Id to access the Key Vault.
        :paramtype key_vault_client_id: str
        :keyword key_vault_client_secret: The Client Secret to access the Key Vault.
        :paramtype key_vault_client_secret: str
        :keyword service_principal_id_name_in_kv: The secret name of the service principal's client Id
         in the Key Vault.
        :paramtype service_principal_id_name_in_kv: str
        :keyword service_principal_secret_name_in_kv: The secret name of the service principal's client
         secret in the Key Vault.
        :paramtype service_principal_secret_name_in_kv: str
        :keyword tenant_id: The tenant id of your service principal.
        :paramtype tenant_id: str
        """
        super(_ServicePrincipalInKVParamPatchGenerated, self).__init__(**kwargs)
        self.key_vault_endpoint = key_vault_endpoint
        self.key_vault_client_id = key_vault_client_id
        self.key_vault_client_secret = key_vault_client_secret
        self.service_principal_id_name_in_kv = service_principal_id_name_in_kv
        self.service_principal_secret_name_in_kv = service_principal_secret_name_in_kv
        self.tenant_id = tenant_id

class ServicePrincipalInKVParamPatch(ServicePrincipalInKVParamPatchCustomization, _ServicePrincipalInKVParamPatchGenerated):
    pass


class _ServicePrincipalParamGenerated(msrest.serialization.Model):
    """ServicePrincipalParam.

    All required parameters must be populated in order to send to Azure.

    :ivar client_id: Required. The client id of the service principal.
    :vartype client_id: str
    :ivar client_secret: The client secret of the service principal.
    :vartype client_secret: str
    :ivar tenant_id: Required. The tenant id of the service principal.
    :vartype tenant_id: str
    """

    _validation = {
        'client_id': {'required': True},
        'tenant_id': {'required': True},
    }

    _attribute_map = {
        'client_id': {'key': 'clientId', 'type': 'str'},
        'client_secret': {'key': 'clientSecret', 'type': 'str'},
        'tenant_id': {'key': 'tenantId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        client_id: str,
        tenant_id: str,
        client_secret: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword client_id: Required. The client id of the service principal.
        :paramtype client_id: str
        :keyword client_secret: The client secret of the service principal.
        :paramtype client_secret: str
        :keyword tenant_id: Required. The tenant id of the service principal.
        :paramtype tenant_id: str
        """
        super(_ServicePrincipalParamGenerated, self).__init__(**kwargs)
        self.client_id = client_id
        self.client_secret = client_secret
        self.tenant_id = tenant_id

class ServicePrincipalParam(ServicePrincipalParamCustomization, _ServicePrincipalParamGenerated):
    pass


class _ServicePrincipalParamPatchGenerated(msrest.serialization.Model):
    """ServicePrincipalParamPatch.

    :ivar client_id: The client id of the service principal.
    :vartype client_id: str
    :ivar client_secret: The client secret of the service principal.
    :vartype client_secret: str
    :ivar tenant_id: The tenant id of the service principal.
    :vartype tenant_id: str
    """

    _attribute_map = {
        'client_id': {'key': 'clientId', 'type': 'str'},
        'client_secret': {'key': 'clientSecret', 'type': 'str'},
        'tenant_id': {'key': 'tenantId', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        client_id: Optional[str] = None,
        client_secret: Optional[str] = None,
        tenant_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword client_id: The client id of the service principal.
        :paramtype client_id: str
        :keyword client_secret: The client secret of the service principal.
        :paramtype client_secret: str
        :keyword tenant_id: The tenant id of the service principal.
        :paramtype tenant_id: str
        """
        super(_ServicePrincipalParamPatchGenerated, self).__init__(**kwargs)
        self.client_id = client_id
        self.client_secret = client_secret
        self.tenant_id = tenant_id

class ServicePrincipalParamPatch(ServicePrincipalParamPatchCustomization, _ServicePrincipalParamPatchGenerated):
    pass


class _SeverityConditionGenerated(msrest.serialization.Model):
    """SeverityCondition.

    All required parameters must be populated in order to send to Azure.

    :ivar min_alert_severity: Required. min alert severity. Possible values include: "Low",
     "Medium", "High".
    :vartype min_alert_severity: str or ~azure.ai.metricsadvisor.models.Severity
    :ivar max_alert_severity: Required. max alert severity. Possible values include: "Low",
     "Medium", "High".
    :vartype max_alert_severity: str or ~azure.ai.metricsadvisor.models.Severity
    """

    _validation = {
        'min_alert_severity': {'required': True},
        'max_alert_severity': {'required': True},
    }

    _attribute_map = {
        'min_alert_severity': {'key': 'minAlertSeverity', 'type': 'str'},
        'max_alert_severity': {'key': 'maxAlertSeverity', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        min_alert_severity: Union[str, "Severity"],
        max_alert_severity: Union[str, "Severity"],
        **kwargs
    ):
        """
        :keyword min_alert_severity: Required. min alert severity. Possible values include: "Low",
         "Medium", "High".
        :paramtype min_alert_severity: str or ~azure.ai.metricsadvisor.models.Severity
        :keyword max_alert_severity: Required. max alert severity. Possible values include: "Low",
         "Medium", "High".
        :paramtype max_alert_severity: str or ~azure.ai.metricsadvisor.models.Severity
        """
        super(_SeverityConditionGenerated, self).__init__(**kwargs)
        self.min_alert_severity = min_alert_severity
        self.max_alert_severity = max_alert_severity

class SeverityCondition(SeverityConditionCustomization, _SeverityConditionGenerated):
    pass


class _SeverityFilterConditionGenerated(msrest.serialization.Model):
    """SeverityFilterCondition.

    All required parameters must be populated in order to send to Azure.

    :ivar min: Required. min severity. Possible values include: "Low", "Medium", "High".
    :vartype min: str or ~azure.ai.metricsadvisor.models.Severity
    :ivar max: Required. max severity. Possible values include: "Low", "Medium", "High".
    :vartype max: str or ~azure.ai.metricsadvisor.models.Severity
    """

    _validation = {
        'min': {'required': True},
        'max': {'required': True},
    }

    _attribute_map = {
        'min': {'key': 'min', 'type': 'str'},
        'max': {'key': 'max', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        min: Union[str, "Severity"],
        max: Union[str, "Severity"],
        **kwargs
    ):
        """
        :keyword min: Required. min severity. Possible values include: "Low", "Medium", "High".
        :paramtype min: str or ~azure.ai.metricsadvisor.models.Severity
        :keyword max: Required. max severity. Possible values include: "Low", "Medium", "High".
        :paramtype max: str or ~azure.ai.metricsadvisor.models.Severity
        """
        super(_SeverityFilterConditionGenerated, self).__init__(**kwargs)
        self.min = min
        self.max = max

class SeverityFilterCondition(SeverityFilterConditionCustomization, _SeverityFilterConditionGenerated):
    pass


class _SmartDetectionConditionGenerated(msrest.serialization.Model):
    """SmartDetectionCondition.

    All required parameters must be populated in order to send to Azure.

    :ivar sensitivity: Required. sensitivity, value range : (0, 100].
    :vartype sensitivity: float
    :ivar anomaly_detector_direction: Required. detection direction. Possible values include:
     "Both", "Down", "Up".
    :vartype anomaly_detector_direction: str or
     ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
    :ivar suppress_condition: Required.
    :vartype suppress_condition: ~azure.ai.metricsadvisor.models.SuppressCondition
    """

    _validation = {
        'sensitivity': {'required': True},
        'anomaly_detector_direction': {'required': True},
        'suppress_condition': {'required': True},
    }

    _attribute_map = {
        'sensitivity': {'key': 'sensitivity', 'type': 'float'},
        'anomaly_detector_direction': {'key': 'anomalyDetectorDirection', 'type': 'str'},
        'suppress_condition': {'key': 'suppressCondition', 'type': 'SuppressCondition'},
    }

    def __init__(
        self,
        *,
        sensitivity: float,
        anomaly_detector_direction: Union[str, "AnomalyDetectorDirection"],
        suppress_condition: "SuppressCondition",
        **kwargs
    ):
        """
        :keyword sensitivity: Required. sensitivity, value range : (0, 100].
        :paramtype sensitivity: float
        :keyword anomaly_detector_direction: Required. detection direction. Possible values include:
         "Both", "Down", "Up".
        :paramtype anomaly_detector_direction: str or
         ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
        :keyword suppress_condition: Required.
        :paramtype suppress_condition: ~azure.ai.metricsadvisor.models.SuppressCondition
        """
        super(_SmartDetectionConditionGenerated, self).__init__(**kwargs)
        self.sensitivity = sensitivity
        self.anomaly_detector_direction = anomaly_detector_direction
        self.suppress_condition = suppress_condition

class SmartDetectionCondition(SmartDetectionConditionCustomization, _SmartDetectionConditionGenerated):
    pass


class _SmartDetectionConditionPatchGenerated(msrest.serialization.Model):
    """SmartDetectionConditionPatch.

    :ivar sensitivity: sensitivity, value range : (0, 100].
    :vartype sensitivity: float
    :ivar anomaly_detector_direction: detection direction. Possible values include: "Both", "Down",
     "Up".
    :vartype anomaly_detector_direction: str or
     ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
    :ivar suppress_condition:
    :vartype suppress_condition: ~azure.ai.metricsadvisor.models.SuppressConditionPatch
    """

    _attribute_map = {
        'sensitivity': {'key': 'sensitivity', 'type': 'float'},
        'anomaly_detector_direction': {'key': 'anomalyDetectorDirection', 'type': 'str'},
        'suppress_condition': {'key': 'suppressCondition', 'type': 'SuppressConditionPatch'},
    }

    def __init__(
        self,
        *,
        sensitivity: Optional[float] = None,
        anomaly_detector_direction: Optional[Union[str, "AnomalyDetectorDirection"]] = None,
        suppress_condition: Optional["SuppressConditionPatch"] = None,
        **kwargs
    ):
        """
        :keyword sensitivity: sensitivity, value range : (0, 100].
        :paramtype sensitivity: float
        :keyword anomaly_detector_direction: detection direction. Possible values include: "Both",
         "Down", "Up".
        :paramtype anomaly_detector_direction: str or
         ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
        :keyword suppress_condition:
        :paramtype suppress_condition: ~azure.ai.metricsadvisor.models.SuppressConditionPatch
        """
        super(_SmartDetectionConditionPatchGenerated, self).__init__(**kwargs)
        self.sensitivity = sensitivity
        self.anomaly_detector_direction = anomaly_detector_direction
        self.suppress_condition = suppress_condition

class SmartDetectionConditionPatch(SmartDetectionConditionPatchCustomization, _SmartDetectionConditionPatchGenerated):
    pass


class _SQLServerDataFeedGenerated(_DataFeedGenerated):
    """SQLServerDataFeed.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_id: data feed unique id.
    :vartype data_feed_id: str
    :ivar data_feed_name: Required. data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar granularity_name: Required. granularity of the time series. Possible values include:
     "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
    :vartype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
    :ivar granularity_amount: if granularity is custom,it is required.
    :vartype granularity_amount: int
    :ivar metrics: Required. measure list.
    :vartype metrics: list[~azure.ai.metricsadvisor.models.Metric]
    :ivar dimension: dimension list.
    :vartype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: Required. ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar is_admin: the query user is one of data feed administrator or not.
    :vartype is_admin: bool
    :ivar creator: data feed creator.
    :vartype creator: str
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar created_time: data feed created time.
    :vartype created_time: ~datetime.datetime
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter: Required.
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.SqlSourceParameter
    """

    _validation = {
        'data_source_type': {'required': True},
        'data_feed_id': {'readonly': True},
        'data_feed_name': {'required': True},
        'granularity_name': {'required': True},
        'metrics': {'required': True, 'unique': True},
        'dimension': {'unique': True},
        'data_start_from': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
        'is_admin': {'readonly': True},
        'creator': {'readonly': True},
        'status': {'readonly': True},
        'created_time': {'readonly': True},
        'data_source_parameter': {'required': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_id': {'key': 'dataFeedId', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'granularity_name': {'key': 'granularityName', 'type': 'str'},
        'granularity_amount': {'key': 'granularityAmount', 'type': 'int'},
        'metrics': {'key': 'metrics', 'type': '[Metric]'},
        'dimension': {'key': 'dimension', 'type': '[Dimension]'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'is_admin': {'key': 'isAdmin', 'type': 'bool'},
        'creator': {'key': 'creator', 'type': 'str'},
        'status': {'key': 'status', 'type': 'str'},
        'created_time': {'key': 'createdTime', 'type': 'iso-8601'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'SqlSourceParameter'},
    }

    def __init__(
        self,
        *,
        data_feed_name: str,
        granularity_name: Union[str, "Granularity"],
        metrics: List["Metric"],
        data_start_from: datetime.datetime,
        data_source_parameter: "SqlSourceParameter",
        data_feed_description: Optional[str] = "",
        granularity_amount: Optional[int] = None,
        dimension: Optional[List["Dimension"]] = None,
        timestamp_column: Optional[str] = "",
        start_offset_in_seconds: Optional[int] = 0,
        max_concurrency: Optional[int] = -1,
        min_retry_interval_in_seconds: Optional[int] = -1,
        stop_retry_after_in_seconds: Optional[int] = -1,
        need_rollup: Optional[Union[str, "DataFeedRollupType"]] = "NoRollup",
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        action_link_template: Optional[str] = "",
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: Required. data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword granularity_name: Required. granularity of the time series. Possible values include:
         "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Custom".
        :paramtype granularity_name: str or ~azure.ai.metricsadvisor.models.Granularity
        :keyword granularity_amount: if granularity is custom,it is required.
        :paramtype granularity_amount: int
        :keyword metrics: Required. measure list.
        :paramtype metrics: list[~azure.ai.metricsadvisor.models.Metric]
        :keyword dimension: dimension list.
        :paramtype dimension: list[~azure.ai.metricsadvisor.models.Dimension]
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: Required. ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "AutoRollup", "AlreadyRollup". Default value: "NoRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter: Required.
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.SqlSourceParameter
        """
        super(_SQLServerDataFeedGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, granularity_name=granularity_name, granularity_amount=granularity_amount, metrics=metrics, dimension=dimension, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'SqlServer'  # type: str
        self.data_source_parameter = data_source_parameter

class SQLServerDataFeed(SQLServerDataFeedCustomization, DataFeed, _SQLServerDataFeedGenerated):
    pass


class _SQLServerDataFeedPatchGenerated(_DataFeedPatchGenerated):
    """SQLServerDataFeedPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar data_source_type: Required. data source type.Constant filled by server. Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DataSourceType
    :ivar data_feed_name: data feed name.
    :vartype data_feed_name: str
    :ivar data_feed_description: data feed description.
    :vartype data_feed_description: str
    :ivar timestamp_column: user-defined timestamp column. if timestampColumn is null, start time
     of every time slice will be used as default value.
    :vartype timestamp_column: str
    :ivar data_start_from: ingestion start time.
    :vartype data_start_from: ~datetime.datetime
    :ivar start_offset_in_seconds: the time that the beginning of data ingestion task will delay
     for every data slice according to this offset.
    :vartype start_offset_in_seconds: long
    :ivar max_concurrency: the max concurrency of data ingestion queries against user data source.
     0 means no limitation.
    :vartype max_concurrency: int
    :ivar min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
    :vartype min_retry_interval_in_seconds: long
    :ivar stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
     schedule time in seconds.
    :vartype stop_retry_after_in_seconds: long
    :ivar need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
     "NeedRollup", "AlreadyRollup".
    :vartype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
    :ivar roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
     "Avg", "Count".
    :vartype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
    :ivar roll_up_columns: roll up columns.
    :vartype roll_up_columns: list[str]
    :ivar all_up_identification: the identification value for the row of calculated all-up value.
    :vartype all_up_identification: str
    :ivar fill_missing_point_type: the type of fill missing point for anomaly detection. Possible
     values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
    :vartype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
    :ivar fill_missing_point_value: the value of fill missing point for anomaly detection.
    :vartype fill_missing_point_value: float
    :ivar view_mode: data feed access mode, default is Private. Possible values include: "Private",
     "Public".
    :vartype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
    :ivar admins: data feed administrator.
    :vartype admins: list[str]
    :ivar viewers: data feed viewer.
    :vartype viewers: list[str]
    :ivar status: data feed status. Possible values include: "Active", "Paused".
    :vartype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
    :ivar action_link_template: action link for alert.
    :vartype action_link_template: str
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
    :ivar credential_id: The credential entity id.
    :vartype credential_id: str
    :ivar data_source_parameter:
    :vartype data_source_parameter: ~azure.ai.metricsadvisor.models.SQLSourceParameterPatch
    """

    _validation = {
        'data_source_type': {'required': True},
        'roll_up_columns': {'unique': True},
        'admins': {'unique': True},
        'viewers': {'unique': True},
    }

    _attribute_map = {
        'data_source_type': {'key': 'dataSourceType', 'type': 'str'},
        'data_feed_name': {'key': 'dataFeedName', 'type': 'str'},
        'data_feed_description': {'key': 'dataFeedDescription', 'type': 'str'},
        'timestamp_column': {'key': 'timestampColumn', 'type': 'str'},
        'data_start_from': {'key': 'dataStartFrom', 'type': 'iso-8601'},
        'start_offset_in_seconds': {'key': 'startOffsetInSeconds', 'type': 'long'},
        'max_concurrency': {'key': 'maxConcurrency', 'type': 'int'},
        'min_retry_interval_in_seconds': {'key': 'minRetryIntervalInSeconds', 'type': 'long'},
        'stop_retry_after_in_seconds': {'key': 'stopRetryAfterInSeconds', 'type': 'long'},
        'need_rollup': {'key': 'needRollup', 'type': 'str'},
        'roll_up_method': {'key': 'rollUpMethod', 'type': 'str'},
        'roll_up_columns': {'key': 'rollUpColumns', 'type': '[str]'},
        'all_up_identification': {'key': 'allUpIdentification', 'type': 'str'},
        'fill_missing_point_type': {'key': 'fillMissingPointType', 'type': 'str'},
        'fill_missing_point_value': {'key': 'fillMissingPointValue', 'type': 'float'},
        'view_mode': {'key': 'viewMode', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'viewers': {'key': 'viewers', 'type': '[str]'},
        'status': {'key': 'status', 'type': 'str'},
        'action_link_template': {'key': 'actionLinkTemplate', 'type': 'str'},
        'authentication_type': {'key': 'authenticationType', 'type': 'str'},
        'credential_id': {'key': 'credentialId', 'type': 'str'},
        'data_source_parameter': {'key': 'dataSourceParameter', 'type': 'SQLSourceParameterPatch'},
    }

    def __init__(
        self,
        *,
        data_feed_name: Optional[str] = None,
        data_feed_description: Optional[str] = None,
        timestamp_column: Optional[str] = None,
        data_start_from: Optional[datetime.datetime] = None,
        start_offset_in_seconds: Optional[int] = None,
        max_concurrency: Optional[int] = None,
        min_retry_interval_in_seconds: Optional[int] = None,
        stop_retry_after_in_seconds: Optional[int] = None,
        need_rollup: Optional[Union[str, "NeedRollupEnum"]] = None,
        roll_up_method: Optional[Union[str, "RollUpMethod"]] = None,
        roll_up_columns: Optional[List[str]] = None,
        all_up_identification: Optional[str] = None,
        fill_missing_point_type: Optional[Union[str, "FillMissingPointType"]] = None,
        fill_missing_point_value: Optional[float] = None,
        view_mode: Optional[Union[str, "ViewMode"]] = None,
        admins: Optional[List[str]] = None,
        viewers: Optional[List[str]] = None,
        status: Optional[Union[str, "EntityStatus"]] = None,
        action_link_template: Optional[str] = None,
        authentication_type: Optional[Union[str, "AuthenticationTypeEnum"]] = None,
        credential_id: Optional[str] = None,
        data_source_parameter: Optional["SQLSourceParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword data_feed_name: data feed name.
        :paramtype data_feed_name: str
        :keyword data_feed_description: data feed description.
        :paramtype data_feed_description: str
        :keyword timestamp_column: user-defined timestamp column. if timestampColumn is null, start
         time of every time slice will be used as default value.
        :paramtype timestamp_column: str
        :keyword data_start_from: ingestion start time.
        :paramtype data_start_from: ~datetime.datetime
        :keyword start_offset_in_seconds: the time that the beginning of data ingestion task will delay
         for every data slice according to this offset.
        :paramtype start_offset_in_seconds: long
        :keyword max_concurrency: the max concurrency of data ingestion queries against user data
         source. 0 means no limitation.
        :paramtype max_concurrency: int
        :keyword min_retry_interval_in_seconds: the min retry interval for failed data ingestion tasks.
        :paramtype min_retry_interval_in_seconds: long
        :keyword stop_retry_after_in_seconds: stop retry data ingestion after the data slice first
         schedule time in seconds.
        :paramtype stop_retry_after_in_seconds: long
        :keyword need_rollup: mark if the data feed need rollup. Possible values include: "NoRollup",
         "NeedRollup", "AlreadyRollup".
        :paramtype need_rollup: str or ~azure.ai.metricsadvisor.models.NeedRollupEnum
        :keyword roll_up_method: roll up method. Possible values include: "None", "Sum", "Max", "Min",
         "Avg", "Count".
        :paramtype roll_up_method: str or ~azure.ai.metricsadvisor.models.RollUpMethod
        :keyword roll_up_columns: roll up columns.
        :paramtype roll_up_columns: list[str]
        :keyword all_up_identification: the identification value for the row of calculated all-up
         value.
        :paramtype all_up_identification: str
        :keyword fill_missing_point_type: the type of fill missing point for anomaly detection.
         Possible values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling".
        :paramtype fill_missing_point_type: str or ~azure.ai.metricsadvisor.models.FillMissingPointType
        :keyword fill_missing_point_value: the value of fill missing point for anomaly detection.
        :paramtype fill_missing_point_value: float
        :keyword view_mode: data feed access mode, default is Private. Possible values include:
         "Private", "Public".
        :paramtype view_mode: str or ~azure.ai.metricsadvisor.models.ViewMode
        :keyword admins: data feed administrator.
        :paramtype admins: list[str]
        :keyword viewers: data feed viewer.
        :paramtype viewers: list[str]
        :keyword status: data feed status. Possible values include: "Active", "Paused".
        :paramtype status: str or ~azure.ai.metricsadvisor.models.EntityStatus
        :keyword action_link_template: action link for alert.
        :paramtype action_link_template: str
        :keyword authentication_type: authentication type for corresponding data source. Possible
         values include: "Basic", "ManagedIdentity", "AzureSQLConnectionString",
         "DataLakeGen2SharedKey", "ServicePrincipal", "ServicePrincipalInKV".
        :paramtype authentication_type: str or ~azure.ai.metricsadvisor.models.AuthenticationTypeEnum
        :keyword credential_id: The credential entity id.
        :paramtype credential_id: str
        :keyword data_source_parameter:
        :paramtype data_source_parameter: ~azure.ai.metricsadvisor.models.SQLSourceParameterPatch
        """
        super(_SQLServerDataFeedPatchGenerated, self).__init__(data_feed_name=data_feed_name, data_feed_description=data_feed_description, timestamp_column=timestamp_column, data_start_from=data_start_from, start_offset_in_seconds=start_offset_in_seconds, max_concurrency=max_concurrency, min_retry_interval_in_seconds=min_retry_interval_in_seconds, stop_retry_after_in_seconds=stop_retry_after_in_seconds, need_rollup=need_rollup, roll_up_method=roll_up_method, roll_up_columns=roll_up_columns, all_up_identification=all_up_identification, fill_missing_point_type=fill_missing_point_type, fill_missing_point_value=fill_missing_point_value, view_mode=view_mode, admins=admins, viewers=viewers, status=status, action_link_template=action_link_template, authentication_type=authentication_type, credential_id=credential_id, **kwargs)
        self.data_source_type = 'SqlServer'  # type: str
        self.data_source_parameter = data_source_parameter

class SQLServerDataFeedPatch(SQLServerDataFeedPatchCustomization, DataFeedPatch, _SQLServerDataFeedPatchGenerated):
    pass


class _SqlSourceParameterGenerated(msrest.serialization.Model):
    """SqlSourceParameter.

    All required parameters must be populated in order to send to Azure.

    :ivar connection_string: The connection string of this database.
    :vartype connection_string: str
    :ivar query: Required. The script to query this database.
    :vartype query: str
    """

    _validation = {
        'query': {'required': True},
    }

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'query': {'key': 'query', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        query: str,
        connection_string: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this database.
        :paramtype connection_string: str
        :keyword query: Required. The script to query this database.
        :paramtype query: str
        """
        super(_SqlSourceParameterGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.query = query

class SqlSourceParameter(SqlSourceParameterCustomization, _SqlSourceParameterGenerated):
    pass


class _SQLSourceParameterPatchGenerated(msrest.serialization.Model):
    """SQLSourceParameterPatch.

    :ivar connection_string: The connection string of this database.
    :vartype connection_string: str
    :ivar query: The script to query this database.
    :vartype query: str
    """

    _attribute_map = {
        'connection_string': {'key': 'connectionString', 'type': 'str'},
        'query': {'key': 'query', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        connection_string: Optional[str] = None,
        query: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword connection_string: The connection string of this database.
        :paramtype connection_string: str
        :keyword query: The script to query this database.
        :paramtype query: str
        """
        super(_SQLSourceParameterPatchGenerated, self).__init__(**kwargs)
        self.connection_string = connection_string
        self.query = query

class SQLSourceParameterPatch(SQLSourceParameterPatchCustomization, _SQLSourceParameterPatchGenerated):
    pass


class _SuppressConditionGenerated(msrest.serialization.Model):
    """SuppressCondition.

    All required parameters must be populated in order to send to Azure.

    :ivar min_number: Required. min point number, value range : [1, +∞).
    :vartype min_number: int
    :ivar min_ratio: Required. min point ratio, value range : (0, 100].
    :vartype min_ratio: float
    """

    _validation = {
        'min_number': {'required': True},
        'min_ratio': {'required': True},
    }

    _attribute_map = {
        'min_number': {'key': 'minNumber', 'type': 'int'},
        'min_ratio': {'key': 'minRatio', 'type': 'float'},
    }

    def __init__(
        self,
        *,
        min_number: int,
        min_ratio: float,
        **kwargs
    ):
        """
        :keyword min_number: Required. min point number, value range : [1, +∞).
        :paramtype min_number: int
        :keyword min_ratio: Required. min point ratio, value range : (0, 100].
        :paramtype min_ratio: float
        """
        super(_SuppressConditionGenerated, self).__init__(**kwargs)
        self.min_number = min_number
        self.min_ratio = min_ratio

class SuppressCondition(SuppressConditionCustomization, _SuppressConditionGenerated):
    pass


class _SuppressConditionPatchGenerated(msrest.serialization.Model):
    """SuppressConditionPatch.

    :ivar min_number: min point number, value range : [1, +∞).
    :vartype min_number: int
    :ivar min_ratio: min point ratio, value range : (0, 100].
    :vartype min_ratio: float
    """

    _attribute_map = {
        'min_number': {'key': 'minNumber', 'type': 'int'},
        'min_ratio': {'key': 'minRatio', 'type': 'float'},
    }

    def __init__(
        self,
        *,
        min_number: Optional[int] = None,
        min_ratio: Optional[float] = None,
        **kwargs
    ):
        """
        :keyword min_number: min point number, value range : [1, +∞).
        :paramtype min_number: int
        :keyword min_ratio: min point ratio, value range : (0, 100].
        :paramtype min_ratio: float
        """
        super(_SuppressConditionPatchGenerated, self).__init__(**kwargs)
        self.min_number = min_number
        self.min_ratio = min_ratio

class SuppressConditionPatch(SuppressConditionPatchCustomization, _SuppressConditionPatchGenerated):
    pass


class _TopNGroupScopeGenerated(msrest.serialization.Model):
    """TopNGroupScope.

    All required parameters must be populated in order to send to Azure.

    :ivar top: Required. top N, value range : [1, +∞).
    :vartype top: int
    :ivar period: Required. point count used to look back, value range : [1, +∞).
    :vartype period: int
    :ivar min_top_count: Required. min count should be in top N, value range : [1, +∞)

     should be less than or equal to period.
    :vartype min_top_count: int
    """

    _validation = {
        'top': {'required': True},
        'period': {'required': True},
        'min_top_count': {'required': True},
    }

    _attribute_map = {
        'top': {'key': 'top', 'type': 'int'},
        'period': {'key': 'period', 'type': 'int'},
        'min_top_count': {'key': 'minTopCount', 'type': 'int'},
    }

    def __init__(
        self,
        *,
        top: int,
        period: int,
        min_top_count: int,
        **kwargs
    ):
        """
        :keyword top: Required. top N, value range : [1, +∞).
        :paramtype top: int
        :keyword period: Required. point count used to look back, value range : [1, +∞).
        :paramtype period: int
        :keyword min_top_count: Required. min count should be in top N, value range : [1, +∞)

         should be less than or equal to period.
        :paramtype min_top_count: int
        """
        super(_TopNGroupScopeGenerated, self).__init__(**kwargs)
        self.top = top
        self.period = period
        self.min_top_count = min_top_count

class TopNGroupScope(TopNGroupScopeCustomization, _TopNGroupScopeGenerated):
    pass


class _UsageStatsGenerated(msrest.serialization.Model):
    """UsageStats.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar timestamp: The timestamp of the stats.
    :vartype timestamp: ~datetime.datetime
    :ivar active_series_count: The active series count.
    :vartype active_series_count: int
    :ivar all_series_count: All series count under non deleted data feed.
    :vartype all_series_count: int
    :ivar metrics_count: The metrics count under non deleted data feed.
    :vartype metrics_count: int
    :ivar data_feed_count: The count of non deleted data feed.
    :vartype data_feed_count: int
    """

    _validation = {
        'timestamp': {'readonly': True},
        'active_series_count': {'readonly': True},
        'all_series_count': {'readonly': True},
        'metrics_count': {'readonly': True},
        'data_feed_count': {'readonly': True},
    }

    _attribute_map = {
        'timestamp': {'key': 'timestamp', 'type': 'iso-8601'},
        'active_series_count': {'key': 'activeSeriesCount', 'type': 'int'},
        'all_series_count': {'key': 'allSeriesCount', 'type': 'int'},
        'metrics_count': {'key': 'metricsCount', 'type': 'int'},
        'data_feed_count': {'key': 'dataFeedCount', 'type': 'int'},
    }

    def __init__(
        self,
        **kwargs
    ):
        """
        """
        super(_UsageStatsGenerated, self).__init__(**kwargs)
        self.timestamp = None
        self.active_series_count = None
        self.all_series_count = None
        self.metrics_count = None
        self.data_feed_count = None

class UsageStats(UsageStatsCustomization, _UsageStatsGenerated):
    pass


class _ValueConditionGenerated(msrest.serialization.Model):
    """ValueCondition.

    All required parameters must be populated in order to send to Azure.

    :ivar lower: lower bound

     should be specified when direction is Both or Down.
    :vartype lower: float
    :ivar upper: upper bound

     should be specified when direction is Both or Up.
    :vartype upper: float
    :ivar direction: Required. value filter direction. Possible values include: "Both", "Down",
     "Up".
    :vartype direction: str or ~azure.ai.metricsadvisor.models.Direction
    :ivar type: data used to implement value filter. Possible values include: "Value", "Mean".
     Default value: "Value".
    :vartype type: str or ~azure.ai.metricsadvisor.models.ValueType
    :ivar metric_id: the other metric unique id used for value filter.
    :vartype metric_id: str
    :ivar trigger_for_missing: trigger alert when the corresponding point is missing in the other
     metric

     should be specified only when using other metric to filter.
    :vartype trigger_for_missing: bool
    """

    _validation = {
        'direction': {'required': True},
    }

    _attribute_map = {
        'lower': {'key': 'lower', 'type': 'float'},
        'upper': {'key': 'upper', 'type': 'float'},
        'direction': {'key': 'direction', 'type': 'str'},
        'type': {'key': 'type', 'type': 'str'},
        'metric_id': {'key': 'metricId', 'type': 'str'},
        'trigger_for_missing': {'key': 'triggerForMissing', 'type': 'bool'},
    }

    def __init__(
        self,
        *,
        direction: Union[str, "Direction"],
        lower: Optional[float] = None,
        upper: Optional[float] = None,
        type: Optional[Union[str, "ValueType"]] = "Value",
        metric_id: Optional[str] = None,
        trigger_for_missing: Optional[bool] = None,
        **kwargs
    ):
        """
        :keyword lower: lower bound

         should be specified when direction is Both or Down.
        :paramtype lower: float
        :keyword upper: upper bound

         should be specified when direction is Both or Up.
        :paramtype upper: float
        :keyword direction: Required. value filter direction. Possible values include: "Both", "Down",
         "Up".
        :paramtype direction: str or ~azure.ai.metricsadvisor.models.Direction
        :keyword type: data used to implement value filter. Possible values include: "Value", "Mean".
         Default value: "Value".
        :paramtype type: str or ~azure.ai.metricsadvisor.models.ValueType
        :keyword metric_id: the other metric unique id used for value filter.
        :paramtype metric_id: str
        :keyword trigger_for_missing: trigger alert when the corresponding point is missing in the
         other metric

         should be specified only when using other metric to filter.
        :paramtype trigger_for_missing: bool
        """
        super(_ValueConditionGenerated, self).__init__(**kwargs)
        self.lower = lower
        self.upper = upper
        self.direction = direction
        self.type = type
        self.metric_id = metric_id
        self.trigger_for_missing = trigger_for_missing

class ValueCondition(ValueConditionCustomization, _ValueConditionGenerated):
    pass


class _WebhookHookInfoGenerated(_HookInfoGenerated):
    """WebhookHookInfo.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar hook_type: Required. hook type.Constant filled by server. Possible values include:
     "Webhook", "Email".
    :vartype hook_type: str or ~azure.ai.metricsadvisor.models.HookType
    :ivar hook_id: Hook unique id.
    :vartype hook_id: str
    :ivar hook_name: Required. hook unique name.
    :vartype hook_name: str
    :ivar description: hook description.
    :vartype description: str
    :ivar external_link: hook external link.
    :vartype external_link: str
    :ivar admins: hook administrators.
    :vartype admins: list[str]
    :ivar hook_parameter: Required.
    :vartype hook_parameter: ~azure.ai.metricsadvisor.models.WebhookHookParameter
    """

    _validation = {
        'hook_type': {'required': True},
        'hook_id': {'readonly': True},
        'hook_name': {'required': True},
        'admins': {'unique': True},
        'hook_parameter': {'required': True},
    }

    _attribute_map = {
        'hook_type': {'key': 'hookType', 'type': 'str'},
        'hook_id': {'key': 'hookId', 'type': 'str'},
        'hook_name': {'key': 'hookName', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'external_link': {'key': 'externalLink', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'hook_parameter': {'key': 'hookParameter', 'type': 'WebhookHookParameter'},
    }

    def __init__(
        self,
        *,
        hook_name: str,
        hook_parameter: "WebhookHookParameter",
        description: Optional[str] = "",
        external_link: Optional[str] = "",
        admins: Optional[List[str]] = None,
        **kwargs
    ):
        """
        :keyword hook_name: Required. hook unique name.
        :paramtype hook_name: str
        :keyword description: hook description.
        :paramtype description: str
        :keyword external_link: hook external link.
        :paramtype external_link: str
        :keyword admins: hook administrators.
        :paramtype admins: list[str]
        :keyword hook_parameter: Required.
        :paramtype hook_parameter: ~azure.ai.metricsadvisor.models.WebhookHookParameter
        """
        super(_WebhookHookInfoGenerated, self).__init__(hook_name=hook_name, description=description, external_link=external_link, admins=admins, **kwargs)
        self.hook_type = 'Webhook'  # type: str
        self.hook_parameter = hook_parameter

class WebhookHookInfo(WebhookHookInfoCustomization, HookInfo, _WebhookHookInfoGenerated):
    pass


class _WebhookHookInfoPatchGenerated(_HookInfoPatchGenerated):
    """WebhookHookInfoPatch.

    All required parameters must be populated in order to send to Azure.

    :ivar hook_type: Required. hook type.Constant filled by server. Possible values include:
     "Webhook", "Email".
    :vartype hook_type: str or ~azure.ai.metricsadvisor.models.HookType
    :ivar hook_name: hook unique name.
    :vartype hook_name: str
    :ivar description: hook description.
    :vartype description: str
    :ivar external_link: hook external link.
    :vartype external_link: str
    :ivar admins: hook administrators.
    :vartype admins: list[str]
    :ivar hook_parameter:
    :vartype hook_parameter: ~azure.ai.metricsadvisor.models.WebhookHookParameterPatch
    """

    _validation = {
        'hook_type': {'required': True},
        'admins': {'unique': True},
    }

    _attribute_map = {
        'hook_type': {'key': 'hookType', 'type': 'str'},
        'hook_name': {'key': 'hookName', 'type': 'str'},
        'description': {'key': 'description', 'type': 'str'},
        'external_link': {'key': 'externalLink', 'type': 'str'},
        'admins': {'key': 'admins', 'type': '[str]'},
        'hook_parameter': {'key': 'hookParameter', 'type': 'WebhookHookParameterPatch'},
    }

    def __init__(
        self,
        *,
        hook_name: Optional[str] = None,
        description: Optional[str] = None,
        external_link: Optional[str] = None,
        admins: Optional[List[str]] = None,
        hook_parameter: Optional["WebhookHookParameterPatch"] = None,
        **kwargs
    ):
        """
        :keyword hook_name: hook unique name.
        :paramtype hook_name: str
        :keyword description: hook description.
        :paramtype description: str
        :keyword external_link: hook external link.
        :paramtype external_link: str
        :keyword admins: hook administrators.
        :paramtype admins: list[str]
        :keyword hook_parameter:
        :paramtype hook_parameter: ~azure.ai.metricsadvisor.models.WebhookHookParameterPatch
        """
        super(_WebhookHookInfoPatchGenerated, self).__init__(hook_name=hook_name, description=description, external_link=external_link, admins=admins, **kwargs)
        self.hook_type = 'Webhook'  # type: str
        self.hook_parameter = hook_parameter

class WebhookHookInfoPatch(WebhookHookInfoPatchCustomization, HookInfoPatch, _WebhookHookInfoPatchGenerated):
    pass


class _WebhookHookParameterGenerated(msrest.serialization.Model):
    """WebhookHookParameter.

    All required parameters must be populated in order to send to Azure.

    :ivar endpoint: Required. API address, will be called when alert is triggered, only support
     POST method via SSL.
    :vartype endpoint: str
    :ivar username: (Deprecated) The username, if using basic authentication.
    :vartype username: str
    :ivar password: (Deprecated) The password, if using basic authentication.
    :vartype password: str
    :ivar headers: custom headers in api call.
    :vartype headers: dict[str, str]
    :ivar certificate_key: The certificate key/URL, if using client certificate, please read
     documents for more informations.
    :vartype certificate_key: str
    :ivar certificate_password: The certificate password, if using client certificate, please read
     documents for more informations.
    :vartype certificate_password: str
    """

    _validation = {
        'endpoint': {'required': True},
    }

    _attribute_map = {
        'endpoint': {'key': 'endpoint', 'type': 'str'},
        'username': {'key': 'username', 'type': 'str'},
        'password': {'key': 'password', 'type': 'str'},
        'headers': {'key': 'headers', 'type': '{str}'},
        'certificate_key': {'key': 'certificateKey', 'type': 'str'},
        'certificate_password': {'key': 'certificatePassword', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        endpoint: str,
        username: Optional[str] = None,
        password: Optional[str] = None,
        headers: Optional[Dict[str, str]] = None,
        certificate_key: Optional[str] = None,
        certificate_password: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword endpoint: Required. API address, will be called when alert is triggered, only support
         POST method via SSL.
        :paramtype endpoint: str
        :keyword username: (Deprecated) The username, if using basic authentication.
        :paramtype username: str
        :keyword password: (Deprecated) The password, if using basic authentication.
        :paramtype password: str
        :keyword headers: custom headers in api call.
        :paramtype headers: dict[str, str]
        :keyword certificate_key: The certificate key/URL, if using client certificate, please read
         documents for more informations.
        :paramtype certificate_key: str
        :keyword certificate_password: The certificate password, if using client certificate, please
         read documents for more informations.
        :paramtype certificate_password: str
        """
        super(_WebhookHookParameterGenerated, self).__init__(**kwargs)
        self.endpoint = endpoint
        self.username = username
        self.password = password
        self.headers = headers
        self.certificate_key = certificate_key
        self.certificate_password = certificate_password

class WebhookHookParameter(WebhookHookParameterCustomization, _WebhookHookParameterGenerated):
    pass


class _WebhookHookParameterPatchGenerated(msrest.serialization.Model):
    """WebhookHookParameterPatch.

    :ivar endpoint: API address, will be called when alert is triggered, only support POST method
     via SSL.
    :vartype endpoint: str
    :ivar username: (Deprecated) The username, if using basic authentication.
    :vartype username: str
    :ivar password: (Deprecated) The password, if using basic authentication.
    :vartype password: str
    :ivar headers: custom headers in api call.
    :vartype headers: dict[str, str]
    :ivar certificate_key: The certificate key, if using client certificate.
    :vartype certificate_key: str
    :ivar certificate_password: The certificate password, if using client certificate.
    :vartype certificate_password: str
    """

    _attribute_map = {
        'endpoint': {'key': 'endpoint', 'type': 'str'},
        'username': {'key': 'username', 'type': 'str'},
        'password': {'key': 'password', 'type': 'str'},
        'headers': {'key': 'headers', 'type': '{str}'},
        'certificate_key': {'key': 'certificateKey', 'type': 'str'},
        'certificate_password': {'key': 'certificatePassword', 'type': 'str'},
    }

    def __init__(
        self,
        *,
        endpoint: Optional[str] = None,
        username: Optional[str] = None,
        password: Optional[str] = None,
        headers: Optional[Dict[str, str]] = None,
        certificate_key: Optional[str] = None,
        certificate_password: Optional[str] = None,
        **kwargs
    ):
        """
        :keyword endpoint: API address, will be called when alert is triggered, only support POST
         method via SSL.
        :paramtype endpoint: str
        :keyword username: (Deprecated) The username, if using basic authentication.
        :paramtype username: str
        :keyword password: (Deprecated) The password, if using basic authentication.
        :paramtype password: str
        :keyword headers: custom headers in api call.
        :paramtype headers: dict[str, str]
        :keyword certificate_key: The certificate key, if using client certificate.
        :paramtype certificate_key: str
        :keyword certificate_password: The certificate password, if using client certificate.
        :paramtype certificate_password: str
        """
        super(_WebhookHookParameterPatchGenerated, self).__init__(**kwargs)
        self.endpoint = endpoint
        self.username = username
        self.password = password
        self.headers = headers
        self.certificate_key = certificate_key
        self.certificate_password = certificate_password

class WebhookHookParameterPatch(WebhookHookParameterPatchCustomization, _WebhookHookParameterPatchGenerated):
    pass


class _WholeMetricConfigurationGenerated(msrest.serialization.Model):
    """WholeMetricConfiguration.

    :ivar condition_operator: condition operator

     should be specified when combining multiple detection conditions. Possible values include:
     "AND", "OR".
    :vartype condition_operator: str or
     ~azure.ai.metricsadvisor.models.AnomalyDetectionConfigurationLogicType
    :ivar smart_detection_condition:
    :vartype smart_detection_condition: ~azure.ai.metricsadvisor.models.SmartDetectionCondition
    :ivar hard_threshold_condition:
    :vartype hard_threshold_condition: ~azure.ai.metricsadvisor.models.HardThresholdCondition
    :ivar change_threshold_condition:
    :vartype change_threshold_condition: ~azure.ai.metricsadvisor.models.ChangeThresholdCondition
    """

    _attribute_map = {
        'condition_operator': {'key': 'conditionOperator', 'type': 'str'},
        'smart_detection_condition': {'key': 'smartDetectionCondition', 'type': 'SmartDetectionCondition'},
        'hard_threshold_condition': {'key': 'hardThresholdCondition', 'type': 'HardThresholdCondition'},
        'change_threshold_condition': {'key': 'changeThresholdCondition', 'type': 'ChangeThresholdCondition'},
    }

    def __init__(
        self,
        *,
        condition_operator: Optional[Union[str, "AnomalyDetectionConfigurationLogicType"]] = None,
        smart_detection_condition: Optional["SmartDetectionCondition"] = None,
        hard_threshold_condition: Optional["HardThresholdCondition"] = None,
        change_threshold_condition: Optional["ChangeThresholdCondition"] = None,
        **kwargs
    ):
        """
        :keyword condition_operator: condition operator

         should be specified when combining multiple detection conditions. Possible values include:
         "AND", "OR".
        :paramtype condition_operator: str or
         ~azure.ai.metricsadvisor.models.AnomalyDetectionConfigurationLogicType
        :keyword smart_detection_condition:
        :paramtype smart_detection_condition: ~azure.ai.metricsadvisor.models.SmartDetectionCondition
        :keyword hard_threshold_condition:
        :paramtype hard_threshold_condition: ~azure.ai.metricsadvisor.models.HardThresholdCondition
        :keyword change_threshold_condition:
        :paramtype change_threshold_condition: ~azure.ai.metricsadvisor.models.ChangeThresholdCondition
        """
        super(_WholeMetricConfigurationGenerated, self).__init__(**kwargs)
        self.condition_operator = condition_operator
        self.smart_detection_condition = smart_detection_condition
        self.hard_threshold_condition = hard_threshold_condition
        self.change_threshold_condition = change_threshold_condition

class WholeMetricConfiguration(WholeMetricConfigurationCustomization, _WholeMetricConfigurationGenerated):
    pass


class _WholeMetricConfigurationPatchGenerated(msrest.serialization.Model):
    """WholeMetricConfigurationPatch.

    :ivar condition_operator: condition operator

     should be specified when combining multiple detection conditions. Possible values include:
     "AND", "OR".
    :vartype condition_operator: str or
     ~azure.ai.metricsadvisor.models.AnomalyDetectionConfigurationLogicType
    :ivar smart_detection_condition:
    :vartype smart_detection_condition:
     ~azure.ai.metricsadvisor.models.SmartDetectionConditionPatch
    :ivar hard_threshold_condition:
    :vartype hard_threshold_condition: ~azure.ai.metricsadvisor.models.HardThresholdConditionPatch
    :ivar change_threshold_condition:
    :vartype change_threshold_condition:
     ~azure.ai.metricsadvisor.models.ChangeThresholdConditionPatch
    """

    _attribute_map = {
        'condition_operator': {'key': 'conditionOperator', 'type': 'str'},
        'smart_detection_condition': {'key': 'smartDetectionCondition', 'type': 'SmartDetectionConditionPatch'},
        'hard_threshold_condition': {'key': 'hardThresholdCondition', 'type': 'HardThresholdConditionPatch'},
        'change_threshold_condition': {'key': 'changeThresholdCondition', 'type': 'ChangeThresholdConditionPatch'},
    }

    def __init__(
        self,
        *,
        condition_operator: Optional[Union[str, "AnomalyDetectionConfigurationLogicType"]] = None,
        smart_detection_condition: Optional["SmartDetectionConditionPatch"] = None,
        hard_threshold_condition: Optional["HardThresholdConditionPatch"] = None,
        change_threshold_condition: Optional["ChangeThresholdConditionPatch"] = None,
        **kwargs
    ):
        """
        :keyword condition_operator: condition operator

         should be specified when combining multiple detection conditions. Possible values include:
         "AND", "OR".
        :paramtype condition_operator: str or
         ~azure.ai.metricsadvisor.models.AnomalyDetectionConfigurationLogicType
        :keyword smart_detection_condition:
        :paramtype smart_detection_condition:
         ~azure.ai.metricsadvisor.models.SmartDetectionConditionPatch
        :keyword hard_threshold_condition:
        :paramtype hard_threshold_condition:
         ~azure.ai.metricsadvisor.models.HardThresholdConditionPatch
        :keyword change_threshold_condition:
        :paramtype change_threshold_condition:
         ~azure.ai.metricsadvisor.models.ChangeThresholdConditionPatch
        """
        super(_WholeMetricConfigurationPatchGenerated, self).__init__(**kwargs)
        self.condition_operator = condition_operator
        self.smart_detection_condition = smart_detection_condition
        self.hard_threshold_condition = hard_threshold_condition
        self.change_threshold_condition = change_threshold_condition

class WholeMetricConfigurationPatch(WholeMetricConfigurationPatchCustomization, _WholeMetricConfigurationPatchGenerated):
    pass


if TYPE_CHECKING:
    from . import (
        AnomalySeverity,
        SnoozeScope,
        AnomalyDetectorDirection,
        DataFeedGranularityType,
    )


class DataFeed(object):  # pylint:disable=too-many-instance-attributes
    """Represents a data feed.

    :ivar ~datetime.datetime created_time: Data feed created time.
    :ivar granularity: Granularity of the time series.
    :vartype granularity: ~azure.ai.metricsadvisor.models.DataFeedGranularity
    :ivar str id: Data feed unique id.
    :ivar ingestion_settings: Data feed ingestion settings.
    :vartype ingestion_settings: ~azure.ai.metricsadvisor.models.DataFeedIngestionSettings
    :ivar bool is_admin: Whether the query user is one of data feed administrators or not.
    :ivar dict metric_ids: metric name and metric id dict
    :ivar str name: Data feed name.
    :ivar schema: Data feed schema
    :vartype schema: ~azure.ai.metricsadvisor.models.DataFeedSchema
    :ivar source: Data feed source.
    :vartype source: Union[AzureApplicationInsightsDataFeedSource, AzureBlobDataFeedSource, AzureCosmosDbDataFeedSource,
        AzureDataExplorerDataFeedSource, AzureDataLakeStorageGen2DataFeedSource, AzureTableDataFeedSource,
        AzureEventHubsDataFeedSource, InfluxDbDataFeedSource, MySqlDataFeedSource, PostgreSqlDataFeedSource,
        SqlServerDataFeedSource, MongoDbDataFeedSource, AzureLogAnalyticsDataFeedSource]
    :ivar status: Data feed status. Possible values include: "Active", "Paused".
        Default value: "Active".
    :vartype status: str or ~azure.ai.metricsadvisor.models.DataFeedStatus
    :ivar list[str] admins: Data feed administrators.
    :ivar str data_feed_description: Data feed description.
    :ivar missing_data_point_fill_settings: The fill missing point type and value.
    :vartype missing_data_point_fill_settings:
        ~azure.ai.metricsadvisor.models.DataFeedMissingDataPointFillSettings
    :ivar rollup_settings: The rollup settings.
    :vartype rollup_settings:
        ~azure.ai.metricsadvisor.models.DataFeedRollupSettings
    :ivar list[str] viewers: Data feed viewers.
    :ivar access_mode: Data feed access mode. Possible values include:
        "Private", "Public". Default value: "Private".
    :vartype access_mode: str or ~azure.ai.metricsadvisor.models.DataFeedAccessMode
    :ivar str action_link_template: action link for alert.
    """

    def __init__(
        self,
        name,  # type: str
        source,  # type: DataFeedSourceUnion
        granularity,  # type: DataFeedGranularity
        schema,  # type: DataFeedSchema
        ingestion_settings,  # type: DataFeedIngestionSettings
        **kwargs  # type: Any
    ):
        # type: (...) -> None
        self.name = name
        self.granularity = granularity
        self.ingestion_settings = ingestion_settings
        self.schema = schema
        self.source = source
        self.id = kwargs.get("id", None)
        self.created_time = kwargs.get("created_time", None)
        self.is_admin = kwargs.get("is_admin", None)
        self.metric_ids = kwargs.get("metric_ids", None)
        self.status = kwargs.get("status", None)
        self.admins = kwargs.get("admins", None)
        self.data_feed_description = kwargs.get("data_feed_description", None)
        self.missing_data_point_fill_settings = kwargs.get(
            "missing_data_point_fill_settings", None
        )
        self.rollup_settings = kwargs.get("rollup_settings", None)
        self.viewers = kwargs.get("viewers", None)
        self.access_mode = kwargs.get("access_mode", "Private")
        self.action_link_template = kwargs.get("action_link_template", None)

    def __repr__(self):
        return (
            "DataFeed(created_time={}, granularity={}, id={}, ingestion_settings={}, is_admin={}, "
            "metric_ids={}, name={}, schema={}, source={}, status={}, admins={}, "
            "data_feed_description={}, missing_data_point_fill_settings={}, "
            "rollup_settings={}, viewers={}, access_mode={}, action_link_template={})".format(
                self.created_time,
                repr(self.granularity),
                self.id,
                repr(self.ingestion_settings),
                self.is_admin,
                self.metric_ids,
                self.name,
                repr(self.schema),
                repr(self.source),
                self.status,
                self.admins,
                self.data_feed_description,
                repr(self.missing_data_point_fill_settings),
                repr(self.rollup_settings),
                self.viewers,
                self.access_mode,
                self.action_link_template,
            )[
                :1024
            ]
        )

class MetricAnomalyAlertScope(object):
    """MetricAnomalyAlertScope

    :param scope_type: Required. Anomaly scope. Possible values include: "WholeSeries",
     "SeriesGroup", "TopN".
    :type scope_type: str or ~azure.ai.metricsadvisor.models.MetricAnomalyAlertScopeType
    :keyword series_group_in_scope: Dimension specified for series group.
    :paramtype series_group_in_scope: dict[str, str]
    :keyword top_n_group_in_scope:
    :paramtype top_n_group_in_scope: ~azure.ai.metricsadvisor.models.TopNGroupScope
    """

    def __init__(self, scope_type, **kwargs):
        # type: (Union[str, MetricAnomalyAlertScopeType], Any) -> None
        self.scope_type = scope_type
        self.series_group_in_scope = kwargs.get("series_group_in_scope", None)
        self.top_n_group_in_scope = kwargs.get("top_n_group_in_scope", None)

    def __repr__(self):
        return "MetricAnomalyAlertScope(scope_type={}, series_group_in_scope={}, top_n_group_in_scope={})".format(
            self.scope_type, self.series_group_in_scope, repr(self.top_n_group_in_scope)
        )[
            :1024
        ]


class TopNGroupScope(object):
    """TopNGroupScope.

    :param top: Required. top N, value range : [1, +∞).
    :type top: int
    :param period: Required. point count used to look back, value range : [1, +∞).
    :type period: int
    :param min_top_count: Required. min count should be in top N, value range : [1, +∞)
        should be less than or equal to period.
    :type min_top_count: int
    """

    def __init__(
        self, top, period, min_top_count, **kwargs
    ):  # pylint: disable=unused-argument
        # type: (int, int, int, Any) -> None
        self.top = top
        self.period = period
        self.min_top_count = min_top_count

    def __repr__(self):
        return "TopNGroupScope(top={}, period={}, min_top_count={})".format(
            self.top, self.period, self.min_top_count
        )[:1024]


class SeverityCondition(object):
    """SeverityCondition.

    :param min_alert_severity: Required. min alert severity. Possible values include: "Low",
     "Medium", "High".
    :type min_alert_severity: str or ~azure.ai.metricsadvisor.models.AnomalySeverity
    :param max_alert_severity: Required. max alert severity. Possible values include: "Low",
     "Medium", "High".
    :type max_alert_severity: str or ~azure.ai.metricsadvisor.models.AnomalySeverity
    """

    def __init__(
        self, min_alert_severity, max_alert_severity, **kwargs
    ):  # pylint: disable=unused-argument
        # type: (Union[str, AnomalySeverity], Union[str, AnomalySeverity], Any) -> None
        self.min_alert_severity = min_alert_severity
        self.max_alert_severity = max_alert_severity

    def __repr__(self):
        return "SeverityCondition(min_alert_severity={}, max_alert_severity={})".format(
            self.min_alert_severity, self.max_alert_severity
        )[:1024]


class MetricAnomalyAlertSnoozeCondition(object):
    """MetricAnomalyAlertSnoozeCondition.

    :param auto_snooze: Required. snooze point count, value range : [0, +∞).
    :type auto_snooze: int
    :param snooze_scope: Required. snooze scope. Possible values include: "Metric", "Series".
    :type snooze_scope: str or ~azure.ai.metricsadvisor.models.SnoozeScope
    :param only_for_successive: Required. only snooze for successive anomalies.
    :type only_for_successive: bool
    """

    def __init__(
        self, auto_snooze, snooze_scope, only_for_successive, **kwargs
    ):  # pylint: disable=unused-argument
        # type: (int, Union[str, SnoozeScope], bool, Any) -> None
        self.auto_snooze = auto_snooze
        self.snooze_scope = snooze_scope
        self.only_for_successive = only_for_successive

    def __repr__(self):
        return "MetricAnomalyAlertSnoozeCondition(auto_snooze={}, snooze_scope={}, only_for_successive={})".format(
            self.auto_snooze, self.snooze_scope, self.only_for_successive
        )[
            :1024
        ]


class MetricAnomalyAlertConditions(object):
    """MetricAnomalyAlertConditions

    :keyword metric_boundary_condition:
    :paramtype metric_boundary_condition: ~azure.ai.metricsadvisor.models.MetricBoundaryCondition
    :keyword severity_condition:
    :paramtype severity_condition: ~azure.ai.metricsadvisor.models.SeverityCondition
    """

    def __init__(self, **kwargs):
        self.metric_boundary_condition = kwargs.get("metric_boundary_condition", None)
        self.severity_condition = kwargs.get("severity_condition", None)

    def __repr__(self):
        return "MetricAnomalyAlertConditions(metric_boundary_condition={}, severity_condition={})".format(
            repr(self.metric_boundary_condition), repr(self.severity_condition)
        )[
            :1024
        ]


class MetricBoundaryCondition(object):
    """MetricBoundaryCondition.

    :param direction: Required. value filter direction. Possible values include: "Both", "Down",
     "Up".
    :type direction: str or ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
    :keyword float lower: lower bound should be specified when direction is Both or Down.
    :keyword float upper: upper bound should be specified when direction is Both or Up.
    :keyword str companion_metric_id: the other metric unique id used for value filter.
    :keyword bool trigger_for_missing: trigger alert when the corresponding point is missing in the other
     metric should be specified only when using other metric to filter.
    """

    def __init__(self, direction, **kwargs):
        # type: (Union[str, AnomalyDetectorDirection], Any) -> None
        self.direction = direction
        self.lower = kwargs.get("lower", None)
        self.upper = kwargs.get("upper", None)
        self.companion_metric_id = kwargs.get("companion_metric_id", None)
        self.trigger_for_missing = kwargs.get("trigger_for_missing", None)

    def __repr__(self):
        return (
            "MetricBoundaryCondition(direction={}, lower={}, upper={}, companion_metric_id={}, "
            "trigger_for_missing={})".format(
                self.direction,
                self.lower,
                self.upper,
                self.companion_metric_id,
                self.trigger_for_missing,
            )[:1024]
        )


class MetricAlertConfiguration(object):
    """MetricAlertConfiguration.

    :param detection_configuration_id: Required. Anomaly detection configuration unique id.
    :type detection_configuration_id: str
    :param alert_scope: Required. Anomaly scope.
    :type alert_scope: ~azure.ai.metricsadvisor.models.MetricAnomalyAlertScope
    :keyword negation_operation: Negation operation.
    :paramtype negation_operation: bool
    :keyword alert_conditions:
    :paramtype alert_conditions: ~azure.ai.metricsadvisor.models.MetricAnomalyAlertConditions
    :keyword alert_snooze_condition:
    :paramtype alert_snooze_condition: ~azure.ai.metricsadvisor.models.MetricAnomalyAlertSnoozeCondition
    """

    def __init__(self, detection_configuration_id, alert_scope, **kwargs):
        # type: (str, MetricAnomalyAlertScope, Any) -> None
        self.detection_configuration_id = detection_configuration_id
        self.alert_scope = alert_scope
        self.negation_operation = kwargs.get("negation_operation", None)
        self.alert_conditions = kwargs.get("alert_conditions", None)
        self.alert_snooze_condition = kwargs.get("alert_snooze_condition", None)

    def __repr__(self):
        return (
            "MetricAlertConfiguration(detection_configuration_id={}, alert_scope={}, negation_operation={}, "
            "alert_conditions={}, alert_snooze_condition={})".format(
                self.detection_configuration_id,
                repr(self.alert_scope),
                self.negation_operation,
                repr(self.alert_conditions),
                repr(self.alert_snooze_condition),
            )[:1024]
        )

class AnomalyAlertConfiguration(object):
    """AnomalyAlertConfiguration.

    :param str name: Required. anomaly alert configuration name.
    :param list[str] hook_ids: Required. hook unique ids.
    :param metric_alert_configurations: Required. Anomaly alert configurations.
    :type metric_alert_configurations:
     list[~azure.ai.metricsadvisor.models.MetricAlertConfiguration]
    :ivar id: anomaly alert configuration unique id.
    :vartype id: str
    :ivar description: anomaly alert configuration description.
    :vartype description: str
    :ivar cross_metrics_operator: cross metrics operator
     should be specified when setting up multiple metric alert configurations. Possible values
     include: "AND", "OR", "XOR".
    :vartype cross_metrics_operator: str or
     ~azure.ai.metricsadvisor.models.MetricAnomalyAlertConfigurationsOperator
    :keyword list[str] dimensions_to_split_alert: dimensions used to split alert.

    """

    def __init__(self, name, metric_alert_configurations, hook_ids, **kwargs):
        # type: (str, List[MetricAlertConfiguration], List[str], Any) -> None
        self.name = name
        self.hook_ids = hook_ids
        self.metric_alert_configurations = metric_alert_configurations
        self.id = kwargs.get("id", None)
        self.description = kwargs.get("description", None)
        self.cross_metrics_operator = kwargs.get("cross_metrics_operator", None)
        self.dimensions_to_split_alert = kwargs.get("dimensions_to_split_alert", None)

    def __repr__(self):
        return (
            "AnomalyAlertConfiguration(id={}, name={}, description={}, cross_metrics_operator={}, hook_ids={}, "
            "metric_alert_configurations={}, dimensions_to_split_alert={})".format(
                self.id,
                self.name,
                self.description,
                self.cross_metrics_operator,
                self.hook_ids,
                repr(self.metric_alert_configurations),
                self.dimensions_to_split_alert,
            )[:1024]
        )

class AnomalyDetectionConfiguration(object):
    """AnomalyDetectionConfiguration.


    :param str name: Required. anomaly detection configuration name.
    :param str metric_id: Required. metric unique id.
    :param whole_series_detection_condition: Required.
        Conditions to detect anomalies in all time series of a metric.
    :type whole_series_detection_condition: ~azure.ai.metricsadvisor.models.MetricDetectionCondition
    :ivar str description: anomaly detection configuration description.
    :ivar str id: anomaly detection configuration unique id.
    :ivar series_group_detection_conditions: detection configuration for series group.
    :vartype series_group_detection_conditions:
        list[~azure.ai.metricsadvisor.models.MetricSeriesGroupDetectionCondition]
    :ivar series_detection_conditions: detection configuration for specific series.
    :vartype series_detection_conditions:
        list[~azure.ai.metricsadvisor.models.MetricSingleSeriesDetectionCondition]
    """

    def __init__(self, name, metric_id, whole_series_detection_condition, **kwargs):
        # type: (str, str, MetricDetectionCondition, Any) -> None
        self.name = name
        self.metric_id = metric_id
        self.whole_series_detection_condition = whole_series_detection_condition
        self.id = kwargs.get("id", None)
        self.description = kwargs.get("description", None)
        self.series_group_detection_conditions = kwargs.get(
            "series_group_detection_conditions", None
        )
        self.series_detection_conditions = kwargs.get(
            "series_detection_conditions", None
        )

    def __repr__(self):
        return (
            "AnomalyDetectionConfiguration(id={}, name={}, description={}, metric_id={}, "
            "whole_series_detection_condition={}, series_group_detection_conditions={}, "
            "series_detection_conditions={})".format(
                self.id,
                self.name,
                self.description,
                self.metric_id,
                repr(self.whole_series_detection_condition),
                repr(self.series_group_detection_conditions),
                repr(self.series_detection_conditions),
            )[:1024]
        )

class DataFeedSource(dict):
    """DataFeedSource base class

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :ivar str credential_id: The datasource credential id.
    """

    def __init__(self, data_source_type, **kwargs):
        # type: (str, **Any) -> None
        super(DataFeedSource, self).__init__(
            data_source_type=data_source_type, **kwargs
        )
        self.data_source_type = data_source_type
        self.authentication_type = kwargs.get("authentication_type", None)
        self.credential_id = kwargs.get("credential_id", None)


class AzureApplicationInsightsDataFeedSource(DataFeedSource):
    """AzureApplicationInsightsDataFeedSource.

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :keyword str credential_id: The datasource credential id.
    :param str query: Required. Query.
    :keyword str azure_cloud: Azure cloud environment.
    :keyword str application_id: Azure Application Insights ID.
    :keyword str api_key: API Key.
    """

    def __init__(self, query, **kwargs):
        # type: (str, **Any) -> None
        super(AzureApplicationInsightsDataFeedSource, self).__init__(
            data_source_type="AzureApplicationInsights",
            authentication_type="Basic",
            **kwargs
        )
        self.azure_cloud = kwargs.get("azure_cloud", None)
        self.application_id = kwargs.get("application_id", None)
        self.api_key = kwargs.get("api_key", None)
        self.query = query

    def __repr__(self):
        return (
            "AzureApplicationInsightsDataFeedSource(data_source_type={}, azure_cloud={}, application_id={}, "
            "api_key={}, query={}, authentication_type={}, credential_id={})".format(
                self.data_source_type,
                self.azure_cloud,
                self.application_id,
                self.api_key,
                self.query,
                self.authentication_type,
                self.credential_id,
            )[:1024]
        )

class AzureBlobDataFeedSource(DataFeedSource):
    """AzureBlobDataFeedSource.

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :keyword str credential_id: The datasource credential id.
    :param container: Required. Container.
    :type container: str
    :param blob_template: Required. Blob Template.
    :type blob_template: str
    :keyword str connection_string: Azure Blob connection string.
    :keyword bool msi: If using managed identity authentication.
    """

    def __init__(self, container, blob_template, **kwargs):
        # type: (str, str, **Any) -> None
        super(AzureBlobDataFeedSource, self).__init__(
            data_source_type="AzureBlob", **kwargs
        )
        msi = kwargs.get("msi", False)
        if msi:
            self.authentication_type = "ManagedIdentity"
        else:
            self.authentication_type = "Basic"
            self.connection_string = kwargs.get("connection_string", None)
        self.container = container
        self.blob_template = blob_template

    def __repr__(self):
        return (
            "AzureBlobDataFeedSource(data_source_type={}, connection_string={}, container={}, "
            "blob_template={}, authentication_type={}, credential_id={})".format(
                self.data_source_type,
                self.connection_string,
                self.container,
                self.blob_template,
                self.authentication_type,
                self.credential_id,
            )[:1024]
        )

class AzureCosmosDbDataFeedSource(DataFeedSource):
    """AzureCosmosDbDataFeedSource.

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :keyword str credential_id: The datasource credential id.
    :param sql_query: Required. Query script.
    :type sql_query: str
    :param database: Required. Database name.
    :type database: str
    :param collection_id: Required. Collection id.
    :type collection_id: str
    :keyword str connection_string: Azure CosmosDB connection string.
    """

    def __init__(self, sql_query, database, collection_id, **kwargs):
        # type: (str, str, str, **Any) -> None
        super(AzureCosmosDbDataFeedSource, self).__init__(
            data_source_type="AzureCosmosDB", authentication_type="Basic", **kwargs
        )
        self.connection_string = kwargs.get("connection_string", None)
        self.sql_query = sql_query
        self.database = database
        self.collection_id = collection_id

    def __repr__(self):
        return (
            "AzureCosmosDbDataFeedSource(data_source_type={}, connection_string={}, sql_query={}, database={}, "
            "collection_id={}, authentication_type={}, credential_id={})".format(
                self.data_source_type,
                self.connection_string,
                self.sql_query,
                self.database,
                self.collection_id,
                self.authentication_type,
                self.credential_id,
            )[:1024]
        )

class AzureDataExplorerDataFeedSource(DataFeedSource):
    """AzureDataExplorerDataFeedSource.

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :keyword str credential_id: The datasource credential id.
    :param query: Required. Query script.
    :type query: str
    :keyword str connection_string: Database connection string.
    :keyword bool msi: If using managed identity authentication.
    :keyword str datasource_service_principal_id: Datasource service principal unique id.
    :keyword str datasource_service_principal_in_kv_id: Datasource service principal in key vault unique id.
    """

    def __init__(self, query, **kwargs):
        # type: (str, **Any) -> None
        super(AzureDataExplorerDataFeedSource, self).__init__(
            data_source_type="AzureDataExplorer", **kwargs
        )
        msi = kwargs.get("msi", False)
        datasource_service_principal_id = kwargs.get(
            "datasource_service_principal_id", False
        )
        datasource_service_principal_in_kv_id = kwargs.get(
            "datasource_service_principal_in_kv_id", False
        )
        if msi:
            self.authentication_type = "ManagedIdentity"
        elif datasource_service_principal_id:
            self.authentication_type = "ServicePrincipal"
            self.credential_id = datasource_service_principal_id
        elif datasource_service_principal_in_kv_id:
            self.authentication_type = "ServicePrincipalInKV"
            self.credential_id = datasource_service_principal_in_kv_id
        else:
            self.authentication_type = "Basic"
        self.connection_string = kwargs.get("connection_string", None)
        self.query = query

    def __repr__(self):
        return (
            "AzureDataExplorerDataFeedSource(data_source_type={}, connection_string={}, query={}, "
            "authentication_type={}, credential_id={})".format(
                self.data_source_type,
                self.connection_string,
                self.query,
                self.authentication_type,
                self.credential_id,
            )[:1024]
        )

class AzureTableDataFeedSource(DataFeedSource):
    """AzureTableDataFeedSource.

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :keyword str credential_id: The datasource credential id.
    :param str query: Required. Query script.
    :param str table: Required. Table name.
    :keyword str connection_string: Azure Table connection string.
    """

    def __init__(self, query, table, **kwargs):
        # type: (str, str, **Any) -> None
        super(AzureTableDataFeedSource, self).__init__(
            data_source_type="AzureTable", authentication_type="Basic", **kwargs
        )
        self.connection_string = kwargs.get("connection_string", None)
        self.query = query
        self.table = table

    def __repr__(self):
        return (
            "AzureTableDataFeedSource(data_source_type={}, connection_string={}, query={}, table={}, "
            "authentication_type={}, credential_id={})".format(
                self.data_source_type,
                self.connection_string,
                self.query,
                self.table,
                self.authentication_type,
                self.credential_id,
            )[:1024]
        )

class AzureEventHubsDataFeedSource(DataFeedSource):
    """AzureEventHubsDataFeedSource.

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :keyword str credential_id: The datasource credential id.
    :keyword str connection_string: The connection string of this Azure Event Hubs.
    :param str consumer_group: Required. The consumer group to be used in this data feed.
    """

    def __init__(self, consumer_group, **kwargs):
        # type: (str, **Any) -> None
        super(AzureEventHubsDataFeedSource, self).__init__(
            data_source_type="AzureEventHubs", authentication_type="Basic", **kwargs
        )
        self.connection_string = kwargs.get("connection_string", None)
        self.consumer_group = consumer_group

    def __repr__(self):
        return (
            "AzureEventHubsDataFeedSource(data_source_type={}, connection_string={}, consumer_group={}, "
            "authentication_type={}, credential_id={})".format(
                self.data_source_type,
                self.connection_string,
                self.consumer_group,
                self.authentication_type,
                self.credential_id,
            )[:1024]
        )

class InfluxDbDataFeedSource(DataFeedSource):
    """InfluxDbDataFeedSource.

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :keyword str credential_id: The datasource credential id.
    :keyword str connection_string: InfluxDB connection string.
    :keyword str database: Database name.
    :keyword str user_name: Database access user.
    :keyword str password: Required. Database access password.
    :param str query: Required. Query script.
    """

    def __init__(self, query, **kwargs):
        # type: (str, **Any) -> None
        super(InfluxDbDataFeedSource, self).__init__(
            data_source_type="InfluxDB", authentication_type="Basic", **kwargs
        )
        self.connection_string = kwargs.get("connection_string", None)
        self.database = kwargs.get("database", None)
        self.user_name = kwargs.get("user_name", None)
        self.password = kwargs.get("password", None)
        self.query = query

    def __repr__(self):
        return (
            "InfluxDbDataFeedSource(data_source_type={}, connection_string={}, database={}, user_name={}, "
            "password={}, query={}, authentication_type={}, credential_id={})".format(
                self.data_source_type,
                self.connection_string,
                self.database,
                self.user_name,
                self.password,
                self.query,
                self.authentication_type,
                self.credential_id,
            )[:1024]
        )


class MySqlDataFeedSource(DataFeedSource):
    """MySqlDataFeedSource.

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :keyword str credential_id: The datasource credential id.
    :keyword str connection_string: Database connection string.
    :param str query: Required. Query script.
    """

    def __init__(self, query, **kwargs):
        # type: (str, **Any) -> None
        super(MySqlDataFeedSource, self).__init__(
            data_source_type="MySql", authentication_type="Basic", **kwargs
        )
        self.connection_string = kwargs.get("connection_string", None)
        self.query = query

    def __repr__(self):
        return (
            "MySqlDataFeedSource(data_source_type={}, connection_string={}, query={}, "
            "authentication_type={}, credential_id={})".format(
                self.data_source_type,
                self.connection_string,
                self.query,
                self.authentication_type,
                self.credential_id,
            )[:1024]
        )

class PostgreSqlDataFeedSource(DataFeedSource):
    """PostgreSqlDataFeedSource.

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :keyword str credential_id: The datasource credential id.
    :keyword str connection_string: Database connection string.
    :param str query: Required. Query script.
    """

    def __init__(self, query, **kwargs):
        # type: (str, **Any) -> None
        super(PostgreSqlDataFeedSource, self).__init__(
            data_source_type="PostgreSql", authentication_type="Basic", **kwargs
        )
        self.connection_string = kwargs.get("connection_string", None)
        self.query = query

    def __repr__(self):
        return (
            "PostgreSqlDataFeedSource(data_source_type={}, connection_string={}, query={}, "
            "authentication_type={}, credential_id={})".format(
                self.data_source_type,
                self.connection_string,
                self.query,
                self.authentication_type,
                self.credential_id,
            )[:1024]
        )

class SqlServerDataFeedSource(DataFeedSource):
    """SqlServerDataFeedSource.

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :keyword str credential_id: The datasource credential id.
    :param str query: Required. Query script.
    :keyword str connection_string: Database connection string.
    :keyword bool msi: If using managed identity authentication.
    :keyword str datasource_service_principal_id: Datasource service principal unique id.
    :keyword str datasource_service_principal_in_kv_id: Datasource service principal in key vault unique id.
    :keyword str datasource_sql_connection_string_id: Datasource sql connection string unique id.
    """

    def __init__(self, query, **kwargs):
        # type: (str, **Any) -> None
        super(SqlServerDataFeedSource, self).__init__(
            data_source_type="SqlServer", **kwargs
        )
        msi = kwargs.get("msi", False)
        datasource_service_principal_id = kwargs.get(
            "datasource_service_principal_id", False
        )
        datasource_service_principal_in_kv_id = kwargs.get(
            "datasource_service_principal_in_kv_id", False
        )
        datasource_sql_connection_string_id = kwargs.get(
            "datasource_sql_connection_string_id", False
        )
        if msi:
            self.authentication_type = "ManagedIdentity"
        elif datasource_service_principal_id:
            self.authentication_type = "ServicePrincipal"
            self.credential_id = datasource_service_principal_id
        elif datasource_service_principal_in_kv_id:
            self.authentication_type = "ServicePrincipalInKV"
            self.credential_id = datasource_service_principal_in_kv_id
        elif datasource_sql_connection_string_id:
            self.authentication_type = "AzureSQLConnectionString"
            self.credential_id = datasource_sql_connection_string_id
        else:
            self.authentication_type = "Basic"
        self.connection_string = kwargs.get("connection_string", None)
        self.query = query

    def __repr__(self):
        return (
            "SqlServerDataFeedSource(data_source_type={}, connection_string={}, query={}, "
            "authentication_type={}, credential_id={})".format(
                self.data_source_type,
                self.connection_string,
                self.query,
                self.authentication_type,
                self.credential_id,
            )[:1024]
        )

class AzureDataLakeStorageGen2DataFeedSource(DataFeedSource):
    """AzureDataLakeStorageGen2DataFeedSource.

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :keyword str credential_id: The datasource credential id.
    :keyword str account_name: Account name.
    :keyword str account_key: Account key.
    :param str file_system_name: Required. File system name (Container).
    :param str directory_template: Required. Directory template.
    :param str file_template: Required. File template.
    :keyword bool msi: If using managed identity authentication.
    :keyword str datasource_service_principal_id: Datasource service principal unique id.
    :keyword str datasource_service_principal_in_kv_id: Datasource service principal in key vault unique id.
    :keyword str datasource_datalake_gen2_shared_key_id: Datasource datalake gen2 shared key unique id.
    """

    def __init__(self, file_system_name, directory_template, file_template, **kwargs):
        # type: (str, str, str, **Any) -> None
        super(AzureDataLakeStorageGen2DataFeedSource, self).__init__(
            data_source_type="AzureDataLakeStorageGen2", **kwargs
        )
        msi = kwargs.get("msi", False)
        datasource_service_principal_id = kwargs.get(
            "datasource_service_principal_id", False
        )
        datasource_service_principal_in_kv_id = kwargs.get(
            "datasource_service_principal_in_kv_id", False
        )
        datasource_datalake_gen2_shared_key_id = kwargs.get(
            "datasource_datalake_gen2_shared_key_id", False
        )
        if msi:
            self.authentication_type = "ManagedIdentity"
        elif datasource_service_principal_id:
            self.authentication_type = "ServicePrincipal"
            self.credential_id = datasource_service_principal_id
        elif datasource_service_principal_in_kv_id:
            self.authentication_type = "ServicePrincipalInKV"
            self.credential_id = datasource_service_principal_in_kv_id
        elif datasource_datalake_gen2_shared_key_id:
            self.authentication_type = "DataLakeGen2SharedKey"
            self.credential_id = datasource_datalake_gen2_shared_key_id
        else:
            self.authentication_type = "Basic"
        self.account_name = kwargs.get("account_name", None)
        self.account_key = kwargs.get("account_key", None)
        self.file_system_name = file_system_name
        self.directory_template = directory_template
        self.file_template = file_template

    def __repr__(self):
        return (
            "AzureDataLakeStorageGen2DataFeedSource(data_source_type={}, account_name={}, account_key={}, "
            "file_system_name={}, directory_template={}, file_template={}, authentication_type={},"
            " credential_id={})".format(
                self.data_source_type,
                self.account_name,
                self.account_key,
                self.file_system_name,
                self.directory_template,
                self.file_template,
                self.authentication_type,
                self.credential_id,
            )[:1024]
        )

class AzureLogAnalyticsDataFeedSource(DataFeedSource):
    """AzureLogAnalyticsDataFeedSource.

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :keyword str credential_id: The datasource credential id.
    :keyword str tenant_id: The tenant id of service principal that have access to this Log
     Analytics.
    :keyword str client_id: The client id of service principal that have access to this Log
     Analytics.
    :keyword str client_secret: The client secret of service principal that have access to this Log Analytics.
    :keyword str datasource_service_principal_id: Datasource service principal unique id.
    :keyword str datasource_service_principal_in_kv_id: Datasource service principal in key vault unique id.
    :param str workspace_id: Required. The workspace id of this Log Analytics.
    :param str query: Required. The KQL (Kusto Query Language) query to fetch data from this Log
     Analytics.
    """

    def __init__(self, workspace_id, query, **kwargs):
        # type: (str, str, **Any) -> None
        super(AzureLogAnalyticsDataFeedSource, self).__init__(
            data_source_type="AzureLogAnalytics", **kwargs
        )
        datasource_service_principal_id = kwargs.get(
            "datasource_service_principal_id", False
        )
        datasource_service_principal_in_kv_id = kwargs.get(
            "datasource_service_principal_in_kv_id", False
        )
        if datasource_service_principal_id:
            self.authentication_type = "ServicePrincipal"
            self.credential_id = datasource_service_principal_id
        elif datasource_service_principal_in_kv_id:
            self.authentication_type = "ServicePrincipalInKV"
            self.credential_id = datasource_service_principal_in_kv_id
        else:
            self.authentication_type = "Basic"
            self.tenant_id = kwargs.get("tenant_id", None)
            self.client_id = kwargs.get("client_id", None)
            self.client_secret = kwargs.get("client_secret", None)
        self.workspace_id = workspace_id
        self.query = query

    def __repr__(self):
        return (
            "AzureLogAnalyticsDataFeedSource(data_source_type={}, tenant_id={}, client_id={}, "
            "client_secret={}, workspace_id={}, query={}, authentication_type={}, credential_id={})".format(
                self.data_source_type,
                self.tenant_id,
                self.client_id,
                self.client_secret,
                self.workspace_id,
                self.query,
                self.authentication_type,
                self.credential_id,
            )[
                :1024
            ]
        )

class MongoDbDataFeedSource(DataFeedSource):
    """MongoDbDataFeedSource.

    :ivar data_source_type: Required. data source type.Constant filled by server.  Possible values
     include: "AzureApplicationInsights", "AzureBlob", "AzureCosmosDB", "AzureDataExplorer",
     "AzureDataLakeStorageGen2", "AzureEventHubs", "AzureLogAnalytics", "AzureTable", "InfluxDB",
     "MongoDB", "MySql", "PostgreSql", "SqlServer".
    :vartype data_source_type: str or ~azure.ai.metricsadvisor.models.DatasourceType
    :ivar authentication_type: authentication type for corresponding data source. Possible values
     include: "Basic", "ManagedIdentity", "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV". Default is "Basic".
    :vartype authentication_type: str or ~azure.ai.metricsadvisor.models.DatasourceAuthenticationType
    :keyword str credential_id: The datasource credential id.
    :keyword str connection_string: MongoDb connection string.
    :keyword str database: Database name.
    :param str command: Required. Query script.
    """

    def __init__(self, command, **kwargs):
        # type: (str, **Any) -> None
        super(MongoDbDataFeedSource, self).__init__(
            data_source_type="MongoDB", authentication_type="Basic", **kwargs
        )
        self.connection_string = kwargs.get("connection_string", None)
        self.database = kwargs.get("database", None)
        self.command = command

    def __repr__(self):
        return (
            "MongoDbDataFeedSource(data_source_type={}, connection_string={}, database={}, command={}, "
            "authentication_type={}, credential_id={})".format(
                self.data_source_type,
                self.connection_string,
                self.database,
                self.command,
                self.authentication_type,
                self.credential_id,
            )[:1024]
        )

class NotificationHook(dict):
    """NotificationHook.

    :param str name: Hook unique name.
    :ivar str description: Hook description.
    :ivar str external_link: Hook external link.
    :ivar list[str] admins: Hook administrators.
    :ivar str hook_type: Constant filled by server. Possible values include:
        "Webhook", "Email".
    :ivar str id: Hook unique id.
    """

    def __init__(self, name, **kwargs):
        super(NotificationHook, self).__init__(name=name, **kwargs)
        self.id = kwargs.get("id", None)
        self.name = name
        self.description = kwargs.get("description", None)
        self.external_link = kwargs.get("external_link", None)
        self.admins = kwargs.get("admins", None)
        self.hook_type = None

    def __repr__(self):
        return (
            "NotificationHook(id={}, name={}, description={}, external_link={}, admins={}, "
            "hook_type={})".format(
                self.id,
                self.name,
                self.description,
                self.external_link,
                self.admins,
                self.hook_type,
            )[:1024]
        )


class EmailNotificationHook(NotificationHook):
    """EmailNotificationHook.

    :param str name: Hook unique name.
    :param list[str] emails_to_alert: Required. Email TO: list.
    :keyword str description: Hook description.
    :keyword str external_link: Hook external link.
    :ivar list[str] admins: Hook administrators.
    :ivar str hook_type: Constant filled by server - "Email".
    :ivar str id: Hook unique id.
    """

    def __init__(self, name, emails_to_alert, **kwargs):
        # type: (str, List[str], Any) -> None
        super(EmailNotificationHook, self).__init__(name, **kwargs)
        self.hook_type = "Email"  # type: str
        self.emails_to_alert = emails_to_alert

    def __repr__(self):
        return (
            "EmailNotificationHook(id={}, name={}, description={}, external_link={}, admins={}, hook_type={}, "
            "emails_to_alert={})".format(
                self.id,
                self.name,
                self.description,
                self.external_link,
                self.admins,
                self.hook_type,
                self.emails_to_alert,
            )[:1024]
        )


class WebNotificationHook(NotificationHook):
    """WebNotificationHook.

    :param str name: Hook unique name.
    :param str endpoint: Required. API address, will be called when alert is triggered, only support
        POST method via SSL.
    :keyword str username: basic authentication.
    :keyword str password: basic authentication.
    :keyword str certificate_key: client certificate.
    :keyword str certificate_password: client certificate password.
    :keyword str description: Hook description.
    :keyword str external_link: Hook external link.
    :ivar list[str] admins: Hook administrators.
    :ivar str hook_type: Constant filled by server - "Webhook".
    :ivar str id: Hook unique id.
    """

    def __init__(self, name, endpoint, **kwargs):
        # type: (str, str, Any) -> None
        super(WebNotificationHook, self).__init__(name, **kwargs)
        self.hook_type = "Webhook"  # type: str
        self.endpoint = endpoint
        self.username = kwargs.get("username", None)
        self.password = kwargs.get("password", None)
        self.certificate_key = kwargs.get("certificate_key", None)
        self.certificate_password = kwargs.get("certificate_password", None)

    def __repr__(self):
        return (
            "WebNotificationHook(id={}, name={}, description={}, external_link={}, admins={}, hook_type={}, "
            "endpoint={}, username={}, password={}, certificate_key={}, certificate_password={})".format(
                self.id,
                self.name,
                self.description,
                self.external_link,
                self.admins,
                self.hook_type,
                self.endpoint,
                self.username,
                self.password,
                self.certificate_key,
                self.certificate_password,
            )[
                :1024
            ]
        )

class MetricDetectionCondition(object):
    """MetricDetectionCondition.

    :keyword condition_operator: condition operator
     should be specified when combining multiple detection conditions. Possible values include:
     "AND", "OR".
    :paramtype condition_operator: str or
     ~azure.ai.metricsadvisor.models.DetectionConditionOperator
    :keyword smart_detection_condition:
    :paramtype smart_detection_condition: ~azure.ai.metricsadvisor.models.SmartDetectionCondition
    :keyword hard_threshold_condition:
    :paramtype hard_threshold_condition: ~azure.ai.metricsadvisor.models.HardThresholdCondition
    :keyword change_threshold_condition:
    :paramtype change_threshold_condition: ~azure.ai.metricsadvisor.models.ChangeThresholdCondition
    """

    def __init__(self, **kwargs):
        self.condition_operator = kwargs.get("condition_operator", None)
        self.smart_detection_condition = kwargs.get("smart_detection_condition", None)
        self.hard_threshold_condition = kwargs.get("hard_threshold_condition", None)
        self.change_threshold_condition = kwargs.get("change_threshold_condition", None)

    def __repr__(self):
        return (
            "MetricDetectionCondition(condition_operator={}, smart_detection_condition={}, "
            "hard_threshold_condition={}, change_threshold_condition={})".format(
                self.condition_operator,
                repr(self.smart_detection_condition),
                repr(self.hard_threshold_condition),
                repr(self.change_threshold_condition),
            )[:1024]
        )

class ChangeThresholdCondition(object):
    """ChangeThresholdCondition.

    :param change_percentage: Required. change percentage, value range : [0, +∞).
    :type change_percentage: float
    :param shift_point: Required. shift point, value range : [1, +∞).
    :type shift_point: int
    :param within_range: Required. if the withinRange = true, detected data is abnormal when the
        value falls in the range, in this case anomalyDetectorDirection must be Both
        if the withinRange = false, detected data is abnormal when the value falls out of the range.
    :type within_range: bool
    :param anomaly_detector_direction: Required. detection direction. Possible values include:
        "Both", "Down", "Up".
    :type anomaly_detector_direction: str or
        ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
    :param suppress_condition: Required.
    :type suppress_condition: ~azure.ai.metricsadvisor.models.SuppressCondition
    """

    def __init__(
        self,
        change_percentage,  # type: float
        shift_point,  # type: int
        within_range,  # type: bool
        anomaly_detector_direction,  # type: Union[str, AnomalyDetectorDirection]
        suppress_condition,  # type: SuppressCondition
        **kwargs  # type: Any
    ):  # pylint: disable=unused-argument
        # type: (...) -> None
        self.change_percentage = change_percentage
        self.shift_point = shift_point
        self.within_range = within_range
        self.anomaly_detector_direction = anomaly_detector_direction
        self.suppress_condition = suppress_condition

    def __repr__(self):
        return (
            "ChangeThresholdCondition(change_percentage={}, shift_point={}, within_range={}, "
            "anomaly_detector_direction={}, suppress_condition={})".format(
                self.change_percentage,
                self.shift_point,
                self.within_range,
                self.anomaly_detector_direction,
                repr(self.suppress_condition),
            )[:1024]
        )

class SuppressCondition(object):
    """SuppressCondition.

    :param min_number: Required. min point number, value range : [1, +∞).
    :type min_number: int
    :param min_ratio: Required. min point ratio, value range : (0, 100].
    :type min_ratio: float
    """

    def __init__(
        self, min_number, min_ratio, **kwargs
    ):  # pylint: disable=unused-argument
        # type: (int, float, Any) -> None
        self.min_number = min_number
        self.min_ratio = min_ratio

    def __repr__(self):
        return "SuppressCondition(min_number={}, min_ratio={})".format(
            self.min_number, self.min_ratio
        )[:1024]

class SmartDetectionCondition(object):
    """SmartDetectionCondition.

    :param sensitivity: Required. sensitivity, value range : (0, 100].
    :type sensitivity: float
    :param anomaly_detector_direction: Required. detection direction. Possible values include:
     "Both", "Down", "Up".
    :type anomaly_detector_direction: str or
     ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
    :param suppress_condition: Required.
    :type suppress_condition: ~azure.ai.metricsadvisor.models.SuppressCondition
    """

    def __init__(
        self, sensitivity, anomaly_detector_direction, suppress_condition, **kwargs
    ):  # pylint: disable=unused-argument
        # type: (float, Union[str, AnomalyDetectorDirection], SuppressCondition, Any) -> None
        self.sensitivity = sensitivity
        self.anomaly_detector_direction = anomaly_detector_direction
        self.suppress_condition = suppress_condition

    def __repr__(self):
        return "SmartDetectionCondition(sensitivity={}, anomaly_detector_direction={}, suppress_condition={})".format(
            self.sensitivity,
            self.anomaly_detector_direction,
            repr(self.suppress_condition),
        )[
            :1024
        ]

class HardThresholdCondition(object):
    """HardThresholdCondition.

    :param anomaly_detector_direction: Required. detection direction. Possible values include:
        "Both", "Down", "Up".
    :type anomaly_detector_direction: str or
        ~azure.ai.metricsadvisor.models.AnomalyDetectorDirection
    :param suppress_condition: Required.
    :type suppress_condition: ~azure.ai.metricsadvisor.models.SuppressCondition
    :keyword lower_bound: lower bound
        should be specified when anomalyDetectorDirection is Both or Down.
    :paramtype lower_bound: float
    :keyword upper_bound: upper bound
        should be specified when anomalyDetectorDirection is Both or Up.
    :paramtype upper_bound: float
    """

    def __init__(self, anomaly_detector_direction, suppress_condition, **kwargs):
        # type: (Union[str, AnomalyDetectorDirection], SuppressCondition, Any) -> None
        self.anomaly_detector_direction = anomaly_detector_direction
        self.suppress_condition = suppress_condition
        self.lower_bound = kwargs.get("lower_bound", None)
        self.upper_bound = kwargs.get("upper_bound", None)

    def __repr__(self):
        return (
            "HardThresholdCondition(anomaly_detector_direction={}, suppress_condition={}, lower_bound={}, "
            "upper_bound={})".format(
                self.anomaly_detector_direction,
                repr(self.suppress_condition),
                self.lower_bound,
                self.upper_bound,
            )[:1024]
        )

class MetricSeriesGroupDetectionCondition(MetricDetectionCondition):
    """MetricSeriesGroupAnomalyDetectionConditions.

    :param series_group_key: Required. dimension specified for series group.
    :type series_group_key: dict[str, str]
    :keyword condition_operator: condition operator
        should be specified when combining multiple detection conditions. Possible values include:
        "AND", "OR".
    :paramtype condition_operator: str or
        ~azure.ai.metricsadvisor.models.DetectionConditionOperator
    :keyword smart_detection_condition:
    :paramtype smart_detection_condition: ~azure.ai.metricsadvisor.models.SmartDetectionCondition
    :keyword hard_threshold_condition:
    :paramtype hard_threshold_condition: ~azure.ai.metricsadvisor.models.HardThresholdCondition
    :keyword change_threshold_condition:
    :paramtype change_threshold_condition: ~azure.ai.metricsadvisor.models.ChangeThresholdCondition
    """

    def __init__(self, series_group_key, **kwargs):
        # type: (Dict[str, str], Any) -> None
        super(MetricSeriesGroupDetectionCondition, self).__init__(**kwargs)
        self.series_group_key = series_group_key

    def __repr__(self):
        return (
            "MetricSeriesGroupDetectionCondition(condition_operator={}, smart_detection_condition={}, "
            "hard_threshold_condition={}, change_threshold_condition={}, series_group_key={})".format(
                self.condition_operator,
                repr(self.smart_detection_condition),
                repr(self.hard_threshold_condition),
                repr(self.change_threshold_condition),
                self.series_group_key,
            )[
                :1024
            ]
        )


class MetricSingleSeriesDetectionCondition(MetricDetectionCondition):
    """MetricSingleSeriesDetectionCondition.

    :param series_key: Required. dimension specified for series.
    :type series_key: dict[str, str]
    :keyword condition_operator: condition operator
        should be specified when combining multiple detection conditions. Possible values include:
        "AND", "OR".
    :paramtype condition_operator: str or
        ~azure.ai.metricsadvisor.models.DetectionConditionOperator
    :keyword smart_detection_condition:
    :paramtype smart_detection_condition: ~azure.ai.metricsadvisor.models.SmartDetectionCondition
    :keyword hard_threshold_condition:
    :paramtype hard_threshold_condition: ~azure.ai.metricsadvisor.models.HardThresholdCondition
    :keyword change_threshold_condition:
    :paramtype change_threshold_condition: ~azure.ai.metricsadvisor.models.ChangeThresholdCondition
    """

    def __init__(self, series_key, **kwargs):
        # type: (Dict[str, str], Any) -> None
        super(MetricSingleSeriesDetectionCondition, self).__init__(**kwargs)
        self.series_key = series_key

    def __repr__(self):
        return (
            "MetricSingleSeriesDetectionCondition(condition_operator={}, smart_detection_condition={}, "
            "hard_threshold_condition={}, change_threshold_condition={}, series_key={})".format(
                self.condition_operator,
                repr(self.smart_detection_condition),
                repr(self.hard_threshold_condition),
                repr(self.change_threshold_condition),
                self.series_key,
            )[
                :1024
            ]
        )

class DataFeedMetric(object):
    """DataFeedMetric.

    :param name: Required. metric name.
    :type name: str
    :keyword display_name: metric display name.
    :paramtype display_name: str
    :keyword description: metric description.
    :paramtype description: str
    :ivar id: metric id.
    :vartype id: str
    """

    def __init__(self, name, **kwargs):
        # type: (str, Any) -> None
        self.name = name
        self.id = kwargs.get("id", None)
        self.display_name = kwargs.get("display_name", None)
        self.description = kwargs.get("description", None)

    def __repr__(self):
        return "DataFeedMetric(name={}, id={}, display_name={}, description={})".format(
            self.name, self.id, self.display_name, self.description
        )[:1024]

class DataFeedDimension(object):
    """DataFeedDimension.

    :param name: Required. dimension name.
    :type name: str
    :keyword display_name: dimension display name.
    :paramtype display_name: str
    """

    def __init__(self, name, **kwargs):
        # type: (str, Any) -> None
        self.name = name
        self.display_name = kwargs.get("display_name", None)

    def __repr__(self):
        return "DataFeedDimension(name={}, display_name={})".format(
            self.name, self.display_name
        )[:1024]

class DataFeedIngestionProgress(object):
    """DataFeedIngestionProgress.

    :ivar latest_success_timestamp: the timestamp of lastest success ingestion job.
     null indicates not available.
    :vartype latest_success_timestamp: ~datetime.datetime
    :ivar latest_active_timestamp: the timestamp of lastest ingestion job with status update.
     null indicates not available.
    :vartype latest_active_timestamp: ~datetime.datetime
    """

    def __init__(self, **kwargs):
        self.latest_success_timestamp = kwargs.get("latest_success_timestamp")
        self.latest_active_timestamp = kwargs.get("latest_active_timestamp")

    def __repr__(self):
        return "DataFeedIngestionProgress(latest_success_timestamp={}, latest_active_timestamp={})".format(
            self.latest_success_timestamp, self.latest_active_timestamp
        )[
            :1024
        ]

class MetricSeriesData(object):
    """MetricSeriesData.

    :ivar metric_id: metric unique id.
    :vartype metric_id: str
    :ivar series_key: dimension name and value pair.
    :vartype series_key: dict[str, str]
    :ivar timestamps: timestamps of the data related to this time series.
    :vartype timestamps: list[~datetime.datetime]
    :ivar values: values of the data related to this time series.
    :vartype values: list[float]
    """

    def __init__(self, **kwargs):
        self.metric_id = kwargs.get("metric_id", None)
        self.series_key = kwargs.get("series_key", None)
        self.timestamps = kwargs.get("timestamps", None)
        self.values = kwargs.get("values", None)

    def __repr__(self):
        return "MetricSeriesData(metric_id={}, series_key={}, timestamps={}, values={})".format(
            self.metric_id, self.series_key, self.timestamps, self.values
        )[
            :1024
        ]

class MetricEnrichedSeriesData(object):
    """MetricEnrichedSeriesData.

    All required parameters must be populated in order to send to Azure.

    :param series_key: Required.
    :type series_key: ~azure.ai.metricsadvisor.models.SeriesIdentity
    :param timestamps: Required. timestamps of the series.
    :type timestamps: list[~datetime.datetime]
    :param values: Required. values of the series.
    :type values: list[float]
    :param is_anomaly: Required. whether points of the series are anomalies.
    :type is_anomaly: list[bool]
    :param periods: Required. period calculated on each point of the series.
    :type periods: list[int]
    :param expected_values: Required. expected values of the series given by smart detector.
    :type expected_values: list[float]
    :param lower_bounds: Required. lower boundary list of the series given by smart
     detector.
    :type lower_bounds: list[float]
    :param upper_bounds: Required. upper boundary list of the series given by smart
     detector.
    :type upper_bounds: list[float]
    """

    def __init__(self, **kwargs):
        self.series_key = kwargs.get("series_key", None)
        self.timestamps = kwargs.get("timestamps", None)
        self.values = kwargs.get("values", None)
        self.is_anomaly = kwargs.get("is_anomaly", None)
        self.periods = kwargs.get("periods", None)
        self.expected_values = kwargs.get("expected_values", None)
        self.lower_bounds = kwargs.get("lower_bounds", None)
        self.upper_bounds = kwargs.get("upper_bounds", None)

    def __repr__(self):
        return (
            "MetricEnrichedSeriesData(series_key={}, timestamps={}, values={}, is_anomaly={}, periods={}, "
            "expected_values={}, lower_bounds={}, upper_bounds={})".format(
                self.series_key,
                self.timestamps,
                self.values,
                self.is_anomaly,
                self.periods,
                self.expected_values,
                self.lower_bounds,
                self.upper_bounds,
            )[:1024]
        )

class AnomalyAlert(object):
    """AnomalyAlert

    :ivar id: alert id.
    :vartype id: str
    :ivar timestamp: anomaly time.
    :vartype timestamp: ~datetime.datetime
    :ivar created_time: created time.
    :vartype created_time: ~datetime.datetime
    :ivar modified_time: modified time.
    :vartype modified_time: ~datetime.datetime
    """

    def __init__(self, **kwargs):
        self.id = kwargs.get("id", None)
        self.timestamp = kwargs.get("timestamp", None)
        self.created_time = kwargs.get("created_time", None)
        self.modified_time = kwargs.get("modified_time", None)

    def __repr__(self):
        return "AnomalyAlert(id={}, timestamp={}, created_time={}, modified_time={})".format(
            self.id, self.timestamp, self.created_time, self.modified_time
        )[
            :1024
        ]

DATA_FEED_TRANSFORM = {
    "SqlServer": SqlServerDataFeedSource,
    "AzureApplicationInsights": AzureApplicationInsightsDataFeedSource,
    "AzureBlob": AzureBlobDataFeedSource,
    "AzureCosmosDB": AzureCosmosDbDataFeedSource,
    "AzureDataExplorer": AzureDataExplorerDataFeedSource,
    "AzureTable": AzureTableDataFeedSource,
    "AzureLogAnalytics": AzureLogAnalyticsDataFeedSource,
    "InfluxDB": InfluxDbDataFeedSource,
    "MySql": MySqlDataFeedSource,
    "PostgreSql": PostgreSqlDataFeedSource,
    "MongoDB": MongoDbDataFeedSource,
    "AzureDataLakeStorageGen2": AzureDataLakeStorageGen2DataFeedSource,
    "AzureEventHubs": AzureEventHubsDataFeedSource,
}


class DataPointAnomaly(msrest.serialization.Model):
    """DataPointAnomaly.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar metric_id: metric unique id. Only returned for alerting anomaly result.
    :vartype metric_id: str
    :ivar detection_configuration_id: anomaly detection configuration unique id.
     Only returned for alerting anomaly result.
    :vartype detection_configuration_id: str
    :ivar timestamp: anomaly time.
    :vartype timestamp: ~datetime.datetime
    :ivar created_time: created time. Only returned for alerting result.
    :vartype created_time: ~datetime.datetime
    :ivar modified_time: modified time. Only returned for alerting result.
    :vartype modified_time: ~datetime.datetime
    :ivar dimension: dimension specified for series.
    :vartype dimension: dict[str, str]
    :ivar severity: anomaly severity. Possible values include: "Low", "Medium", "High".
    :vartype anomaly_severity: str or ~azure.ai.metricsadvisor.models.AnomalySeverity
    :vartype severity: str
    :ivar status: anomaly status. only returned for alerting anomaly result. Possible
     values include: "Active", "Resolved".
    :vartype status: str
    """

    _attribute_map = {
        "metric_id": {"key": "metricId", "type": "str"},
        "detection_configuration_id": {
            "key": "detectionConfigurationId",
            "type": "str",
        },
        "timestamp": {"key": "timestamp", "type": "iso-8601"},
        "created_time": {"key": "createdTime", "type": "iso-8601"},
        "modified_time": {"key": "modifiedTime", "type": "iso-8601"},
        "dimension": {"key": "dimension", "type": "{str}"},
        "severity": {"key": "severity", "type": "str"},
        "status": {"key": "status", "type": "str"},
    }

    def __init__(self, **kwargs):
        super(DataPointAnomaly, self).__init__(**kwargs)
        self.metric_id = kwargs.get("metric_id", None)
        self.detection_configuration_id = kwargs.get("detection_configuration_id", None)
        self.timestamp = kwargs.get("timestamp", None)
        self.created_time = kwargs.get("created_time", None)
        self.modified_time = kwargs.get("modified_time", None)
        self.dimension = kwargs.get("dimension", None)
        self.severity = kwargs.get("severity", None)
        self.status = kwargs.get("status", None)

    def __repr__(self):
        return (
            "DataPointAnomaly(metric_id={}, detection_configuration_id={}, timestamp={}, created_time={}, "
            "modified_time={}, dimension={}, severity={}, status={})".format(
                self.metric_id,
                self.detection_configuration_id,
                self.timestamp,
                self.created_time,
                self.modified_time,
                self.dimension,
                self.severity,
                self.status,
            )[:1024]
        )

class AnomalyIncident(msrest.serialization.Model):
    """AnomalyIncident.

    Variables are only populated by the server, and will be ignored when sending a request.

    :ivar metric_id: metric unique id. Only returned for alerting incident result.
    :vartype metric_id: str
    :ivar detection_configuration_id: anomaly detection configuration unique id.
     Only returned for alerting incident result.
    :vartype detection_configuration_id: str
    :ivar id: incident id.
    :vartype id: str
    :ivar start_time: incident start time.
    :vartype start_time: ~datetime.datetime
    :ivar last_time: incident last time.
    :vartype last_time: ~datetime.datetime
    :param dimension_key: dimension specified for series.
    :type dimension_key: dict[str, str]
    :ivar severity: max severity of latest anomalies in the incident. Possible values include:
     "Low", "Medium", "High".
    :vartype severity: str or ~azure.ai.metricsadvisor.models.AnomalySeverity
    :ivar status: incident status
     only return for alerting incident result. Possible values include: "Active", "Resolved".
    :vartype status: str or ~azure.ai.metricsadvisor.models.AnomalyIncidentStatus
    """

    _attribute_map = {
        "metric_id": {"key": "metricId", "type": "str"},
        "detection_configuration_id": {
            "key": "detectionConfigurationId",
            "type": "str",
        },
        "id": {"key": "id", "type": "str"},
        "start_time": {"key": "startTime", "type": "iso-8601"},
        "last_time": {"key": "lastTime", "type": "iso-8601"},
        "dimension_key": {"key": "dimensionKey", "type": "{str}"},
        "severity": {"key": "severity", "type": "str"},
        "status": {"key": "status", "type": "str"},
    }

    def __init__(self, **kwargs):
        super(AnomalyIncident, self).__init__(**kwargs)
        self.metric_id = kwargs.get("metric_id", None)
        self.detection_configuration_id = kwargs.get("detection_configuration_id", None)
        self.id = kwargs.get("id", None)
        self.start_time = kwargs.get("start_time", None)
        self.last_time = kwargs.get("last_time", None)
        self.dimension_key = kwargs.get("dimension_key", None)
        self.severity = kwargs.get("severity", None)
        self.status = kwargs.get("status", None)

    def __repr__(self):
        return (
            "AnomalyIncident(metric_id={}, detection_configuration_id={}, id={}, start_time={}, last_time={}, "
            "dimension_key={}, severity={}, status={})".format(
                self.metric_id,
                self.detection_configuration_id,
                self.id,
                self.start_time,
                self.last_time,
                self.dimension_key,
                self.severity,
                self.status,
            )[:1024]
        )

class IncidentRootCause(msrest.serialization.Model):
    """Incident Root Cause.

    Variables are only populated by the server, and will be ignored when sending a request.

    :param dimension_key: dimension specified for series group.
    :type dimension_key: dict[str, str]
    :ivar path: drilling down path from query anomaly to root cause.
    :vartype path: list[str]
    :ivar score: score.
    :vartype score: float
    :ivar description: description.
    :vartype description: str
    """

    _attribute_map = {
        "dimension_key": {"key": "dimensionKey", "type": "{str}"},
        "path": {"key": "path", "type": "[str]"},
        "score": {"key": "score", "type": "float"},
        "description": {"key": "description", "type": "str"},
    }

    def __init__(self, **kwargs):
        super(IncidentRootCause, self).__init__(**kwargs)
        self.dimension_key = kwargs.get("dimension_key", None)
        self.path = kwargs.get("path", None)
        self.score = kwargs.get("score", None)
        self.description = kwargs.get("description", None)

    def __repr__(self):
        return "IncidentRootCause(dimension_key={}, path={}, score={}, description={})".format(
            self.dimension_key, self.path, self.score, self.description
        )[
            :1024
        ]

class MetricFeedbackCustomization(dict):
    """Feedback base class

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar feedback_type: Required. feedback type.Constant filled by server.  Possible values
     include: "Anomaly", "ChangePoint", "Period", "Comment".
    :vartype feedback_type: str or ~azure.ai.metricsadvisor.models.FeedbackType
    :ivar str id: feedback unique id.
    :ivar created_time: feedback created time.
    :vartype created_time: ~datetime.datetime
    :ivar user_principal: user who gives this feedback.
    :vartype user_principal: str
    :ivar str metric_id: Required. metric unique id.
    :ivar dict[str, str] dimension_key: Required. metric dimension filter.
    """

    _attribute_map = {
        "feedback_type": {"key": "feedbackType", "type": "str"},
        "id": {"key": "id", "type": "str"},
        "created_time": {"key": "createdTime", "type": "iso-8601"},
        "user_principal": {"key": "userPrincipal", "type": "str"},
        "metric_id": {"key": "metricId", "type": "str"},
        "dimension_key": {"key": "dimensionKey", "type": "{str}"},
    }

    def __init__(self, feedback_type, metric_id, dimension_key, **kwargs):
        super(MetricFeedbackCustomization, self).__init__(
            metric_id=metric_id,
            dimension_filter=dimension_key,
            **kwargs
        )
        self.feedback_type = feedback_type  # type: str
        self.id = kwargs.get("id", None)
        self.created_time = kwargs.get("created_time", None)
        self.user_principal = kwargs.get("user_principal", None)
        self.metric_id = metric_id
        self.dimension_key = dimension_key

    def __repr__(self):
        return (
            "MetricFeedback(feedback_type={}, id={}, created_time={}, user_principal={}, metric_id={}, "
            "dimension_key={})".format(
                self.feedback_type,
                self.id,
                self.created_time,
                self.user_principal,
                self.metric_id,
                self.dimension_key,
            )[:1024]
        )

class AnomalyFeedback(MetricFeedback):
    """AnomalyFeedback.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar feedback_type: Required. feedback type.Constant filled by server.  Possible values
     include: "Anomaly", "ChangePoint", "Period", "Comment".
    :vartype feedback_type: str or ~azure.ai.metricsadvisor.models.FeedbackType
    :ivar str id: feedback unique id.
    :keyword created_time: feedback created time.
    :paramtype created_time: ~datetime.datetime
    :keyword str user_principal: user who gives this feedback.
    :param str metric_id: Required. metric unique id.
    :param dict[str, str] dimension_key: Required. metric dimension filter.
    :param start_time: Required. the start timestamp of feedback timerange.
    :type start_time: ~datetime.datetime
    :param end_time: Required. the end timestamp of feedback timerange, when equals to startTime
     means only one timestamp.
    :type end_time: ~datetime.datetime
    :param value: Required. Possible values include: "AutoDetect", "Anomaly", "NotAnomaly".
    :type value: str or ~azure.ai.metricsadvisor.models.AnomalyValue
    :keyword anomaly_detection_configuration_id: the corresponding anomaly detection configuration of
     this feedback.
    :paramtype anomaly_detection_configuration_id: str
    :keyword anomaly_detection_configuration_snapshot:
    :paramtype anomaly_detection_configuration_snapshot:
     ~azure.ai.metricsadvisor.models.AnomalyDetectionConfiguration
    """

    _attribute_map = {
        "feedback_type": {"key": "feedbackType", "type": "str"},
        "id": {"key": "id", "type": "str"},
        "created_time": {"key": "createdTime", "type": "iso-8601"},
        "user_principal": {"key": "userPrincipal", "type": "str"},
        "metric_id": {"key": "metricId", "type": "str"},
        "dimension_key": {"key": "dimensionKey", "type": "{str}"},
        "start_time": {"key": "startTime", "type": "iso-8601"},
        "end_time": {"key": "endTime", "type": "iso-8601"},
        "value": {"key": "value", "type": "str"},
        "anomaly_detection_configuration_id": {
            "key": "anomalyDetectionConfigurationId",
            "type": "str",
        },
        "anomaly_detection_configuration_snapshot": {
            "key": "anomalyDetectionConfigurationSnapshot",
            "type": "AnomalyDetectionConfiguration",
        },
    }

    def __init__(self, metric_id, dimension_key, start_time, end_time, value, **kwargs):
        super(AnomalyFeedback, self).__init__(
            feedback_type="Anomaly",
            metric_id=metric_id,
            dimension_key=dimension_key,
            **kwargs
        )
        self.start_time = start_time
        self.end_time = end_time
        self.value = value
        self.anomaly_detection_configuration_id = kwargs.get(
            "anomaly_detection_configuration_id", None
        )
        self.anomaly_detection_configuration_snapshot = kwargs.get(
            "anomaly_detection_configuration_snapshot", None
        )

    def __repr__(self):
        return (
            "AnomalyFeedback(feedback_type={}, id={}, created_time={}, user_principal={}, metric_id={}, "
            "dimension_key={}, start_time={}, end_time={}, value={}, anomaly_detection_configuration_id={}, "
            "anomaly_detection_configuration_snapshot={})".format(
                self.feedback_type,
                self.id,
                self.created_time,
                self.user_principal,
                self.metric_id,
                self.dimension_key,
                self.start_time,
                self.end_time,
                self.value,
                self.anomaly_detection_configuration_id,
                self.anomaly_detection_configuration_snapshot,
            )[:1024]
        )

class ChangePointFeedback(MetricFeedbackCustomization):
    """ChangePointFeedback.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar feedback_type: Required. feedback type.Constant filled by server.  Possible values
     include: "Anomaly", "ChangePoint", "Period", "Comment".
    :vartype feedback_type: str or ~azure.ai.metricsadvisor.models.FeedbackType
    :ivar str id: feedback unique id.
    :keyword created_time: feedback created time.
    :paramtype created_time: ~datetime.datetime
    :keyword str user_principal: user who gives this feedback.
    :param str metric_id: Required. metric unique id.
    :param dict[str, str] dimension_key: Required. metric dimension filter.
    :param start_time: Required. the start timestamp of feedback timerange.
    :type start_time: ~datetime.datetime
    :param end_time: Required. the end timestamp of feedback timerange, when equals to startTime
     means only one timestamp.
    :type end_time: ~datetime.datetime
    :param value: Required. Possible values include: "AutoDetect", "ChangePoint", "NotChangePoint".
    :type value: str or ~azure.ai.metricsadvisor.models.ChangePointValue
    """

    _attribute_map = {
        "feedback_type": {"key": "feedbackType", "type": "str"},
        "id": {"key": "id", "type": "str"},
        "created_time": {"key": "createdTime", "type": "iso-8601"},
        "user_principal": {"key": "userPrincipal", "type": "str"},
        "metric_id": {"key": "metricId", "type": "str"},
        "dimension_key": {"key": "dimensionKey", "type": "{str}"},
        "start_time": {"key": "startTime", "type": "iso-8601"},
        "end_time": {"key": "endTime", "type": "iso-8601"},
        "value": {"key": "value", "type": "str"},
    }

    def __init__(self, metric_id, dimension_key, start_time, end_time, value, **kwargs):
        super(ChangePointFeedback, self).__init__(
            feedback_type="ChangePoint",
            metric_id=metric_id,
            dimension_key=dimension_key,
            **kwargs
        )
        self.start_time = start_time
        self.end_time = end_time
        self.value = value

    def __repr__(self):
        return (
            "ChangePointFeedback(feedback_type={}, id={}, created_time={}, user_principal={}, metric_id={}, "
            "dimension_key={}, start_time={}, end_time={}, value={})".format(
                self.feedback_type,
                self.id,
                self.created_time,
                self.user_principal,
                self.metric_id,
                self.dimension_key,
                self.start_time,
                self.end_time,
                self.value,
            )[:1024]
        )

class CommentFeedback(MetricFeedback):
    """CommentFeedback.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar feedback_type: Required. feedback type.Constant filled by server.  Possible values
     include: "Anomaly", "ChangePoint", "Period", "Comment".
    :vartype feedback_type: str or ~azure.ai.metricsadvisor.models.FeedbackType
    :ivar str id: feedback unique id.
    :keyword created_time: feedback created time.
    :paramtype created_time: ~datetime.datetime
    :keyword str user_principal: user who gives this feedback.
    :param str metric_id: Required. metric unique id.
    :param dict[str, str] dimension_key: Required. metric dimension filter.
    :param start_time: the start timestamp of feedback timerange.
    :type start_time: ~datetime.datetime
    :param end_time: the end timestamp of feedback timerange, when equals to startTime means only
     one timestamp.
    :type end_time: ~datetime.datetime
    :param value: Required. the comment string.
    :type value: str
    """

    _attribute_map = {
        "feedback_type": {"key": "feedbackType", "type": "str"},
        "id": {"key": "id", "type": "str"},
        "created_time": {"key": "createdTime", "type": "iso-8601"},
        "user_principal": {"key": "userPrincipal", "type": "str"},
        "metric_id": {"key": "metricId", "type": "str"},
        "dimension_key": {"key": "dimensionKey", "type": "{str}"},
        "start_time": {"key": "startTime", "type": "iso-8601"},
        "end_time": {"key": "endTime", "type": "iso-8601"},
        "value": {"key": "value", "type": "str"},
    }

    def __init__(self, metric_id, dimension_key, start_time, end_time, value, **kwargs):
        super(CommentFeedback, self).__init__(
            feedback_type="Comment",
            metric_id=metric_id,
            dimension_key=dimension_key,
            **kwargs
        )
        self.start_time = start_time
        self.end_time = end_time
        self.value = value

    def __repr__(self):
        return (
            "CommentFeedback(feedback_type={}, id={}, created_time={}, user_principal={}, metric_id={}, "
            "dimension_key={}, start_time={}, end_time={}, value={})".format(
                self.feedback_type,
                self.id,
                self.created_time,
                self.user_principal,
                self.metric_id,
                self.dimension_key,
                self.start_time,
                self.end_time,
                self.value,
            )[:1024]
        )


class PeriodFeedback(MetricFeedbackCustomization):
    """PeriodFeedback.

    Variables are only populated by the server, and will be ignored when sending a request.

    All required parameters must be populated in order to send to Azure.

    :ivar feedback_type: Required. feedback type.Constant filled by server.  Possible values
     include: "Anomaly", "ChangePoint", "Period", "Comment".
    :vartype feedback_type: str or ~azure.ai.metricsadvisor.models.FeedbackType
    :ivar str id: feedback unique id.
    :keyword created_time: feedback created time.
    :paramtype created_time: ~datetime.datetime
    :keyword str user_principal: user who gives this feedback.
    :param str metric_id: Required. metric unique id.
    :param dict[str, str] dimension_key: Required. metric dimension filter.
    :param value: Required.
    :type value: int
    :param period_type: Required. the type of setting period. Possible values include:
     "AutoDetect", "AssignValue".
    :type period_type: str or ~azure.ai.metricsadvisor.models.PeriodType
    """

    _attribute_map = {
        "feedback_type": {"key": "feedbackType", "type": "str"},
        "id": {"key": "id", "type": "str"},
        "created_time": {"key": "createdTime", "type": "iso-8601"},
        "user_principal": {"key": "userPrincipal", "type": "str"},
        "metric_id": {"key": "metricId", "type": "str"},
        "dimension_key": {"key": "dimensionKey", "type": "{str}"},
        "value": {"key": "value", "type": "int"},
        "period_type": {"key": "periodType", "type": "str"},
    }

    def __init__(self, metric_id, dimension_key, value, period_type, **kwargs):
        super(PeriodFeedback, self).__init__(
            feedback_type="Period",
            metric_id=metric_id,
            dimension_key=dimension_key,
            **kwargs
        )
        self.value = value
        self.period_type = period_type

    def __repr__(self):
        return (
            "PeriodFeedback(feedback_type={}, id={}, created_time={}, user_principal={}, metric_id={}, "
            "dimension_key={}, value={}, period_type={})".format(
                self.feedback_type,
                self.id,
                self.created_time,
                self.user_principal,
                self.metric_id,
                self.dimension_key,
                self.value,
                self.period_type,
            )[:1024]
        )

class DatasourceCredential(dict):
    """DatasourceCredential base class.

    :param credential_type: Required. Type of data source credential.Constant filled by
     server.  Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :type credential_type: str or
     ~azure.ai.metricsadvisor.models.DatasourceCredentialType
    :ivar id: Unique id of data source credential.
    :vartype id: str
    :param name: Required. Name of data source credential.
    :type name: str
    :keyword str description: Description of data source credential.
    """

    _attribute_map = {
        "credential_type": {"key": "credentialType", "type": "str"},
        "id": {"key": "id", "type": "str"},
        "name": {"key": "name", "type": "str"},
        "description": {"key": "description", "type": "str"},
    }

    def __init__(self, name, credential_type, **kwargs):
        # type: (str, str, Any) -> None
        super(DatasourceCredential, self).__init__(
            name=name, credential_type=credential_type, **kwargs
        )
        self.credential_type = credential_type
        self.name = name
        self.id = kwargs.get("id", None)
        self.description = kwargs.get("description", None)

    def __repr__(self):
        return "DatasourceCredential(id={}, credential_type={}, name={}, description={})".format(
            self.id, self.credential_type, self.name, self.description
        )[
            :1024
        ]


class DatasourceSqlConnectionString(DatasourceCredential):
    """DatasourceSqlConnectionString.

    All required parameters must be populated in order to send to Azure.

    :ivar credential_type: Required. Type of data source credential.Constant filled by
     server.  Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :type credential_type: str or
     ~azure.ai.metricsadvisor.models.DatasourceCredentialType
    :ivar id: Unique id of data source credential.
    :vartype id: str
    :param name: Required. Name of data source credential.
    :type name: str
    :keyword str description: Description of data source credential.
    :param connection_string: Required. The connection string to access the Azure SQL.
    :type connection_string: str
    """

    _attribute_map = {
        "credential_type": {"key": "credentialType", "type": "str"},
        "id": {"key": "id", "type": "str"},
        "name": {"key": "name", "type": "str"},
        "description": {"key": "description", "type": "str"},
        "connection_string": {"key": "connectionString", "type": "str"},
    }

    def __init__(self, name, connection_string, **kwargs):
        # type: (str, str, Any) -> None
        super(DatasourceSqlConnectionString, self).__init__(
            name=name, credential_type="AzureSQLConnectionString", **kwargs
        )
        self.connection_string = connection_string

    def __repr__(self):
        return (
            "DatasourceSqlConnectionString(id={}, credential_type={}, name={}, "
            "connection_string={}, description={})".format(
                self.id,
                self.credential_type,
                self.name,
                self.connection_string,
                self.description,
            )[:1024]
        )

class DatasourceDataLakeGen2SharedKey(DatasourceCredential):
    """DatasourceDataLakeGen2SharedKey.

    All required parameters must be populated in order to send to Azure.

    :ivar credential_type: Required. Type of data source credential.Constant filled by
     server.  Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :type credential_type: str or
     ~azure.ai.metricsadvisor.models.DatasourceCredentialType
    :ivar id: Unique id of data source credential.
    :vartype id: str
    :param name: Required. Name of data source credential.
    :type name: str
    :keyword str description: Description of data source credential.
    :param account_key: Required. The account key to access the Azure Data Lake Storage Gen2.
    :type account_key: str
    """

    _attribute_map = {
        "credential_type": {"key": "credentialType", "type": "str"},
        "id": {"key": "id", "type": "str"},
        "name": {"key": "name", "type": "str"},
        "description": {"key": "description", "type": "str"},
        "account_key": {"key": "accountKey", "type": "str"},
    }

    def __init__(self, name, account_key, **kwargs):
        # type: (str, str, Any) -> None
        super(DatasourceDataLakeGen2SharedKey, self).__init__(
            name=name, credential_type="DataLakeGen2SharedKey", **kwargs
        )
        self.account_key = account_key

    def __repr__(self):
        return (
            "DatasourceDataLakeGen2SharedKey(id={}, credential_type={}, name={}, "
            "account_key={}, description={})".format(
                self.id,
                self.credential_type,
                self.name,
                self.account_key,
                self.description,
            )[:1024]
        )

class DatasourceServicePrincipal(DatasourceCredential):
    """DatasourceServicePrincipal.

    All required parameters must be populated in order to send to Azure.

    :ivar credential_type: Required. Type of data source credential.Constant filled by
     server.  Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :type credential_type: str or
     ~azure.ai.metricsadvisor.models.DatasourceCredentialType
    :ivar id: Unique id of data source credential.
    :vartype id: str
    :param name: Required. Name of data source credential.
    :type name: str
    :keyword str description: Description of data source credential.
    :param client_id: Required. The client id of the service principal.
    :type client_id: str
    :param client_secret: Required. The client secret of the service principal.
    :type client_secret: str
    :param tenant_id: Required. The tenant id of the service principal.
    :type tenant_id: str
    """

    _attribute_map = {
        "credential_type": {"key": "credentialType", "type": "str"},
        "id": {"key": "id", "type": "str"},
        "name": {"key": "name", "type": "str"},
        "description": {"key": "description", "type": "str"},
        "client_id": {"key": "clientId", "type": "str"},
        "client_secret": {"key": "clientSecret", "type": "str"},
        "tenant_id": {"key": "tenantId", "type": "str"},
    }

    def __init__(self, name, client_id, client_secret, tenant_id, **kwargs):
        # type: (str, str, str, str, Any) -> None
        super(DatasourceServicePrincipal, self).__init__(
            name=name, credential_type="ServicePrincipal", **kwargs
        )
        self.client_id = client_id
        self.client_secret = client_secret
        self.tenant_id = tenant_id

    def __repr__(self):
        return (
            "DatasourceServicePrincipal(id={}, credential_type={}, name={}, "
            "client_id={}, client_secret={}, tenant_id={}, description={})".format(
                self.id,
                self.credential_type,
                self.name,
                self.client_id,
                self.client_secret,
                self.tenant_id,
                self.description,
            )[:1024]
        )

class DatasourceServicePrincipalInKeyVault(DatasourceCredential):
    """DatasourceServicePrincipalInKeyVault.

    All required parameters must be populated in order to send to Azure.

    :ivar credential_type: Required. Type of data source credential.Constant filled by
     server.  Possible values include: "AzureSQLConnectionString", "DataLakeGen2SharedKey",
     "ServicePrincipal", "ServicePrincipalInKV".
    :type credential_type: str or
     ~azure.ai.metricsadvisor.models.DatasourceCredentialType
    :ivar id: Unique id of data source credential.
    :vartype id: str
    :param name: Required. Name of data source credential.
    :type name: str
    :keyword str description: Description of data source credential.
    :keyword str key_vault_endpoint: Required. The Key Vault endpoint that storing the service principal.
    :keyword str key_vault_client_id: Required. The Client Id to access the Key Vault.
    :keyword str key_vault_client_secret: Required. The Client Secret to access the Key Vault.
    :keyword str service_principal_id_name_in_kv: Required. The secret name of the service principal's
     client Id in the Key Vault.
    :keyword str service_principal_secret_name_in_kv: Required. The secret name of the service
     principal's client secret in the Key Vault.
    :keyword str tenant_id: Required. The tenant id of your service principal.
    """

    _attribute_map = {
        "credential_type": {"key": "credentialType", "type": "str"},
        "id": {"key": "id", "type": "str"},
        "name": {"key": "name", "type": "str"},
        "description": {"key": "description", "type": "str"},
        "key_vault_endpoint": {"key": "keyVaultEndpoint", "type": "str"},
        "key_vault_client_id": {"key": "keyVaultClientId", "type": "str"},
        "key_vault_client_secret": {"key": "keyVaultClientSecret", "type": "str"},
        "service_principal_id_name_in_kv": {
            "key": "servicePrincipalIdNameInKV",
            "type": "str",
        },
        "service_principal_secret_name_in_kv": {
            "key": "servicePrincipalSecretNameInKV",
            "type": "str",
        },
        "tenant_id": {"key": "tenantId", "type": "str"},
    }

    def __init__(self, name, **kwargs):
        # type: (str, Any) -> None
        if "key_vault_endpoint" not in kwargs:
            raise ValueError("key_vault_endpoint is required.")
        if "key_vault_client_id" not in kwargs:
            raise ValueError("key_vault_client_id is required.")
        if "key_vault_client_secret" not in kwargs:
            raise ValueError("key_vault_client_secret is required.")
        if "service_principal_id_name_in_kv" not in kwargs:
            raise ValueError("service_principal_id_name_in_kv is required.")
        if "service_principal_secret_name_in_kv" not in kwargs:
            raise ValueError("service_principal_secret_name_in_kv is required.")
        if "tenant_id" not in kwargs:
            raise ValueError("tenant_id is required.")
        super(DatasourceServicePrincipalInKeyVault, self).__init__(
            name=name, credential_type="ServicePrincipalInKV", **kwargs
        )
        self.key_vault_endpoint = kwargs["key_vault_endpoint"]
        self.key_vault_client_id = kwargs["key_vault_client_id"]
        self.key_vault_client_secret = kwargs["key_vault_client_secret"]
        self.service_principal_id_name_in_kv = kwargs["service_principal_id_name_in_kv"]
        self.service_principal_secret_name_in_kv = kwargs[
            "service_principal_secret_name_in_kv"
        ]
        self.tenant_id = kwargs["tenant_id"]

    def __repr__(self):
        return (
            "DatasourceServicePrincipalInKeyVault(id={}, credential_type={}, name={}, "
            "key_vault_endpoint={}, key_vault_client_id={}, key_vault_client_secret={}, "
            "service_principal_id_name_in_kv={}, service_principal_secret_name_in_kv={}, tenant_id={}, "
            "description={})".format(
                self.id,
                self.credential_type,
                self.name,
                self.key_vault_endpoint,
                self.key_vault_client_id,
                self.key_vault_client_secret,
                self.service_principal_id_name_in_kv,
                self.service_principal_secret_name_in_kv,
                self.tenant_id,
                self.description,
            )[:1024]
        )

class DetectionAnomalyFilterCondition(msrest.serialization.Model):
    """DetectionAnomalyFilterCondition.

    :param series_group_key: dimension filter.
    :type series_group_key: dict[str, str]
    :param severity_filter:
    :type severity_filter: ~azure.ai.metricsadvisor.models.SeverityFilterCondition
    """

    _attribute_map = {
        "series_group_key": {"key": "seriesGroupKey", "type": "{str}"},
        "severity_filter": {"key": "severityFilter", "type": "SeverityFilterCondition"},
    }

    def __init__(self, **kwargs):
        super(DetectionAnomalyFilterCondition, self).__init__(**kwargs)
        self.series_group_key = kwargs.get("series_group_key", None)
        self.severity_filter = kwargs.get("severity_filter", None)

class DataFeedGranularity(object):
    """Data feed granularity
    :param granularity_type: Granularity of the time series. Possible values include:
        "Yearly", "Monthly", "Weekly", "Daily", "Hourly", "Minutely", "Secondly", "Custom".
    :type granularity_type: str or ~azure.ai.metricsadvisor.models.DataFeedGranularityType
    :keyword int custom_granularity_value: Must be populated if granularity_type is "Custom".
    """

    def __init__(self, granularity_type, **kwargs):
        # type: (Union[str, DataFeedGranularityType], Any) -> None
        self.granularity_type = granularity_type
        self.custom_granularity_value = kwargs.get("custom_granularity_value", None)

    def __repr__(self):
        return "DataFeedGranularity(granularity_type={}, custom_granularity_value={})".format(
            self.granularity_type, self.custom_granularity_value
        )[
            :1024
        ]

class DataFeedIngestionSettings(object):
    """Data feed ingestion settings.
    :param ~datetime.datetime ingestion_begin_time: Ingestion start time.
    :keyword int data_source_request_concurrency: The max concurrency of data ingestion queries against
        user data source. Zero (0) means no limitation.
    :keyword int ingestion_retry_delay: The min retry interval for failed data ingestion tasks, in seconds.
    :keyword int ingestion_start_offset: The time that the beginning of data ingestion task will delay
        for every data slice according to this offset, in seconds.
    :keyword int stop_retry_after: Stop retry data ingestion after the data slice first
        schedule time in seconds.
    """

    def __init__(self, ingestion_begin_time, **kwargs):
        # type: (datetime.datetime, Any) -> None
        self.ingestion_begin_time = ingestion_begin_time
        self.ingestion_start_offset = kwargs.get("ingestion_start_offset", 0)
        self.data_source_request_concurrency = kwargs.get(
            "data_source_request_concurrency", -1
        )
        self.ingestion_retry_delay = kwargs.get("ingestion_retry_delay", -1)
        self.stop_retry_after = kwargs.get("stop_retry_after", -1)

    def __repr__(self):
        return (
            "DataFeedIngestionSettings(ingestion_begin_time={}, ingestion_start_offset={}, "
            "data_source_request_concurrency={}, ingestion_retry_delay={}, stop_retry_after={})".format(
                self.ingestion_begin_time,
                self.ingestion_start_offset,
                self.data_source_request_concurrency,
                self.ingestion_retry_delay,
                self.stop_retry_after,
            )[
                :1024
            ]
        )


class DataFeedMissingDataPointFillSettings(object):
    """Data feed missing data point fill settings
    :keyword fill_type: The type of fill missing point for anomaly detection. Possible
        values include: "SmartFilling", "PreviousValue", "CustomValue", "NoFilling". Default value:
        "SmartFilling".
    :paramtype fill_type: str or ~azure.ai.metricsadvisor.models.DatasourceMissingDataPointFillType
    :keyword float custom_fill_value: The value of fill missing point for anomaly detection
        if "CustomValue" fill type is specified.
    """

    def __init__(self, **kwargs):
        self.fill_type = kwargs.get("fill_type", "SmartFilling")
        self.custom_fill_value = kwargs.get("custom_fill_value", None)

    def __repr__(self):
        return "DataFeedMissingDataPointFillSettings(fill_type={}, custom_fill_value={})".format(
            self.fill_type,
            self.custom_fill_value,
        )[
            :1024
        ]


class DataFeedRollupSettings(object):
    """Data feed rollup settings
    :keyword str rollup_identification_value: The identification value for the row of calculated all-up value.
    :keyword rollup_type: Mark if the data feed needs rollup. Possible values include: "NoRollup",
        "AutoRollup", "AlreadyRollup". Default value: "AutoRollup".
    :paramtype rollup_type: str or ~azure.ai.metricsadvisor.models.DataFeedRollupType
    :keyword list[str] auto_rollup_group_by_column_names: Roll up columns.
    :keyword rollup_method: Roll up method. Possible values include: "None", "Sum", "Max", "Min",
        "Avg", "Count".
    :paramtype rollup_method: str or ~azure.ai.metricsadvisor.models.DataFeedAutoRollupMethod
    """

    def __init__(self, **kwargs):
        self.rollup_identification_value = kwargs.get(
            "rollup_identification_value", None
        )
        self.rollup_type = kwargs.get("rollup_type", "AutoRollup")
        self.auto_rollup_group_by_column_names = kwargs.get(
            "auto_rollup_group_by_column_names", None
        )
        self.rollup_method = kwargs.get("rollup_method", None)

    def __repr__(self):
        return (
            "DataFeedRollupSettings(rollup_identification_value={}, rollup_type={}, "
            "auto_rollup_group_by_column_names={}, rollup_method={})".format(
                self.rollup_identification_value,
                self.rollup_type,
                self.auto_rollup_group_by_column_names,
                self.rollup_method,
            )[:1024]
        )


class DataFeedSchema(object):
    """Data feed schema
    :param metrics: List of metrics.
    :type metrics: list[~azure.ai.metricsadvisor.models.DataFeedMetric]
    :keyword dimensions: List of dimension.
    :paramtype dimensions: list[~azure.ai.metricsadvisor.models.DataFeedDimension]
    :keyword str timestamp_column: User-defined timestamp column.
        If timestamp_column is None, start time of every time slice will be used as default value.
    """

    def __init__(self, metrics, **kwargs):
        # type: (List[DataFeedMetric], Any) -> None
        self.metrics = metrics
        self.dimensions = kwargs.get("dimensions", None)
        self.timestamp_column = kwargs.get("timestamp_column", None)

    def __repr__(self):
        return "DataFeedSchema(metrics={}, dimensions={}, timestamp_column={})".format(
            repr(self.metrics),
            repr(self.dimensions),
            self.timestamp_column,
        )[:1024]

class MetricAnomalyAlertConfigurationsOperator(str, Enum):
    """Cross metrics operator"""

    AND = "AND"
    OR = "OR"
    XOR = "XOR"

class DetectionConditionOperator(str, Enum):

    AND = "AND"
    OR = "OR"
