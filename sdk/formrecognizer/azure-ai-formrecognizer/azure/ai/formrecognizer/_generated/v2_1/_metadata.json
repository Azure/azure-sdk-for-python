{
    "chosen_version": "2.1",
    "total_api_version_list": ["2.1"],
    "client": {
        "name": "FormRecognizerClient",
        "filename": "_form_recognizer_client",
        "description": "Extracts information from forms and images into structured data.",
        "host_value": null,
        "parameterized_host_template": "\u0027{endpoint}/formrecognizer/v2.1\u0027",
        "azure_arm": false,
        "has_lro_operations": true,
        "client_side_validation": false,
        "sync_imports": "{\"typing\": {\"azurecore\": {\"azure.core.credentials\": [\"TokenCredential\"]}}, \"regular\": {\"azurecore\": {\"azure.profiles\": [\"KnownProfiles\", \"ProfileDefinition\"], \"azure.profiles.multiapiclient\": [\"MultiApiClientMixin\"], \"azure.core\": [\"PipelineClient\"]}, \"local\": {\"._configuration\": [\"FormRecognizerClientConfiguration\"], \"._operations_mixin\": [\"FormRecognizerClientOperationsMixin\"]}, \"thirdparty\": {\"msrest\": [\"Deserializer\", \"Serializer\"]}}, \"conditional\": {\"stdlib\": {\"typing\": [\"Any\", \"Optional\"]}}}",
        "async_imports": "{\"typing\": {\"azurecore\": {\"azure.core.credentials_async\": [\"AsyncTokenCredential\"], \"azure.core.credentials\": [\"TokenCredential\"]}}, \"regular\": {\"azurecore\": {\"azure.profiles\": [\"KnownProfiles\", \"ProfileDefinition\"], \"azure.profiles.multiapiclient\": [\"MultiApiClientMixin\"], \"azure.core\": [\"AsyncPipelineClient\"]}, \"local\": {\"._configuration\": [\"FormRecognizerClientConfiguration\"], \"._operations_mixin\": [\"FormRecognizerClientOperationsMixin\"]}, \"thirdparty\": {\"msrest\": [\"Deserializer\", \"Serializer\"]}}, \"conditional\": {\"stdlib\": {\"typing\": [\"Any\", \"Optional\"]}}}"
    },
    "global_parameters": {
        "sync": {
            "credential": {
                "signature": "credential,  # type: \"TokenCredential\"",
                "description": "Credential needed for the client to connect to Azure.",
                "docstring_type": "~azure.core.credentials.TokenCredential",
                "required": true
            },
            "endpoint": {
                "signature": "endpoint,  # type: str",
                "description": "Supported Cognitive Services endpoints (protocol and hostname, for example: https://westus2.api.cognitive.microsoft.com).",
                "docstring_type": "str",
                "required": true
            }
        },
        "async": {
            "credential": {
                "signature": "credential: \"AsyncTokenCredential\",",
                "description": "Credential needed for the client to connect to Azure.",
                "docstring_type": "~azure.core.credentials_async.AsyncTokenCredential",
                "required": true
            },
            "endpoint": {
                "signature": "endpoint: str,",
                "description": "Supported Cognitive Services endpoints (protocol and hostname, for example: https://westus2.api.cognitive.microsoft.com).",
                "docstring_type": "str",
                "required": true
            }
        },
        "constant": {
        },
        "call": "credential, endpoint",
        "service_client_specific": {
            "sync": {
                "api_version": {
                    "signature": "api_version=None, # type: Optional[str]",
                    "description": "API version to use if no profile is provided, or if missing in profile.",
                    "docstring_type": "str",
                    "required": false
                },
                "profile": {
                    "signature": "profile=KnownProfiles.default, # type: KnownProfiles",
                    "description": "A profile definition, from KnownProfiles to dict.",
                    "docstring_type": "azure.profiles.KnownProfiles",
                    "required": false
                }
            },
            "async": {
                "api_version": {
                    "signature": "api_version: Optional[str] = None,",
                    "description": "API version to use if no profile is provided, or if missing in profile.",
                    "docstring_type": "str",
                    "required": false
                },
                "profile": {
                    "signature": "profile: KnownProfiles = KnownProfiles.default,",
                    "description": "A profile definition, from KnownProfiles to dict.",
                    "docstring_type": "azure.profiles.KnownProfiles",
                    "required": false
                }
            }
        }
    },
    "config": {
        "credential": true,
        "credential_scopes": ["https://cognitiveservices.azure.com/.default"],
        "credential_call_sync": "policies.BearerTokenCredentialPolicy(self.credential, *self.credential_scopes, **kwargs)",
        "credential_call_async": "policies.AsyncBearerTokenCredentialPolicy(self.credential, *self.credential_scopes, **kwargs)",
        "sync_imports": "{\"regular\": {\"azurecore\": {\"azure.core.configuration\": [\"Configuration\"], \"azure.core.pipeline\": [\"policies\"]}, \"local\": {\"._version\": [\"VERSION\"]}}, \"conditional\": {\"stdlib\": {\"typing\": [\"Any\"]}}, \"typing\": {\"azurecore\": {\"azure.core.credentials\": [\"TokenCredential\"]}}}",
        "async_imports": "{\"regular\": {\"azurecore\": {\"azure.core.configuration\": [\"Configuration\"], \"azure.core.pipeline\": [\"policies\"]}, \"local\": {\".._version\": [\"VERSION\"]}}, \"conditional\": {\"stdlib\": {\"typing\": [\"Any\"]}}, \"typing\": {\"azurecore\": {\"azure.core.credentials_async\": [\"AsyncTokenCredential\"]}}}"
    },
    "operation_groups": {
    },
    "operation_mixins": {
        "sync_imports": "{\"conditional\": {\"stdlib\": {\"typing\": [\"Any\", \"IO\", \"Iterable\", \"List\", \"Optional\", \"Union\"]}, \"azurecore\": {\"azure.core.polling\": [\"LROPoller\"], \"azure.core.paging\": [\"ItemPaged\"]}}, \"regular\": {\"local\": {\".\": [[\"models\", \"_models\"]]}}}",
        "async_imports": "{\"conditional\": {\"stdlib\": {\"typing\": [\"Any\", \"AsyncIterable\", \"IO\", \"List\", \"Optional\", \"Union\"]}, \"azurecore\": {\"azure.core.polling\": [\"AsyncLROPoller\"], \"azure.core.async_paging\": [\"AsyncItemPaged\"]}}, \"regular\": {\"local\": {\"..\": [[\"models\", \"_models\"]]}}}",
        "operations": {
            "_train_custom_model_async_initial" : {
                "sync": {
                    "signature": "def _train_custom_model_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    train_request,  # type: _models.TrainRequest\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e None\n",
                    "doc": "\"\"\"Train Custom Model.\n\n:param train_request: Training request parameters.\n:type train_request: ~azure.ai.formrecognizer.v2_1.models.TrainRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "train_request, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _train_custom_model_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    train_request: _models.TrainRequest,\n    **kwargs: Any\n) -\u003e None:\n",
                    "doc": "\"\"\"Train Custom Model.\n\n:param train_request: Training request parameters.\n:type train_request: ~azure.ai.formrecognizer.v2_1.models.TrainRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "train_request, **kwargs"
                }
            },
            "begin_train_custom_model_async" : {
                "sync": {
                    "signature": "def begin_train_custom_model_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    train_request,  # type: _models.TrainRequest\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e LROPoller[None]\n",
                    "doc": "\"\"\"Train Custom Model.\n\nCreate and train a custom model. The request must include a source parameter that is either an\nexternally accessible Azure storage blob container Uri (preferably a Shared Access Signature\nUri) or valid path to a data folder in a locally mounted drive. When local paths are specified,\nthey must follow the Linux/Unix path format and be an absolute path rooted to the input mount\nconfiguration setting value e.g., if \u0027{Mounts:Input}\u0027 configuration setting value is \u0027/input\u0027\nthen a valid source path would be \u0027/input/contosodataset\u0027. All data to be trained is expected\nto be under the source folder or sub folders under it. Models are trained using documents that\nare of the following content type - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027, \u0027image/tiff\u0027\nor \u0027image/bmp\u0027. Other type of content is ignored.\n\n:param train_request: Training request parameters.\n:type train_request: ~azure.ai.formrecognizer.v2_1.models.TrainRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be LROBasePolling. Pass in False for\n this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "train_request, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_train_custom_model_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    train_request: _models.TrainRequest,\n    **kwargs: Any\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Train Custom Model.\n\nCreate and train a custom model. The request must include a source parameter that is either an\nexternally accessible Azure storage blob container Uri (preferably a Shared Access Signature\nUri) or valid path to a data folder in a locally mounted drive. When local paths are specified,\nthey must follow the Linux/Unix path format and be an absolute path rooted to the input mount\nconfiguration setting value e.g., if \u0027{Mounts:Input}\u0027 configuration setting value is \u0027/input\u0027\nthen a valid source path would be \u0027/input/contosodataset\u0027. All data to be trained is expected\nto be under the source folder or sub folders under it. Models are trained using documents that\nare of the following content type - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027, \u0027image/tiff\u0027\nor \u0027image/bmp\u0027. Other type of content is ignored.\n\n:param train_request: Training request parameters.\n:type train_request: ~azure.ai.formrecognizer.v2_1.models.TrainRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be AsyncLROBasePolling. Pass in False\n for this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "train_request, **kwargs"
                }
            },
            "get_custom_model" : {
                "sync": {
                    "signature": "def get_custom_model(\n    self,\n    model_id,  # type: str\n    include_keys=False,  # type: Optional[bool]\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e _models.Model\n",
                    "doc": "\"\"\"Get Custom Model.\n\nGet detailed information about a custom model.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param include_keys: Include list of extracted keys in model information. Default value is\n False.\n:type include_keys: bool\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: Model, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.Model\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, include_keys, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_custom_model(\n    self,\n    model_id: str,\n    include_keys: Optional[bool] = False,\n    **kwargs: Any\n) -\u003e _models.Model:\n",
                    "doc": "\"\"\"Get Custom Model.\n\nGet detailed information about a custom model.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param include_keys: Include list of extracted keys in model information. Default value is\n False.\n:type include_keys: bool\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: Model, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.Model\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, include_keys, **kwargs"
                }
            },
            "delete_custom_model" : {
                "sync": {
                    "signature": "def delete_custom_model(  # pylint: disable=inconsistent-return-statements\n    self,\n    model_id,  # type: str\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e None\n",
                    "doc": "\"\"\"Delete Custom Model.\n\nMark model for deletion. Model artifacts will be permanently removed within a predetermined\nperiod.\n\n:param model_id: Model identifier.\n:type model_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def delete_custom_model(  # pylint: disable=inconsistent-return-statements\n    self,\n    model_id: str,\n    **kwargs: Any\n) -\u003e None:\n",
                    "doc": "\"\"\"Delete Custom Model.\n\nMark model for deletion. Model artifacts will be permanently removed within a predetermined\nperiod.\n\n:param model_id: Model identifier.\n:type model_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, **kwargs"
                }
            },
            "_analyze_with_custom_model_initial" : {
                "sync": {
                    "signature": "def _analyze_with_custom_model_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    model_id,  # type: str\n    include_text_details=False,  # type: Optional[bool]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, _models.SourcePath]]\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e None\n",
                    "doc": "\"\"\"Analyze Form.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, include_text_details, pages, file_stream, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _analyze_with_custom_model_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    model_id: str,\n    include_text_details: Optional[bool] = False,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, _models.SourcePath]] = None,\n    *,\n    content_type: Optional[Union[str, \"_models.ContentType\"]] = \"application/json\",\n    **kwargs: Any\n) -\u003e None:\n",
                    "doc": "\"\"\"Analyze Form.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, include_text_details, pages, file_stream, content_type=content_type, **kwargs"
                }
            },
            "begin_analyze_with_custom_model" : {
                "sync": {
                    "signature": "def begin_analyze_with_custom_model(  # pylint: disable=inconsistent-return-statements\n    self,\n    model_id,  # type: str\n    include_text_details=False,  # type: Optional[bool]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, _models.SourcePath]]\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e LROPoller[None]\n",
                    "doc": "\"\"\"Analyze Form.\n\nExtract key-value pairs, tables, and semantic values from a given document. The input document\nmust be of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri or local path) of the document to be analyzed.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be LROBasePolling. Pass in False for\n this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, include_text_details, pages, file_stream, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_analyze_with_custom_model(  # pylint: disable=inconsistent-return-statements\n    self,\n    model_id: str,\n    include_text_details: Optional[bool] = False,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, _models.SourcePath]] = None,\n    *,\n    content_type: Optional[Union[str, \"_models.ContentType\"]] = \"application/json\",\n    **kwargs: Any\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Analyze Form.\n\nExtract key-value pairs, tables, and semantic values from a given document. The input document\nmust be of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri or local path) of the document to be analyzed.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be AsyncLROBasePolling. Pass in False\n for this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, include_text_details, pages, file_stream, content_type=content_type, **kwargs"
                }
            },
            "get_analyze_form_result" : {
                "sync": {
                    "signature": "def get_analyze_form_result(\n    self,\n    model_id,  # type: str\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e _models.AnalyzeOperationResult\n",
                    "doc": "\"\"\"Get Analyze Form Result.\n\nObtain current status and the result of the analyze form operation.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, result_id, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_analyze_form_result(\n    self,\n    model_id: str,\n    result_id: str,\n    **kwargs: Any\n) -\u003e _models.AnalyzeOperationResult:\n",
                    "doc": "\"\"\"Get Analyze Form Result.\n\nObtain current status and the result of the analyze form operation.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, result_id, **kwargs"
                }
            },
            "_copy_custom_model_initial" : {
                "sync": {
                    "signature": "def _copy_custom_model_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    model_id,  # type: str\n    copy_request,  # type: _models.CopyRequest\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e None\n",
                    "doc": "\"\"\"Copy Custom Model.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param copy_request: Copy request parameters.\n:type copy_request: ~azure.ai.formrecognizer.v2_1.models.CopyRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, copy_request, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _copy_custom_model_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    model_id: str,\n    copy_request: _models.CopyRequest,\n    **kwargs: Any\n) -\u003e None:\n",
                    "doc": "\"\"\"Copy Custom Model.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param copy_request: Copy request parameters.\n:type copy_request: ~azure.ai.formrecognizer.v2_1.models.CopyRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, copy_request, **kwargs"
                }
            },
            "begin_copy_custom_model" : {
                "sync": {
                    "signature": "def begin_copy_custom_model(  # pylint: disable=inconsistent-return-statements\n    self,\n    model_id,  # type: str\n    copy_request,  # type: _models.CopyRequest\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e LROPoller[None]\n",
                    "doc": "\"\"\"Copy Custom Model.\n\nCopy custom model stored in this resource (the source) to user specified target Form Recognizer\nresource.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param copy_request: Copy request parameters.\n:type copy_request: ~azure.ai.formrecognizer.v2_1.models.CopyRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be LROBasePolling. Pass in False for\n this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, copy_request, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_copy_custom_model(  # pylint: disable=inconsistent-return-statements\n    self,\n    model_id: str,\n    copy_request: _models.CopyRequest,\n    **kwargs: Any\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Copy Custom Model.\n\nCopy custom model stored in this resource (the source) to user specified target Form Recognizer\nresource.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param copy_request: Copy request parameters.\n:type copy_request: ~azure.ai.formrecognizer.v2_1.models.CopyRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be AsyncLROBasePolling. Pass in False\n for this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, copy_request, **kwargs"
                }
            },
            "get_custom_model_copy_result" : {
                "sync": {
                    "signature": "def get_custom_model_copy_result(\n    self,\n    model_id,  # type: str\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e _models.CopyOperationResult\n",
                    "doc": "\"\"\"Get Custom Model Copy Result.\n\nObtain current status and the result of a custom model copy operation.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param result_id: Copy operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: CopyOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.CopyOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, result_id, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_custom_model_copy_result(\n    self,\n    model_id: str,\n    result_id: str,\n    **kwargs: Any\n) -\u003e _models.CopyOperationResult:\n",
                    "doc": "\"\"\"Get Custom Model Copy Result.\n\nObtain current status and the result of a custom model copy operation.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param result_id: Copy operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: CopyOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.CopyOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "model_id, result_id, **kwargs"
                }
            },
            "generate_model_copy_authorization" : {
                "sync": {
                    "signature": "def generate_model_copy_authorization(\n    self,\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e _models.CopyAuthorizationResult\n",
                    "doc": "\"\"\"Generate Copy Authorization.\n\nGenerate authorization to copy a model into the target Form Recognizer resource.\n\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: CopyAuthorizationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.CopyAuthorizationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "**kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def generate_model_copy_authorization(\n    self,\n    **kwargs: Any\n) -\u003e _models.CopyAuthorizationResult:\n",
                    "doc": "\"\"\"Generate Copy Authorization.\n\nGenerate authorization to copy a model into the target Form Recognizer resource.\n\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: CopyAuthorizationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.CopyAuthorizationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "**kwargs"
                }
            },
            "_compose_custom_models_async_initial" : {
                "sync": {
                    "signature": "def _compose_custom_models_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    compose_request,  # type: _models.ComposeRequest\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e None\n",
                    "doc": "\"\"\"Compose trained with labels models into one composed model.\n\n:param compose_request: Compose models.\n:type compose_request: ~azure.ai.formrecognizer.v2_1.models.ComposeRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "compose_request, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _compose_custom_models_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    compose_request: _models.ComposeRequest,\n    **kwargs: Any\n) -\u003e None:\n",
                    "doc": "\"\"\"Compose trained with labels models into one composed model.\n\n:param compose_request: Compose models.\n:type compose_request: ~azure.ai.formrecognizer.v2_1.models.ComposeRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "compose_request, **kwargs"
                }
            },
            "begin_compose_custom_models_async" : {
                "sync": {
                    "signature": "def begin_compose_custom_models_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    compose_request,  # type: _models.ComposeRequest\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e LROPoller[None]\n",
                    "doc": "\"\"\"Compose trained with labels models into one composed model.\n\nCompose request would include list of models ids.\nIt would validate what all models either trained with labels model or composed model.\nIt would validate limit of models put together.\n\n:param compose_request: Compose models.\n:type compose_request: ~azure.ai.formrecognizer.v2_1.models.ComposeRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be LROBasePolling. Pass in False for\n this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "compose_request, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_compose_custom_models_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    compose_request: _models.ComposeRequest,\n    **kwargs: Any\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Compose trained with labels models into one composed model.\n\nCompose request would include list of models ids.\nIt would validate what all models either trained with labels model or composed model.\nIt would validate limit of models put together.\n\n:param compose_request: Compose models.\n:type compose_request: ~azure.ai.formrecognizer.v2_1.models.ComposeRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be AsyncLROBasePolling. Pass in False\n for this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "compose_request, **kwargs"
                }
            },
            "_analyze_business_card_async_initial" : {
                "sync": {
                    "signature": "def _analyze_business_card_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    locale=None,  # type: Optional[Union[str, \"_models.Locale\"]]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, _models.SourcePath]]\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e None\n",
                    "doc": "\"\"\"Analyze Business Card.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default). Default value is None.\n:type locale: str or ~azure.ai.formrecognizer.v2_1.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, locale, pages, file_stream, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _analyze_business_card_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details: Optional[bool] = False,\n    locale: Optional[Union[str, \"_models.Locale\"]] = None,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, _models.SourcePath]] = None,\n    *,\n    content_type: Optional[Union[str, \"_models.ContentType\"]] = \"application/json\",\n    **kwargs: Any\n) -\u003e None:\n",
                    "doc": "\"\"\"Analyze Business Card.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default). Default value is None.\n:type locale: str or ~azure.ai.formrecognizer.v2_1.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, locale, pages, file_stream, content_type=content_type, **kwargs"
                }
            },
            "begin_analyze_business_card_async" : {
                "sync": {
                    "signature": "def begin_analyze_business_card_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    locale=None,  # type: Optional[Union[str, \"_models.Locale\"]]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, _models.SourcePath]]\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e LROPoller[None]\n",
                    "doc": "\"\"\"Analyze Business Card.\n\nExtract field text and semantic values from a given business card document. The input document\nmust be of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri) of the document to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default). Default value is None.\n:type locale: str or ~azure.ai.formrecognizer.v2_1.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be LROBasePolling. Pass in False for\n this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, locale, pages, file_stream, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_analyze_business_card_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details: Optional[bool] = False,\n    locale: Optional[Union[str, \"_models.Locale\"]] = None,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, _models.SourcePath]] = None,\n    *,\n    content_type: Optional[Union[str, \"_models.ContentType\"]] = \"application/json\",\n    **kwargs: Any\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Analyze Business Card.\n\nExtract field text and semantic values from a given business card document. The input document\nmust be of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri) of the document to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default). Default value is None.\n:type locale: str or ~azure.ai.formrecognizer.v2_1.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be AsyncLROBasePolling. Pass in False\n for this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, locale, pages, file_stream, content_type=content_type, **kwargs"
                }
            },
            "get_analyze_business_card_result" : {
                "sync": {
                    "signature": "def get_analyze_business_card_result(\n    self,\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e _models.AnalyzeOperationResult\n",
                    "doc": "\"\"\"Get Analyze Business Card Result.\n\nTrack the progress and obtain the result of the analyze business card operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "result_id, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_analyze_business_card_result(\n    self,\n    result_id: str,\n    **kwargs: Any\n) -\u003e _models.AnalyzeOperationResult:\n",
                    "doc": "\"\"\"Get Analyze Business Card Result.\n\nTrack the progress and obtain the result of the analyze business card operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "result_id, **kwargs"
                }
            },
            "_analyze_invoice_async_initial" : {
                "sync": {
                    "signature": "def _analyze_invoice_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    locale=None,  # type: Optional[Union[str, \"_models.Locale\"]]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, _models.SourcePath]]\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e None\n",
                    "doc": "\"\"\"Analyze Invoice Document.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default). Default value is None.\n:type locale: str or ~azure.ai.formrecognizer.v2_1.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, locale, pages, file_stream, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _analyze_invoice_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details: Optional[bool] = False,\n    locale: Optional[Union[str, \"_models.Locale\"]] = None,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, _models.SourcePath]] = None,\n    *,\n    content_type: Optional[Union[str, \"_models.ContentType\"]] = \"application/json\",\n    **kwargs: Any\n) -\u003e None:\n",
                    "doc": "\"\"\"Analyze Invoice Document.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default). Default value is None.\n:type locale: str or ~azure.ai.formrecognizer.v2_1.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, locale, pages, file_stream, content_type=content_type, **kwargs"
                }
            },
            "begin_analyze_invoice_async" : {
                "sync": {
                    "signature": "def begin_analyze_invoice_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    locale=None,  # type: Optional[Union[str, \"_models.Locale\"]]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, _models.SourcePath]]\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e LROPoller[None]\n",
                    "doc": "\"\"\"Analyze Invoice Document.\n\nExtract field text and semantic values from a given invoice document. The input document must\nbe of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri) of the document to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default). Default value is None.\n:type locale: str or ~azure.ai.formrecognizer.v2_1.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be LROBasePolling. Pass in False for\n this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, locale, pages, file_stream, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_analyze_invoice_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details: Optional[bool] = False,\n    locale: Optional[Union[str, \"_models.Locale\"]] = None,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, _models.SourcePath]] = None,\n    *,\n    content_type: Optional[Union[str, \"_models.ContentType\"]] = \"application/json\",\n    **kwargs: Any\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Analyze Invoice Document.\n\nExtract field text and semantic values from a given invoice document. The input document must\nbe of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri) of the document to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default). Default value is None.\n:type locale: str or ~azure.ai.formrecognizer.v2_1.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be AsyncLROBasePolling. Pass in False\n for this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, locale, pages, file_stream, content_type=content_type, **kwargs"
                }
            },
            "get_analyze_invoice_result" : {
                "sync": {
                    "signature": "def get_analyze_invoice_result(\n    self,\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e _models.AnalyzeOperationResult\n",
                    "doc": "\"\"\"Get Analyze Invoice Result.\n\nTrack the progress and obtain the result of the analyze invoice operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "result_id, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_analyze_invoice_result(\n    self,\n    result_id: str,\n    **kwargs: Any\n) -\u003e _models.AnalyzeOperationResult:\n",
                    "doc": "\"\"\"Get Analyze Invoice Result.\n\nTrack the progress and obtain the result of the analyze invoice operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "result_id, **kwargs"
                }
            },
            "_analyze_id_document_async_initial" : {
                "sync": {
                    "signature": "def _analyze_id_document_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, _models.SourcePath]]\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e None\n",
                    "doc": "\"\"\"Analyze ID Document.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, pages, file_stream, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _analyze_id_document_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details: Optional[bool] = False,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, _models.SourcePath]] = None,\n    *,\n    content_type: Optional[Union[str, \"_models.ContentType\"]] = \"application/json\",\n    **kwargs: Any\n) -\u003e None:\n",
                    "doc": "\"\"\"Analyze ID Document.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, pages, file_stream, content_type=content_type, **kwargs"
                }
            },
            "begin_analyze_id_document_async" : {
                "sync": {
                    "signature": "def begin_analyze_id_document_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, _models.SourcePath]]\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e LROPoller[None]\n",
                    "doc": "\"\"\"Analyze ID Document.\n\nExtract field text and semantic values from a given ID document. The input document must be of\none of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027, \u0027image/tiff\u0027\nor \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location (Uri) of the\ndocument to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be LROBasePolling. Pass in False for\n this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, pages, file_stream, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_analyze_id_document_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details: Optional[bool] = False,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, _models.SourcePath]] = None,\n    *,\n    content_type: Optional[Union[str, \"_models.ContentType\"]] = \"application/json\",\n    **kwargs: Any\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Analyze ID Document.\n\nExtract field text and semantic values from a given ID document. The input document must be of\none of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027, \u0027image/tiff\u0027\nor \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location (Uri) of the\ndocument to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be AsyncLROBasePolling. Pass in False\n for this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, pages, file_stream, content_type=content_type, **kwargs"
                }
            },
            "get_analyze_id_document_result" : {
                "sync": {
                    "signature": "def get_analyze_id_document_result(\n    self,\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e _models.AnalyzeOperationResult\n",
                    "doc": "\"\"\"Get Analyze ID Document Result.\n\nTrack the progress and obtain the result of the analyze ID operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "result_id, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_analyze_id_document_result(\n    self,\n    result_id: str,\n    **kwargs: Any\n) -\u003e _models.AnalyzeOperationResult:\n",
                    "doc": "\"\"\"Get Analyze ID Document Result.\n\nTrack the progress and obtain the result of the analyze ID operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "result_id, **kwargs"
                }
            },
            "_analyze_receipt_async_initial" : {
                "sync": {
                    "signature": "def _analyze_receipt_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    locale=None,  # type: Optional[Union[str, \"_models.Locale\"]]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, _models.SourcePath]]\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e None\n",
                    "doc": "\"\"\"Analyze Receipt.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default). Default value is None.\n:type locale: str or ~azure.ai.formrecognizer.v2_1.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, locale, pages, file_stream, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _analyze_receipt_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details: Optional[bool] = False,\n    locale: Optional[Union[str, \"_models.Locale\"]] = None,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, _models.SourcePath]] = None,\n    *,\n    content_type: Optional[Union[str, \"_models.ContentType\"]] = \"application/json\",\n    **kwargs: Any\n) -\u003e None:\n",
                    "doc": "\"\"\"Analyze Receipt.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default). Default value is None.\n:type locale: str or ~azure.ai.formrecognizer.v2_1.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, locale, pages, file_stream, content_type=content_type, **kwargs"
                }
            },
            "begin_analyze_receipt_async" : {
                "sync": {
                    "signature": "def begin_analyze_receipt_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    locale=None,  # type: Optional[Union[str, \"_models.Locale\"]]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, _models.SourcePath]]\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e LROPoller[None]\n",
                    "doc": "\"\"\"Analyze Receipt.\n\nExtract field text and semantic values from a given receipt document. The input document must\nbe of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri) of the document to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default). Default value is None.\n:type locale: str or ~azure.ai.formrecognizer.v2_1.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be LROBasePolling. Pass in False for\n this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, locale, pages, file_stream, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_analyze_receipt_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    include_text_details: Optional[bool] = False,\n    locale: Optional[Union[str, \"_models.Locale\"]] = None,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, _models.SourcePath]] = None,\n    *,\n    content_type: Optional[Union[str, \"_models.ContentType\"]] = \"application/json\",\n    **kwargs: Any\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Analyze Receipt.\n\nExtract field text and semantic values from a given receipt document. The input document must\nbe of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri) of the document to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result. Default\n value is False.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default). Default value is None.\n:type locale: str or ~azure.ai.formrecognizer.v2_1.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be AsyncLROBasePolling. Pass in False\n for this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "include_text_details, locale, pages, file_stream, content_type=content_type, **kwargs"
                }
            },
            "get_analyze_receipt_result" : {
                "sync": {
                    "signature": "def get_analyze_receipt_result(\n    self,\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e _models.AnalyzeOperationResult\n",
                    "doc": "\"\"\"Get Analyze Receipt Result.\n\nTrack the progress and obtain the result of the analyze receipt operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "result_id, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_analyze_receipt_result(\n    self,\n    result_id: str,\n    **kwargs: Any\n) -\u003e _models.AnalyzeOperationResult:\n",
                    "doc": "\"\"\"Get Analyze Receipt Result.\n\nTrack the progress and obtain the result of the analyze receipt operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "result_id, **kwargs"
                }
            },
            "_analyze_layout_async_initial" : {
                "sync": {
                    "signature": "def _analyze_layout_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    pages=None,  # type: Optional[List[str]]\n    language=None,  # type: Optional[Union[str, \"_models.Language\"]]\n    reading_order=\"basic\",  # type: Optional[Union[str, \"_models.ReadingOrder\"]]\n    file_stream=None,  # type: Optional[Union[IO, _models.SourcePath]]\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e None\n",
                    "doc": "\"\"\"Analyze Layout.\n\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param language: Currently, only Afrikaans (\u2018af\u2019), Albanian (\u2018sq\u2019), Asturian (\u2018ast\u2019), Basque\n (\u2018eu\u2019), Bislama (\u2018bi\u2019), Breton (\u2018br\u2019), Catalan (\u2018ca\u2019), Cebuano (\u2018ceb\u2019), Chamorro (\u2018ch\u2019),\n Cornish (\u2018kw\u2019), Corsican (\u2018co\u2019), Crimean Tatar - Latin script(\u2018crh\u2019), Czech (\u2018cs\u2019), Danish\n (\u2018da\u2019), Dutch (\u2018nl\u2019), English (\u0027en\u0027), Estonian (\u2018et\u2019), Fijian (\u2018fj\u2019), Filipino (\u2018fil\u2019), Finnish\n (\u2018fi\u2019), French (\u2018fr\u2019), Friulian (\u2018fur\u2019), Galician (\u2018gl\u2019), German (\u2018de\u2019), Gilbertese (\u2018gil\u2019),\n Greenlandic (\u2018kl\u2019), Haitian Creole (\u2018ht\u2019), Hani (\u2018hni\u2019), Hmong Daw (\u2018mww\u2019), Hungarian (\u2018hu\u2019),\n Indonesian (\u2018id\u2019), Interlingua (\u2018ia\u2019), Inuktitut (\u2018iu\u2019), Irish (\u2018ga\u2019), Italian (\u2018it\u2019), Japanese\n (\u2018ja\u2019), Javanese (\u2018jv\u2019), Kabuverdianu (\u2018kea\u2019), Kachin (\u2018kac\u2019), Kara-Kalpak (\u2018kaa\u2019), Kashubian\n (\u2018csb\u2019), Khasi (\u2018kha\u2019), Korean (\u2018ko\u2019), Kurdish - Latin script (\u2018ku\u2019), K\u2019iche\u2019 (\u2018quc\u2019),\n Luxembourgish (\u2018lb\u2019), Malay (\u2018ms\u2019), Manx (\u2018gv\u2019), Neapolitan (\u2018nap\u2019), Norwegian (\u2018no\u2019), Occitan\n (\u2018oc\u2019), Polish (\u2018pl\u2019), Portuguese (\u2018pt\u2019), Romansh (\u2018rm\u2019), Scots (\u2018sco\u2019), Scottish Gaelic\n (\u2018gd\u2019), simplified Chinese (\u2018zh-Hans\u2019), Slovenian (\u2018sl\u2019), Spanish (\u2018es\u2019), Swahili (\u2018sw\u2019),\n Swedish (\u2018sv\u2019), Tatar - Latin script (\u2018tt\u2019), Tetum (\u2018tet\u2019), traditional Chinese (\u2018zh-Hant\u2019),\n Turkish (\u2018tr\u2019), Upper Sorbian (\u2018hsb\u2019), Uzbek (\u2018uz\u2019), Volap\u00fck (\u2018vo\u2019), Walser (\u2018wae\u2019), Western\n Frisian (\u2018fy\u2019), Yucatec Maya (\u2018yua\u2019), Zhuang (\u2018za\u2019) and Zulu (\u2018zu\u2019) are supported (print \u2013\n seventy-three languages and handwritten \u2013 English only). Layout supports auto language\n identification and multi language documents, so only provide a language code if you would like\n to force the documented to be processed as that specific language. Default value is None.\n:type language: str or ~azure.ai.formrecognizer.v2_1.models.Language\n:param reading_order: Reading order algorithm to sort the text lines returned. Supported\n reading orders include: basic(default), natural. Default value is \"basic\".\n:type reading_order: str or ~azure.ai.formrecognizer.v2_1.models.ReadingOrder\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "pages, language, reading_order, file_stream, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _analyze_layout_async_initial(  # pylint: disable=inconsistent-return-statements\n    self,\n    pages: Optional[List[str]] = None,\n    language: Optional[Union[str, \"_models.Language\"]] = None,\n    reading_order: Optional[Union[str, \"_models.ReadingOrder\"]] = \"basic\",\n    file_stream: Optional[Union[IO, _models.SourcePath]] = None,\n    *,\n    content_type: Optional[Union[str, \"_models.ContentType\"]] = \"application/json\",\n    **kwargs: Any\n) -\u003e None:\n",
                    "doc": "\"\"\"Analyze Layout.\n\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param language: Currently, only Afrikaans (\u2018af\u2019), Albanian (\u2018sq\u2019), Asturian (\u2018ast\u2019), Basque\n (\u2018eu\u2019), Bislama (\u2018bi\u2019), Breton (\u2018br\u2019), Catalan (\u2018ca\u2019), Cebuano (\u2018ceb\u2019), Chamorro (\u2018ch\u2019),\n Cornish (\u2018kw\u2019), Corsican (\u2018co\u2019), Crimean Tatar - Latin script(\u2018crh\u2019), Czech (\u2018cs\u2019), Danish\n (\u2018da\u2019), Dutch (\u2018nl\u2019), English (\u0027en\u0027), Estonian (\u2018et\u2019), Fijian (\u2018fj\u2019), Filipino (\u2018fil\u2019), Finnish\n (\u2018fi\u2019), French (\u2018fr\u2019), Friulian (\u2018fur\u2019), Galician (\u2018gl\u2019), German (\u2018de\u2019), Gilbertese (\u2018gil\u2019),\n Greenlandic (\u2018kl\u2019), Haitian Creole (\u2018ht\u2019), Hani (\u2018hni\u2019), Hmong Daw (\u2018mww\u2019), Hungarian (\u2018hu\u2019),\n Indonesian (\u2018id\u2019), Interlingua (\u2018ia\u2019), Inuktitut (\u2018iu\u2019), Irish (\u2018ga\u2019), Italian (\u2018it\u2019), Japanese\n (\u2018ja\u2019), Javanese (\u2018jv\u2019), Kabuverdianu (\u2018kea\u2019), Kachin (\u2018kac\u2019), Kara-Kalpak (\u2018kaa\u2019), Kashubian\n (\u2018csb\u2019), Khasi (\u2018kha\u2019), Korean (\u2018ko\u2019), Kurdish - Latin script (\u2018ku\u2019), K\u2019iche\u2019 (\u2018quc\u2019),\n Luxembourgish (\u2018lb\u2019), Malay (\u2018ms\u2019), Manx (\u2018gv\u2019), Neapolitan (\u2018nap\u2019), Norwegian (\u2018no\u2019), Occitan\n (\u2018oc\u2019), Polish (\u2018pl\u2019), Portuguese (\u2018pt\u2019), Romansh (\u2018rm\u2019), Scots (\u2018sco\u2019), Scottish Gaelic\n (\u2018gd\u2019), simplified Chinese (\u2018zh-Hans\u2019), Slovenian (\u2018sl\u2019), Spanish (\u2018es\u2019), Swahili (\u2018sw\u2019),\n Swedish (\u2018sv\u2019), Tatar - Latin script (\u2018tt\u2019), Tetum (\u2018tet\u2019), traditional Chinese (\u2018zh-Hant\u2019),\n Turkish (\u2018tr\u2019), Upper Sorbian (\u2018hsb\u2019), Uzbek (\u2018uz\u2019), Volap\u00fck (\u2018vo\u2019), Walser (\u2018wae\u2019), Western\n Frisian (\u2018fy\u2019), Yucatec Maya (\u2018yua\u2019), Zhuang (\u2018za\u2019) and Zulu (\u2018zu\u2019) are supported (print \u2013\n seventy-three languages and handwritten \u2013 English only). Layout supports auto language\n identification and multi language documents, so only provide a language code if you would like\n to force the documented to be processed as that specific language. Default value is None.\n:type language: str or ~azure.ai.formrecognizer.v2_1.models.Language\n:param reading_order: Reading order algorithm to sort the text lines returned. Supported\n reading orders include: basic(default), natural. Default value is \"basic\".\n:type reading_order: str or ~azure.ai.formrecognizer.v2_1.models.ReadingOrder\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "pages, language, reading_order, file_stream, content_type=content_type, **kwargs"
                }
            },
            "begin_analyze_layout_async" : {
                "sync": {
                    "signature": "def begin_analyze_layout_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    pages=None,  # type: Optional[List[str]]\n    language=None,  # type: Optional[Union[str, \"_models.Language\"]]\n    reading_order=\"basic\",  # type: Optional[Union[str, \"_models.ReadingOrder\"]]\n    file_stream=None,  # type: Optional[Union[IO, _models.SourcePath]]\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e LROPoller[None]\n",
                    "doc": "\"\"\"Analyze Layout.\n\nExtract text and layout information from a given document. The input document must be of one of\nthe supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027, \u0027image/tiff\u0027 or\n\u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location (Uri or local\npath) of the document to be analyzed.\n\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param language: Currently, only Afrikaans (\u2018af\u2019), Albanian (\u2018sq\u2019), Asturian (\u2018ast\u2019), Basque\n (\u2018eu\u2019), Bislama (\u2018bi\u2019), Breton (\u2018br\u2019), Catalan (\u2018ca\u2019), Cebuano (\u2018ceb\u2019), Chamorro (\u2018ch\u2019),\n Cornish (\u2018kw\u2019), Corsican (\u2018co\u2019), Crimean Tatar - Latin script(\u2018crh\u2019), Czech (\u2018cs\u2019), Danish\n (\u2018da\u2019), Dutch (\u2018nl\u2019), English (\u0027en\u0027), Estonian (\u2018et\u2019), Fijian (\u2018fj\u2019), Filipino (\u2018fil\u2019), Finnish\n (\u2018fi\u2019), French (\u2018fr\u2019), Friulian (\u2018fur\u2019), Galician (\u2018gl\u2019), German (\u2018de\u2019), Gilbertese (\u2018gil\u2019),\n Greenlandic (\u2018kl\u2019), Haitian Creole (\u2018ht\u2019), Hani (\u2018hni\u2019), Hmong Daw (\u2018mww\u2019), Hungarian (\u2018hu\u2019),\n Indonesian (\u2018id\u2019), Interlingua (\u2018ia\u2019), Inuktitut (\u2018iu\u2019), Irish (\u2018ga\u2019), Italian (\u2018it\u2019), Japanese\n (\u2018ja\u2019), Javanese (\u2018jv\u2019), Kabuverdianu (\u2018kea\u2019), Kachin (\u2018kac\u2019), Kara-Kalpak (\u2018kaa\u2019), Kashubian\n (\u2018csb\u2019), Khasi (\u2018kha\u2019), Korean (\u2018ko\u2019), Kurdish - Latin script (\u2018ku\u2019), K\u2019iche\u2019 (\u2018quc\u2019),\n Luxembourgish (\u2018lb\u2019), Malay (\u2018ms\u2019), Manx (\u2018gv\u2019), Neapolitan (\u2018nap\u2019), Norwegian (\u2018no\u2019), Occitan\n (\u2018oc\u2019), Polish (\u2018pl\u2019), Portuguese (\u2018pt\u2019), Romansh (\u2018rm\u2019), Scots (\u2018sco\u2019), Scottish Gaelic\n (\u2018gd\u2019), simplified Chinese (\u2018zh-Hans\u2019), Slovenian (\u2018sl\u2019), Spanish (\u2018es\u2019), Swahili (\u2018sw\u2019),\n Swedish (\u2018sv\u2019), Tatar - Latin script (\u2018tt\u2019), Tetum (\u2018tet\u2019), traditional Chinese (\u2018zh-Hant\u2019),\n Turkish (\u2018tr\u2019), Upper Sorbian (\u2018hsb\u2019), Uzbek (\u2018uz\u2019), Volap\u00fck (\u2018vo\u2019), Walser (\u2018wae\u2019), Western\n Frisian (\u2018fy\u2019), Yucatec Maya (\u2018yua\u2019), Zhuang (\u2018za\u2019) and Zulu (\u2018zu\u2019) are supported (print \u2013\n seventy-three languages and handwritten \u2013 English only). Layout supports auto language\n identification and multi language documents, so only provide a language code if you would like\n to force the documented to be processed as that specific language. Default value is None.\n:type language: str or ~azure.ai.formrecognizer.v2_1.models.Language\n:param reading_order: Reading order algorithm to sort the text lines returned. Supported\n reading orders include: basic(default), natural. Default value is \"basic\".\n:type reading_order: str or ~azure.ai.formrecognizer.v2_1.models.ReadingOrder\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be LROBasePolling. Pass in False for\n this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "pages, language, reading_order, file_stream, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_analyze_layout_async(  # pylint: disable=inconsistent-return-statements\n    self,\n    pages: Optional[List[str]] = None,\n    language: Optional[Union[str, \"_models.Language\"]] = None,\n    reading_order: Optional[Union[str, \"_models.ReadingOrder\"]] = \"basic\",\n    file_stream: Optional[Union[IO, _models.SourcePath]] = None,\n    *,\n    content_type: Optional[Union[str, \"_models.ContentType\"]] = \"application/json\",\n    **kwargs: Any\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Analyze Layout.\n\nExtract text and layout information from a given document. The input document must be of one of\nthe supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027, \u0027image/tiff\u0027 or\n\u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location (Uri or local\npath) of the document to be analyzed.\n\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma. Default value is None.\n:type pages: list[str]\n:param language: Currently, only Afrikaans (\u2018af\u2019), Albanian (\u2018sq\u2019), Asturian (\u2018ast\u2019), Basque\n (\u2018eu\u2019), Bislama (\u2018bi\u2019), Breton (\u2018br\u2019), Catalan (\u2018ca\u2019), Cebuano (\u2018ceb\u2019), Chamorro (\u2018ch\u2019),\n Cornish (\u2018kw\u2019), Corsican (\u2018co\u2019), Crimean Tatar - Latin script(\u2018crh\u2019), Czech (\u2018cs\u2019), Danish\n (\u2018da\u2019), Dutch (\u2018nl\u2019), English (\u0027en\u0027), Estonian (\u2018et\u2019), Fijian (\u2018fj\u2019), Filipino (\u2018fil\u2019), Finnish\n (\u2018fi\u2019), French (\u2018fr\u2019), Friulian (\u2018fur\u2019), Galician (\u2018gl\u2019), German (\u2018de\u2019), Gilbertese (\u2018gil\u2019),\n Greenlandic (\u2018kl\u2019), Haitian Creole (\u2018ht\u2019), Hani (\u2018hni\u2019), Hmong Daw (\u2018mww\u2019), Hungarian (\u2018hu\u2019),\n Indonesian (\u2018id\u2019), Interlingua (\u2018ia\u2019), Inuktitut (\u2018iu\u2019), Irish (\u2018ga\u2019), Italian (\u2018it\u2019), Japanese\n (\u2018ja\u2019), Javanese (\u2018jv\u2019), Kabuverdianu (\u2018kea\u2019), Kachin (\u2018kac\u2019), Kara-Kalpak (\u2018kaa\u2019), Kashubian\n (\u2018csb\u2019), Khasi (\u2018kha\u2019), Korean (\u2018ko\u2019), Kurdish - Latin script (\u2018ku\u2019), K\u2019iche\u2019 (\u2018quc\u2019),\n Luxembourgish (\u2018lb\u2019), Malay (\u2018ms\u2019), Manx (\u2018gv\u2019), Neapolitan (\u2018nap\u2019), Norwegian (\u2018no\u2019), Occitan\n (\u2018oc\u2019), Polish (\u2018pl\u2019), Portuguese (\u2018pt\u2019), Romansh (\u2018rm\u2019), Scots (\u2018sco\u2019), Scottish Gaelic\n (\u2018gd\u2019), simplified Chinese (\u2018zh-Hans\u2019), Slovenian (\u2018sl\u2019), Spanish (\u2018es\u2019), Swahili (\u2018sw\u2019),\n Swedish (\u2018sv\u2019), Tatar - Latin script (\u2018tt\u2019), Tetum (\u2018tet\u2019), traditional Chinese (\u2018zh-Hant\u2019),\n Turkish (\u2018tr\u2019), Upper Sorbian (\u2018hsb\u2019), Uzbek (\u2018uz\u2019), Volap\u00fck (\u2018vo\u2019), Walser (\u2018wae\u2019), Western\n Frisian (\u2018fy\u2019), Yucatec Maya (\u2018yua\u2019), Zhuang (\u2018za\u2019) and Zulu (\u2018zu\u2019) are supported (print \u2013\n seventy-three languages and handwritten \u2013 English only). Layout supports auto language\n identification and multi language documents, so only provide a language code if you would like\n to force the documented to be processed as that specific language. Default value is None.\n:type language: str or ~azure.ai.formrecognizer.v2_1.models.Language\n:param reading_order: Reading order algorithm to sort the text lines returned. Supported\n reading orders include: basic(default), natural. Default value is \"basic\".\n:type reading_order: str or ~azure.ai.formrecognizer.v2_1.models.ReadingOrder\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream. Default value is\n None.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1.models.SourcePath\n:keyword content_type: Media type of the body sent to the API. Known values are:\n \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", and\n \"application/json\". Default value is \"application/json\".\n:paramtype content_type: str or ~azure.ai.formrecognizer.v2_1.models.ContentType\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: By default, your polling method will be AsyncLROBasePolling. Pass in False\n for this operation to not poll, or pass in your own initialized polling object for a personal\n polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no\n Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "pages, language, reading_order, file_stream, content_type=content_type, **kwargs"
                }
            },
            "get_analyze_layout_result" : {
                "sync": {
                    "signature": "def get_analyze_layout_result(\n    self,\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e _models.AnalyzeOperationResult\n",
                    "doc": "\"\"\"Get Analyze Layout Result.\n\nTrack the progress and obtain the result of the analyze layout operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "result_id, **kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_analyze_layout_result(\n    self,\n    result_id: str,\n    **kwargs: Any\n) -\u003e _models.AnalyzeOperationResult:\n",
                    "doc": "\"\"\"Get Analyze Layout Result.\n\nTrack the progress and obtain the result of the analyze layout operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "result_id, **kwargs"
                }
            },
            "list_custom_models" : {
                "sync": {
                    "signature": "def list_custom_models(\n    self,\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e Iterable[_models.Models]\n",
                    "doc": "\"\"\"List Custom Models.\n\nGet information about all custom models.\n\n:keyword op: Specify whether to return summary or full list of models. Default value is \"full\".\n Note that overriding this default value may result in unsupported behavior.\n:paramtype op: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: An iterator like instance of either Models or the result of cls(response)\n:rtype: ~azure.core.paging.ItemPaged[~azure.ai.formrecognizer.v2_1.models.Models]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "**kwargs"
                },
                "async": {
                    "coroutine": false,
                    "signature": "def list_custom_models(\n    self,\n    **kwargs: Any\n) -\u003e AsyncIterable[_models.Models]:\n",
                    "doc": "\"\"\"List Custom Models.\n\nGet information about all custom models.\n\n:keyword op: Specify whether to return summary or full list of models. Default value is \"full\".\n Note that overriding this default value may result in unsupported behavior.\n:paramtype op: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: An iterator like instance of either Models or the result of cls(response)\n:rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.ai.formrecognizer.v2_1.models.Models]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "**kwargs"
                }
            },
            "get_custom_models" : {
                "sync": {
                    "signature": "def get_custom_models(\n    self,\n    **kwargs  # type: Any\n):\n    # type: (...) -\u003e _models.Models\n",
                    "doc": "\"\"\"Get Custom Models.\n\nGet information about all custom models.\n\n:keyword op: Specify whether to return summary or full list of models. Default value is\n \"summary\". Note that overriding this default value may result in unsupported behavior.\n:paramtype op: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: Models, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.Models\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "**kwargs"
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_custom_models(\n    self,\n    **kwargs: Any\n) -\u003e _models.Models:\n",
                    "doc": "\"\"\"Get Custom Models.\n\nGet information about all custom models.\n\n:keyword op: Specify whether to return summary or full list of models. Default value is\n \"summary\". Note that overriding this default value may result in unsupported behavior.\n:paramtype op: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: Models, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1.models.Models\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\"",
                    "call": "**kwargs"
                }
            }
        }
    }
}