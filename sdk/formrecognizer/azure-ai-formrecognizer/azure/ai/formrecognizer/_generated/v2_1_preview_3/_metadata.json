{
    "chosen_version": "2.1-preview.3",
    "total_api_version_list": ["2.1-preview.3"],
    "client": {
        "name": "FormRecognizerClient",
        "filename": "_form_recognizer_client",
        "description": "Extracts information from forms and images into structured data.",
        "base_url": null,
        "custom_base_url": "\u0027{endpoint}/formrecognizer/v2.1-preview.3\u0027",
        "azure_arm": false,
        "has_lro_operations": true,
        "client_side_validation": false,
        "sync_imports": "{\"typing\": {\"azurecore\": {\"azure.core.credentials\": [\"TokenCredential\"]}}, \"regular\": {\"azurecore\": {\"azure.profiles\": [\"KnownProfiles\", \"ProfileDefinition\"], \"azure.profiles.multiapiclient\": [\"MultiApiClientMixin\"], \"msrest\": [\"Deserializer\", \"Serializer\"], \"azure.core\": [\"PipelineClient\"]}, \"local\": {\"._configuration\": [\"FormRecognizerClientConfiguration\"], \"._operations_mixin\": [\"FormRecognizerClientOperationsMixin\"]}}, \"conditional\": {\"stdlib\": {\"typing\": [\"Any\", \"Optional\"]}, \"azurecore\": {\"azure.core.pipeline.transport\": [\"HttpRequest\", \"HttpResponse\"]}}}",
        "async_imports": "{\"typing\": {\"azurecore\": {\"azure.core.credentials_async\": [\"AsyncTokenCredential\"]}}, \"regular\": {\"azurecore\": {\"azure.profiles\": [\"KnownProfiles\", \"ProfileDefinition\"], \"azure.profiles.multiapiclient\": [\"MultiApiClientMixin\"], \"msrest\": [\"Deserializer\", \"Serializer\"], \"azure.core\": [\"AsyncPipelineClient\"]}, \"local\": {\"._configuration\": [\"FormRecognizerClientConfiguration\"], \"._operations_mixin\": [\"FormRecognizerClientOperationsMixin\"]}}, \"conditional\": {\"stdlib\": {\"typing\": [\"Any\", \"Optional\"]}, \"azurecore\": {\"azure.core.pipeline.transport\": [\"AsyncHttpResponse\", \"HttpRequest\"]}}}"
    },
    "global_parameters": {
        "sync": {
            "credential": {
                "signature": "credential,  # type: \"TokenCredential\"",
                "description": "Credential needed for the client to connect to Azure.",
                "docstring_type": "~azure.core.credentials.TokenCredential",
                "required": true
            },
            "endpoint": {
                "signature": "endpoint,  # type: str",
                "description": "Supported Cognitive Services endpoints (protocol and hostname, for example: https://westus2.api.cognitive.microsoft.com).",
                "docstring_type": "str",
                "required": true
            }
        },
        "async": {
            "credential": {
                "signature": "credential: \"AsyncTokenCredential\",",
                "description": "Credential needed for the client to connect to Azure.",
                "docstring_type": "~azure.core.credentials_async.AsyncTokenCredential",
                "required": true
            },
            "endpoint": {
                "signature": "endpoint: str,",
                "description": "Supported Cognitive Services endpoints (protocol and hostname, for example: https://westus2.api.cognitive.microsoft.com).",
                "docstring_type": "str",
                "required": true
            }
        },
        "constant": {
        },
        "call": "credential, endpoint",
        "service_client_specific": {
            "sync": {
                "api_version": {
                    "signature": "api_version=None, # type: Optional[str]",
                    "description": "API version to use if no profile is provided, or if missing in profile.",
                    "docstring_type": "str",
                    "required": false
                },
                "profile": {
                    "signature": "profile=KnownProfiles.default, # type: KnownProfiles",
                    "description": "A profile definition, from KnownProfiles to dict.",
                    "docstring_type": "azure.profiles.KnownProfiles",
                    "required": false
                }
            },
            "async": {
                "api_version": {
                    "signature": "api_version: Optional[str] = None,",
                    "description": "API version to use if no profile is provided, or if missing in profile.",
                    "docstring_type": "str",
                    "required": false
                },
                "profile": {
                    "signature": "profile: KnownProfiles = KnownProfiles.default,",
                    "description": "A profile definition, from KnownProfiles to dict.",
                    "docstring_type": "azure.profiles.KnownProfiles",
                    "required": false
                }
            }
        }
    },
    "config": {
        "credential": true,
        "credential_scopes": ["https://cognitiveservices.azure.com/.default"],
        "credential_default_policy_type": "BearerTokenCredentialPolicy",
        "credential_default_policy_type_has_async_version": true,
        "credential_key_header_name": null,
        "sync_imports": "{\"regular\": {\"azurecore\": {\"azure.core.configuration\": [\"Configuration\"], \"azure.core.pipeline\": [\"policies\"]}, \"local\": {\"._version\": [\"VERSION\"]}}, \"conditional\": {\"stdlib\": {\"typing\": [\"Any\"]}}, \"typing\": {\"azurecore\": {\"azure.core.credentials\": [\"TokenCredential\"]}}}",
        "async_imports": "{\"regular\": {\"azurecore\": {\"azure.core.configuration\": [\"Configuration\"], \"azure.core.pipeline\": [\"policies\"]}, \"local\": {\".._version\": [\"VERSION\"]}}, \"conditional\": {\"stdlib\": {\"typing\": [\"Any\"]}}, \"typing\": {\"azurecore\": {\"azure.core.credentials_async\": [\"AsyncTokenCredential\"]}}}"
    },
    "operation_groups": {
    },
    "operation_mixins": {
        "sync_imports": "{\"regular\": {\"azurecore\": {\"azure.core.exceptions\": [\"ClientAuthenticationError\", \"HttpResponseError\", \"ResourceExistsError\", \"ResourceNotFoundError\", \"map_error\"], \"azure.core.pipeline\": [\"PipelineResponse\"], \"azure.core.pipeline.transport\": [\"HttpRequest\", \"HttpResponse\"], \"azure.core.polling\": [\"LROPoller\", \"NoPolling\", \"PollingMethod\"], \"azure.core.polling.base_polling\": [\"LROBasePolling\"], \"azure.core.paging\": [\"ItemPaged\"]}, \"stdlib\": {\"warnings\": [null]}}, \"conditional\": {\"stdlib\": {\"typing\": [\"Any\", \"Callable\", \"Dict\", \"Generic\", \"IO\", \"Iterable\", \"List\", \"Optional\", \"TypeVar\", \"Union\"]}}}",
        "async_imports": "{\"regular\": {\"azurecore\": {\"azure.core.exceptions\": [\"ClientAuthenticationError\", \"HttpResponseError\", \"ResourceExistsError\", \"ResourceNotFoundError\", \"map_error\"], \"azure.core.pipeline\": [\"PipelineResponse\"], \"azure.core.pipeline.transport\": [\"AsyncHttpResponse\", \"HttpRequest\"], \"azure.core.polling\": [\"AsyncLROPoller\", \"AsyncNoPolling\", \"AsyncPollingMethod\"], \"azure.core.polling.async_base_polling\": [\"AsyncLROBasePolling\"], \"azure.core.async_paging\": [\"AsyncItemPaged\", \"AsyncList\"]}, \"stdlib\": {\"warnings\": [null]}}, \"conditional\": {\"stdlib\": {\"typing\": [\"Any\", \"AsyncIterable\", \"Callable\", \"Dict\", \"Generic\", \"IO\", \"List\", \"Optional\", \"TypeVar\", \"Union\"]}}}",
        "operations": {
            "_train_custom_model_async_initial" : {
                "sync": {
                    "signature": "def _train_custom_model_async_initial(\n    self,\n    train_request,  # type: \"_models.TrainRequest\"\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"\n\n:param train_request: Training request parameters.\n:type train_request: ~azure.ai.formrecognizer.v2_1_preview_3.models.TrainRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _train_custom_model_async_initial(\n    self,\n    train_request: \"_models.TrainRequest\",\n    **kwargs\n) -\u003e None:\n",
                    "doc": "\"\"\"\n\n:param train_request: Training request parameters.\n:type train_request: ~azure.ai.formrecognizer.v2_1_preview_3.models.TrainRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "train_request"
            },
            "begin_train_custom_model_async" : {
                "sync": {
                    "signature": "def begin_train_custom_model_async(\n    self,\n    train_request,  # type: \"_models.TrainRequest\"\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Train Custom Model.\n\nCreate and train a custom model. The request must include a source parameter that is either an\nexternally accessible Azure storage blob container Uri (preferably a Shared Access Signature\nUri) or valid path to a data folder in a locally mounted drive. When local paths are specified,\nthey must follow the Linux/Unix path format and be an absolute path rooted to the input mount\nconfiguration setting value e.g., if \u0027{Mounts:Input}\u0027 configuration setting value is \u0027/input\u0027\nthen a valid source path would be \u0027/input/contosodataset\u0027. All data to be trained is expected\nto be under the source folder or sub folders under it. Models are trained using documents that\nare of the following content type - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027, \u0027image/tiff\u0027\nor \u0027image/bmp\u0027. Other type of content is ignored.\n\n:param train_request: Training request parameters.\n:type train_request: ~azure.ai.formrecognizer.v2_1_preview_3.models.TrainRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the LROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_train_custom_model_async(\n    self,\n    train_request: \"_models.TrainRequest\",\n    **kwargs\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Train Custom Model.\n\nCreate and train a custom model. The request must include a source parameter that is either an\nexternally accessible Azure storage blob container Uri (preferably a Shared Access Signature\nUri) or valid path to a data folder in a locally mounted drive. When local paths are specified,\nthey must follow the Linux/Unix path format and be an absolute path rooted to the input mount\nconfiguration setting value e.g., if \u0027{Mounts:Input}\u0027 configuration setting value is \u0027/input\u0027\nthen a valid source path would be \u0027/input/contosodataset\u0027. All data to be trained is expected\nto be under the source folder or sub folders under it. Models are trained using documents that\nare of the following content type - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027, \u0027image/tiff\u0027\nor \u0027image/bmp\u0027. Other type of content is ignored.\n\n:param train_request: Training request parameters.\n:type train_request: ~azure.ai.formrecognizer.v2_1_preview_3.models.TrainRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the AsyncLROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "call": "train_request"
            },
            "get_custom_model" : {
                "sync": {
                    "signature": "def get_custom_model(\n    self,\n    model_id,  # type: str\n    include_keys=False,  # type: Optional[bool]\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Get Custom Model.\n\nGet detailed information about a custom model.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param include_keys: Include list of extracted keys in model information.\n:type include_keys: bool\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: Model, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.Model\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_custom_model(\n    self,\n    model_id: str,\n    include_keys: Optional[bool] = False,\n    **kwargs\n) -\u003e \"_models.Model\":\n",
                    "doc": "\"\"\"Get Custom Model.\n\nGet detailed information about a custom model.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param include_keys: Include list of extracted keys in model information.\n:type include_keys: bool\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: Model, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.Model\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "model_id, include_keys"
            },
            "delete_custom_model" : {
                "sync": {
                    "signature": "def delete_custom_model(\n    self,\n    model_id,  # type: str\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Delete Custom Model.\n\nMark model for deletion. Model artifacts will be permanently removed within a predetermined\nperiod.\n\n:param model_id: Model identifier.\n:type model_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def delete_custom_model(\n    self,\n    model_id: str,\n    **kwargs\n) -\u003e None:\n",
                    "doc": "\"\"\"Delete Custom Model.\n\nMark model for deletion. Model artifacts will be permanently removed within a predetermined\nperiod.\n\n:param model_id: Model identifier.\n:type model_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "model_id"
            },
            "_analyze_with_custom_model_initial" : {
                "sync": {
                    "signature": "def _analyze_with_custom_model_initial(\n    self,\n    model_id,  # type: str\n    include_text_details=False,  # type: Optional[bool]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, \"_models.SourcePath\"]]\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"\n\n:param model_id: Model identifier.\n:type model_id: str\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _analyze_with_custom_model_initial(\n    self,\n    model_id: str,\n    include_text_details: Optional[bool] = False,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, \"_models.SourcePath\"]] = None,\n    **kwargs\n) -\u003e None:\n",
                    "doc": "\"\"\"\n\n:param model_id: Model identifier.\n:type model_id: str\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "model_id, include_text_details, pages, file_stream"
            },
            "begin_analyze_with_custom_model" : {
                "sync": {
                    "signature": "def begin_analyze_with_custom_model(\n    self,\n    model_id,  # type: str\n    include_text_details=False,  # type: Optional[bool]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, \"_models.SourcePath\"]]\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Analyze Form.\n\nExtract key-value pairs, tables, and semantic values from a given document. The input document\nmust be of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri or local path) of the document to be analyzed.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the LROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_analyze_with_custom_model(\n    self,\n    model_id: str,\n    include_text_details: Optional[bool] = False,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, \"_models.SourcePath\"]] = None,\n    **kwargs\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Analyze Form.\n\nExtract key-value pairs, tables, and semantic values from a given document. The input document\nmust be of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri or local path) of the document to be analyzed.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the AsyncLROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "call": "model_id, include_text_details, pages, file_stream"
            },
            "get_analyze_form_result" : {
                "sync": {
                    "signature": "def get_analyze_form_result(\n    self,\n    model_id,  # type: str\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Get Analyze Form Result.\n\nObtain current status and the result of the analyze form operation.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_analyze_form_result(\n    self,\n    model_id: str,\n    result_id: str,\n    **kwargs\n) -\u003e \"_models.AnalyzeOperationResult\":\n",
                    "doc": "\"\"\"Get Analyze Form Result.\n\nObtain current status and the result of the analyze form operation.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "model_id, result_id"
            },
            "_copy_custom_model_initial" : {
                "sync": {
                    "signature": "def _copy_custom_model_initial(\n    self,\n    model_id,  # type: str\n    copy_request,  # type: \"_models.CopyRequest\"\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"\n\n:param model_id: Model identifier.\n:type model_id: str\n:param copy_request: Copy request parameters.\n:type copy_request: ~azure.ai.formrecognizer.v2_1_preview_3.models.CopyRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _copy_custom_model_initial(\n    self,\n    model_id: str,\n    copy_request: \"_models.CopyRequest\",\n    **kwargs\n) -\u003e None:\n",
                    "doc": "\"\"\"\n\n:param model_id: Model identifier.\n:type model_id: str\n:param copy_request: Copy request parameters.\n:type copy_request: ~azure.ai.formrecognizer.v2_1_preview_3.models.CopyRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "model_id, copy_request"
            },
            "begin_copy_custom_model" : {
                "sync": {
                    "signature": "def begin_copy_custom_model(\n    self,\n    model_id,  # type: str\n    copy_request,  # type: \"_models.CopyRequest\"\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Copy Custom Model.\n\nCopy custom model stored in this resource (the source) to user specified target Form Recognizer\nresource.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param copy_request: Copy request parameters.\n:type copy_request: ~azure.ai.formrecognizer.v2_1_preview_3.models.CopyRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the LROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_copy_custom_model(\n    self,\n    model_id: str,\n    copy_request: \"_models.CopyRequest\",\n    **kwargs\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Copy Custom Model.\n\nCopy custom model stored in this resource (the source) to user specified target Form Recognizer\nresource.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param copy_request: Copy request parameters.\n:type copy_request: ~azure.ai.formrecognizer.v2_1_preview_3.models.CopyRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the AsyncLROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "call": "model_id, copy_request"
            },
            "get_custom_model_copy_result" : {
                "sync": {
                    "signature": "def get_custom_model_copy_result(\n    self,\n    model_id,  # type: str\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Get Custom Model Copy Result.\n\nObtain current status and the result of a custom model copy operation.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param result_id: Copy operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: CopyOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.CopyOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_custom_model_copy_result(\n    self,\n    model_id: str,\n    result_id: str,\n    **kwargs\n) -\u003e \"_models.CopyOperationResult\":\n",
                    "doc": "\"\"\"Get Custom Model Copy Result.\n\nObtain current status and the result of a custom model copy operation.\n\n:param model_id: Model identifier.\n:type model_id: str\n:param result_id: Copy operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: CopyOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.CopyOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "model_id, result_id"
            },
            "generate_model_copy_authorization" : {
                "sync": {
                    "signature": "def generate_model_copy_authorization(\n    self,\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Generate Copy Authorization.\n\nGenerate authorization to copy a model into the target Form Recognizer resource.\n\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: CopyAuthorizationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.CopyAuthorizationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def generate_model_copy_authorization(\n    self,\n    **kwargs\n) -\u003e \"_models.CopyAuthorizationResult\":\n",
                    "doc": "\"\"\"Generate Copy Authorization.\n\nGenerate authorization to copy a model into the target Form Recognizer resource.\n\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: CopyAuthorizationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.CopyAuthorizationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": ""
            },
            "_compose_custom_models_async_initial" : {
                "sync": {
                    "signature": "def _compose_custom_models_async_initial(\n    self,\n    compose_request,  # type: \"_models.ComposeRequest\"\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"\n\n:param compose_request: Compose models.\n:type compose_request: ~azure.ai.formrecognizer.v2_1_preview_3.models.ComposeRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _compose_custom_models_async_initial(\n    self,\n    compose_request: \"_models.ComposeRequest\",\n    **kwargs\n) -\u003e None:\n",
                    "doc": "\"\"\"\n\n:param compose_request: Compose models.\n:type compose_request: ~azure.ai.formrecognizer.v2_1_preview_3.models.ComposeRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "compose_request"
            },
            "begin_compose_custom_models_async" : {
                "sync": {
                    "signature": "def begin_compose_custom_models_async(\n    self,\n    compose_request,  # type: \"_models.ComposeRequest\"\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Compose trained with labels models into one composed model.\n\nCompose request would include list of models ids.\nIt would validate what all models either trained with labels model or composed model.\nIt would validate limit of models put together.\n\n:param compose_request: Compose models.\n:type compose_request: ~azure.ai.formrecognizer.v2_1_preview_3.models.ComposeRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the LROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_compose_custom_models_async(\n    self,\n    compose_request: \"_models.ComposeRequest\",\n    **kwargs\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Compose trained with labels models into one composed model.\n\nCompose request would include list of models ids.\nIt would validate what all models either trained with labels model or composed model.\nIt would validate limit of models put together.\n\n:param compose_request: Compose models.\n:type compose_request: ~azure.ai.formrecognizer.v2_1_preview_3.models.ComposeRequest\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the AsyncLROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "call": "compose_request"
            },
            "_analyze_business_card_async_initial" : {
                "sync": {
                    "signature": "def _analyze_business_card_async_initial(\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    locale=None,  # type: Optional[Union[str, \"_models.Locale\"]]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, \"_models.SourcePath\"]]\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default).\n:type locale: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _analyze_business_card_async_initial(\n    self,\n    include_text_details: Optional[bool] = False,\n    locale: Optional[Union[str, \"_models.Locale\"]] = None,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, \"_models.SourcePath\"]] = None,\n    **kwargs\n) -\u003e None:\n",
                    "doc": "\"\"\"\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default).\n:type locale: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "include_text_details, locale, pages, file_stream"
            },
            "begin_analyze_business_card_async" : {
                "sync": {
                    "signature": "def begin_analyze_business_card_async(\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    locale=None,  # type: Optional[Union[str, \"_models.Locale\"]]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, \"_models.SourcePath\"]]\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Analyze Business Card.\n\nExtract field text and semantic values from a given business card document. The input document\nmust be of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri) of the document to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default).\n:type locale: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the LROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_analyze_business_card_async(\n    self,\n    include_text_details: Optional[bool] = False,\n    locale: Optional[Union[str, \"_models.Locale\"]] = None,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, \"_models.SourcePath\"]] = None,\n    **kwargs\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Analyze Business Card.\n\nExtract field text and semantic values from a given business card document. The input document\nmust be of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri) of the document to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default).\n:type locale: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the AsyncLROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "call": "include_text_details, locale, pages, file_stream"
            },
            "get_analyze_business_card_result" : {
                "sync": {
                    "signature": "def get_analyze_business_card_result(\n    self,\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Get Analyze Business Card Result.\n\nTrack the progress and obtain the result of the analyze business card operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_analyze_business_card_result(\n    self,\n    result_id: str,\n    **kwargs\n) -\u003e \"_models.AnalyzeOperationResult\":\n",
                    "doc": "\"\"\"Get Analyze Business Card Result.\n\nTrack the progress and obtain the result of the analyze business card operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "result_id"
            },
            "_analyze_invoice_async_initial" : {
                "sync": {
                    "signature": "def _analyze_invoice_async_initial(\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    locale=None,  # type: Optional[Union[str, \"_models.Locale\"]]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, \"_models.SourcePath\"]]\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default).\n:type locale: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _analyze_invoice_async_initial(\n    self,\n    include_text_details: Optional[bool] = False,\n    locale: Optional[Union[str, \"_models.Locale\"]] = None,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, \"_models.SourcePath\"]] = None,\n    **kwargs\n) -\u003e None:\n",
                    "doc": "\"\"\"\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default).\n:type locale: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "include_text_details, locale, pages, file_stream"
            },
            "begin_analyze_invoice_async" : {
                "sync": {
                    "signature": "def begin_analyze_invoice_async(\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    locale=None,  # type: Optional[Union[str, \"_models.Locale\"]]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, \"_models.SourcePath\"]]\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Analyze Invoice Document.\n\nExtract field text and semantic values from a given invoice document. The input document must\nbe of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri) of the document to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default).\n:type locale: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the LROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_analyze_invoice_async(\n    self,\n    include_text_details: Optional[bool] = False,\n    locale: Optional[Union[str, \"_models.Locale\"]] = None,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, \"_models.SourcePath\"]] = None,\n    **kwargs\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Analyze Invoice Document.\n\nExtract field text and semantic values from a given invoice document. The input document must\nbe of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri) of the document to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default).\n:type locale: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the AsyncLROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "call": "include_text_details, locale, pages, file_stream"
            },
            "get_analyze_invoice_result" : {
                "sync": {
                    "signature": "def get_analyze_invoice_result(\n    self,\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Get Analyze Invoice Result.\n\nTrack the progress and obtain the result of the analyze invoice operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_analyze_invoice_result(\n    self,\n    result_id: str,\n    **kwargs\n) -\u003e \"_models.AnalyzeOperationResult\":\n",
                    "doc": "\"\"\"Get Analyze Invoice Result.\n\nTrack the progress and obtain the result of the analyze invoice operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "result_id"
            },
            "_analyze_id_document_async_initial" : {
                "sync": {
                    "signature": "def _analyze_id_document_async_initial(\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, \"_models.SourcePath\"]]\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _analyze_id_document_async_initial(\n    self,\n    include_text_details: Optional[bool] = False,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, \"_models.SourcePath\"]] = None,\n    **kwargs\n) -\u003e None:\n",
                    "doc": "\"\"\"\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "include_text_details, pages, file_stream"
            },
            "begin_analyze_id_document_async" : {
                "sync": {
                    "signature": "def begin_analyze_id_document_async(\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, \"_models.SourcePath\"]]\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Analyze ID Document.\n\nExtract field text and semantic values from a given ID document. The input document must be of\none of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027, \u0027image/tiff\u0027\nor \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location (Uri) of the\ndocument to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the LROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_analyze_id_document_async(\n    self,\n    include_text_details: Optional[bool] = False,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, \"_models.SourcePath\"]] = None,\n    **kwargs\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Analyze ID Document.\n\nExtract field text and semantic values from a given ID document. The input document must be of\none of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027, \u0027image/tiff\u0027\nor \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location (Uri) of the\ndocument to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the AsyncLROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "call": "include_text_details, pages, file_stream"
            },
            "get_analyze_id_document_result" : {
                "sync": {
                    "signature": "def get_analyze_id_document_result(\n    self,\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Get Analyze ID Document Result.\n\nTrack the progress and obtain the result of the analyze ID operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_analyze_id_document_result(\n    self,\n    result_id: str,\n    **kwargs\n) -\u003e \"_models.AnalyzeOperationResult\":\n",
                    "doc": "\"\"\"Get Analyze ID Document Result.\n\nTrack the progress and obtain the result of the analyze ID operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "result_id"
            },
            "_analyze_receipt_async_initial" : {
                "sync": {
                    "signature": "def _analyze_receipt_async_initial(\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    locale=None,  # type: Optional[Union[str, \"_models.Locale\"]]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, \"_models.SourcePath\"]]\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default).\n:type locale: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _analyze_receipt_async_initial(\n    self,\n    include_text_details: Optional[bool] = False,\n    locale: Optional[Union[str, \"_models.Locale\"]] = None,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, \"_models.SourcePath\"]] = None,\n    **kwargs\n) -\u003e None:\n",
                    "doc": "\"\"\"\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default).\n:type locale: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "include_text_details, locale, pages, file_stream"
            },
            "begin_analyze_receipt_async" : {
                "sync": {
                    "signature": "def begin_analyze_receipt_async(\n    self,\n    include_text_details=False,  # type: Optional[bool]\n    locale=None,  # type: Optional[Union[str, \"_models.Locale\"]]\n    pages=None,  # type: Optional[List[str]]\n    file_stream=None,  # type: Optional[Union[IO, \"_models.SourcePath\"]]\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Analyze Receipt.\n\nExtract field text and semantic values from a given receipt document. The input document must\nbe of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri) of the document to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default).\n:type locale: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the LROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_analyze_receipt_async(\n    self,\n    include_text_details: Optional[bool] = False,\n    locale: Optional[Union[str, \"_models.Locale\"]] = None,\n    pages: Optional[List[str]] = None,\n    file_stream: Optional[Union[IO, \"_models.SourcePath\"]] = None,\n    **kwargs\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Analyze Receipt.\n\nExtract field text and semantic values from a given receipt document. The input document must\nbe of one of the supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027,\n\u0027image/tiff\u0027 or \u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location\n(Uri) of the document to be analyzed.\n\n:param include_text_details: Include text lines and element references in the result.\n:type include_text_details: bool\n:param locale: Locale of the input document. Supported locales include: en-AU, en-CA, en-GB,\n en-IN, en-US(default).\n:type locale: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Locale\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the AsyncLROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "call": "include_text_details, locale, pages, file_stream"
            },
            "get_analyze_receipt_result" : {
                "sync": {
                    "signature": "def get_analyze_receipt_result(\n    self,\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Get Analyze Receipt Result.\n\nTrack the progress and obtain the result of the analyze receipt operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_analyze_receipt_result(\n    self,\n    result_id: str,\n    **kwargs\n) -\u003e \"_models.AnalyzeOperationResult\":\n",
                    "doc": "\"\"\"Get Analyze Receipt Result.\n\nTrack the progress and obtain the result of the analyze receipt operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "result_id"
            },
            "_analyze_layout_async_initial" : {
                "sync": {
                    "signature": "def _analyze_layout_async_initial(\n    self,\n    pages=None,  # type: Optional[List[str]]\n    language=None,  # type: Optional[Union[str, \"_models.Language\"]]\n    reading_order=\"basic\",  # type: Optional[Union[str, \"_models.ReadingOrder\"]]\n    file_stream=None,  # type: Optional[Union[IO, \"_models.SourcePath\"]]\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"\n\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param language: Currently, only Afrikaans (\u2018af\u2019), Albanian (\u2018sq\u2019), Asturian (\u2018ast\u2019), Basque\n (\u2018eu\u2019), Bislama (\u2018bi\u2019), Breton (\u2018br\u2019), Catalan (\u2018ca\u2019), Cebuano (\u2018ceb\u2019), Chamorro (\u2018ch\u2019),\n Cornish (\u2018kw\u2019), Corsican (\u2018co\u2019), Crimean Tatar - Latin script(\u2018crh\u2019), Czech (\u2018cs\u2019), Danish\n (\u2018da\u2019), Dutch (\u2018nl\u2019), English (\u0027en\u0027), Estonian (\u2018et\u2019), Fijian (\u2018fj\u2019), Filipino (\u2018fil\u2019), Finnish\n (\u2018fi\u2019), French (\u2018fr\u2019), Friulian (\u2018fur\u2019), Galician (\u2018gl\u2019), German (\u2018de\u2019), Gilbertese (\u2018gil\u2019),\n Greenlandic (\u2018kl\u2019), Haitian Creole (\u2018ht\u2019), Hani (\u2018hni\u2019), Hmong Daw (\u2018mww\u2019), Hungarian (\u2018hu\u2019),\n Indonesian (\u2018id\u2019), Interlingua (\u2018ia\u2019), Inuktitut (\u2018iu\u2019), Irish (\u2018ga\u2019), Italian (\u2018it\u2019), Japanese\n (\u2018ja\u2019), Javanese (\u2018jv\u2019), Kabuverdianu (\u2018kea\u2019), Kachin (\u2018kac\u2019), Kara-Kalpak (\u2018kaa\u2019), Kashubian\n (\u2018csb\u2019), Khasi (\u2018kha\u2019), Korean (\u2018ko\u2019), Kurdish - Latin script (\u2018ku\u2019), K\u2019iche\u2019 (\u2018quc\u2019),\n Luxembourgish (\u2018lb\u2019), Malay (\u2018ms\u2019), Manx (\u2018gv\u2019), Neapolitan (\u2018nap\u2019), Norwegian (\u2018no\u2019), Occitan\n (\u2018oc\u2019), Polish (\u2018pl\u2019), Portuguese (\u2018pt\u2019), Romansh (\u2018rm\u2019), Scots (\u2018sco\u2019), Scottish Gaelic\n (\u2018gd\u2019), simplified Chinese (\u2018zh-Hans\u2019), Slovenian (\u2018sl\u2019), Spanish (\u2018es\u2019), Swahili (\u2018sw\u2019),\n Swedish (\u2018sv\u2019), Tatar - Latin script (\u2018tt\u2019), Tetum (\u2018tet\u2019), traditional Chinese (\u2018zh-Hant\u2019),\n Turkish (\u2018tr\u2019), Upper Sorbian (\u2018hsb\u2019), Uzbek (\u2018uz\u2019), Volap\u00fck (\u2018vo\u2019), Walser (\u2018wae\u2019), Western\n Frisian (\u2018fy\u2019), Yucatec Maya (\u2018yua\u2019), Zhuang (\u2018za\u2019) and Zulu (\u2018zu\u2019) are supported (print \u2013\n seventy-three languages and handwritten \u2013 English only). Layout supports auto language\n identification and multi language documents, so only provide a language code if you would like\n to force the documented to be processed as that specific language.\n:type language: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Language\n:param reading_order: Reading order algorithm to sort the text lines returned. Supported\n reading orders include: basic(default), natural.\n:type reading_order: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.ReadingOrder\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def _analyze_layout_async_initial(\n    self,\n    pages: Optional[List[str]] = None,\n    language: Optional[Union[str, \"_models.Language\"]] = None,\n    reading_order: Optional[Union[str, \"_models.ReadingOrder\"]] = \"basic\",\n    file_stream: Optional[Union[IO, \"_models.SourcePath\"]] = None,\n    **kwargs\n) -\u003e None:\n",
                    "doc": "\"\"\"\n\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param language: Currently, only Afrikaans (\u2018af\u2019), Albanian (\u2018sq\u2019), Asturian (\u2018ast\u2019), Basque\n (\u2018eu\u2019), Bislama (\u2018bi\u2019), Breton (\u2018br\u2019), Catalan (\u2018ca\u2019), Cebuano (\u2018ceb\u2019), Chamorro (\u2018ch\u2019),\n Cornish (\u2018kw\u2019), Corsican (\u2018co\u2019), Crimean Tatar - Latin script(\u2018crh\u2019), Czech (\u2018cs\u2019), Danish\n (\u2018da\u2019), Dutch (\u2018nl\u2019), English (\u0027en\u0027), Estonian (\u2018et\u2019), Fijian (\u2018fj\u2019), Filipino (\u2018fil\u2019), Finnish\n (\u2018fi\u2019), French (\u2018fr\u2019), Friulian (\u2018fur\u2019), Galician (\u2018gl\u2019), German (\u2018de\u2019), Gilbertese (\u2018gil\u2019),\n Greenlandic (\u2018kl\u2019), Haitian Creole (\u2018ht\u2019), Hani (\u2018hni\u2019), Hmong Daw (\u2018mww\u2019), Hungarian (\u2018hu\u2019),\n Indonesian (\u2018id\u2019), Interlingua (\u2018ia\u2019), Inuktitut (\u2018iu\u2019), Irish (\u2018ga\u2019), Italian (\u2018it\u2019), Japanese\n (\u2018ja\u2019), Javanese (\u2018jv\u2019), Kabuverdianu (\u2018kea\u2019), Kachin (\u2018kac\u2019), Kara-Kalpak (\u2018kaa\u2019), Kashubian\n (\u2018csb\u2019), Khasi (\u2018kha\u2019), Korean (\u2018ko\u2019), Kurdish - Latin script (\u2018ku\u2019), K\u2019iche\u2019 (\u2018quc\u2019),\n Luxembourgish (\u2018lb\u2019), Malay (\u2018ms\u2019), Manx (\u2018gv\u2019), Neapolitan (\u2018nap\u2019), Norwegian (\u2018no\u2019), Occitan\n (\u2018oc\u2019), Polish (\u2018pl\u2019), Portuguese (\u2018pt\u2019), Romansh (\u2018rm\u2019), Scots (\u2018sco\u2019), Scottish Gaelic\n (\u2018gd\u2019), simplified Chinese (\u2018zh-Hans\u2019), Slovenian (\u2018sl\u2019), Spanish (\u2018es\u2019), Swahili (\u2018sw\u2019),\n Swedish (\u2018sv\u2019), Tatar - Latin script (\u2018tt\u2019), Tetum (\u2018tet\u2019), traditional Chinese (\u2018zh-Hant\u2019),\n Turkish (\u2018tr\u2019), Upper Sorbian (\u2018hsb\u2019), Uzbek (\u2018uz\u2019), Volap\u00fck (\u2018vo\u2019), Walser (\u2018wae\u2019), Western\n Frisian (\u2018fy\u2019), Yucatec Maya (\u2018yua\u2019), Zhuang (\u2018za\u2019) and Zulu (\u2018zu\u2019) are supported (print \u2013\n seventy-three languages and handwritten \u2013 English only). Layout supports auto language\n identification and multi language documents, so only provide a language code if you would like\n to force the documented to be processed as that specific language.\n:type language: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Language\n:param reading_order: Reading order algorithm to sort the text lines returned. Supported\n reading orders include: basic(default), natural.\n:type reading_order: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.ReadingOrder\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: None, or the result of cls(response)\n:rtype: None\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "pages, language, reading_order, file_stream"
            },
            "begin_analyze_layout_async" : {
                "sync": {
                    "signature": "def begin_analyze_layout_async(\n    self,\n    pages=None,  # type: Optional[List[str]]\n    language=None,  # type: Optional[Union[str, \"_models.Language\"]]\n    reading_order=\"basic\",  # type: Optional[Union[str, \"_models.ReadingOrder\"]]\n    file_stream=None,  # type: Optional[Union[IO, \"_models.SourcePath\"]]\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Analyze Layout.\n\nExtract text and layout information from a given document. The input document must be of one of\nthe supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027, \u0027image/tiff\u0027 or\n\u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location (Uri or local\npath) of the document to be analyzed.\n\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param language: Currently, only Afrikaans (\u2018af\u2019), Albanian (\u2018sq\u2019), Asturian (\u2018ast\u2019), Basque\n (\u2018eu\u2019), Bislama (\u2018bi\u2019), Breton (\u2018br\u2019), Catalan (\u2018ca\u2019), Cebuano (\u2018ceb\u2019), Chamorro (\u2018ch\u2019),\n Cornish (\u2018kw\u2019), Corsican (\u2018co\u2019), Crimean Tatar - Latin script(\u2018crh\u2019), Czech (\u2018cs\u2019), Danish\n (\u2018da\u2019), Dutch (\u2018nl\u2019), English (\u0027en\u0027), Estonian (\u2018et\u2019), Fijian (\u2018fj\u2019), Filipino (\u2018fil\u2019), Finnish\n (\u2018fi\u2019), French (\u2018fr\u2019), Friulian (\u2018fur\u2019), Galician (\u2018gl\u2019), German (\u2018de\u2019), Gilbertese (\u2018gil\u2019),\n Greenlandic (\u2018kl\u2019), Haitian Creole (\u2018ht\u2019), Hani (\u2018hni\u2019), Hmong Daw (\u2018mww\u2019), Hungarian (\u2018hu\u2019),\n Indonesian (\u2018id\u2019), Interlingua (\u2018ia\u2019), Inuktitut (\u2018iu\u2019), Irish (\u2018ga\u2019), Italian (\u2018it\u2019), Japanese\n (\u2018ja\u2019), Javanese (\u2018jv\u2019), Kabuverdianu (\u2018kea\u2019), Kachin (\u2018kac\u2019), Kara-Kalpak (\u2018kaa\u2019), Kashubian\n (\u2018csb\u2019), Khasi (\u2018kha\u2019), Korean (\u2018ko\u2019), Kurdish - Latin script (\u2018ku\u2019), K\u2019iche\u2019 (\u2018quc\u2019),\n Luxembourgish (\u2018lb\u2019), Malay (\u2018ms\u2019), Manx (\u2018gv\u2019), Neapolitan (\u2018nap\u2019), Norwegian (\u2018no\u2019), Occitan\n (\u2018oc\u2019), Polish (\u2018pl\u2019), Portuguese (\u2018pt\u2019), Romansh (\u2018rm\u2019), Scots (\u2018sco\u2019), Scottish Gaelic\n (\u2018gd\u2019), simplified Chinese (\u2018zh-Hans\u2019), Slovenian (\u2018sl\u2019), Spanish (\u2018es\u2019), Swahili (\u2018sw\u2019),\n Swedish (\u2018sv\u2019), Tatar - Latin script (\u2018tt\u2019), Tetum (\u2018tet\u2019), traditional Chinese (\u2018zh-Hant\u2019),\n Turkish (\u2018tr\u2019), Upper Sorbian (\u2018hsb\u2019), Uzbek (\u2018uz\u2019), Volap\u00fck (\u2018vo\u2019), Walser (\u2018wae\u2019), Western\n Frisian (\u2018fy\u2019), Yucatec Maya (\u2018yua\u2019), Zhuang (\u2018za\u2019) and Zulu (\u2018zu\u2019) are supported (print \u2013\n seventy-three languages and handwritten \u2013 English only). Layout supports auto language\n identification and multi language documents, so only provide a language code if you would like\n to force the documented to be processed as that specific language.\n:type language: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Language\n:param reading_order: Reading order algorithm to sort the text lines returned. Supported\n reading orders include: basic(default), natural.\n:type reading_order: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.ReadingOrder\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the LROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.PollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of LROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.LROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def begin_analyze_layout_async(\n    self,\n    pages: Optional[List[str]] = None,\n    language: Optional[Union[str, \"_models.Language\"]] = None,\n    reading_order: Optional[Union[str, \"_models.ReadingOrder\"]] = \"basic\",\n    file_stream: Optional[Union[IO, \"_models.SourcePath\"]] = None,\n    **kwargs\n) -\u003e AsyncLROPoller[None]:\n",
                    "doc": "\"\"\"Analyze Layout.\n\nExtract text and layout information from a given document. The input document must be of one of\nthe supported content types - \u0027application/pdf\u0027, \u0027image/jpeg\u0027, \u0027image/png\u0027, \u0027image/tiff\u0027 or\n\u0027image/bmp\u0027. Alternatively, use \u0027application/json\u0027 type to specify the location (Uri or local\npath) of the document to be analyzed.\n\n:param pages: Custom page numbers for multi-page documents(PDF/TIFF), input the number of the\n pages you want to get OCR result. For a range of pages, use a hyphen. Separate each page or\n range with a comma.\n:type pages: list[str]\n:param language: Currently, only Afrikaans (\u2018af\u2019), Albanian (\u2018sq\u2019), Asturian (\u2018ast\u2019), Basque\n (\u2018eu\u2019), Bislama (\u2018bi\u2019), Breton (\u2018br\u2019), Catalan (\u2018ca\u2019), Cebuano (\u2018ceb\u2019), Chamorro (\u2018ch\u2019),\n Cornish (\u2018kw\u2019), Corsican (\u2018co\u2019), Crimean Tatar - Latin script(\u2018crh\u2019), Czech (\u2018cs\u2019), Danish\n (\u2018da\u2019), Dutch (\u2018nl\u2019), English (\u0027en\u0027), Estonian (\u2018et\u2019), Fijian (\u2018fj\u2019), Filipino (\u2018fil\u2019), Finnish\n (\u2018fi\u2019), French (\u2018fr\u2019), Friulian (\u2018fur\u2019), Galician (\u2018gl\u2019), German (\u2018de\u2019), Gilbertese (\u2018gil\u2019),\n Greenlandic (\u2018kl\u2019), Haitian Creole (\u2018ht\u2019), Hani (\u2018hni\u2019), Hmong Daw (\u2018mww\u2019), Hungarian (\u2018hu\u2019),\n Indonesian (\u2018id\u2019), Interlingua (\u2018ia\u2019), Inuktitut (\u2018iu\u2019), Irish (\u2018ga\u2019), Italian (\u2018it\u2019), Japanese\n (\u2018ja\u2019), Javanese (\u2018jv\u2019), Kabuverdianu (\u2018kea\u2019), Kachin (\u2018kac\u2019), Kara-Kalpak (\u2018kaa\u2019), Kashubian\n (\u2018csb\u2019), Khasi (\u2018kha\u2019), Korean (\u2018ko\u2019), Kurdish - Latin script (\u2018ku\u2019), K\u2019iche\u2019 (\u2018quc\u2019),\n Luxembourgish (\u2018lb\u2019), Malay (\u2018ms\u2019), Manx (\u2018gv\u2019), Neapolitan (\u2018nap\u2019), Norwegian (\u2018no\u2019), Occitan\n (\u2018oc\u2019), Polish (\u2018pl\u2019), Portuguese (\u2018pt\u2019), Romansh (\u2018rm\u2019), Scots (\u2018sco\u2019), Scottish Gaelic\n (\u2018gd\u2019), simplified Chinese (\u2018zh-Hans\u2019), Slovenian (\u2018sl\u2019), Spanish (\u2018es\u2019), Swahili (\u2018sw\u2019),\n Swedish (\u2018sv\u2019), Tatar - Latin script (\u2018tt\u2019), Tetum (\u2018tet\u2019), traditional Chinese (\u2018zh-Hant\u2019),\n Turkish (\u2018tr\u2019), Upper Sorbian (\u2018hsb\u2019), Uzbek (\u2018uz\u2019), Volap\u00fck (\u2018vo\u2019), Walser (\u2018wae\u2019), Western\n Frisian (\u2018fy\u2019), Yucatec Maya (\u2018yua\u2019), Zhuang (\u2018za\u2019) and Zulu (\u2018zu\u2019) are supported (print \u2013\n seventy-three languages and handwritten \u2013 English only). Layout supports auto language\n identification and multi language documents, so only provide a language code if you would like\n to force the documented to be processed as that specific language.\n:type language: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.Language\n:param reading_order: Reading order algorithm to sort the text lines returned. Supported\n reading orders include: basic(default), natural.\n:type reading_order: str or ~azure.ai.formrecognizer.v2_1_preview_3.models.ReadingOrder\n:param file_stream: .json, .pdf, .jpg, .png, .tiff or .bmp type file stream.\n:type file_stream: IO or ~azure.ai.formrecognizer.v2_1_preview_3.models.SourcePath\n:keyword str content_type: Media type of the body sent to the API. Default value is \"application/json\".\n Allowed values are: \"application/pdf\", \"image/bmp\", \"image/jpeg\", \"image/png\", \"image/tiff\", \"application/json\".\n:keyword callable cls: A custom type or function that will be passed the direct response\n:keyword str continuation_token: A continuation token to restart a poller from a saved state.\n:keyword polling: Pass in True if you\u0027d like the AsyncLROBasePolling polling method,\n False for no polling, or your own initialized polling object for a personal polling strategy.\n:paramtype polling: bool or ~azure.core.polling.AsyncPollingMethod\n:keyword int polling_interval: Default waiting time between two polls for LRO operations if no Retry-After header is present.\n:return: An instance of AsyncLROPoller that returns either None or the result of cls(response)\n:rtype: ~azure.core.polling.AsyncLROPoller[None]\n:raises ~azure.core.exceptions.HttpResponseError:\n\"\"\""
                },
                "call": "pages, language, reading_order, file_stream"
            },
            "get_analyze_layout_result" : {
                "sync": {
                    "signature": "def get_analyze_layout_result(\n    self,\n    result_id,  # type: str\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Get Analyze Layout Result.\n\nTrack the progress and obtain the result of the analyze layout operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_analyze_layout_result(\n    self,\n    result_id: str,\n    **kwargs\n) -\u003e \"_models.AnalyzeOperationResult\":\n",
                    "doc": "\"\"\"Get Analyze Layout Result.\n\nTrack the progress and obtain the result of the analyze layout operation.\n\n:param result_id: Analyze operation result identifier.\n:type result_id: str\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: AnalyzeOperationResult, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.AnalyzeOperationResult\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": "result_id"
            },
            "list_custom_models" : {
                "sync": {
                    "signature": "def list_custom_models(\n    self,\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"List Custom Models.\n\nGet information about all custom models.\n\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: An iterator like instance of either Models or the result of cls(response)\n:rtype: ~azure.core.paging.ItemPaged[~azure.ai.formrecognizer.v2_1_preview_3.models.Models]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": false,
                    "signature": "def list_custom_models(\n    self,\n    **kwargs\n) -\u003e AsyncItemPaged[\"_models.Models\"]:\n",
                    "doc": "\"\"\"List Custom Models.\n\nGet information about all custom models.\n\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: An iterator like instance of either Models or the result of cls(response)\n:rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.ai.formrecognizer.v2_1_preview_3.models.Models]\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": ""
            },
            "get_custom_models" : {
                "sync": {
                    "signature": "def get_custom_models(\n    self,\n    **kwargs  # type: Any\n):\n",
                    "doc": "\"\"\"Get Custom Models.\n\nGet information about all custom models.\n\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: Models, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.Models\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "async": {
                    "coroutine": true,
                    "signature": "async def get_custom_models(\n    self,\n    **kwargs\n) -\u003e \"_models.Models\":\n",
                    "doc": "\"\"\"Get Custom Models.\n\nGet information about all custom models.\n\n:keyword callable cls: A custom type or function that will be passed the direct response\n:return: Models, or the result of cls(response)\n:rtype: ~azure.ai.formrecognizer.v2_1_preview_3.models.Models\n:raises: ~azure.core.exceptions.HttpResponseError\n\"\"\""
                },
                "call": ""
            }
        }
    }
}