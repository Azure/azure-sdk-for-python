# pylint: disable=line-too-long,useless-suppression,too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
# pylint: disable=useless-super-delegation

from typing import Literal, Union, Dict, Optional, List, Any
from typing_extensions import NotRequired, TypedDict, TypeAlias, ReadOnly
from ._enums import  ServiceTier, ToolChoiceOptions, ResponseTextFormatConfigurationType, ToolType, ResponseErrorCode, ResponseStreamEventType
import datetime


class AgentId(TypedDict):
    type: str  # TODO: should this be a Literal?
    """Required. Default value is \"agent_id\"."""
    name: str
    """The name of the agent. Required."""
    version: str
    """The version identifier of the agent. Required.""" 

class AgentReference(TypedDict):
    type: str  # TODO: should this be a Literal?
    """Required. Default value is \"agent_reference\"."""
    name: str
    """The name of the agent. Required."""
    version: NotRequired[str]
    """The version identifier of the agent."""    

class CreatedBy(TypedDict):
    agent: NotRequired[AgentId]
    """The agent that created the item."""
    response_id: NotRequired[str]
    """The response on which the item is created."""

class ItemResource(TypedDict):
    type: ReadOnly[Literal[
        "message", "file_search_call", "function_call", "function_call_output", 
        "computer_call", "computer_call_output", "web_search_call", "reasoning", 
        "item_reference", "image_generation_call", "code_interpreter_call",
        "local_shell_call", "local_shell_call_output", "mcp_list_tools", 
        "mcp_approval_request", "mcp_approval_response", "mcp_call", 
        "structured_outputs", "workflow_action", "memory_search_call", 
        "oauth_consent_request"
    ]]
    id: str
    created_by: NotRequired[CreatedBy]

class FunctionToolCallItemResource(ItemResource):
    """Function tool call item resource with discriminator 'function_call'."""
    type: ReadOnly[Literal['function_call']]
    """Required. Discriminator value is \"function_call\"."""
    status: Union[str, Literal["in_progress"], Literal["completed"], Literal["incomplete"]]
    """The status of the function call."""
    call_id: str
    """The call ID of the function call."""
    name: str
    """The name of the function."""
    arguments: str
    """The arguments passed to the function."""

class FunctionToolCallOutputItemResource(ItemResource):
    """Function tool call output item resource with discriminator 'function_call_output'."""
    type: ReadOnly[Literal["function_call_output"]]
    """Required. Discriminator value is \"function_call_output\"."""
    status: Union[str, Literal["in_progress"], Literal["completed"], Literal["incomplete"]]
    """The status of the function call."""
    call_id: str
    """The call ID of the function call."""
    output: str
    """The output returned from the function call."""

class ItemContent(TypedDict):
    type: ReadOnly[Literal[
        "input_text", "input_audio", "input_image", "input_file", 
        "output_text", "output_audio", "refusal"
    ]]

class Annotation(TypedDict):
    type: Union[str, Literal["file_citation", "url_citation", "file_path", "container_file_citation"]]

class TopLogProb(TypedDict):
    token: str
    logprob: float
    bytes: List[int]

class LogProb(TypedDict):
    token: str
    logprob: float
    bytes: List[int]
    top_logprobs: List[TopLogProb]

class ItemContentOutputText(ItemContent):

    type: ReadOnly[Literal["output_text"]]
    """The type of the output text. Always ``output_text``. Required."""
    text: str
    """The text output from the model. Required."""
    annotations: List[Annotation]
    """The annotations of the text output. Required."""
    logprobs: NotRequired[List[LogProb]]
    """Log probabilities for the output text. Optional."""

class ItemParam(TypedDict):
    type: Union[str, Literal[
        "message", "file_search_call", "function_call", "function_call_output", 
        "computer_call", "computer_call_output", "web_search_call", "reasoning", 
        "item_reference", "image_generation_call", "code_interpreter_call",
        "local_shell_call", "local_shell_call_output", "mcp_list_tools", 
        "mcp_approval_request", "mcp_approval_response", "mcp_call", 
        "structured_outputs", "workflow_action", "memory_search_call", 
        "oauth_consent_request"
    ]]


### Response type and associated types

class Reasoning(TypedDict):
    """**o-series models only**
    Configuration options for
    `reasoning models <https://platform.openai.com/docs/guides/reasoning>`_.
    """
    
    effort: NotRequired[Union[str, Literal["low", "medium", "high"]]]
    """Known values are: \"low\", \"medium\", and \"high\"."""
    summary: NotRequired[Literal["auto", "concise", "detailed"]]
    """A summary of the reasoning performed by the model. This can be
     useful for debugging and understanding the model's reasoning process.
     One of ``auto``, ``concise``, or ``detailed``."""
    generate_summary: NotRequired[Literal["auto", "concise", "detailed"]]
    """**Deprecated:** use ``summary`` instead.
     A summary of the reasoning performed by the model. This can be
     useful for debugging and understanding the model's reasoning process.
     One of ``auto``, ``concise``, or ``detailed``."""

class ResponseTextFormatConfiguration(TypedDict):
    type: Union[str, ResponseTextFormatConfigurationType]

class ResponseText(TypedDict):
    format: NotRequired[ResponseTextFormatConfiguration]

ResponsePromptVariables: TypeAlias = Dict[str, Any]

class Tool(TypedDict):
    type: Union[str, ToolType]

class Prompt(TypedDict):
    id: str
    version: NotRequired[str]
    variables: NotRequired[ResponsePromptVariables]

class ResponseError(TypedDict):
    code: Union[str, ResponseErrorCode]
    message: str

class ResponseIncompleteDetails1(TypedDict):
    reason: Literal["max_output_tokens", "content_filter"]

class MemoryStoreOperationUsageInputTokenDetails(TypedDict):
    cached_tokens: int
    """Number of input tokens retrieved from cache."""

class MemoryStoreOperationUsageOutputTokenDetails(TypedDict):
    cached_tokens: int
    """Number of output tokens retrieved from cache."""

class ResponseUsage(TypedDict):
    input_tokens: int
    """The number of input tokens used in the response."""
    input_tokens_details: MemoryStoreOperationUsageInputTokenDetails
    """A detailed breakdown of input token usage."""
    output_tokens: int
    """The number of output tokens"""
    output_tokens_details: MemoryStoreOperationUsageOutputTokenDetails
    """A detailed breakdown of output token usage."""
    total_tokens: int
    """The total number of tokens used."""

class ResponseConversation1(TypedDict):
    id: str


class Response(TypedDict):

    metadata: Dict[str, str]
    """Set of 16 key-value pairs that can be attached to an object. This can be
     useful for storing additional information about the object in a structured
     format, and querying for objects via API or the dashboard.
     Keys are strings with a maximum length of 64 characters. Values are strings
     with a maximum length of 512 characters. Required."""
    temperature: float
    """What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
     more random, while lower values like 0.2 will make it more focused and deterministic.
     We generally recommend altering this or ``top_p`` but not both. Required."""
    top_p: float
    """An alternative to sampling with temperature, called nucleus sampling,
     where the model considers the results of the tokens with top_p probability
     mass. So 0.1 means only the tokens comprising the top 10% probability mass
     are considered. We generally recommend altering this or ``temperature`` but not both. Required."""
    user: str
    """A unique identifier representing your end-user, which can help OpenAI to monitor and detect
     abuse. Required."""
    id: str
    """Unique identifier for this Response. Required."""
    object: Literal["response"]
    """The object type of this resource - always set to ``response``. Required."""
    created_at: datetime.datetime
    """Unix timestamp (in seconds) of when this Response was created. Required."""
    output: List[ItemResource]
    """An array of content items generated by the model. Required."""
    instructions: Union[str, List[ItemParam]]
    """A system (or developer) message inserted into the model's context. Required."""
    parallel_tool_calls: bool
    """Whether to allow the model to run tool calls in parallel. Required."""
    
    # Optional fields
    service_tier: NotRequired[Union[str, Literal["auto", "default", "flex", "scale", "priority"], ServiceTier]]
    """Note: service_tier is not applicable to Azure OpenAI. Known values are:
     \"auto\", \"default\", \"flex\", \"scale\", and \"priority\"."""
    top_logprobs: NotRequired[int]
    """An integer between 0 and 20 specifying the number of most likely tokens to return at each token
     position, each with an associated log probability."""
    previous_response_id: NotRequired[str]
    """The unique ID of the previous response to the model. Use this to
     create multi-turn conversations."""
    model: NotRequired[str]
    """The model deployment to use for the creation of this response."""
    reasoning: NotRequired[Reasoning]  # TODO: Replace with proper Reasoning type when available
    background: NotRequired[bool]
    """Whether to run the model response in the background."""
    max_output_tokens: NotRequired[int]
    """An upper bound for the number of tokens that can be generated for a response."""
    max_tool_calls: NotRequired[int]
    """The maximum number of total calls to built-in tools that can be processed in a response."""
    text: NotRequired[ResponseText]  # TODO: Replace with proper ResponseText type when available
    """Configuration options for a text response from the model."""
    tools: NotRequired[List[Tool]]  # TODO: Replace with proper Tool type when available
    """An array of tools the model may call while generating a response."""
    tool_choice: NotRequired[Union[str, ToolChoiceOptions]]  # TODO: Replace with proper types when available
    """How the model should select which tool (or tools) to use when generating a response."""
    prompt: NotRequired[Prompt]  # TODO: Replace with proper Prompt type when available
    truncation: NotRequired[Literal["auto", "disabled"]]
    """The truncation strategy to use for the model response."""
    status: NotRequired[Literal["completed", "failed", "in_progress", "cancelled", "queued", "incomplete"]]
    """The status of the response generation."""
    error: NotRequired[ResponseError]  # TODO: Replace with proper ResponseError type when available
    incomplete_details: NotRequired[ResponseIncompleteDetails1]  # TODO: Replace with proper ResponseIncompleteDetails1 type when available
    """Details about why the response is incomplete."""
    output_text: NotRequired[str]
    """SDK-only convenience property that contains the aggregated text output."""
    usage: NotRequired[ResponseUsage]  # TODO: Replace with proper ResponseUsage type when available
    conversation: NotRequired[ResponseConversation1]  # TODO: Replace with proper ResponseConversation type when available
    agent: NotRequired[AgentId]
    """The agent used for this response."""
    structured_inputs: NotRequired[Dict[str, Any]]
    """The structured inputs to the response that can participate in prompt template substitution."""


class ResponseStreamEvent(TypedDict):
    """Base type for all response stream events."""
    type: ReadOnly[Union[ str,
        Literal[
            "response.audio.delta",
            "response.audio.done",
            "response.audio_transcript.delta",
            "response.audio_transcript.done",
            "response.code_interpreter_call_code.delta",
            "response.code_interpreter_call_code.done",
            "response.code_interpreter_call.completed",
            "response.code_interpreter_call.in_progress",
            "response.code_interpreter_call.interpreting",
            "response.completed",
            "response.content_part.added",
            "response.content_part.done",
            "response.created",
            "error",
            "response.file_search_call.completed",
            "response.file_search_call.in_progress",
            "response.file_search_call.searching",
            "response.function_call_arguments.delta",
            "response.function_call_arguments.done",
            "response.in_progress",
            "response.failed",
            "response.incomplete",
            "response.output_item.added",
            "response.output_item.done",
            "response.refusal.delta",
            "response.refusal.done",
            "response.output_text.annotation.added",
            "response.output_text.delta",
            "response.output_text.done",
            "response.reasoning_summary_part.added",
            "response.reasoning_summary_part.done",
            "response.reasoning_summary_text.delta",
            "response.reasoning_summary_text.done",
            "response.web_search_call.completed",
            "response.web_search_call.in_progress",
            "response.web_search_call.searching",
            "response.image_generation_call.completed",
            "response.image_generation_call.generating",
            "response.image_generation_call.in_progress",
            "response.image_generation_call.partial_image",
            "response.mcp_call.arguments_delta",
            "response.mcp_call.arguments_done",
            "response.mcp_call.completed",
            "response.mcp_call.failed",
            "response.mcp_call.in_progress",
            "response.mcp_list_tools.completed",
            "response.mcp_list_tools.failed",
            "response.mcp_list_tools.in_progress",
            "response.queued",
            "response.reasoning.delta",
            "response.reasoning.done",
            "response.reasoning_summary.delta",
            "response.reasoning_summary.done"
    ]]]
    """The type of the response stream event. Required."""
    sequence_number: int
    """The sequence number of the event. Required."""


class ResponseCompletedEvent(ResponseStreamEvent):
    type: ReadOnly[Literal["response_completed"]]
    """Required. Discriminator value is \"response_completed\"."""
    response: Response
    """The completed response object. Required."""

class ResponseContentPartAddedEvent(ResponseStreamEvent):
    type: ReadOnly[Literal["response.content_part.added"]]
    """Required. Discriminator value is \"response.content_part.added\"."""
    item_id: str
    """The ID of the output item that the content part was added to. Required."""
    output_index: int
    """The index of the output item that the content part was added to. Required."""
    content_index: int
    """The index of the content part that was added. Required."""
    part: ItemContent
    """The content part that was added. Required."""

class ResponseContentPartDoneEvent(ResponseStreamEvent):
    type: ReadOnly[Literal["response.content_part.done"]]
    """Required. Discriminator value is \"response.content_part.done\"."""
    item_id: str
    """The ID of the output item that the content part was added to. Required."""
    output_index: int
    """The index of the output item that the content part was added to. Required."""
    content_index: int
    """The index of the content part that was added. Required."""
    part: ItemContent
    """The content part that was added. Required."""

class ResponseCreatedEvent(ResponseStreamEvent):
    type: ReadOnly[Literal["response.created"]]
    """Required. Discriminator value is \"response.created\"."""
    response: Response
    """The created response object. Required."""

class ResponseErrorEvent(ResponseStreamEvent):
    type: ReadOnly[Literal["error"]]
    """Required. Discriminator value is \"error\"."""
    code: str
    """The error code. Required."""
    message: str
    """The error message. Required."""
    param: str
    """The error parameter. Required."""

class ResponseFunctionCallArgumentsDeltaEvent(ResponseStreamEvent):
    type: ReadOnly[Literal["response.function_call_arguments.delta"]]
    """Required. Discriminator value is \"response.function_call_arguments.delta\"."""
    item_id: str
    """ The ID of thee output item that the function call arguments delta belongs to. Required."""
    output_index: int
    """The index of the output item that the function call arguments delta belongs to. Required."""
    delta: str
    """The function call arguments delta. Required."""


class ResponseFunctionCallArgumentsDoneEvent(ResponseStreamEvent):
    type: ReadOnly[Literal["response.function_call_arguments.done"]]
    """Required. Discriminator value is \"response.function_call_arguments.done\"."""
    item_id: str
    """The ID of the output item that the function call arguments belongs to. Required."""
    output_index: int
    """The index of the output item that the function call arguments belongs to. Required."""
    arguments: str
    """The complete function call arguments. Required."""


class ResponseInProgressEvent(ResponseStreamEvent):
    type: ReadOnly[Literal["response.in_progress"]]
    """Required. Discriminator value is \"response.in_progress\"."""
    response: Response
    """The in-progress response object. Required."""


class ResponseOutputItemAddedEvent(ResponseStreamEvent):
    type: ReadOnly[Literal["response.output_item.added"]]
    """Required. Discriminator value is \"response.output_item.added\"."""
    output_index: int
    """The index of the output item that was added. Required."""
    item: ItemResource
    """The output item that was added. Required."""


class ResponseOutputItemDoneEvent(ResponseStreamEvent):
    type: ReadOnly[Literal["response.output_item.done"]]
    """Required. Discriminator value is \"response.output_item.done\"."""
    output_index: int
    """The index of the output item that was completed. Required."""
    item: ItemResource
    """The completed output item. Required."""


class ResponseTextDeltaEvent(ResponseStreamEvent):
    type: ReadOnly[Literal["response.output_text.delta"]]
    """Required. Discriminator value is \"response.output_text.delta\"."""
    item_id: str
    """The ID of the output item that the text delta belongs to. Required."""
    output_index: int
    """The index of the output item that the text delta belongs to. Required."""
    content_index: int
    """The index of the content part that the text delta belongs to. Required."""
    delta: str
    """The text delta. Required."""


class ResponseTextDoneEvent(ResponseStreamEvent):
    type: ReadOnly[Literal["response.output_text.done"]]
    """Required. Discriminator value is \"response.output_text.done\"."""
    item_id: str
    """The ID of the output item that the text belongs to. Required."""
    output_index: int
    """The index of the output item that the text belongs to. Required."""
    content_index: int
    """The index of the content part that the text belongs to. Required."""
    text: str
    """The complete text. Required."""


class ResponsesMessageItemResource(ItemResource):
    """Base message item resource."""
    type: ReadOnly[Literal["message"]]
    """Required. Discriminator value is \"message\"."""
    role: ReadOnly[Union[str, Literal["assistant", "user", "system", "developer"]]]
    """The role of the message. Required."""
    status: Union[str, Literal["in_progress", "completed", "incomplete"]]
    """The status of the message. Required."""


class ResponsesAssistantMessageItemResource(ResponsesMessageItemResource):
    """Assistant message item resource with role='assistant'."""
    role: ReadOnly[Literal["assistant"]]
    """The role of the message. Always ``assistant``. Required."""
    content: List[ItemContent]
    """The content of the message. Required."""


