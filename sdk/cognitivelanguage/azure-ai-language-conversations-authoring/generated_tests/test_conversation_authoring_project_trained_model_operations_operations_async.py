# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
import pytest
from devtools_testutils.aio import recorded_by_proxy_async
from testpreparer import ConversationAuthoringProjectPreparer
from testpreparer_async import ConversationAuthoringProjectClientTestBaseAsync


@pytest.mark.skip("you may need to update the auto-generated test case before run it")
class TestConversationAuthoringProjectTrainedModelOperationsOperationsAsync(
    ConversationAuthoringProjectClientTestBaseAsync
):
    @ConversationAuthoringProjectPreparer()
    @recorded_by_proxy_async
    async def test_trained_model_operations_get_trained_model(self, conversationauthoringproject_endpoint):
        client = self.create_async_client(endpoint=conversationauthoringproject_endpoint)
        response = await client.trained_model_operations.get_trained_model(
            project_name="str",
            trained_model_label="str",
        )

        # please add some check logic here by yourself
        # ...

    @ConversationAuthoringProjectPreparer()
    @recorded_by_proxy_async
    async def test_trained_model_operations_delete_trained_model(self, conversationauthoringproject_endpoint):
        client = self.create_async_client(endpoint=conversationauthoringproject_endpoint)
        response = await client.trained_model_operations.delete_trained_model(
            project_name="str",
            trained_model_label="str",
        )

        # please add some check logic here by yourself
        # ...

    @ConversationAuthoringProjectPreparer()
    @recorded_by_proxy_async
    async def test_trained_model_operations_begin_evaluate_model(self, conversationauthoringproject_endpoint):
        client = self.create_async_client(endpoint=conversationauthoringproject_endpoint)
        response = await (
            await client.trained_model_operations.begin_evaluate_model(
                project_name="str",
                trained_model_label="str",
                body={"kind": "str", "testingSplitPercentage": 0, "trainingSplitPercentage": 0},
            )
        ).result()  # call '.result()' to poll until service return final result

        # please add some check logic here by yourself
        # ...

    @ConversationAuthoringProjectPreparer()
    @recorded_by_proxy_async
    async def test_trained_model_operations_begin_load_snapshot(self, conversationauthoringproject_endpoint):
        client = self.create_async_client(endpoint=conversationauthoringproject_endpoint)
        response = await (
            await client.trained_model_operations.begin_load_snapshot(
                project_name="str",
                trained_model_label="str",
            )
        ).result()  # call '.result()' to poll until service return final result

        # please add some check logic here by yourself
        # ...

    @ConversationAuthoringProjectPreparer()
    @recorded_by_proxy_async
    async def test_trained_model_operations_get_evaluation_status(self, conversationauthoringproject_endpoint):
        client = self.create_async_client(endpoint=conversationauthoringproject_endpoint)
        response = await client.trained_model_operations.get_evaluation_status(
            project_name="str",
            trained_model_label="str",
            job_id="str",
        )

        # please add some check logic here by yourself
        # ...

    @ConversationAuthoringProjectPreparer()
    @recorded_by_proxy_async
    async def test_trained_model_operations_get_model_evaluation_results(self, conversationauthoringproject_endpoint):
        client = self.create_async_client(endpoint=conversationauthoringproject_endpoint)
        response = client.trained_model_operations.get_model_evaluation_results(
            project_name="str",
            trained_model_label="str",
            string_index_type="str",
        )
        result = [r async for r in response]
        # please add some check logic here by yourself
        # ...

    @ConversationAuthoringProjectPreparer()
    @recorded_by_proxy_async
    async def test_trained_model_operations_get_model_evaluation_summary(self, conversationauthoringproject_endpoint):
        client = self.create_async_client(endpoint=conversationauthoringproject_endpoint)
        response = await client.trained_model_operations.get_model_evaluation_summary(
            project_name="str",
            trained_model_label="str",
        )

        # please add some check logic here by yourself
        # ...

    @ConversationAuthoringProjectPreparer()
    @recorded_by_proxy_async
    async def test_trained_model_operations_get_load_snapshot_status(self, conversationauthoringproject_endpoint):
        client = self.create_async_client(endpoint=conversationauthoringproject_endpoint)
        response = await client.trained_model_operations.get_load_snapshot_status(
            project_name="str",
            trained_model_label="str",
            job_id="str",
        )

        # please add some check logic here by yourself
        # ...
