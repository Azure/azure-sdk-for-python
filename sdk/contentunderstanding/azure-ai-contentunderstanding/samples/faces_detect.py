# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------

import asyncio
import os
from azure.ai.contentunderstanding.aio import ContentUnderstandingClient
from azure.ai.contentunderstanding.models import DetectFacesResult
from azure.core.credentials import AzureKeyCredential
from dotenv import load_dotenv

from azure.core.credentials import AzureKeyCredential
from azure.identity.aio import DefaultAzureCredential

load_dotenv()

"""
Prerequisites:
    pip install azure-ai-contentunderstanding python-dotenv
    az login  # Used for DefaultAzureCredential(). Alternatively, set the AZURE_CONTENT_UNDERSTANDING_KEY environment variable

Environment variables:
    AZURE_CONTENT_UNDERSTANDING_ENDPOINT   (required)
    AZURE_CONTENT_UNDERSTANDING_KEY        (optional - DefaultAzureCredential() will be used if not set)
    These variables can be set in a .env file in the samples directory for repeated use. Please see env.sample for an example.

Run:
    python faces_detect.py
"""


async def main():
    """
    Detect faces in an image using the faces detect API.

    High-level steps:
    1. Load a test image from local file
    2. Convert image to base64 format
    3. Call the faces detect API
    4. Display detection results with face details
    """
    endpoint = os.getenv("AZURE_CONTENT_UNDERSTANDING_ENDPOINT") or ""
    # Return AzureKeyCredential if AZURE_CONTENT_UNDERSTANDING_KEY is set, otherwise DefaultAzureCredential
    key = os.getenv("AZURE_CONTENT_UNDERSTANDING_KEY")
    credential = AzureKeyCredential(key) if key else DefaultAzureCredential()

    async with ContentUnderstandingClient(
        endpoint=endpoint, credential=credential
    ) as client, credential:
        """Detect faces in a test image and display results."""

        # Load test image from sample files
        sample_file_dir = os.path.dirname(os.path.abspath(__file__))
        image_path = os.path.join(sample_file_dir, "sample_files", "face", "family.jpg")

        print(f"üîç Detecting faces in image: {image_path}")

        # Read image as raw bytes
        with open(image_path, "rb") as image_file:
            image_data = image_file.read()

        # Detect faces in the image using the enhanced detect method
        response: DetectFacesResult = await client.faces.detect(
            data=image_data, max_detected_faces=10
        )

        if hasattr(response, "detected_faces") and response.detected_faces:
            face_count = len(response.detected_faces)
            print(f"üë§ Detected {face_count} face{'s' if face_count != 1 else ''}")

            # Display details for each detected face
            for i, face in enumerate(response.detected_faces, 1):
                print(f"\n   Face {i}:")

                # Display bounding box information
                if hasattr(face, "bounding_box") and face.bounding_box:
                    bbox = face.bounding_box
                    print(f"      Bounding Box:")
                    print(f"         Left: {bbox.left}, Top: {bbox.top}")
                    print(f"         Width: {bbox.width}, Height: {bbox.height}")
        else:
            print("üë§ No faces detected in the image")

        print("\nüéâ Face detection sample completed successfully!")


# x-ms-original-file: 2025-05-01-preview/Faces_Detect.json
if __name__ == "__main__":
    asyncio.run(main())
