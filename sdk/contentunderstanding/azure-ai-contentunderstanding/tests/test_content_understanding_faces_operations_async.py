# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
import pytest
import os
import uuid
from datetime import datetime
from typing import Optional, Dict, Any, List
from devtools_testutils.aio import recorded_by_proxy_async
from testpreparer import ContentUnderstandingPreparer
from testpreparer_async import ContentUnderstandingClientTestBaseAsync
from azure.core.exceptions import ResourceNotFoundError
from test_helpers import read_image_to_base64, read_image_to_base64_bytes


def generate_test_id() -> str:
    """Generate a unique test ID with current date, time, and GUID."""
    now = datetime.now()
    date_str = now.strftime("%Y%m%d")
    time_str = now.strftime("%H%M%S")
    guid = str(uuid.uuid4()).replace("-", "")[:8]
    return f"test_{date_str}_{time_str}_{guid}"


import pytest

class TestContentUnderstandingFacesOperationsAsync(ContentUnderstandingClientTestBaseAsync):
    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_faces_detect_original_body(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Test original body parameter method
        - Load a test image
        - Detect faces using JSON body
        - Verify detection results
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        
        # Load test image
        test_file_dir = os.path.dirname(os.path.abspath(__file__))
        image_path = os.path.join(test_file_dir, "test_data", "face", "family.jpg")
        image_data = read_image_to_base64(image_path)
        
        print(f"Testing original body method with image: {image_path}")
        response = await client.faces.detect(
            body={
                "data": image_data,  # image_data is already a string
                "maxDetectedFaces": 10
            }
        )
        
        # Verify the response
        assert response is not None
        assert hasattr(response, 'detected_faces')
        print(f"Original body method: Detected {len(response.detected_faces) if response.detected_faces else 0} faces")
        
        # Verify each detected face has required properties
        if response.detected_faces:
            for i, face in enumerate(response.detected_faces):
                assert hasattr(face, 'bounding_box'), f"Detected face {i} should have bounding_box"
                
                # Print bounding box information
                if hasattr(face, 'bounding_box') and face.bounding_box:
                    bbox = face.bounding_box
                    print(f"Face {i+1}: BoundingBox(left={bbox.left}, top={bbox.top}, width={bbox.width}, height={bbox.height})")
        
        print("Original body method test completed successfully")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_faces_detect_url_keyword(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Test original url keyword parameter method
        - Use a URL to detect faces
        - Verify detection results
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        
        # Use a test image URL
        image_url = "https://media.githubusercontent.com/media/Azure-Samples/azure-ai-content-understanding-python/refs/heads/main/data/face/family.jpg"
        
        print(f"Testing original url keyword method with URL: {image_url}")
        response = await client.faces.detect(
            url=image_url,
            max_detected_faces=10
        )
        
        # Verify the response
        assert response is not None
        assert hasattr(response, 'detected_faces')
        print(f"URL keyword method: Detected {len(response.detected_faces) if response.detected_faces else 0} faces")
        
        # Verify each detected face has required properties
        if response.detected_faces:
            for i, face in enumerate(response.detected_faces):
                assert hasattr(face, 'bounding_box'), f"Detected face {i} should have bounding_box"
        
        print("URL keyword method test completed successfully")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_faces_detect_data_keyword(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Test original data keyword parameter method with bytes conversion
        - Load a test image as bytes
        - Detect faces using data keyword parameter
        - Verify detection results
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        
        # Load test image
        test_file_dir = os.path.dirname(os.path.abspath(__file__))
        image_path = os.path.join(test_file_dir, "test_data", "face", "family.jpg")
        image_data = read_image_to_base64_bytes(image_path)  # Returns bytes
        
        print(f"Testing data keyword method with image: {image_path}")
        response = await client.faces.detect(
            data=image_data,  # Our patch will convert bytes to string automatically
            max_detected_faces=10
        )
        
        # Verify the response
        assert response is not None
        assert hasattr(response, 'detected_faces')
        print(f"Data keyword method: Detected {len(response.detected_faces) if response.detected_faces else 0} faces")
        
        # Verify each detected face has required properties
        if response.detected_faces:
            for i, face in enumerate(response.detected_faces):
                assert hasattr(face, 'bounding_box'), f"Detected face {i} should have bounding_box"
        
        print("Data keyword method test completed successfully")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_faces_detect_url_positional(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Test new URL positional overload
        - Use URL as positional argument
        - Verify detection results
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        
        # Use a test image URL
        image_url = "https://media.githubusercontent.com/media/Azure-Samples/azure-ai-content-understanding-python/refs/heads/main/data/face/family.jpg"
        
        print(f"Testing new URL positional overload with URL: {image_url}")
        response = await client.faces.detect(
            image_url,  # URL as positional argument (new overload)
            max_detected_faces=10
        )
        
        # Verify the response
        assert response is not None
        assert hasattr(response, 'detected_faces')
        print(f"URL positional overload: Detected {len(response.detected_faces) if response.detected_faces else 0} faces")
        
        # Verify each detected face has required properties
        if response.detected_faces:
            for i, face in enumerate(response.detected_faces):
                assert hasattr(face, 'bounding_box'), f"Detected face {i} should have bounding_box"
        
        print("URL positional overload test completed successfully")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_faces_detect_bytes_positional(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Test new bytes positional overload
        - Load image as bytes and use as positional argument
        - Verify detection results
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        
        # Load test image
        test_file_dir = os.path.dirname(os.path.abspath(__file__))
        image_path = os.path.join(test_file_dir, "test_data", "face", "family.jpg")
        image_data = read_image_to_base64_bytes(image_path)  # Returns bytes
        
        print(f"Testing new bytes positional overload with image: {image_path}")
        response = await client.faces.detect(
            image_data,  # Bytes as positional argument (new overload)
            max_detected_faces=10
        )
        
        # Verify the response
        assert response is not None
        assert hasattr(response, 'detected_faces')
        print(f"Bytes positional overload: Detected {len(response.detected_faces) if response.detected_faces else 0} faces")
        
        # Verify each detected face has required properties
        if response.detected_faces:
            for i, face in enumerate(response.detected_faces):
                assert hasattr(face, 'bounding_box'), f"Detected face {i} should have bounding_box"
        
        print("Bytes positional overload test completed successfully")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy_async
    async def test_faces_compare(self, contentunderstanding_endpoint):
        """
        Test Summary:
        - Load two different images of the same person (Bill)
        - Compare faces between the images
        - Verify comparison results show high similarity
        """
        client = self.create_async_client(endpoint=contentunderstanding_endpoint)
        
        # Load two different images of the same person (Bill)
        test_file_dir = os.path.dirname(os.path.abspath(__file__))
        image1_path = os.path.join(test_file_dir, "test_data", "face", "enrollment_data", "Bill", "Family1-Dad1.jpg")
        image2_path = os.path.join(test_file_dir, "test_data", "face", "enrollment_data", "Bill", "Family1-Dad2.jpg")
        
        image1_data = read_image_to_base64(image1_path)
        image2_data = read_image_to_base64(image2_path)
        
        print(f"Comparing faces between two images of the same person (Bill)")
        print(f"Image 1: {image1_path}")
        print(f"Image 2: {image2_path}")
        
        response = await client.faces.compare(
            body={
                "faceSource1": {
                    "data": image1_data  # image_data is already a string
                },
                "faceSource2": {
                    "data": image2_data  # image_data is already a string
                }
            }
        )
        
        # Verify the response
        assert response is not None
        assert hasattr(response, 'detected_face1'), "Response should have detected_face1 property"
        assert hasattr(response, 'detected_face2'), "Response should have detected_face2 property"
        assert hasattr(response, 'confidence'), "Response should have confidence property"
        
        print(f"Face comparison result: Confidence={response.confidence}")
        
        # Verify confidence is a numeric value
        assert isinstance(response.confidence, (int, float)), "Confidence should be a number"
        assert response.confidence >= 0, "Confidence should be non-negative"
        
        # Print detected face information
        if hasattr(response, 'detected_face1') and response.detected_face1:
            face1 = response.detected_face1
            if hasattr(face1, 'bounding_box') and face1.bounding_box:
                bbox1 = face1.bounding_box
                print(f"Detected Face 1: BoundingBox(left={bbox1.left}, top={bbox1.top}, width={bbox1.width}, height={bbox1.height})")
        
        if hasattr(response, 'detected_face2') and response.detected_face2:
            face2 = response.detected_face2
            if hasattr(face2, 'bounding_box') and face2.bounding_box:
                bbox2 = face2.bounding_box
                print(f"Detected Face 2: BoundingBox(left={bbox2.left}, top={bbox2.top}, width={bbox2.width}, height={bbox2.height})")
        
        # For faces of the same person, we expect high confidence
        print(f"Confidence score: {response.confidence} (expected high for same person)")
        
        print("Face comparison test completed successfully")
