# pylint: disable=line-too-long,useless-suppression
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
import os
import uuid
import re
import json
from datetime import datetime
from typing import Optional, Dict, Any, List
import sys
from azure.ai.contentunderstanding.models import (
    ContentAnalyzer,
    ContentAnalyzerConfig,
    ContentFieldSchema,
    ContentFieldDefinition,
)
from azure.ai.contentunderstanding.models import GenerationMethod, ContentFieldType, ProcessingLocation

from devtools_testutils import is_live, is_live_and_not_recording


def generate_analyzer_id(client, test_name: str, is_async: bool = False) -> str:
    """Generate a unique analyzer ID using test name.

    Args:
        client: The ContentUnderstandingClient instance (not used, kept for compatibility)
        test_name: Short test identifier
        is_async: If True, uses 'async' prefix; if False, uses 'sync' prefix

    Returns:
        str: A unique analyzer ID (format: python_sdk_{sync|async}_{test_name})
    """
    prefix = "async" if is_async else "sync"
    analyzer_id = f"python_sdk_{prefix}_{test_name}"
    return analyzer_id


def new_simple_content_analyzer_object(
    analyzer_id: str, description: Optional[str] = None, tags: Optional[Dict[str, str]] = None
) -> ContentAnalyzer:
    """Create a simple ContentAnalyzer object with default configuration.

    Args:
        analyzer_id: The analyzer ID
        description: Optional description for the analyzer
        tags: Optional tags for the analyzer

    Returns:
        ContentAnalyzer: A configured ContentAnalyzer object
    """
    if description is None:
        description = f"test analyzer: {analyzer_id}"
    if tags is None:
        tags = {"test_type": "simple"}

    return ContentAnalyzer(
        base_analyzer_id="prebuilt-document",
        config=ContentAnalyzerConfig(
            enable_formula=True,
            enable_layout=True,
            enable_ocr=True,
            estimate_field_source_and_confidence=True,
            return_details=True,
        ),
        description=description,
        field_schema=ContentFieldSchema(
            fields={
                "total_amount": ContentFieldDefinition(
                    description="Total amount of this table",
                    method=GenerationMethod.EXTRACT,
                    type=ContentFieldType.NUMBER,
                )
            },
            description="schema description here",
            name="schema name here",
        ),
        processing_location=ProcessingLocation.GLOBAL,
        models={"completion": "gpt-4o"},  # Required when using field_schema
        tags=tags,
    )


def new_marketing_video_analyzer_object(
    analyzer_id: str, description: Optional[str] = None, tags: Optional[Dict[str, str]] = None
) -> ContentAnalyzer:
    """Create a marketing video ContentAnalyzer object based on the marketing video template.

    Args:
        analyzer_id: The analyzer ID
        description: Optional description for the analyzer
        tags: Optional tags for the analyzer

    Returns:
        ContentAnalyzer: A configured ContentAnalyzer object for video analysis
    """
    if description is None:
        description = f"marketing video analyzer: {analyzer_id}"
    if tags is None:
        tags = {"test_type": "marketing_video"}

    return ContentAnalyzer(
        base_analyzer_id="prebuilt-video",
        config=ContentAnalyzerConfig(
            return_details=True,
        ),
        description=description,
        processing_location=ProcessingLocation.GLOBAL,
        models={"completion": "gpt-4o"},  # Required when using field_schema
        tags=tags,
    )


def assert_poller_properties(poller: Any, poller_name: str = "Poller") -> None:
    """Assert common poller properties for any LROPoller or AsyncLROPoller.

    Args:
        poller: The LROPoller or AsyncLROPoller instance to validate
        poller_name: Optional name for the poller in log messages

    Raises:
        AssertionError: If any poller property assertion fails
    """
    assert poller is not None, f"{poller_name} should not be None"
    assert poller.status() is not None, f"{poller_name} status should not be None"
    assert poller.status() != "", f"{poller_name} status should not be empty"
    assert poller.continuation_token() is not None, f"{poller_name} continuation_token should not be None"
    print(f"{poller_name} properties verified successfully")


def assert_simple_content_analyzer_result(analysis_result: Any, result_name: str = "Analysis result") -> None:
    """Assert simple content analyzer result properties and field extraction.

    Args:
        analysis_result: The analysis result object to validate
        result_name: Optional name for the result in log messages

    Raises:
        AssertionError: If any analysis result property assertion fails
    """
    print(f"Validating {result_name} properties")
    assert analysis_result is not None, f"{result_name} should not be None"
    assert (
        analysis_result.__class__.__name__ == "AnalyzeResult"
    ), f"{result_name} should be AnalyzeResult, got {analysis_result.__class__.__name__}"
    assert analysis_result.contents is not None, f"{result_name} should have contents"
    assert len(analysis_result.contents) > 0, f"{result_name} should have at least one content"

    print(f"{result_name} properties verified successfully")

    # Verify fields node exists in the first result of contents

    first_content = analysis_result.contents[0]
    assert hasattr(first_content, "fields"), "First content should have fields"
    print(f"Verified fields node exists in first result")

    # Verify total_amount field exists and equals 110
    fields = first_content.fields

    # Fields is expected to be a dictionary
    assert isinstance(fields, dict), f"Fields should be a dictionary, got {type(fields)}"
    assert "total_amount" in fields, f"Fields should contain total_amount. Available fields: {list(fields.keys())}"

    total_amount_field = fields["total_amount"]
    assert total_amount_field is not None, "total_amount field should not be None"
    assert (
        total_amount_field.__class__.__name__ == "NumberField"
    ), f"total_amount field should be of type NumberField, got {total_amount_field.__class__.__name__}"

    total_amount_value = total_amount_field.value

    print(f"Total amount field value: {total_amount_value}")
    assert total_amount_value == 110, f"Expected total_amount to be 110, but got {total_amount_value}"
    print(f"Total amount field validation successful")


def save_analysis_result_to_file(
    analysis_result: Any,
    test_name: str,
    test_py_file_dir: str,
    identifier: Optional[str] = None,
    output_dir: str = "test_output",
) -> str:
    """Save analysis result to output file using pytest naming convention.

    Args:
        analysis_result: The analysis result object to save
        test_name: Name of the test case (e.g., function name)
        test_py_file_dir: Directory where pytest files are located
        identifier: Optional unique identifier for the result (e.g., analyzer_id)
        output_dir: Directory name to save the output file (default: "test_output")

    Returns:
        str: Path to the saved output file

    Raises:
        OSError: If there are issues creating directory or writing file
    """
    # Create output directory if it doesn't exist
    output_dir_path = os.path.join(test_py_file_dir, output_dir)
    os.makedirs(output_dir_path, exist_ok=True)

    # Generate output filename with timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # Build filename with test name and optional identifier
    if identifier:
        output_filename = f"{test_name}_{identifier}_{timestamp}.json"
    else:
        output_filename = f"{test_name}_{timestamp}.json"

    saved_file_path = os.path.join(output_dir_path, output_filename)

    # Save the analysis result
    with open(saved_file_path, "w") as output_file:
        json.dump(analysis_result.as_dict(), output_file, indent=2)

    print(f"Analysis result saved to: {saved_file_path}")
    return saved_file_path


def save_keyframe_image_to_file(
    image_content: bytes,
    keyframe_id: str,
    test_name: str,
    test_py_file_dir: str,
    identifier: Optional[str] = None,
    output_dir: str = "test_output",
) -> str:
    """Save keyframe image to output file using pytest naming convention.

    Args:
        image_content: The binary image content to save
        keyframe_id: The keyframe ID (e.g., "keyframes/733")
        test_name: Name of the test case (e.g., function name)
        test_py_file_dir: Directory where pytest files are located
        identifier: Optional unique identifier to avoid conflicts (e.g., analyzer_id)
        output_dir: Directory name to save the output file (default: "test_output")

    Returns:
        str: Path to the saved image file

    Raises:
        OSError: If there are issues creating directory or writing file
    """
    # Generate timestamp and frame ID
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    # Extract the frame time from the keyframe path (e.g., "keyframes/733" -> "733")
    if "/" in keyframe_id:
        frame_id = keyframe_id.split("/")[-1]
    else:
        # Fallback: use as-is if no slash found
        frame_id = keyframe_id

    # Create output directory if it doesn't exist
    output_dir_path = os.path.join(test_py_file_dir, output_dir)
    os.makedirs(output_dir_path, exist_ok=True)

    # Generate output filename with optional identifier to avoid conflicts
    if identifier:
        output_filename = f"{test_name}_{identifier}_{timestamp}_{frame_id}.jpg"
    else:
        output_filename = f"{test_name}_{timestamp}_{frame_id}.jpg"

    saved_file_path = os.path.join(output_dir_path, output_filename)

    # Write the image content to file
    with open(saved_file_path, "wb") as image_file:
        image_file.write(image_content)

    print(f"Image file saved to: {saved_file_path}")
    return saved_file_path


def read_image_bytes(image_path: str) -> bytes:
    """Read image file and return raw bytes.

    Args:
        image_path: Path to the image file

    Returns:
        bytes: Raw image data as bytes

    Raises:
        FileNotFoundError: If the image file doesn't exist
        OSError: If there are issues reading the file
    """
    with open(image_path, "rb") as image_file:
        return image_file.read()


def get_test_data_path(relative_path: str) -> str:
    """Get the absolute path to test data files.

    Args:
        relative_path: Relative path from the test data directory

    Returns:
        str: Absolute path to the test data file
    """
    test_file_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.join(test_file_dir, "test_data", relative_path)
