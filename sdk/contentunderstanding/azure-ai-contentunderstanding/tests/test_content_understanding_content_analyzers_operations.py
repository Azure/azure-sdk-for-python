# pylint: disable=line-too-long,useless-suppression
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
import pytest
import os
import re
from typing import Tuple, Union, Dict, Any, Optional, List, Set
from devtools_testutils import recorded_by_proxy
from testpreparer import ContentUnderstandingPreparer
from testpreparer import ContentUnderstandingClientTestBase
from azure.ai.contentunderstanding.models import ContentAnalyzer
from azure.ai.contentunderstanding import ContentUnderstandingClient
from test_helpers import (
    generate_analyzer_id_sync,
    new_simple_content_analyzer_object,
    new_marketing_video_analyzer_object,
    assert_poller_properties,
    assert_simple_content_analyzer_result,
    save_analysis_result_to_file,
    save_keyframe_image_to_file,
)

from devtools_testutils import is_live, is_live_and_not_recording


def analyzer_in_list_sync(client: ContentUnderstandingClient, analyzer_id: str) -> bool:
    """Check if an analyzer with the given ID exists in the list of analyzers (sync version).

    Args:
        client: The ContentUnderstandingClient instance
        analyzer_id: The analyzer ID to search for

    Returns:
        bool: True if the analyzer is found, False otherwise
    """
    response = client.content_analyzers.list()
    for r in response:
        if hasattr(r, "analyzer_id") and r.analyzer_id == analyzer_id:
            return True
    return False


def create_analyzer_and_assert_sync(
    client: ContentUnderstandingClient, analyzer_id: str, resource: Union[ContentAnalyzer, Dict[str, Any]]
) -> Any:
    """Create an analyzer and perform basic assertions (sync version).

    Args:
        client: The ContentUnderstandingClient instance
        analyzer_id: The analyzer ID to create
        resource: The analyzer resource (ContentAnalyzer object or dict)

    Returns:
        Any: The poller object

    Raises:
        AssertionError: If the creation fails or assertions fail
    """
    print(f"\nCreating analyzer {analyzer_id}")

    # Start the analyzer creation operation
    poller = client.content_analyzers.begin_create_or_replace(
        analyzer_id=analyzer_id,
        resource=resource,
    )

    # Wait for the operation to complete
    print(f"  Waiting for analyzer {analyzer_id} to be created")
    response = poller.result()
    assert response is not None
    assert poller.status() == "Succeeded"
    assert poller.done()
    print(f"  Analyzer {analyzer_id} is created successfully")

    # Additional poller assertions
    assert poller is not None
    assert poller.status() is not None
    assert poller.status() != ""
    assert poller.continuation_token() is not None

    # Verify the analyzer is in the list
    assert analyzer_in_list_sync(
        client, analyzer_id
    ), f"Created analyzer with ID '{analyzer_id}' was not found in the list"
    print(f"  Verified analyzer {analyzer_id} is in the list")

    return poller


def delete_analyzer_and_assert_sync(client: ContentUnderstandingClient, analyzer_id: str, created_analyzer: bool) -> None:
    """Delete an analyzer and assert it was deleted successfully (sync version).

    Args:
        client: The ContentUnderstandingClient instance
        analyzer_id: The analyzer ID to delete
        created_analyzer: Whether the analyzer was created (to determine if cleanup is needed)

    Raises:
        AssertionError: If the analyzer still exists after deletion
    """
    if created_analyzer:
        print(f"Cleaning up analyzer {analyzer_id}")
        try:
            client.content_analyzers.delete(analyzer_id=analyzer_id)
            # Verify deletion
            assert not analyzer_in_list_sync(
                client, analyzer_id
            ), f"Deleted analyzer with ID '{analyzer_id}' was found in the list"
            print(f"Analyzer {analyzer_id} is deleted successfully")
        except Exception as e:
            # If deletion fails, the test should fail
            raise AssertionError(f"Failed to delete analyzer {analyzer_id}: {e}") from e
    else:
        print(f"Analyzer {analyzer_id} was not created, no cleanup needed")


def download_keyframes_and_assert_sync(
    client: ContentUnderstandingClient, analysis_operation_id: str, result: Any, test_py_file_dir: str, identifier: Optional[str] = None
) -> None:
    """Download keyframes from video analysis result and assert their existence (sync version).

    Downloads up to 3 keyframes: first, middle, and last frame to avoid duplicates.

    Args:
        client: The ContentUnderstandingClient instance
        analysis_operation_id: The operation ID from the analysis
        result: The analysis result containing markdown with keyframes
        test_py_file_dir: The directory where pytest files are located
        identifier: Optional unique identifier to avoid conflicts (e.g., analyzer_id)

    Returns:
        None

    Raises:
        AssertionError: If no keyframes are found in the analysis result
    """
    keyframe_ids: Set[str] = set()

    # Iterate over contents to find keyframes from markdown
    for content in result.contents:
        # Extract keyframe IDs from "markdown" if it exists and is a string
        markdown_content = getattr(content, "markdown", "")
        if isinstance(markdown_content, str):
            # Use the same regex pattern as the official sample: (keyFrame\.d+)\.jpg
            keyframe_ids.update(re.findall(r"(keyFrame\.\d+)\.jpg", markdown_content))

    print(f"Found keyframe IDs in markdown: {keyframe_ids}")

    # Assert that keyframe IDs were found in the video analysis
    assert (
        keyframe_ids
    ), "No keyframe IDs were found in the video analysis markdown content. Video analysis should generate keyframes that can be extracted using regex pattern."

    print(f"Successfully extracted {len(keyframe_ids)} keyframe IDs from video analysis")

    # Sort keyframes by frame number to get first, middle, and last
    sorted_keyframes: List[str] = sorted(keyframe_ids, key=lambda x: int(x.replace("keyFrame.", "")))

    # Create a set with first, middle, and last frames (automatically removes duplicates)
    frames_set: Set[str] = {sorted_keyframes[0], sorted_keyframes[-1], sorted_keyframes[len(sorted_keyframes) // 2]}

    # Convert set to list for processing
    frames_to_download: List[str] = list(frames_set)

    print(f"Selected frames to download: {frames_to_download}")

    # Try to retrieve the selected keyframe images using get_result_file API
    files_retrieved: int = 0

    for keyframe_id in frames_to_download:
        print(f"Trying to get result file with path: {keyframe_id}")
        response = client.content_analyzers.get_result_file(
            operation_id=analysis_operation_id,
            path=keyframe_id,  # Use keyframe_id directly as path, no .jpg extension
        )

        # Handle the response - it's an iterator that needs to be collected
        if hasattr(response, "__iter__"):
            # It's an iterator, collect all bytes efficiently
            chunks = []
            for chunk in response:
                chunks.append(chunk)
            response = b"".join(chunks)

        # Assert that we successfully get a response and it's valid image data
        assert response is not None, f"Response for path {keyframe_id} should not be None"
        assert isinstance(
            response, bytes
        ), f"Response for {keyframe_id} should be bytes (image data), got {type(response)}"
        assert len(response) > 0, f"Image file content for {keyframe_id} should not be empty"

        print(f"Successfully retrieved image file for path: {keyframe_id}")
        print(f"Image file content length: {len(response)} bytes")

        # Save the image file using the helper function
        saved_file_path = save_keyframe_image_to_file(
            image_content=response,
            keyframe_id=keyframe_id,
            test_name="test_content_analyzers_get_result_file",
            test_py_file_dir=test_py_file_dir,
            identifier=identifier,
        )

        # Verify the saved file exists and has content
        assert os.path.exists(saved_file_path), f"Saved image file should exist at {saved_file_path}"
        assert os.path.getsize(saved_file_path) > 0, f"Saved image file should not be empty"

        files_retrieved += 1
        print(f"Successfully downloaded keyframe image: {keyframe_id}")

    # Assert that we successfully downloaded all expected files
    assert files_retrieved == len(
        frames_to_download
    ), f"Expected to download {len(frames_to_download)} files, but only downloaded {files_retrieved}"
    print(f"Successfully completed get_result_file test - downloaded {files_retrieved} keyframe images")


class TestContentUnderstandingContentAnalyzersOperations(ContentUnderstandingClientTestBase):

    @ContentUnderstandingPreparer()
    @recorded_by_proxy
    def test_content_analyzers_begin_create_with_content_analyzer(self, contentunderstanding_endpoint: str) -> None:
        """
        Test Summary:
        - Create analyzer using ContentAnalyzer object
        - Verify analyzer creation and poller properties
        - Clean up created analyzer
        """
        client: ContentUnderstandingClient = self.create_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id_sync(client, "test_content_analyzers_begin_create_with_content_analyzer")
        created_analyzer = False

        content_analyzer = new_simple_content_analyzer_object(
            analyzer_id=analyzer_id, description=f"test analyzer: {analyzer_id}", tags={"tag1_name": "tag1_value"}
        )

        try:
            # Create analyzer using the refactored function
            poller = create_analyzer_and_assert_sync(client, analyzer_id, content_analyzer)
            created_analyzer = True

        finally:
            # Always clean up the created analyzer, even if the test fails
            delete_analyzer_and_assert_sync(client, analyzer_id, created_analyzer)

    @ContentUnderstandingPreparer()
    @recorded_by_proxy
    def test_content_analyzers_begin_create_with_json(self, contentunderstanding_endpoint: str) -> None:
        """
        Test Summary:
        - Create analyzer using JSON dictionary
        - Verify analyzer creation and poller properties
        - Clean up created analyzer
        """
        client: ContentUnderstandingClient = self.create_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id_sync(client, "test_content_analyzers_begin_create_with_json")
        created_analyzer = False

        try:
            # Create analyzer using the refactored function with JSON resource
            poller = create_analyzer_and_assert_sync(
                client,
                analyzer_id,
                {
                    "analyzerId": analyzer_id,
                    "baseAnalyzerId": "prebuilt-documentAnalyzer",
                    "config": {
                        "disableContentFiltering": False,
                        "disableFaceBlurring": False,
                        "enableFace": False,
                        "enableFormula": True,
                        "enableLayout": True,
                        "enableOcr": True,
                        "estimateFieldSourceAndConfidence": True,
                        "returnDetails": True,
                    },
                    "description": f"test analyzer: {analyzer_id}",
                    "fieldSchema": {
                        "fields": {
                            "total_amount": {
                                "description": "Total amount of this table",
                                "method": "extract",
                                "type": "number",
                            }
                        },
                        "description": "schema description here",
                        "name": "schema name here",
                    },
                    "mode": "standard",
                    "processingLocation": "global",
                    "tags": {"tag1_name": "tag1_value"},
                },
            )
            created_analyzer = True

        finally:
            # Always clean up the created analyzer, even if the test fails
            delete_analyzer_and_assert_sync(client, analyzer_id, created_analyzer)

    @ContentUnderstandingPreparer()
    @recorded_by_proxy
    def test_content_analyzers_update(self, contentunderstanding_endpoint: str) -> None:
        """
        Test Summary:
        - Create initial analyzer
        - Get analyzer before update to verify initial state
        - Update analyzer with new description and tags
        - Get analyzer after update to verify changes persisted
        - Clean up created analyzer
        """
        client: ContentUnderstandingClient = self.create_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id_sync(client, "test_content_analyzers_update")
        created_analyzer = False

        # Create initial analyzer
        initial_analyzer = new_simple_content_analyzer_object(
            analyzer_id=analyzer_id,
            description=f"Initial analyzer for update test: {analyzer_id}",
            tags={"initial_tag": "initial_value"},
        )

        try:
            # Create the initial analyzer using the refactored function
            poller = create_analyzer_and_assert_sync(client, analyzer_id, initial_analyzer)
            created_analyzer = True

            # Get the analyzer before update to verify initial state
            print(f"Getting analyzer {analyzer_id} before update")
            analyzer_before_update = client.content_analyzers.get(analyzer_id=analyzer_id)
            assert analyzer_before_update is not None
            assert analyzer_before_update.analyzer_id == analyzer_id
            assert analyzer_before_update.description == f"Initial analyzer for update test: {analyzer_id}"
            assert analyzer_before_update.tags == {"initial_tag": "initial_value"}
            print(
                f"Initial analyzer state verified - description: {analyzer_before_update.description}, tags: {analyzer_before_update.tags}"
            )

            # Create updated analyzer with only allowed properties (description and tags)
            updated_analyzer = ContentAnalyzer(
                description=f"Updated analyzer for update test: {analyzer_id}",
                tags={"initial_tag": "initial_value", "tag1_field": "updated_value"},
            )

            print(f"Updating analyzer {analyzer_id} with new tag and description")

            # Update the analyzer
            response = client.content_analyzers.update(
                analyzer_id=analyzer_id,
                resource=updated_analyzer,
            )

            # Verify the update response
            assert response is not None
            print(f"Update response: {response}")

            # Verify the updated analyzer has the new tag and updated description
            assert response.analyzer_id == analyzer_id
            assert response.tags is not None
            assert "tag1_field" in response.tags
            assert response.tags["tag1_field"] == "updated_value"
            assert response.description == f"Updated analyzer for update test: {analyzer_id}"

            print(f"Successfully updated analyzer {analyzer_id} with new tag and description")

            # Get the analyzer after update to verify the changes persisted
            print(f"Getting analyzer {analyzer_id} after update")
            analyzer_after_update = client.content_analyzers.get(analyzer_id=analyzer_id)
            assert analyzer_after_update is not None
            assert analyzer_after_update.analyzer_id == analyzer_id
            assert analyzer_after_update.description == f"Updated analyzer for update test: {analyzer_id}"
            assert analyzer_after_update.tags == {"initial_tag": "initial_value", "tag1_field": "updated_value"}
            print(
                f"Updated analyzer state verified - description: {analyzer_after_update.description}, tags: {analyzer_after_update.tags}"
            )

            # Verify the updated analyzer is in the list
            assert analyzer_in_list_sync(
                client, analyzer_id
            ), f"Updated analyzer with ID '{analyzer_id}' was not found in the list"

        finally:
            # Always clean up the created analyzer, even if the test fails
            delete_analyzer_and_assert_sync(client, analyzer_id, created_analyzer)

    @ContentUnderstandingPreparer()
    @recorded_by_proxy
    def test_content_analyzers_get(self, contentunderstanding_endpoint: str) -> None:
        """
        Test Summary:
        - Get existing prebuilt analyzer
        - Verify analyzer properties and status
        """
        client: ContentUnderstandingClient = self.create_client(endpoint=contentunderstanding_endpoint)
        response = client.content_analyzers.get(
            analyzer_id="prebuilt-documentAnalyzer",
        )
        assert response is not None
        print(response)
        assert response.analyzer_id == "prebuilt-documentAnalyzer"
        assert response.description is not None
        assert len(response.description) > 0
        assert response.status == "ready"
        assert response.created_at is not None
        assert response.config is not None

    @ContentUnderstandingPreparer()
    @recorded_by_proxy
    def test_content_analyzers_delete(self, contentunderstanding_endpoint: str) -> None:
        """
        Test Summary:
        - Create analyzer for deletion test
        - Verify analyzer exists in list before deletion
        - Delete analyzer
        - Verify analyzer no longer exists in list after deletion
        - Clean up if deletion failed
        """
        client: ContentUnderstandingClient = self.create_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id_sync(client, "test_content_analyzers_delete")
        created_analyzer = False

        # Create a simple analyzer for deletion test
        content_analyzer = new_simple_content_analyzer_object(
            analyzer_id=analyzer_id,
            description=f"test analyzer for deletion: {analyzer_id}",
            tags={"test_type": "deletion"},
        )

        try:
            # Create analyzer using the refactored function
            poller = create_analyzer_and_assert_sync(client, analyzer_id, content_analyzer)
            created_analyzer = True

            # Verify the analyzer is in the list before deletion
            assert analyzer_in_list_sync(
                client, analyzer_id
            ), f"Created analyzer with ID '{analyzer_id}' was not found in the list"
            print(f"Verified analyzer {analyzer_id} is in the list before deletion")

            # Delete the analyzer
            print(f"Deleting analyzer {analyzer_id}")
            response = client.content_analyzers.delete(analyzer_id=analyzer_id)

            # Verify the delete response
            assert response is None

            # Verify the analyzer is no longer in the list after deletion
            assert not analyzer_in_list_sync(
                client, analyzer_id
            ), f"Deleted analyzer with ID '{analyzer_id}' was found in the list"
            print(f"Verified analyzer {analyzer_id} is no longer in the list after deletion")

        finally:
            # Clean up if the analyzer was created but deletion failed
            if created_analyzer and analyzer_in_list_sync(client, analyzer_id):
                print(f"Cleaning up analyzer {analyzer_id} that was not properly deleted")
                try:
                    client.content_analyzers.delete(analyzer_id=analyzer_id)
                    assert not analyzer_in_list_sync(
                        client, analyzer_id
                    ), f"Failed to delete analyzer {analyzer_id} during cleanup"
                    print(f"Analyzer {analyzer_id} is deleted successfully during cleanup")
                except Exception as e:
                    # If cleanup fails, the test should fail
                    raise AssertionError(f"Failed to delete analyzer {analyzer_id} during cleanup: {e}") from e
            elif not created_analyzer:
                print(f"Analyzer {analyzer_id} was not created, no cleanup needed")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy
    def test_content_analyzers_list(self, contentunderstanding_endpoint: str) -> None:
        """
        Test Summary:
        - List all available analyzers
        - Verify list response contains expected prebuilt analyzers
        - Verify each analyzer has required properties
        """
        client: ContentUnderstandingClient = self.create_client(endpoint=contentunderstanding_endpoint)
        response = client.content_analyzers.list()
        result = [r for r in response]

        # Verify we get at least one analyzer in the list
        assert len(result) > 0, "Should have at least one analyzer in the list"
        print(f"Found {len(result)} analyzers")

        # Verify that the prebuilt-documentAnalyzer is in the list
        prebuilt_found = False
        for analyzer in result:
            assert hasattr(analyzer, "analyzer_id"), "Each analyzer should have analyzer_id"
            assert hasattr(analyzer, "description"), "Each analyzer should have description"
            assert hasattr(analyzer, "status"), "Each analyzer should have status"
            assert hasattr(analyzer, "created_at"), "Each analyzer should have created_at"

            if analyzer.analyzer_id == "prebuilt-documentAnalyzer":
                prebuilt_found = True
                assert analyzer.status == "ready", "prebuilt-documentAnalyzer should be ready"
                print(f"Found prebuilt-documentAnalyzer: {analyzer.description}")

        assert prebuilt_found, "prebuilt-documentAnalyzer should be in the list"
        print("List analyzers test completed successfully")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy
    def test_content_analyzers_begin_analyze_url(self, contentunderstanding_endpoint: str) -> None:
        """
        Test Summary:
        - Create simple analyzer for URL analysis
        - Begin analysis operation with URL input
        - Wait for analysis completion
        - Save analysis result to output file
        - Verify fields node exists in first result
        - Verify total_amount field exists and equals 110
        - Clean up created analyzer
        """
        client: ContentUnderstandingClient = self.create_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id_sync(client, "test_content_analyzers_begin_analyze_url")
        created_analyzer = False

        # Create a simple analyzer for URL analysis
        content_analyzer = new_simple_content_analyzer_object(
            analyzer_id=analyzer_id,
            description=f"test analyzer for URL analysis: {analyzer_id}",
            tags={"test_type": "url_analysis"},
        )

        try:
            # Create analyzer using the refactored function
            poller = create_analyzer_and_assert_sync(client, analyzer_id, content_analyzer)
            created_analyzer = True

            # Use the provided URL for the invoice PDF
            invoice_url = "https://github.com/Azure-Samples/azure-ai-content-understanding-python/raw/refs/heads/main/data/invoice.pdf"

            print(f"Starting URL analysis with analyzer {analyzer_id}")

            # Begin analysis operation with URL
            analysis_poller = client.content_analyzers.begin_analyze(
                analyzer_id=analyzer_id,
                url=invoice_url,
            )
            assert_poller_properties(analysis_poller, "Analysis poller")

            # Wait for analysis completion
            print(f"Waiting for analysis completion")
            analysis_result = analysis_poller.result()
            print(f"  Analysis completed")

            # Get test file directory for saving output
            test_file_dir = os.path.dirname(os.path.abspath(__file__))
            output_filename = save_analysis_result_to_file(
                analysis_result, "test_content_analyzers_begin_analyze_url", test_file_dir, analyzer_id
            )

            # Now assert the field results
            assert_simple_content_analyzer_result(analysis_result, "Analysis result")

        finally:
            # Always clean up the created analyzer, even if the test fails
            delete_analyzer_and_assert_sync(client, analyzer_id, created_analyzer)

    @ContentUnderstandingPreparer()
    @recorded_by_proxy
    def test_content_analyzers_begin_analyze_binary(self, contentunderstanding_endpoint: str) -> None:
        """
        Test Summary:
        - Create simple analyzer for binary analysis
        - Read sample invoice PDF file
        - Begin binary analysis operation with analyzer
        - Wait for analysis completion
        - Save analysis result to output file
        - Verify fields node exists in first result
        - Verify total_amount field exists and equals 110
        - Clean up created analyzer
        """
        client: ContentUnderstandingClient = self.create_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id_sync(client, "test_content_analyzers_begin_analyze_binary")
        created_analyzer = False

        # Create a simple analyzer for binary analysis
        content_analyzer = new_simple_content_analyzer_object(
            analyzer_id=analyzer_id,
            description=f"test analyzer for binary analysis: {analyzer_id}",
            tags={"test_type": "binary_analysis"},
        )

        try:
            # Create analyzer using the refactored function
            poller = create_analyzer_and_assert_sync(client, analyzer_id, content_analyzer)
            created_analyzer = True

            # Read the sample invoice PDF file using absolute path based on this test file's location
            test_file_dir = os.path.dirname(os.path.abspath(__file__))
            pdf_path = os.path.join(test_file_dir, "test_data", "sample_invoice.pdf")
            with open(pdf_path, "rb") as pdf_file:
                pdf_content = pdf_file.read()

            print(f"Starting binary analysis with analyzer {analyzer_id}")

            # Begin binary analysis operation
            analysis_poller = client.content_analyzers.begin_analyze(
                analyzer_id=analyzer_id,
                data=pdf_content,
                content_type="application/pdf",
            )
            assert_poller_properties(analysis_poller, "Analysis poller")

            # Wait for analysis completion
            print(f"Waiting for analysis completion")
            analysis_result = analysis_poller.result()
            print(f"  Analysis completed")

            output_filename = save_analysis_result_to_file(
                analysis_result, "test_content_analyzers_begin_analyze_binary", test_file_dir, analyzer_id
            )

            # Now assert the field results
            assert_simple_content_analyzer_result(analysis_result, "Analysis result")

        finally:
            # Always clean up the created analyzer, even if the test fails
            delete_analyzer_and_assert_sync(client, analyzer_id, created_analyzer)

    @ContentUnderstandingPreparer()
    @recorded_by_proxy
    def test_content_analyzers_get_result_file(self, contentunderstanding_endpoint: str) -> None:
        """
        Test Summary:
        - Create marketing video analyzer based on the marketing video template
        - Read FlightSimulator.mp4 file
        - Begin video analysis operation with analyzer
        - Wait for analysis completion
        - Use get_result_file to retrieve image files generated from video analysis
        - Verify image file content is returned and save to test_output
        - Clean up created analyzer
        """
        if not is_live_and_not_recording():
            return  # Skip this test in playback mode as it requires large video files is too big for test proxy to record
        client: ContentUnderstandingClient = self.create_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id_sync(client, "test_content_analyzers_get_result_file")
        created_analyzer = False

        # Create a marketing video analyzer based on the template
        video_analyzer = new_marketing_video_analyzer_object(
            analyzer_id=analyzer_id,
            description=f"marketing video analyzer for get result file test: {analyzer_id}",
            tags={"test_type": "get_result_file_video"},
        )

        try:
            # Create analyzer using the refactored function
            poller = create_analyzer_and_assert_sync(client, analyzer_id, video_analyzer)
            created_analyzer = True

            # Use the FlightSimulator.mp4 video file from remote location
            video_file_url = "https://github.com/Azure-Samples/azure-ai-content-understanding-assets/raw/refs/heads/main/videos/sdk_samples/FlightSimulator.mp4"
            print(f"Using video file from URL: {video_file_url}")

            # Get test file directory for saving output
            test_file_dir = os.path.dirname(os.path.abspath(__file__))

            print(f"Starting video analysis to get operation ID")

            # Begin video analysis operation using URL
            analysis_poller = client.content_analyzers.begin_analyze(
                analyzer_id=analyzer_id,
                url=video_file_url,
            )

            # Wait for analysis completion first
            print(f"Waiting for analysis completion")
            analysis_result = analysis_poller.result()
            print(f"Analysis completed")

            # Save the analysis result to file
            output_filename = save_analysis_result_to_file(
                analysis_result, "test_content_analyzers_get_result_file", test_file_dir, analyzer_id
            )

            # Extract operation ID for get_result_file test using custom poller's details property
            from azure.ai.contentunderstanding.operations._patch import ContentUnderstandingAnalyzeLROPoller
            assert isinstance(analysis_poller, ContentUnderstandingAnalyzeLROPoller), "Should return custom ContentUnderstandingAnalyzeLROPoller"
            
            details = analysis_poller.details
            assert "operation_id" in details, "Details should contain operation_id"
            analysis_operation_id = details["operation_id"]
            assert analysis_operation_id is not None, "Operation ID should not be None"
            assert len(analysis_operation_id) > 0, "Operation ID should not be empty"
            print(f"Analysis operation ID: {analysis_operation_id}")

            # Use the analysis result we already have from the poller to see what files are available
            result = analysis_result
            assert result is not None, "Analysis result should not be None"
            print(f"Analysis result contains {len(result.contents)} contents")

            # Use the refactored function to download keyframes by calling client.content_analyzers.get_result_file
            download_keyframes_and_assert_sync(client, analysis_operation_id, result, test_file_dir, analyzer_id)

        finally:
            # Always clean up the created analyzer, even if the test fails
            delete_analyzer_and_assert_sync(client, analyzer_id, created_analyzer)

    @ContentUnderstandingPreparer()
    @recorded_by_proxy
    def test_content_analyzers_begin_analyze_mutual_exclusivity(self, contentunderstanding_endpoint: str) -> None:
        """
        Test Summary:
        - Test that url and data parameters cannot be provided simultaneously
        - Verify that the enhanced ContentAnalyzersOperations enforces mutual exclusivity

        Expected Result:
        - ValueError should be raised when both url and data are provided
        """
        client: ContentUnderstandingClient = self.create_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id_sync(client, "test_content_analyzers_begin_analyze_mutual_exclusivity")
        created_analyzer = False

        # Create a simple analyzer for testing
        content_analyzer = new_simple_content_analyzer_object(
            analyzer_id=analyzer_id, description="Test analyzer for mutual exclusivity validation"
        )

        try:
            # Create the analyzer
            print(f"Creating analyzer {analyzer_id}")
            poller = create_analyzer_and_assert_sync(client, analyzer_id, content_analyzer)
            created_analyzer = True
            print(f"  Analyzer {analyzer_id} created")

            # Test mutual exclusivity validation
            print("Testing mutual exclusivity validation...")

            # This should raise a ValueError
            try:
                analysis_poller = client.content_analyzers.begin_analyze(
                    analyzer_id=analyzer_id, url="https://example.com/test.pdf", data=b"some binary data"
                )
                # If we get here, the test failed
                assert False, "Expected ValueError for providing both url and data"

            except ValueError as e:
                print(f"✅ Mutual exclusivity validation working: {e}")
                assert "Cannot provide both 'url' and 'data' parameters simultaneously" in str(e)

            # Test that individual parameters work
            print("Testing individual parameters work...")

            # URL only should work
            analysis_poller = client.content_analyzers.begin_analyze(
                analyzer_id=analyzer_id,
                url="https://github.com/Azure-Samples/azure-ai-content-understanding-python/raw/refs/heads/main/data/invoice.pdf",
            )
            assert_poller_properties(analysis_poller, "URL analysis poller")

            # Data only should work (if we have a local file)
            try:
                pdf_path = os.path.join(
                    os.path.dirname(os.path.abspath(__file__)), "..", "sample_files", "sample_invoice.pdf"
                )
                with open(pdf_path, "rb") as pdf_file:
                    pdf_content = pdf_file.read()

                analysis_poller = client.content_analyzers.begin_analyze(
                    analyzer_id=analyzer_id, data=pdf_content, content_type="application/pdf"
                )
                assert_poller_properties(analysis_poller, "Data analysis poller")
                print("✅ Both individual parameters work correctly")

            except FileNotFoundError:
                print("ℹ️  Local PDF file not found, skipping data-only test")

        finally:
            if created_analyzer:
                print(f"Cleaning up analyzer {analyzer_id}")
                client.content_analyzers.delete(analyzer_id=analyzer_id)
                print(f"  Analyzer {analyzer_id} deleted")

    @ContentUnderstandingPreparer()
    @recorded_by_proxy
    def test_content_analyzers_video_analysis_keyframe_times_verification(self, contentunderstanding_endpoint: str) -> None:
        """
        Test Summary:
        - Create video analyzer for KeyFrameTimesMs verification
        - Analyze video content using the same URL as in samples
        - Verify that KeyFrameTimesMs is not empty and contains valid data
        - Verify custom poller functionality and operation ID extraction
        - Clean up created analyzer
        
        This test verifies that the service issue with KeyFrameTimesMs deserialization
        has been resolved and that keyframe times are properly extracted from video content.
        """
        if not is_live_and_not_recording():
            return  # Skip this test in playback mode as it requires video analysis
        
        client: ContentUnderstandingClient = self.create_client(endpoint=contentunderstanding_endpoint)
        analyzer_id = generate_analyzer_id_sync(client, "test_content_analyzers_video_analysis_keyframe_times_verification")
        created_analyzer = False

        # Create a video analyzer for KeyFrameTimesMs verification
        video_analyzer = new_marketing_video_analyzer_object(
            analyzer_id=analyzer_id,
            description=f"video analyzer for KeyFrameTimesMs verification: {analyzer_id}",
            tags={"test_type": "keyframe_times_verification"},
        )

        try:
            # Create analyzer using the refactored function
            poller = create_analyzer_and_assert_sync(client, analyzer_id, video_analyzer)
            created_analyzer = True

            # Use the same video URL as in the sample
            video_url = "https://github.com/Azure-Samples/azure-ai-content-understanding-assets/raw/refs/heads/main/videos/sdk_samples/FlightSimulator.mp4"
            print(f"Using video file from URL: {video_url}")

            # Get test file directory for saving output
            test_file_dir = os.path.dirname(os.path.abspath(__file__))

            print(f"Starting video analysis for KeyFrameTimesMs verification")

            # Begin video analysis operation using URL
            analysis_poller = client.content_analyzers.begin_analyze(
                analyzer_id=analyzer_id,
                url=video_url,
            )

            # Verify we get the custom poller
            from azure.ai.contentunderstanding.operations._patch import ContentUnderstandingAnalyzeLROPoller
            assert isinstance(analysis_poller, ContentUnderstandingAnalyzeLROPoller), "Should return custom ContentUnderstandingAnalyzeLROPoller"

            # Test operation ID extraction
            details = analysis_poller.details
            assert "operation_id" in details, "Details should contain operation_id"
            assert details["operation_id"] is not None, "Operation ID should not be None"
            assert len(details["operation_id"]) > 0, "Operation ID should not be empty"
            assert details["operation_type"] == "analyze", "Operation type should be 'analyze'"
            print(f"✅ Operation ID extraction verified: {details['operation_id']}")

            # Wait for analysis completion
            print(f"Waiting for video analysis completion")
            analysis_result = analysis_poller.result()
            print(f"Video analysis completed")

            # Save the analysis result to file
            output_filename = save_analysis_result_to_file(
                analysis_result, "test_content_analyzers_video_analysis_keyframe_times_verification", test_file_dir, analyzer_id
            )

            # Verify the result structure
            assert analysis_result is not None, "Analysis result should not be None"
            assert hasattr(analysis_result, 'contents'), "Analysis result should have contents"
            assert len(analysis_result.contents) > 0, "Analysis result should have at least one content"

            # Find video content and verify KeyFrameTimesMs
            from azure.ai.contentunderstanding.models import AudioVisualContent
            
            video_content_found = False
            for content in analysis_result.contents:
                if isinstance(content, AudioVisualContent):
                    video_content_found = True
                    
                    # Verify KeyFrameTimesMs is not empty
                    assert hasattr(content, 'key_frame_times_ms'), "AudioVisualContent should have key_frame_times_ms attribute"
                    assert content.key_frame_times_ms is not None, "KeyFrameTimesMs should not be None"
                    assert len(content.key_frame_times_ms) > 0, f"KeyFrameTimesMs should not be empty, got: {content.key_frame_times_ms}"
                    
                    # Verify the values are reasonable (positive integers)
                    for time_ms in content.key_frame_times_ms:
                        assert isinstance(time_ms, int), f"KeyFrameTimesMs should contain integers, got: {type(time_ms)}"
                        assert time_ms >= 0, f"KeyFrameTimesMs should contain non-negative values, got: {time_ms}"
                    
                    print(f"✅ KeyFrameTimesMs verification passed: {len(content.key_frame_times_ms)} keyframes found")
                    print(f"   First few keyframes: {content.key_frame_times_ms[:5]}")
                    break
            
            assert video_content_found, "No AudioVisualContent found in analysis result"
            print("✅ Video analysis KeyFrameTimesMs verification completed successfully")

        finally:
            # Always clean up the created analyzer, even if the test fails
            delete_analyzer_and_assert_sync(client, analyzer_id, created_analyzer)
