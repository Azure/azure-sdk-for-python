# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for
# license information.
#
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is
# regenerated.
# --------------------------------------------------------------------------

from msrest.serialization import Model
from msrest.exceptions import HttpOperationError


class AppState(Model):
    """The State of the application.

    :param state: The State of the application. Possible values include:
     'NEW', 'NEW_SAVING', 'SUBMITTED', 'ACCEPTED', 'RUNNING', 'FINISHED',
     'FINISHING', 'FAILED', 'KILLED'
    :type state: str or ~azure.hdinsight.job.models.ApplicationState
    """

    _attribute_map = {
        'state': {'key': 'state', 'type': 'ApplicationState'},
    }

    def __init__(self, **kwargs):
        super(AppState, self).__init__(**kwargs)
        self.state = kwargs.get('state', None)


class CloudError(Model):
    """CloudError.
    """

    _attribute_map = {
    }


class JobDetailRootJsonObject(Model):
    """The object containing the job details.

    :param callback: The callback URL, if any.
    :type callback: object
    :param completed: The string representing completed status, for example
     'done'.
    :type completed: str
    :param exit_value: The job's exit value.
    :type exit_value: int
    :param id: The job ID.
    :type id: str
    :param msg: The message returned.
    :type msg: object
    :param parent_id: The parent job ID.
    :type parent_id: str
    :param percent_complete: The job completion percentage, for example '75%
     complete'.
    :type percent_complete: str
    :param profile: The object containing the job profile information.
    :type profile: ~azure.hdinsight.job.models.Profile
    :param status: The object containing the job status information.
    :type status: ~azure.hdinsight.job.models.Status
    :param user: The user name of the job creator.
    :type user: str
    :param userargs: The arguments passed in by the user.
    :type userargs: ~azure.hdinsight.job.models.Userargs
    """

    _attribute_map = {
        'callback': {'key': 'callback', 'type': 'object'},
        'completed': {'key': 'completed', 'type': 'str'},
        'exit_value': {'key': 'exitValue', 'type': 'int'},
        'id': {'key': 'id', 'type': 'str'},
        'msg': {'key': 'msg', 'type': 'object'},
        'parent_id': {'key': 'parentId', 'type': 'str'},
        'percent_complete': {'key': 'percentComplete', 'type': 'str'},
        'profile': {'key': 'profile', 'type': 'Profile'},
        'status': {'key': 'status', 'type': 'Status'},
        'user': {'key': 'user', 'type': 'str'},
        'userargs': {'key': 'userargs', 'type': 'Userargs'},
    }

    def __init__(self, **kwargs):
        super(JobDetailRootJsonObject, self).__init__(**kwargs)
        self.callback = kwargs.get('callback', None)
        self.completed = kwargs.get('completed', None)
        self.exit_value = kwargs.get('exit_value', None)
        self.id = kwargs.get('id', None)
        self.msg = kwargs.get('msg', None)
        self.parent_id = kwargs.get('parent_id', None)
        self.percent_complete = kwargs.get('percent_complete', None)
        self.profile = kwargs.get('profile', None)
        self.status = kwargs.get('status', None)
        self.user = kwargs.get('user', None)
        self.userargs = kwargs.get('userargs', None)


class JobID(Model):
    """The object with the Job ID.

    :param id: The job number.
    :type id: long
    :param jt_identifier: The jobTracker identifier.
    :type jt_identifier: str
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'long'},
        'jt_identifier': {'key': 'jtIdentifier', 'type': 'str'},
    }

    def __init__(self, **kwargs):
        super(JobID, self).__init__(**kwargs)
        self.id = kwargs.get('id', None)
        self.jt_identifier = kwargs.get('jt_identifier', None)


class JobListJsonObject(Model):
    """The List Job operation response.

    :param detail: The detail of the job.
    :type detail: ~azure.hdinsight.job.models.JobDetailRootJsonObject
    :param id: The Id of the job.
    :type id: str
    """

    _attribute_map = {
        'detail': {'key': 'detail', 'type': 'JobDetailRootJsonObject'},
        'id': {'key': 'id', 'type': 'str'},
    }

    def __init__(self, **kwargs):
        super(JobListJsonObject, self).__init__(**kwargs)
        self.detail = kwargs.get('detail', None)
        self.id = kwargs.get('id', None)


class JobOperationsErrorResponse(Model):
    """Describes the format of Error response.

    :param error: Error message indicating why the operation failed.
    :type error: str
    """

    _attribute_map = {
        'error': {'key': 'error', 'type': 'str'},
    }

    def __init__(self, **kwargs):
        super(JobOperationsErrorResponse, self).__init__(**kwargs)
        self.error = kwargs.get('error', None)


class JobOperationsErrorResponseException(HttpOperationError):
    """Server responsed with exception of type: 'JobOperationsErrorResponse'.

    :param deserialize: A deserializer
    :param response: Server response to be deserialized.
    """

    def __init__(self, deserialize, response, *args):

        super(JobOperationsErrorResponseException, self).__init__(deserialize, response, 'JobOperationsErrorResponse', *args)


class JobSubmissionJsonResponse(Model):
    """The job submission json response.

    :param id: The Id of the created job.
    :type id: str
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
    }

    def __init__(self, **kwargs):
        super(JobSubmissionJsonResponse, self).__init__(**kwargs)
        self.id = kwargs.get('id', None)


class Profile(Model):
    """The object containing the job profile information.

    :param job_file: The job configuration file.
    :type job_file: str
    :param job_id: The full ID of the job.
    :type job_id: str
    :param job_id1: The ID of the job.
    :type job_id1: ~azure.hdinsight.job.models.JobID
    :param job_name: The user-specified job name.
    :type job_name: str
    :param queue_name: The name of the queue to which the job is submitted.
    :type queue_name: str
    :param url: The link to the web-ui for details of the job.
    :type url: str
    :param user: The userid of the person who submitted the job.
    :type user: str
    """

    _attribute_map = {
        'job_file': {'key': 'jobFile', 'type': 'str'},
        'job_id': {'key': 'jobId', 'type': 'str'},
        'job_id1': {'key': 'jobID', 'type': 'JobID'},
        'job_name': {'key': 'jobName', 'type': 'str'},
        'queue_name': {'key': 'queueName', 'type': 'str'},
        'url': {'key': 'url', 'type': 'str'},
        'user': {'key': 'user', 'type': 'str'},
    }

    def __init__(self, **kwargs):
        super(Profile, self).__init__(**kwargs)
        self.job_file = kwargs.get('job_file', None)
        self.job_id = kwargs.get('job_id', None)
        self.job_id1 = kwargs.get('job_id1', None)
        self.job_name = kwargs.get('job_name', None)
        self.queue_name = kwargs.get('queue_name', None)
        self.url = kwargs.get('url', None)
        self.user = kwargs.get('user', None)


class SparkBatchJob(Model):
    """SparkBatchJob.

    :param id:
    :type id: int
    :param app_id:
    :type app_id: str
    :param app_info:
    :type app_info: dict[str, str]
    :param state:
    :type state: str
    :param log_lines:
    :type log_lines: list[str]
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'int'},
        'app_id': {'key': 'appId', 'type': 'str'},
        'app_info': {'key': 'appInfo', 'type': '{str}'},
        'state': {'key': 'state', 'type': 'str'},
        'log_lines': {'key': 'log', 'type': '[str]'},
    }

    def __init__(self, **kwargs):
        super(SparkBatchJob, self).__init__(**kwargs)
        self.id = kwargs.get('id', None)
        self.app_id = kwargs.get('app_id', None)
        self.app_info = kwargs.get('app_info', None)
        self.state = kwargs.get('state', None)
        self.log_lines = kwargs.get('log_lines', None)


class SparkBatchJobCollection(Model):
    """SparkBatchJobCollection.

    :param from_property:
    :type from_property: int
    :param total:
    :type total: int
    :param sessions:
    :type sessions: list[~azure.hdinsight.job.models.SparkBatchJob]
    """

    _attribute_map = {
        'from_property': {'key': 'from', 'type': 'int'},
        'total': {'key': 'total', 'type': 'int'},
        'sessions': {'key': 'sessions', 'type': '[SparkBatchJob]'},
    }

    def __init__(self, **kwargs):
        super(SparkBatchJobCollection, self).__init__(**kwargs)
        self.from_property = kwargs.get('from_property', None)
        self.total = kwargs.get('total', None)
        self.sessions = kwargs.get('sessions', None)


class SparkBatchJobRequest(Model):
    """SparkBatchJobRequest.

    :param file:
    :type file: str
    :param proxy_user:
    :type proxy_user: str
    :param class_name:
    :type class_name: str
    :param arguments:
    :type arguments: list[str]
    :param jars:
    :type jars: list[str]
    :param python_files:
    :type python_files: list[str]
    :param files:
    :type files: list[str]
    :param driver_memory:
    :type driver_memory: str
    :param driver_cores:
    :type driver_cores: int
    :param executor_memory:
    :type executor_memory: str
    :param executor_cores:
    :type executor_cores: int
    :param executor_count:
    :type executor_count: int
    :param archives:
    :type archives: list[str]
    :param queue:
    :type queue: str
    :param name:
    :type name: str
    :param configuration:
    :type configuration: dict[str, str]
    """

    _attribute_map = {
        'file': {'key': 'file', 'type': 'str'},
        'proxy_user': {'key': 'proxyUser', 'type': 'str'},
        'class_name': {'key': 'className', 'type': 'str'},
        'arguments': {'key': 'args', 'type': '[str]'},
        'jars': {'key': 'jars', 'type': '[str]'},
        'python_files': {'key': 'pyFiles', 'type': '[str]'},
        'files': {'key': 'files', 'type': '[str]'},
        'driver_memory': {'key': 'driverMemory', 'type': 'str'},
        'driver_cores': {'key': 'driverCores', 'type': 'int'},
        'executor_memory': {'key': 'executorMemory', 'type': 'str'},
        'executor_cores': {'key': 'executorCores', 'type': 'int'},
        'executor_count': {'key': 'numExecutors', 'type': 'int'},
        'archives': {'key': 'archives', 'type': '[str]'},
        'queue': {'key': 'queue', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'configuration': {'key': 'conf', 'type': '{str}'},
    }

    def __init__(self, **kwargs):
        super(SparkBatchJobRequest, self).__init__(**kwargs)
        self.file = kwargs.get('file', None)
        self.proxy_user = kwargs.get('proxy_user', None)
        self.class_name = kwargs.get('class_name', None)
        self.arguments = kwargs.get('arguments', None)
        self.jars = kwargs.get('jars', None)
        self.python_files = kwargs.get('python_files', None)
        self.files = kwargs.get('files', None)
        self.driver_memory = kwargs.get('driver_memory', None)
        self.driver_cores = kwargs.get('driver_cores', None)
        self.executor_memory = kwargs.get('executor_memory', None)
        self.executor_cores = kwargs.get('executor_cores', None)
        self.executor_count = kwargs.get('executor_count', None)
        self.archives = kwargs.get('archives', None)
        self.queue = kwargs.get('queue', None)
        self.name = kwargs.get('name', None)
        self.configuration = kwargs.get('configuration', None)


class SparkJobDeletedResult(Model):
    """SparkJobDeletedResult.

    :param deleted_message:
    :type deleted_message: str
    """

    _attribute_map = {
        'deleted_message': {'key': 'msg', 'type': 'str'},
    }

    def __init__(self, **kwargs):
        super(SparkJobDeletedResult, self).__init__(**kwargs)
        self.deleted_message = kwargs.get('deleted_message', None)


class SparkJobLog(Model):
    """SparkJobLog.

    :param id:
    :type id: int
    :param from_property:
    :type from_property: int
    :param size:
    :type size: int
    :param total:
    :type total: long
    :param log_lines:
    :type log_lines: list[str]
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'int'},
        'from_property': {'key': 'from', 'type': 'int'},
        'size': {'key': 'size', 'type': 'int'},
        'total': {'key': 'total', 'type': 'long'},
        'log_lines': {'key': 'log', 'type': '[str]'},
    }

    def __init__(self, **kwargs):
        super(SparkJobLog, self).__init__(**kwargs)
        self.id = kwargs.get('id', None)
        self.from_property = kwargs.get('from_property', None)
        self.size = kwargs.get('size', None)
        self.total = kwargs.get('total', None)
        self.log_lines = kwargs.get('log_lines', None)


class SparkJobState(Model):
    """SparkJobState.

    :param id:
    :type id: int
    :param state:
    :type state: str
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'int'},
        'state': {'key': 'state', 'type': 'str'},
    }

    def __init__(self, **kwargs):
        super(SparkJobState, self).__init__(**kwargs)
        self.id = kwargs.get('id', None)
        self.state = kwargs.get('state', None)


class SparkSessionCollection(Model):
    """SparkSessionCollection.

    :param from_property:
    :type from_property: int
    :param total:
    :type total: int
    :param sessions:
    :type sessions: list[~azure.hdinsight.job.models.SparkSessionJob]
    """

    _attribute_map = {
        'from_property': {'key': 'from', 'type': 'int'},
        'total': {'key': 'total', 'type': 'int'},
        'sessions': {'key': 'sessions', 'type': '[SparkSessionJob]'},
    }

    def __init__(self, **kwargs):
        super(SparkSessionCollection, self).__init__(**kwargs)
        self.from_property = kwargs.get('from_property', None)
        self.total = kwargs.get('total', None)
        self.sessions = kwargs.get('sessions', None)


class SparkSessionJob(Model):
    """SparkSessionJob.

    :param id:
    :type id: int
    :param app_id:
    :type app_id: str
    :param owner:
    :type owner: str
    :param proxy_user:
    :type proxy_user: str
    :param kind:
    :type kind: str
    :param log_lines:
    :type log_lines: list[str]
    :param state:
    :type state: str
    :param app_info:
    :type app_info: dict[str, str]
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'int'},
        'app_id': {'key': 'appId', 'type': 'str'},
        'owner': {'key': 'owner', 'type': 'str'},
        'proxy_user': {'key': 'proxyUser', 'type': 'str'},
        'kind': {'key': 'kind', 'type': 'str'},
        'log_lines': {'key': 'log', 'type': '[str]'},
        'state': {'key': 'state', 'type': 'str'},
        'app_info': {'key': 'appInfo', 'type': '{str}'},
    }

    def __init__(self, **kwargs):
        super(SparkSessionJob, self).__init__(**kwargs)
        self.id = kwargs.get('id', None)
        self.app_id = kwargs.get('app_id', None)
        self.owner = kwargs.get('owner', None)
        self.proxy_user = kwargs.get('proxy_user', None)
        self.kind = kwargs.get('kind', None)
        self.log_lines = kwargs.get('log_lines', None)
        self.state = kwargs.get('state', None)
        self.app_info = kwargs.get('app_info', None)


class SparkSessionJobRequest(Model):
    """SparkSessionJobRequest.

    :param kind: Possible values include: 'spark', 'pyspark', 'sparkr', 'sql'
    :type kind: str or ~azure.hdinsight.job.models.SessionJobKind
    :param proxy_user:
    :type proxy_user: str
    :param jars:
    :type jars: list[str]
    :param python_files:
    :type python_files: list[str]
    :param files:
    :type files: list[str]
    :param driver_memory:
    :type driver_memory: str
    :param driver_cores:
    :type driver_cores: int
    :param executor_memory:
    :type executor_memory: str
    :param executor_cores:
    :type executor_cores: int
    :param executor_count:
    :type executor_count: int
    :param archives:
    :type archives: list[str]
    :param queue:
    :type queue: str
    :param name:
    :type name: str
    :param configuration:
    :type configuration: dict[str, str]
    :param heartbeat_timeout_in_second:
    :type heartbeat_timeout_in_second: int
    """

    _attribute_map = {
        'kind': {'key': 'kind', 'type': 'str'},
        'proxy_user': {'key': 'proxyUser', 'type': 'str'},
        'jars': {'key': 'jars', 'type': '[str]'},
        'python_files': {'key': 'pyFiles', 'type': '[str]'},
        'files': {'key': 'files', 'type': '[str]'},
        'driver_memory': {'key': 'driverMemory', 'type': 'str'},
        'driver_cores': {'key': 'driverCores', 'type': 'int'},
        'executor_memory': {'key': 'executorMemory', 'type': 'str'},
        'executor_cores': {'key': 'executorCores', 'type': 'int'},
        'executor_count': {'key': 'numExecutors', 'type': 'int'},
        'archives': {'key': 'archives', 'type': '[str]'},
        'queue': {'key': 'queue', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'configuration': {'key': 'conf', 'type': '{str}'},
        'heartbeat_timeout_in_second': {'key': 'heartbeatTimeoutInSecond', 'type': 'int'},
    }

    def __init__(self, **kwargs):
        super(SparkSessionJobRequest, self).__init__(**kwargs)
        self.kind = kwargs.get('kind', None)
        self.proxy_user = kwargs.get('proxy_user', None)
        self.jars = kwargs.get('jars', None)
        self.python_files = kwargs.get('python_files', None)
        self.files = kwargs.get('files', None)
        self.driver_memory = kwargs.get('driver_memory', None)
        self.driver_cores = kwargs.get('driver_cores', None)
        self.executor_memory = kwargs.get('executor_memory', None)
        self.executor_cores = kwargs.get('executor_cores', None)
        self.executor_count = kwargs.get('executor_count', None)
        self.archives = kwargs.get('archives', None)
        self.queue = kwargs.get('queue', None)
        self.name = kwargs.get('name', None)
        self.configuration = kwargs.get('configuration', None)
        self.heartbeat_timeout_in_second = kwargs.get('heartbeat_timeout_in_second', None)


class SparkStatement(Model):
    """SparkStatement.

    :param id:
    :type id: int
    :param code:
    :type code: str
    :param state:
    :type state: str
    :param output:
    :type output: ~azure.hdinsight.job.models.SparkStatementOutput
    :param progress:
    :type progress: float
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'int'},
        'code': {'key': 'code', 'type': 'str'},
        'state': {'key': 'state', 'type': 'str'},
        'output': {'key': 'output', 'type': 'SparkStatementOutput'},
        'progress': {'key': 'progress', 'type': 'float'},
    }

    def __init__(self, **kwargs):
        super(SparkStatement, self).__init__(**kwargs)
        self.id = kwargs.get('id', None)
        self.code = kwargs.get('code', None)
        self.state = kwargs.get('state', None)
        self.output = kwargs.get('output', None)
        self.progress = kwargs.get('progress', None)


class SparkStatementCancellationResult(Model):
    """SparkStatementCancellationResult.

    :param cancel_message:
    :type cancel_message: str
    """

    _attribute_map = {
        'cancel_message': {'key': 'msg', 'type': 'str'},
    }

    def __init__(self, **kwargs):
        super(SparkStatementCancellationResult, self).__init__(**kwargs)
        self.cancel_message = kwargs.get('cancel_message', None)


class SparkStatementCollection(Model):
    """SparkStatementCollection.

    :param statements:
    :type statements: list[~azure.hdinsight.job.models.SparkStatement]
    """

    _attribute_map = {
        'statements': {'key': 'statements', 'type': '[SparkStatement]'},
    }

    def __init__(self, **kwargs):
        super(SparkStatementCollection, self).__init__(**kwargs)
        self.statements = kwargs.get('statements', None)


class SparkStatementOutput(Model):
    """SparkStatementOutput.

    :param status:
    :type status: str
    :param execution_count:
    :type execution_count: int
    :param data:
    :type data: object
    """

    _attribute_map = {
        'status': {'key': 'status', 'type': 'str'},
        'execution_count': {'key': 'execution_count', 'type': 'int'},
        'data': {'key': 'data', 'type': 'object'},
    }

    def __init__(self, **kwargs):
        super(SparkStatementOutput, self).__init__(**kwargs)
        self.status = kwargs.get('status', None)
        self.execution_count = kwargs.get('execution_count', None)
        self.data = kwargs.get('data', None)


class SparkStatementRequest(Model):
    """SparkStatementRequest.

    :param code:
    :type code: str
    :param kind:
    :type kind: str
    """

    _attribute_map = {
        'code': {'key': 'code', 'type': 'str'},
        'kind': {'key': 'kind', 'type': 'str'},
    }

    def __init__(self, **kwargs):
        super(SparkStatementRequest, self).__init__(**kwargs)
        self.code = kwargs.get('code', None)
        self.kind = kwargs.get('kind', None)


class Status(Model):
    """Gets or sets the object containing the job status information.

    :param cleanup_progress: The progress made on the cleanup.
    :type cleanup_progress: float
    :param failure_info: The information about any failures that have
     occurred.
    :type failure_info: str
    :param finish_time: The time at which the job completed. It is an integer
     in milliseconds, as a Unix timestamp relative to 1/1/1970 00:00:00.
    :type finish_time: long
    :param history_file: The history file of the job.
    :type history_file: str
    :param job_ac_ls: The ACLs of the job.
    :type job_ac_ls: object
    :param job_complete: Whether or not the job has completed.
    :type job_complete: bool
    :param job_file: The job configuration file.
    :type job_file: str
    :param job_id: The full ID of the job.
    :type job_id: str
    :param job_id1: The ID of the job.
    :type job_id1: ~azure.hdinsight.job.models.JobID
    :param job_name: The user-specified job name.
    :type job_name: str
    :param job_priority: The priority of the job.
    :type job_priority: str
    :param map_progress: The progress made on the maps.
    :type map_progress: float
    :param needed_mem: The amount of memory needed for the job.
    :type needed_mem: long
    :param num_reserved_slots: The number of slots reserved.
    :type num_reserved_slots: int
    :param num_used_slots: The number of slots used for the job.
    :type num_used_slots: int
    :param priority: The priority of the job.
    :type priority: str
    :param queue: The job queue name.
    :type queue: str
    :param reduce_progress: The progress made on the reduces.
    :type reduce_progress: float
    :param reserved_mem: The amount of memory reserved for the job.
    :type reserved_mem: long
    :param retired: Whether or not the job has been retired.
    :type retired: bool
    :param run_state: The current state of the job.
    :type run_state: int
    :param scheduling_info: The information about the scheduling of the job.
    :type scheduling_info: str
    :param setup_progress: The progress made on the setup.
    :type setup_progress: float
    :param start_time: The time at which the job started. It is an integer in
     milliseconds, as a Unix timestamp relative to 1/1/1970 00:00:00.
    :type start_time: long
    :param state: The state of the job.
    :type state: str
    :param tracking_url: The link to the web-ui for details of the job.
    :type tracking_url: str
    :param uber: Whether job running in uber mode.
    :type uber: bool
    :param used_mem: The amount of memory used by the job.
    :type used_mem: long
    :param username: The userid of the person who submitted the job.
    :type username: str
    """

    _attribute_map = {
        'cleanup_progress': {'key': 'cleanupProgress', 'type': 'float'},
        'failure_info': {'key': 'failureInfo', 'type': 'str'},
        'finish_time': {'key': 'finishTime', 'type': 'long'},
        'history_file': {'key': 'historyFile', 'type': 'str'},
        'job_ac_ls': {'key': 'jobACLs', 'type': 'object'},
        'job_complete': {'key': 'jobComplete', 'type': 'bool'},
        'job_file': {'key': 'jobFile', 'type': 'str'},
        'job_id': {'key': 'jobId', 'type': 'str'},
        'job_id1': {'key': 'jobID', 'type': 'JobID'},
        'job_name': {'key': 'jobName', 'type': 'str'},
        'job_priority': {'key': 'jobPriority', 'type': 'str'},
        'map_progress': {'key': 'mapProgress', 'type': 'float'},
        'needed_mem': {'key': 'neededMem', 'type': 'long'},
        'num_reserved_slots': {'key': 'numReservedSlots', 'type': 'int'},
        'num_used_slots': {'key': 'numUsedSlots', 'type': 'int'},
        'priority': {'key': 'priority', 'type': 'str'},
        'queue': {'key': 'queue', 'type': 'str'},
        'reduce_progress': {'key': 'reduceProgress', 'type': 'float'},
        'reserved_mem': {'key': 'reservedMem', 'type': 'long'},
        'retired': {'key': 'retired', 'type': 'bool'},
        'run_state': {'key': 'runState', 'type': 'int'},
        'scheduling_info': {'key': 'schedulingInfo', 'type': 'str'},
        'setup_progress': {'key': 'setupProgress', 'type': 'float'},
        'start_time': {'key': 'startTime', 'type': 'long'},
        'state': {'key': 'state', 'type': 'str'},
        'tracking_url': {'key': 'trackingUrl', 'type': 'str'},
        'uber': {'key': 'uber', 'type': 'bool'},
        'used_mem': {'key': 'usedMem', 'type': 'long'},
        'username': {'key': 'username', 'type': 'str'},
    }

    def __init__(self, **kwargs):
        super(Status, self).__init__(**kwargs)
        self.cleanup_progress = kwargs.get('cleanup_progress', None)
        self.failure_info = kwargs.get('failure_info', None)
        self.finish_time = kwargs.get('finish_time', None)
        self.history_file = kwargs.get('history_file', None)
        self.job_ac_ls = kwargs.get('job_ac_ls', None)
        self.job_complete = kwargs.get('job_complete', None)
        self.job_file = kwargs.get('job_file', None)
        self.job_id = kwargs.get('job_id', None)
        self.job_id1 = kwargs.get('job_id1', None)
        self.job_name = kwargs.get('job_name', None)
        self.job_priority = kwargs.get('job_priority', None)
        self.map_progress = kwargs.get('map_progress', None)
        self.needed_mem = kwargs.get('needed_mem', None)
        self.num_reserved_slots = kwargs.get('num_reserved_slots', None)
        self.num_used_slots = kwargs.get('num_used_slots', None)
        self.priority = kwargs.get('priority', None)
        self.queue = kwargs.get('queue', None)
        self.reduce_progress = kwargs.get('reduce_progress', None)
        self.reserved_mem = kwargs.get('reserved_mem', None)
        self.retired = kwargs.get('retired', None)
        self.run_state = kwargs.get('run_state', None)
        self.scheduling_info = kwargs.get('scheduling_info', None)
        self.setup_progress = kwargs.get('setup_progress', None)
        self.start_time = kwargs.get('start_time', None)
        self.state = kwargs.get('state', None)
        self.tracking_url = kwargs.get('tracking_url', None)
        self.uber = kwargs.get('uber', None)
        self.used_mem = kwargs.get('used_mem', None)
        self.username = kwargs.get('username', None)


class Userargs(Model):
    """Gets or sets the object containing the user arguments.

    Variables are only populated by the server, and will be ignored when
    sending a request.

    :ivar arg: The list of args defined by the user.
    :vartype arg: list[str]
    :param callback: The callback URL, if any.
    :type callback: object
    :ivar define: The define properties defined by the user.
    :vartype define: list[str]
    :param enablelog: Whether or not the user enabled logs.
    :type enablelog: str
    :param execute: The query defined by the user.
    :type execute: str
    :param file: The query file provided by the user.
    :type file: object
    :param files: The files defined by the user.
    :type files: object
    :param jar: The JAR file provided by the user.
    :type jar: str
    :param statusdir: The status directory defined by the user.
    :type statusdir: object
    """

    _validation = {
        'arg': {'readonly': True},
        'define': {'readonly': True},
    }

    _attribute_map = {
        'arg': {'key': 'arg', 'type': '[str]'},
        'callback': {'key': 'callback', 'type': 'object'},
        'define': {'key': 'define', 'type': '[str]'},
        'enablelog': {'key': 'enablelog', 'type': 'str'},
        'execute': {'key': 'execute', 'type': 'str'},
        'file': {'key': 'file', 'type': 'object'},
        'files': {'key': 'files', 'type': 'object'},
        'jar': {'key': 'jar', 'type': 'str'},
        'statusdir': {'key': 'statusdir', 'type': 'object'},
    }

    def __init__(self, **kwargs):
        super(Userargs, self).__init__(**kwargs)
        self.arg = None
        self.callback = kwargs.get('callback', None)
        self.define = None
        self.enablelog = kwargs.get('enablelog', None)
        self.execute = kwargs.get('execute', None)
        self.file = kwargs.get('file', None)
        self.files = kwargs.get('files', None)
        self.jar = kwargs.get('jar', None)
        self.statusdir = kwargs.get('statusdir', None)
