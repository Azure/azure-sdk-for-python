# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for
# license information.
#
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is
# regenerated.
# --------------------------------------------------------------------------

from msrest.serialization import Model
from msrest.exceptions import HttpOperationError


class AppState(Model):
    """The State of the application.

    :param state: The State of the application. Possible values include:
     'NEW', 'NEW_SAVING', 'SUBMITTED', 'ACCEPTED', 'RUNNING', 'FINISHED',
     'FINISHING', 'FAILED', 'KILLED'
    :type state: str or ~azure.hdinsight.job.models.ApplicationState
    """

    _attribute_map = {
        'state': {'key': 'state', 'type': 'ApplicationState'},
    }

    def __init__(self, *, state=None, **kwargs) -> None:
        super(AppState, self).__init__(**kwargs)
        self.state = state


class CloudError(Model):
    """CloudError.
    """

    _attribute_map = {
    }


class JobDetailRootJsonObject(Model):
    """The object containing the job details.

    :param callback: The callback URL, if any.
    :type callback: object
    :param completed: The string representing completed status, for example
     'done'.
    :type completed: str
    :param exit_value: The job's exit value.
    :type exit_value: int
    :param id: The job ID.
    :type id: str
    :param msg: The message returned.
    :type msg: object
    :param parent_id: The parent job ID.
    :type parent_id: str
    :param percent_complete: The job completion percentage, for example '75%
     complete'.
    :type percent_complete: str
    :param profile: The object containing the job profile information.
    :type profile: ~azure.hdinsight.job.models.Profile
    :param status: The object containing the job status information.
    :type status: ~azure.hdinsight.job.models.Status
    :param user: The user name of the job creator.
    :type user: str
    :param userargs: The arguments passed in by the user.
    :type userargs: ~azure.hdinsight.job.models.Userargs
    """

    _attribute_map = {
        'callback': {'key': 'callback', 'type': 'object'},
        'completed': {'key': 'completed', 'type': 'str'},
        'exit_value': {'key': 'exitValue', 'type': 'int'},
        'id': {'key': 'id', 'type': 'str'},
        'msg': {'key': 'msg', 'type': 'object'},
        'parent_id': {'key': 'parentId', 'type': 'str'},
        'percent_complete': {'key': 'percentComplete', 'type': 'str'},
        'profile': {'key': 'profile', 'type': 'Profile'},
        'status': {'key': 'status', 'type': 'Status'},
        'user': {'key': 'user', 'type': 'str'},
        'userargs': {'key': 'userargs', 'type': 'Userargs'},
    }

    def __init__(self, *, callback=None, completed: str=None, exit_value: int=None, id: str=None, msg=None, parent_id: str=None, percent_complete: str=None, profile=None, status=None, user: str=None, userargs=None, **kwargs) -> None:
        super(JobDetailRootJsonObject, self).__init__(**kwargs)
        self.callback = callback
        self.completed = completed
        self.exit_value = exit_value
        self.id = id
        self.msg = msg
        self.parent_id = parent_id
        self.percent_complete = percent_complete
        self.profile = profile
        self.status = status
        self.user = user
        self.userargs = userargs


class JobID(Model):
    """The object with the Job ID.

    :param id: The job number.
    :type id: long
    :param jt_identifier: The jobTracker identifier.
    :type jt_identifier: str
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'long'},
        'jt_identifier': {'key': 'jtIdentifier', 'type': 'str'},
    }

    def __init__(self, *, id: int=None, jt_identifier: str=None, **kwargs) -> None:
        super(JobID, self).__init__(**kwargs)
        self.id = id
        self.jt_identifier = jt_identifier


class JobListJsonObject(Model):
    """The List Job operation response.

    :param detail: The detail of the job.
    :type detail: ~azure.hdinsight.job.models.JobDetailRootJsonObject
    :param id: The Id of the job.
    :type id: str
    """

    _attribute_map = {
        'detail': {'key': 'detail', 'type': 'JobDetailRootJsonObject'},
        'id': {'key': 'id', 'type': 'str'},
    }

    def __init__(self, *, detail=None, id: str=None, **kwargs) -> None:
        super(JobListJsonObject, self).__init__(**kwargs)
        self.detail = detail
        self.id = id


class JobOperationsErrorResponse(Model):
    """Describes the format of Error response.

    :param error: Error message indicating why the operation failed.
    :type error: str
    """

    _attribute_map = {
        'error': {'key': 'error', 'type': 'str'},
    }

    def __init__(self, *, error: str=None, **kwargs) -> None:
        super(JobOperationsErrorResponse, self).__init__(**kwargs)
        self.error = error


class JobOperationsErrorResponseException(HttpOperationError):
    """Server responsed with exception of type: 'JobOperationsErrorResponse'.

    :param deserialize: A deserializer
    :param response: Server response to be deserialized.
    """

    def __init__(self, deserialize, response, *args):

        super(JobOperationsErrorResponseException, self).__init__(deserialize, response, 'JobOperationsErrorResponse', *args)


class JobSubmissionJsonResponse(Model):
    """The job submission json response.

    :param id: The Id of the created job.
    :type id: str
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'str'},
    }

    def __init__(self, *, id: str=None, **kwargs) -> None:
        super(JobSubmissionJsonResponse, self).__init__(**kwargs)
        self.id = id


class Profile(Model):
    """The object containing the job profile information.

    :param job_file: The job configuration file.
    :type job_file: str
    :param job_id: The full ID of the job.
    :type job_id: str
    :param job_id1: The ID of the job.
    :type job_id1: ~azure.hdinsight.job.models.JobID
    :param job_name: The user-specified job name.
    :type job_name: str
    :param queue_name: The name of the queue to which the job is submitted.
    :type queue_name: str
    :param url: The link to the web-ui for details of the job.
    :type url: str
    :param user: The userid of the person who submitted the job.
    :type user: str
    """

    _attribute_map = {
        'job_file': {'key': 'jobFile', 'type': 'str'},
        'job_id': {'key': 'jobId', 'type': 'str'},
        'job_id1': {'key': 'jobID', 'type': 'JobID'},
        'job_name': {'key': 'jobName', 'type': 'str'},
        'queue_name': {'key': 'queueName', 'type': 'str'},
        'url': {'key': 'url', 'type': 'str'},
        'user': {'key': 'user', 'type': 'str'},
    }

    def __init__(self, *, job_file: str=None, job_id: str=None, job_id1=None, job_name: str=None, queue_name: str=None, url: str=None, user: str=None, **kwargs) -> None:
        super(Profile, self).__init__(**kwargs)
        self.job_file = job_file
        self.job_id = job_id
        self.job_id1 = job_id1
        self.job_name = job_name
        self.queue_name = queue_name
        self.url = url
        self.user = user


class SparkBatchJob(Model):
    """SparkBatchJob.

    :param id:
    :type id: int
    :param app_id:
    :type app_id: str
    :param app_info:
    :type app_info: dict[str, str]
    :param state:
    :type state: str
    :param log_lines:
    :type log_lines: list[str]
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'int'},
        'app_id': {'key': 'appId', 'type': 'str'},
        'app_info': {'key': 'appInfo', 'type': '{str}'},
        'state': {'key': 'state', 'type': 'str'},
        'log_lines': {'key': 'log', 'type': '[str]'},
    }

    def __init__(self, *, id: int=None, app_id: str=None, app_info=None, state: str=None, log_lines=None, **kwargs) -> None:
        super(SparkBatchJob, self).__init__(**kwargs)
        self.id = id
        self.app_id = app_id
        self.app_info = app_info
        self.state = state
        self.log_lines = log_lines


class SparkBatchJobCollection(Model):
    """SparkBatchJobCollection.

    :param from_property:
    :type from_property: int
    :param total:
    :type total: int
    :param sessions:
    :type sessions: list[~azure.hdinsight.job.models.SparkBatchJob]
    """

    _attribute_map = {
        'from_property': {'key': 'from', 'type': 'int'},
        'total': {'key': 'total', 'type': 'int'},
        'sessions': {'key': 'sessions', 'type': '[SparkBatchJob]'},
    }

    def __init__(self, *, from_property: int=None, total: int=None, sessions=None, **kwargs) -> None:
        super(SparkBatchJobCollection, self).__init__(**kwargs)
        self.from_property = from_property
        self.total = total
        self.sessions = sessions


class SparkBatchJobRequest(Model):
    """SparkBatchJobRequest.

    :param file:
    :type file: str
    :param proxy_user:
    :type proxy_user: str
    :param class_name:
    :type class_name: str
    :param arguments:
    :type arguments: list[str]
    :param jars:
    :type jars: list[str]
    :param python_files:
    :type python_files: list[str]
    :param files:
    :type files: list[str]
    :param driver_memory:
    :type driver_memory: str
    :param driver_cores:
    :type driver_cores: int
    :param executor_memory:
    :type executor_memory: str
    :param executor_cores:
    :type executor_cores: int
    :param executor_count:
    :type executor_count: int
    :param archives:
    :type archives: list[str]
    :param queue:
    :type queue: str
    :param name:
    :type name: str
    :param configuration:
    :type configuration: dict[str, str]
    """

    _attribute_map = {
        'file': {'key': 'file', 'type': 'str'},
        'proxy_user': {'key': 'proxyUser', 'type': 'str'},
        'class_name': {'key': 'className', 'type': 'str'},
        'arguments': {'key': 'args', 'type': '[str]'},
        'jars': {'key': 'jars', 'type': '[str]'},
        'python_files': {'key': 'pyFiles', 'type': '[str]'},
        'files': {'key': 'files', 'type': '[str]'},
        'driver_memory': {'key': 'driverMemory', 'type': 'str'},
        'driver_cores': {'key': 'driverCores', 'type': 'int'},
        'executor_memory': {'key': 'executorMemory', 'type': 'str'},
        'executor_cores': {'key': 'executorCores', 'type': 'int'},
        'executor_count': {'key': 'numExecutors', 'type': 'int'},
        'archives': {'key': 'archives', 'type': '[str]'},
        'queue': {'key': 'queue', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'configuration': {'key': 'conf', 'type': '{str}'},
    }

    def __init__(self, *, file: str=None, proxy_user: str=None, class_name: str=None, arguments=None, jars=None, python_files=None, files=None, driver_memory: str=None, driver_cores: int=None, executor_memory: str=None, executor_cores: int=None, executor_count: int=None, archives=None, queue: str=None, name: str=None, configuration=None, **kwargs) -> None:
        super(SparkBatchJobRequest, self).__init__(**kwargs)
        self.file = file
        self.proxy_user = proxy_user
        self.class_name = class_name
        self.arguments = arguments
        self.jars = jars
        self.python_files = python_files
        self.files = files
        self.driver_memory = driver_memory
        self.driver_cores = driver_cores
        self.executor_memory = executor_memory
        self.executor_cores = executor_cores
        self.executor_count = executor_count
        self.archives = archives
        self.queue = queue
        self.name = name
        self.configuration = configuration


class SparkJobDeletedResult(Model):
    """SparkJobDeletedResult.

    :param deleted_message:
    :type deleted_message: str
    """

    _attribute_map = {
        'deleted_message': {'key': 'msg', 'type': 'str'},
    }

    def __init__(self, *, deleted_message: str=None, **kwargs) -> None:
        super(SparkJobDeletedResult, self).__init__(**kwargs)
        self.deleted_message = deleted_message


class SparkJobLog(Model):
    """SparkJobLog.

    :param id:
    :type id: int
    :param from_property:
    :type from_property: int
    :param size:
    :type size: int
    :param total:
    :type total: long
    :param log_lines:
    :type log_lines: list[str]
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'int'},
        'from_property': {'key': 'from', 'type': 'int'},
        'size': {'key': 'size', 'type': 'int'},
        'total': {'key': 'total', 'type': 'long'},
        'log_lines': {'key': 'log', 'type': '[str]'},
    }

    def __init__(self, *, id: int=None, from_property: int=None, size: int=None, total: int=None, log_lines=None, **kwargs) -> None:
        super(SparkJobLog, self).__init__(**kwargs)
        self.id = id
        self.from_property = from_property
        self.size = size
        self.total = total
        self.log_lines = log_lines


class SparkJobState(Model):
    """SparkJobState.

    :param id:
    :type id: int
    :param state:
    :type state: str
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'int'},
        'state': {'key': 'state', 'type': 'str'},
    }

    def __init__(self, *, id: int=None, state: str=None, **kwargs) -> None:
        super(SparkJobState, self).__init__(**kwargs)
        self.id = id
        self.state = state


class SparkSessionCollection(Model):
    """SparkSessionCollection.

    :param from_property:
    :type from_property: int
    :param total:
    :type total: int
    :param sessions:
    :type sessions: list[~azure.hdinsight.job.models.SparkSessionJob]
    """

    _attribute_map = {
        'from_property': {'key': 'from', 'type': 'int'},
        'total': {'key': 'total', 'type': 'int'},
        'sessions': {'key': 'sessions', 'type': '[SparkSessionJob]'},
    }

    def __init__(self, *, from_property: int=None, total: int=None, sessions=None, **kwargs) -> None:
        super(SparkSessionCollection, self).__init__(**kwargs)
        self.from_property = from_property
        self.total = total
        self.sessions = sessions


class SparkSessionJob(Model):
    """SparkSessionJob.

    :param id:
    :type id: int
    :param app_id:
    :type app_id: str
    :param owner:
    :type owner: str
    :param proxy_user:
    :type proxy_user: str
    :param kind:
    :type kind: str
    :param log_lines:
    :type log_lines: list[str]
    :param state:
    :type state: str
    :param app_info:
    :type app_info: dict[str, str]
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'int'},
        'app_id': {'key': 'appId', 'type': 'str'},
        'owner': {'key': 'owner', 'type': 'str'},
        'proxy_user': {'key': 'proxyUser', 'type': 'str'},
        'kind': {'key': 'kind', 'type': 'str'},
        'log_lines': {'key': 'log', 'type': '[str]'},
        'state': {'key': 'state', 'type': 'str'},
        'app_info': {'key': 'appInfo', 'type': '{str}'},
    }

    def __init__(self, *, id: int=None, app_id: str=None, owner: str=None, proxy_user: str=None, kind: str=None, log_lines=None, state: str=None, app_info=None, **kwargs) -> None:
        super(SparkSessionJob, self).__init__(**kwargs)
        self.id = id
        self.app_id = app_id
        self.owner = owner
        self.proxy_user = proxy_user
        self.kind = kind
        self.log_lines = log_lines
        self.state = state
        self.app_info = app_info


class SparkSessionJobRequest(Model):
    """SparkSessionJobRequest.

    :param kind: Possible values include: 'spark', 'pyspark', 'sparkr', 'sql'
    :type kind: str or ~azure.hdinsight.job.models.SessionJobKind
    :param proxy_user:
    :type proxy_user: str
    :param jars:
    :type jars: list[str]
    :param python_files:
    :type python_files: list[str]
    :param files:
    :type files: list[str]
    :param driver_memory:
    :type driver_memory: str
    :param driver_cores:
    :type driver_cores: int
    :param executor_memory:
    :type executor_memory: str
    :param executor_cores:
    :type executor_cores: int
    :param executor_count:
    :type executor_count: int
    :param archives:
    :type archives: list[str]
    :param queue:
    :type queue: str
    :param name:
    :type name: str
    :param configuration:
    :type configuration: dict[str, str]
    :param heartbeat_timeout_in_second:
    :type heartbeat_timeout_in_second: int
    """

    _attribute_map = {
        'kind': {'key': 'kind', 'type': 'str'},
        'proxy_user': {'key': 'proxyUser', 'type': 'str'},
        'jars': {'key': 'jars', 'type': '[str]'},
        'python_files': {'key': 'pyFiles', 'type': '[str]'},
        'files': {'key': 'files', 'type': '[str]'},
        'driver_memory': {'key': 'driverMemory', 'type': 'str'},
        'driver_cores': {'key': 'driverCores', 'type': 'int'},
        'executor_memory': {'key': 'executorMemory', 'type': 'str'},
        'executor_cores': {'key': 'executorCores', 'type': 'int'},
        'executor_count': {'key': 'numExecutors', 'type': 'int'},
        'archives': {'key': 'archives', 'type': '[str]'},
        'queue': {'key': 'queue', 'type': 'str'},
        'name': {'key': 'name', 'type': 'str'},
        'configuration': {'key': 'conf', 'type': '{str}'},
        'heartbeat_timeout_in_second': {'key': 'heartbeatTimeoutInSecond', 'type': 'int'},
    }

    def __init__(self, *, kind=None, proxy_user: str=None, jars=None, python_files=None, files=None, driver_memory: str=None, driver_cores: int=None, executor_memory: str=None, executor_cores: int=None, executor_count: int=None, archives=None, queue: str=None, name: str=None, configuration=None, heartbeat_timeout_in_second: int=None, **kwargs) -> None:
        super(SparkSessionJobRequest, self).__init__(**kwargs)
        self.kind = kind
        self.proxy_user = proxy_user
        self.jars = jars
        self.python_files = python_files
        self.files = files
        self.driver_memory = driver_memory
        self.driver_cores = driver_cores
        self.executor_memory = executor_memory
        self.executor_cores = executor_cores
        self.executor_count = executor_count
        self.archives = archives
        self.queue = queue
        self.name = name
        self.configuration = configuration
        self.heartbeat_timeout_in_second = heartbeat_timeout_in_second


class SparkStatement(Model):
    """SparkStatement.

    :param id:
    :type id: int
    :param code:
    :type code: str
    :param state:
    :type state: str
    :param output:
    :type output: ~azure.hdinsight.job.models.SparkStatementOutput
    :param progress:
    :type progress: float
    """

    _attribute_map = {
        'id': {'key': 'id', 'type': 'int'},
        'code': {'key': 'code', 'type': 'str'},
        'state': {'key': 'state', 'type': 'str'},
        'output': {'key': 'output', 'type': 'SparkStatementOutput'},
        'progress': {'key': 'progress', 'type': 'float'},
    }

    def __init__(self, *, id: int=None, code: str=None, state: str=None, output=None, progress: float=None, **kwargs) -> None:
        super(SparkStatement, self).__init__(**kwargs)
        self.id = id
        self.code = code
        self.state = state
        self.output = output
        self.progress = progress


class SparkStatementCancellationResult(Model):
    """SparkStatementCancellationResult.

    :param cancel_message:
    :type cancel_message: str
    """

    _attribute_map = {
        'cancel_message': {'key': 'msg', 'type': 'str'},
    }

    def __init__(self, *, cancel_message: str=None, **kwargs) -> None:
        super(SparkStatementCancellationResult, self).__init__(**kwargs)
        self.cancel_message = cancel_message


class SparkStatementCollection(Model):
    """SparkStatementCollection.

    :param statements:
    :type statements: list[~azure.hdinsight.job.models.SparkStatement]
    """

    _attribute_map = {
        'statements': {'key': 'statements', 'type': '[SparkStatement]'},
    }

    def __init__(self, *, statements=None, **kwargs) -> None:
        super(SparkStatementCollection, self).__init__(**kwargs)
        self.statements = statements


class SparkStatementOutput(Model):
    """SparkStatementOutput.

    :param status:
    :type status: str
    :param execution_count:
    :type execution_count: int
    :param data:
    :type data: object
    """

    _attribute_map = {
        'status': {'key': 'status', 'type': 'str'},
        'execution_count': {'key': 'execution_count', 'type': 'int'},
        'data': {'key': 'data', 'type': 'object'},
    }

    def __init__(self, *, status: str=None, execution_count: int=None, data=None, **kwargs) -> None:
        super(SparkStatementOutput, self).__init__(**kwargs)
        self.status = status
        self.execution_count = execution_count
        self.data = data


class SparkStatementRequest(Model):
    """SparkStatementRequest.

    :param code:
    :type code: str
    :param kind:
    :type kind: str
    """

    _attribute_map = {
        'code': {'key': 'code', 'type': 'str'},
        'kind': {'key': 'kind', 'type': 'str'},
    }

    def __init__(self, *, code: str=None, kind: str=None, **kwargs) -> None:
        super(SparkStatementRequest, self).__init__(**kwargs)
        self.code = code
        self.kind = kind


class Status(Model):
    """Gets or sets the object containing the job status information.

    :param cleanup_progress: The progress made on the cleanup.
    :type cleanup_progress: float
    :param failure_info: The information about any failures that have
     occurred.
    :type failure_info: str
    :param finish_time: The time at which the job completed. It is an integer
     in milliseconds, as a Unix timestamp relative to 1/1/1970 00:00:00.
    :type finish_time: long
    :param history_file: The history file of the job.
    :type history_file: str
    :param job_ac_ls: The ACLs of the job.
    :type job_ac_ls: object
    :param job_complete: Whether or not the job has completed.
    :type job_complete: bool
    :param job_file: The job configuration file.
    :type job_file: str
    :param job_id: The full ID of the job.
    :type job_id: str
    :param job_id1: The ID of the job.
    :type job_id1: ~azure.hdinsight.job.models.JobID
    :param job_name: The user-specified job name.
    :type job_name: str
    :param job_priority: The priority of the job.
    :type job_priority: str
    :param map_progress: The progress made on the maps.
    :type map_progress: float
    :param needed_mem: The amount of memory needed for the job.
    :type needed_mem: long
    :param num_reserved_slots: The number of slots reserved.
    :type num_reserved_slots: int
    :param num_used_slots: The number of slots used for the job.
    :type num_used_slots: int
    :param priority: The priority of the job.
    :type priority: str
    :param queue: The job queue name.
    :type queue: str
    :param reduce_progress: The progress made on the reduces.
    :type reduce_progress: float
    :param reserved_mem: The amount of memory reserved for the job.
    :type reserved_mem: long
    :param retired: Whether or not the job has been retired.
    :type retired: bool
    :param run_state: The current state of the job.
    :type run_state: int
    :param scheduling_info: The information about the scheduling of the job.
    :type scheduling_info: str
    :param setup_progress: The progress made on the setup.
    :type setup_progress: float
    :param start_time: The time at which the job started. It is an integer in
     milliseconds, as a Unix timestamp relative to 1/1/1970 00:00:00.
    :type start_time: long
    :param state: The state of the job.
    :type state: str
    :param tracking_url: The link to the web-ui for details of the job.
    :type tracking_url: str
    :param uber: Whether job running in uber mode.
    :type uber: bool
    :param used_mem: The amount of memory used by the job.
    :type used_mem: long
    :param username: The userid of the person who submitted the job.
    :type username: str
    """

    _attribute_map = {
        'cleanup_progress': {'key': 'cleanupProgress', 'type': 'float'},
        'failure_info': {'key': 'failureInfo', 'type': 'str'},
        'finish_time': {'key': 'finishTime', 'type': 'long'},
        'history_file': {'key': 'historyFile', 'type': 'str'},
        'job_ac_ls': {'key': 'jobACLs', 'type': 'object'},
        'job_complete': {'key': 'jobComplete', 'type': 'bool'},
        'job_file': {'key': 'jobFile', 'type': 'str'},
        'job_id': {'key': 'jobId', 'type': 'str'},
        'job_id1': {'key': 'jobID', 'type': 'JobID'},
        'job_name': {'key': 'jobName', 'type': 'str'},
        'job_priority': {'key': 'jobPriority', 'type': 'str'},
        'map_progress': {'key': 'mapProgress', 'type': 'float'},
        'needed_mem': {'key': 'neededMem', 'type': 'long'},
        'num_reserved_slots': {'key': 'numReservedSlots', 'type': 'int'},
        'num_used_slots': {'key': 'numUsedSlots', 'type': 'int'},
        'priority': {'key': 'priority', 'type': 'str'},
        'queue': {'key': 'queue', 'type': 'str'},
        'reduce_progress': {'key': 'reduceProgress', 'type': 'float'},
        'reserved_mem': {'key': 'reservedMem', 'type': 'long'},
        'retired': {'key': 'retired', 'type': 'bool'},
        'run_state': {'key': 'runState', 'type': 'int'},
        'scheduling_info': {'key': 'schedulingInfo', 'type': 'str'},
        'setup_progress': {'key': 'setupProgress', 'type': 'float'},
        'start_time': {'key': 'startTime', 'type': 'long'},
        'state': {'key': 'state', 'type': 'str'},
        'tracking_url': {'key': 'trackingUrl', 'type': 'str'},
        'uber': {'key': 'uber', 'type': 'bool'},
        'used_mem': {'key': 'usedMem', 'type': 'long'},
        'username': {'key': 'username', 'type': 'str'},
    }

    def __init__(self, *, cleanup_progress: float=None, failure_info: str=None, finish_time: int=None, history_file: str=None, job_ac_ls=None, job_complete: bool=None, job_file: str=None, job_id: str=None, job_id1=None, job_name: str=None, job_priority: str=None, map_progress: float=None, needed_mem: int=None, num_reserved_slots: int=None, num_used_slots: int=None, priority: str=None, queue: str=None, reduce_progress: float=None, reserved_mem: int=None, retired: bool=None, run_state: int=None, scheduling_info: str=None, setup_progress: float=None, start_time: int=None, state: str=None, tracking_url: str=None, uber: bool=None, used_mem: int=None, username: str=None, **kwargs) -> None:
        super(Status, self).__init__(**kwargs)
        self.cleanup_progress = cleanup_progress
        self.failure_info = failure_info
        self.finish_time = finish_time
        self.history_file = history_file
        self.job_ac_ls = job_ac_ls
        self.job_complete = job_complete
        self.job_file = job_file
        self.job_id = job_id
        self.job_id1 = job_id1
        self.job_name = job_name
        self.job_priority = job_priority
        self.map_progress = map_progress
        self.needed_mem = needed_mem
        self.num_reserved_slots = num_reserved_slots
        self.num_used_slots = num_used_slots
        self.priority = priority
        self.queue = queue
        self.reduce_progress = reduce_progress
        self.reserved_mem = reserved_mem
        self.retired = retired
        self.run_state = run_state
        self.scheduling_info = scheduling_info
        self.setup_progress = setup_progress
        self.start_time = start_time
        self.state = state
        self.tracking_url = tracking_url
        self.uber = uber
        self.used_mem = used_mem
        self.username = username


class Userargs(Model):
    """Gets or sets the object containing the user arguments.

    Variables are only populated by the server, and will be ignored when
    sending a request.

    :ivar arg: The list of args defined by the user.
    :vartype arg: list[str]
    :param callback: The callback URL, if any.
    :type callback: object
    :ivar define: The define properties defined by the user.
    :vartype define: list[str]
    :param enablelog: Whether or not the user enabled logs.
    :type enablelog: str
    :param execute: The query defined by the user.
    :type execute: str
    :param file: The query file provided by the user.
    :type file: object
    :param files: The files defined by the user.
    :type files: object
    :param jar: The JAR file provided by the user.
    :type jar: str
    :param statusdir: The status directory defined by the user.
    :type statusdir: object
    """

    _validation = {
        'arg': {'readonly': True},
        'define': {'readonly': True},
    }

    _attribute_map = {
        'arg': {'key': 'arg', 'type': '[str]'},
        'callback': {'key': 'callback', 'type': 'object'},
        'define': {'key': 'define', 'type': '[str]'},
        'enablelog': {'key': 'enablelog', 'type': 'str'},
        'execute': {'key': 'execute', 'type': 'str'},
        'file': {'key': 'file', 'type': 'object'},
        'files': {'key': 'files', 'type': 'object'},
        'jar': {'key': 'jar', 'type': 'str'},
        'statusdir': {'key': 'statusdir', 'type': 'object'},
    }

    def __init__(self, *, callback=None, enablelog: str=None, execute: str=None, file=None, files=None, jar: str=None, statusdir=None, **kwargs) -> None:
        super(Userargs, self).__init__(**kwargs)
        self.arg = None
        self.callback = callback
        self.define = None
        self.enablelog = enablelog
        self.execute = execute
        self.file = file
        self.files = files
        self.jar = jar
        self.statusdir = statusdir
