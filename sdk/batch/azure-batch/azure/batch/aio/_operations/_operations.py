# pylint: disable=too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
import datetime
import json
from typing import Any, AsyncIterable, Callable, Dict, List, Optional, TypeVar
import urllib.parse

from azure.core import MatchConditions
from azure.core.async_paging import AsyncItemPaged, AsyncList
from azure.core.exceptions import (
    ClientAuthenticationError,
    HttpResponseError,
    ResourceExistsError,
    ResourceModifiedError,
    ResourceNotFoundError,
    ResourceNotModifiedError,
    map_error,
)
from azure.core.pipeline import PipelineResponse
from azure.core.rest import AsyncHttpResponse, HttpRequest
from azure.core.tracing.decorator import distributed_trace
from azure.core.tracing.decorator_async import distributed_trace_async
from azure.core.utils import case_insensitive_dict

from ... import models as _models
from ..._model_base import AzureJSONEncoder, _deserialize
from ..._operations._operations import (
    build_batch_cancel_certificate_deletion_request,
    build_batch_create_certificate_request,
    build_batch_create_job_request,
    build_batch_create_job_schedule_request,
    build_batch_create_node_user_request,
    build_batch_create_pool_request,
    build_batch_create_task_collection_request,
    build_batch_create_task_request,
    build_batch_delete_certificate_request,
    build_batch_delete_job_request,
    build_batch_delete_job_schedule_request,
    build_batch_delete_node_file_request,
    build_batch_delete_node_user_request,
    build_batch_delete_pool_request,
    build_batch_delete_task_file_request,
    build_batch_delete_task_request,
    build_batch_disable_job_request,
    build_batch_disable_job_schedule_request,
    build_batch_disable_node_scheduling_request,
    build_batch_disable_pool_auto_scale_request,
    build_batch_enable_job_request,
    build_batch_enable_job_schedule_request,
    build_batch_enable_node_scheduling_request,
    build_batch_enable_pool_auto_scale_request,
    build_batch_evaluate_pool_auto_scale_request,
    build_batch_get_application_request,
    build_batch_get_certificate_request,
    build_batch_get_job_request,
    build_batch_get_job_schedule_request,
    build_batch_get_job_task_counts_request,
    build_batch_get_node_extension_request,
    build_batch_get_node_file_properties_request,
    build_batch_get_node_file_request,
    build_batch_get_node_remote_desktop_file_request,
    build_batch_get_node_remote_login_settings_request,
    build_batch_get_node_request,
    build_batch_get_pool_request,
    build_batch_get_task_file_properties_request,
    build_batch_get_task_file_request,
    build_batch_get_task_request,
    build_batch_job_schedule_exists_request,
    build_batch_list_applications_request,
    build_batch_list_certificates_request,
    build_batch_list_job_preparation_and_release_task_status_request,
    build_batch_list_job_schedules_request,
    build_batch_list_jobs_from_schedule_request,
    build_batch_list_jobs_request,
    build_batch_list_node_extensions_request,
    build_batch_list_node_files_request,
    build_batch_list_nodes_request,
    build_batch_list_pool_node_counts_request,
    build_batch_list_pool_usage_metrics_request,
    build_batch_list_pools_request,
    build_batch_list_sub_tasks_request,
    build_batch_list_supported_images_request,
    build_batch_list_task_files_request,
    build_batch_list_tasks_request,
    build_batch_pool_exists_request,
    build_batch_reactivate_task_request,
    build_batch_reboot_node_request,
    build_batch_reimage_node_request,
    build_batch_remove_nodes_request,
    build_batch_replace_job_request,
    build_batch_replace_job_schedule_request,
    build_batch_replace_node_user_request,
    build_batch_replace_pool_properties_request,
    build_batch_replace_task_request,
    build_batch_resize_pool_request,
    build_batch_stop_pool_resize_request,
    build_batch_terminate_job_request,
    build_batch_terminate_job_schedule_request,
    build_batch_terminate_task_request,
    build_batch_update_job_request,
    build_batch_update_job_schedule_request,
    build_batch_update_pool_request,
    build_batch_upload_node_logs_request,
)
from .._vendor import BatchClientMixinABC

T = TypeVar("T")
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]


class BatchClientOperationsMixin(BatchClientMixinABC):  # pylint: disable=too-many-public-methods
    @distributed_trace
    def list_applications(
        self,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchApplication"]:
        """Lists all of the applications available in the specified Account.

        This operation returns only Applications and versions that are available for
        use on Compute Nodes; that is, that can be used in an Package reference. For
        administrator information about applications and versions that are not yet
        available to Compute Nodes, use the Azure portal or the Azure Resource Manager
        API.

        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :return: An iterator like instance of BatchApplication
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchApplication]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchApplication]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_applications_request(
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchApplication], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace_async
    async def get_application(
        self,
        application_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> _models.BatchApplication:
        """Gets information about the specified Application.

        This operation returns only Applications and versions that are available for
        use on Compute Nodes; that is, that can be used in an Package reference. For
        administrator information about Applications and versions that are not yet
        available to Compute Nodes, use the Azure portal or the Azure Resource Manager
        API.

        :param application_id: The ID of the Application. Required.
        :type application_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: BatchApplication. The BatchApplication is compatible with MutableMapping
        :rtype: ~azure.batch.models.BatchApplication
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.BatchApplication] = kwargs.pop("cls", None)

        _request = build_batch_get_application_request(
            application_id=application_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.BatchApplication, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def list_pool_usage_metrics(
        self,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        starttime: Optional[datetime.datetime] = None,
        endtime: Optional[datetime.datetime] = None,
        filter: Optional[str] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchPoolUsageMetrics"]:
        """Lists the usage metrics, aggregated by Pool across individual time intervals,
        for the specified Account.

        If you do not specify a $filter clause including a poolId, the response
        includes all Pools that existed in the Account in the time range of the
        returned aggregation intervals. If you do not specify a $filter clause
        including a startTime or endTime these filters default to the start and end
        times of the last aggregation interval currently available; that is, only the
        last aggregation interval is returned.

        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword starttime: The earliest time from which to include metrics. This must be at least two
         and
         a half hours before the current time. If not specified this defaults to the
         start time of the last aggregation interval currently available. Default value is None.
        :paramtype starttime: ~datetime.datetime
        :keyword endtime: The latest time from which to include metrics. This must be at least two
         hours
         before the current time. If not specified this defaults to the end time of the
         last aggregation interval currently available. Default value is None.
        :paramtype endtime: ~datetime.datetime
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
        https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-account-usage-metrics.
         Default value is None.
        :paramtype filter: str
        :return: An iterator like instance of BatchPoolUsageMetrics
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchPoolUsageMetrics]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchPoolUsageMetrics]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_pool_usage_metrics_request(
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    starttime=starttime,
                    endtime=endtime,
                    filter=filter,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchPoolUsageMetrics], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace_async
    async def create_pool(  # pylint: disable=inconsistent-return-statements
        self,
        pool: _models.BatchPoolCreateParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Creates a Pool to the specified Account.

        When naming Pools, avoid including sensitive information such as user names or
        secret project names. This information may appear in telemetry logs accessible
        to Microsoft Support engineers.

        :param pool: The Pool to be created. Required.
        :type pool: ~azure.batch.models.BatchPoolCreateParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(pool, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_create_pool_request(
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [201]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace
    def list_pools(
        self,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        filter: Optional[str] = None,
        select: Optional[List[str]] = None,
        expand: Optional[List[str]] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchPool"]:
        """Lists all of the Pools in the specified Account.

        Lists all of the Pools in the specified Account.

        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
         https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-pools.
         Default value is None.
        :paramtype filter: str
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :keyword expand: An OData $expand clause. Default value is None.
        :paramtype expand: list[str]
        :return: An iterator like instance of BatchPool
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchPool]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchPool]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_pools_request(
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    filter=filter,
                    select=select,
                    expand=expand,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchPool], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace_async
    async def delete_pool(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Deletes a Pool from the specified Account.

        When you request that a Pool be deleted, the following actions occur: the Pool
        state is set to deleting; any ongoing resize operation on the Pool are stopped;
        the Batch service starts resizing the Pool to zero Compute Nodes; any Tasks
        running on existing Compute Nodes are terminated and requeued (as if a resize
        Pool operation had been requested with the default requeue option); finally,
        the Pool is removed from the system. Because running Tasks are requeued, the
        user can rerun these Tasks by updating their Job to target a different Pool.
        The Tasks can then run on the new Pool. If you want to override the requeue
        behavior, then you should call resize Pool explicitly to shrink the Pool to
        zero size before deleting the Pool. If you call an Update, Patch or Delete API
        on a Pool in the deleting state, it will fail with HTTP status code 409 with
        error code PoolBeingDeleted.

        :param pool_id: The ID of the Pool to get. Required.
        :type pool_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_delete_pool_request(
            pool_id=pool_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def pool_exists(
        self,
        pool_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> bool:
        """Gets basic properties of a Pool.

        :param pool_id: The ID of the Pool to get. Required.
        :type pool_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: bool
        :rtype: bool
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_pool_exists_request(
            pool_id=pool_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 404]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
            response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
            response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
            response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore
        return 200 <= response.status_code <= 299

    @distributed_trace_async
    async def get_pool(
        self,
        pool_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        select: Optional[List[str]] = None,
        expand: Optional[List[str]] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> _models.BatchPool:
        """Gets information about the specified Pool.

        :param pool_id: The ID of the Pool to get. Required.
        :type pool_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :keyword expand: An OData $expand clause. Default value is None.
        :paramtype expand: list[str]
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: BatchPool. The BatchPool is compatible with MutableMapping
        :rtype: ~azure.batch.models.BatchPool
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.BatchPool] = kwargs.pop("cls", None)

        _request = build_batch_get_pool_request(
            pool_id=pool_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            select=select,
            expand=expand,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.BatchPool, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def update_pool(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        pool: _models.BatchPoolUpdateParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Updates the properties of the specified Pool.

        This only replaces the Pool properties specified in the request. For example,
        if the Pool has a StartTask associated with it, and a request does not specify
        a StartTask element, then the Pool keeps the existing StartTask.

        :param pool_id: The ID of the Pool to get. Required.
        :type pool_id: str
        :param pool: The pool properties to update. Required.
        :type pool: ~azure.batch.models.BatchPoolUpdateParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(pool, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_update_pool_request(
            pool_id=pool_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def disable_pool_auto_scale(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Disables automatic scaling for a Pool.

        Disables automatic scaling for a Pool.

        :param pool_id: The ID of the Pool on which to disable automatic scaling. Required.
        :type pool_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_disable_pool_auto_scale_request(
            pool_id=pool_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def enable_pool_auto_scale(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        parameters: _models.BatchPoolEnableAutoScaleParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Enables automatic scaling for a Pool.

        You cannot enable automatic scaling on a Pool if a resize operation is in
        progress on the Pool. If automatic scaling of the Pool is currently disabled,
        you must specify a valid autoscale formula as part of the request. If automatic
        scaling of the Pool is already enabled, you may specify a new autoscale formula
        and/or a new evaluation interval. You cannot call this API for the same Pool
        more than once every 30 seconds.

        :param pool_id: The ID of the Pool to get. Required.
        :type pool_id: str
        :param parameters: The options to use for enabling automatic scaling. Required.
        :type parameters: ~azure.batch.models.BatchPoolEnableAutoScaleParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(parameters, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_enable_pool_auto_scale_request(
            pool_id=pool_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def evaluate_pool_auto_scale(
        self,
        pool_id: str,
        parameters: _models.BatchPoolEvaluateAutoScaleParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> _models.AutoScaleRun:
        """Gets the result of evaluating an automatic scaling formula on the Pool.

        This API is primarily for validating an autoscale formula, as it simply returns
        the result without applying the formula to the Pool. The Pool must have auto
        scaling enabled in order to evaluate a formula.

        :param pool_id: The ID of the Pool on which to evaluate the automatic scaling formula.
         Required.
        :type pool_id: str
        :param parameters: The options to use for evaluating the automatic scaling formula. Required.
        :type parameters: ~azure.batch.models.BatchPoolEvaluateAutoScaleParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: AutoScaleRun. The AutoScaleRun is compatible with MutableMapping
        :rtype: ~azure.batch.models.AutoScaleRun
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[_models.AutoScaleRun] = kwargs.pop("cls", None)

        _content = json.dumps(parameters, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_evaluate_pool_auto_scale_request(
            pool_id=pool_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.AutoScaleRun, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def resize_pool(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        parameters: _models.BatchPoolResizeParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Changes the number of Compute Nodes that are assigned to a Pool.

        You can only resize a Pool when its allocation state is steady. If the Pool is
        already resizing, the request fails with status code 409. When you resize a
        Pool, the Pool's allocation state changes from steady to resizing. You cannot
        resize Pools which are configured for automatic scaling. If you try to do this,
        the Batch service returns an error 409. If you resize a Pool downwards, the
        Batch service chooses which Compute Nodes to remove. To remove specific Compute
        Nodes, use the Pool remove Compute Nodes API instead.

        :param pool_id: The ID of the Pool to get. Required.
        :type pool_id: str
        :param parameters: The options to use for resizing the pool. Required.
        :type parameters: ~azure.batch.models.BatchPoolResizeParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(parameters, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_resize_pool_request(
            pool_id=pool_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def stop_pool_resize(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Stops an ongoing resize operation on the Pool.

        This does not restore the Pool to its previous state before the resize
        operation: it only stops any further changes being made, and the Pool maintains
        its current state. After stopping, the Pool stabilizes at the number of Compute
        Nodes it was at when the stop operation was done. During the stop operation,
        the Pool allocation state changes first to stopping and then to steady. A
        resize operation need not be an explicit resize Pool request; this API can also
        be used to halt the initial sizing of the Pool when it is created.

        :param pool_id: The ID of the Pool to get. Required.
        :type pool_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_stop_pool_resize_request(
            pool_id=pool_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def replace_pool_properties(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        pool: _models.BatchPoolReplaceParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Updates the properties of the specified Pool.

        This fully replaces all the updatable properties of the Pool. For example, if
        the Pool has a StartTask associated with it and if StartTask is not specified
        with this request, then the Batch service will remove the existing StartTask.

        :param pool_id: The ID of the Pool to update. Required.
        :type pool_id: str
        :param pool: The options to use for replacing properties on the pool. Required.
        :type pool: ~azure.batch.models.BatchPoolReplaceParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(pool, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_replace_pool_properties_request(
            pool_id=pool_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [204]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def remove_nodes(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        parameters: _models.BatchNodeRemoveParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Removes Compute Nodes from the specified Pool.

        This operation can only run when the allocation state of the Pool is steady.
        When this operation runs, the allocation state changes from steady to resizing.
        Each request may remove up to 100 nodes.

        :param pool_id: The ID of the Pool to get. Required.
        :type pool_id: str
        :param parameters: The options to use for removing the node. Required.
        :type parameters: ~azure.batch.models.BatchNodeRemoveParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(parameters, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_remove_nodes_request(
            pool_id=pool_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace
    def list_supported_images(
        self,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        filter: Optional[str] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.ImageInfo"]:
        """Lists all Virtual Machine Images supported by the Azure Batch service.

        Lists all Virtual Machine Images supported by the Azure Batch service.

        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
        https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-support-images.
         Default value is None.
        :paramtype filter: str
        :return: An iterator like instance of ImageInfo
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.ImageInfo]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.ImageInfo]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_supported_images_request(
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    filter=filter,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.ImageInfo], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace
    def list_pool_node_counts(
        self,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        filter: Optional[str] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchPoolNodeCounts"]:
        """Gets the number of Compute Nodes in each state, grouped by Pool. Note that the
        numbers returned may not always be up to date. If you need exact node counts,
        use a list query.

        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
        https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-support-images.
         Default value is None.
        :paramtype filter: str
        :return: An iterator like instance of BatchPoolNodeCounts
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchPoolNodeCounts]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchPoolNodeCounts]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_pool_node_counts_request(
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    filter=filter,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchPoolNodeCounts], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace_async
    async def delete_job(  # pylint: disable=inconsistent-return-statements
        self,
        job_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Deletes a Job.

        Deleting a Job also deletes all Tasks that are part of that Job, and all Job
        statistics. This also overrides the retention period for Task data; that is, if
        the Job contains Tasks which are still retained on Compute Nodes, the Batch
        services deletes those Tasks' working directories and all their contents.  When
        a Delete Job request is received, the Batch service sets the Job to the
        deleting state. All update operations on a Job that is in deleting state will
        fail with status code 409 (Conflict), with additional information indicating
        that the Job is being deleted.

        :param job_id: The ID of the Job to delete. Required.
        :type job_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_delete_job_request(
            job_id=job_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def get_job(
        self,
        job_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        select: Optional[List[str]] = None,
        expand: Optional[List[str]] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> _models.BatchJob:
        """Gets information about the specified Job.

        Gets information about the specified Job.

        :param job_id: The ID of the Job. Required.
        :type job_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :keyword expand: An OData $expand clause. Default value is None.
        :paramtype expand: list[str]
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: BatchJob. The BatchJob is compatible with MutableMapping
        :rtype: ~azure.batch.models.BatchJob
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.BatchJob] = kwargs.pop("cls", None)

        _request = build_batch_get_job_request(
            job_id=job_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            select=select,
            expand=expand,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.BatchJob, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def update_job(  # pylint: disable=inconsistent-return-statements
        self,
        job_id: str,
        job: _models.BatchJobUpdateParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Updates the properties of the specified Job.

        This replaces only the Job properties specified in the request. For example, if
        the Job has constraints, and a request does not specify the constraints
        element, then the Job keeps the existing constraints.

        :param job_id: The ID of the Job whose properties you want to update. Required.
        :type job_id: str
        :param job: The options to use for updating the Job. Required.
        :type job: ~azure.batch.models.BatchJobUpdateParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(job, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_update_job_request(
            job_id=job_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def replace_job(  # pylint: disable=inconsistent-return-statements
        self,
        job_id: str,
        job: _models.BatchJob,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Updates the properties of the specified Job.

        This fully replaces all the updatable properties of the Job. For example, if
        the Job has constraints associated with it and if constraints is not specified
        with this request, then the Batch service will remove the existing constraints.

        :param job_id: The ID of the Job whose properties you want to update. Required.
        :type job_id: str
        :param job: A job with updated properties. Required.
        :type job: ~azure.batch.models.BatchJob
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(job, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_replace_job_request(
            job_id=job_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def disable_job(  # pylint: disable=inconsistent-return-statements
        self,
        job_id: str,
        parameters: _models.BatchJobDisableParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Disables the specified Job, preventing new Tasks from running.

        The Batch Service immediately moves the Job to the disabling state. Batch then
        uses the disableTasks parameter to determine what to do with the currently
        running Tasks of the Job. The Job remains in the disabling state until the
        disable operation is completed and all Tasks have been dealt with according to
        the disableTasks option; the Job then moves to the disabled state. No new Tasks
        are started under the Job until it moves back to active state. If you try to
        disable a Job that is in any state other than active, disabling, or disabled,
        the request fails with status code 409.

        :param job_id: The ID of the Job to disable. Required.
        :type job_id: str
        :param parameters: The options to use for disabling the Job. Required.
        :type parameters: ~azure.batch.models.BatchJobDisableParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(parameters, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_disable_job_request(
            job_id=job_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def enable_job(  # pylint: disable=inconsistent-return-statements
        self,
        job_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Enables the specified Job, allowing new Tasks to run.

        When you call this API, the Batch service sets a disabled Job to the enabling
        state. After the this operation is completed, the Job moves to the active
        state, and scheduling of new Tasks under the Job resumes. The Batch service
        does not allow a Task to remain in the active state for more than 180 days.
        Therefore, if you enable a Job containing active Tasks which were added more
        than 180 days ago, those Tasks will not run.

        :param job_id: The ID of the Job to enable. Required.
        :type job_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_enable_job_request(
            job_id=job_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def terminate_job(  # pylint: disable=inconsistent-return-statements
        self,
        job_id: str,
        parameters: Optional[_models.BatchJobTerminateParameters] = None,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Terminates the specified Job, marking it as completed.

        When a Terminate Job request is received, the Batch service sets the Job to the
        terminating state. The Batch service then terminates any running Tasks
        associated with the Job and runs any required Job release Tasks. Then the Job
        moves into the completed state. If there are any Tasks in the Job in the active
        state, they will remain in the active state. Once a Job is terminated, new
        Tasks cannot be added and any remaining active Tasks will not be scheduled.

        :param job_id: The ID of the Job to terminate. Required.
        :type job_id: str
        :param parameters: The options to use for terminating the Job. Default value is None.
        :type parameters: ~azure.batch.models.BatchJobTerminateParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        if parameters is not None:
            _content = json.dumps(parameters, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore
        else:
            _content = None

        _request = build_batch_terminate_job_request(
            job_id=job_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def create_job(  # pylint: disable=inconsistent-return-statements
        self,
        job: _models.BatchJobCreateParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Creates a Job to the specified Account.

        The Batch service supports two ways to control the work done as part of a Job.
        In the first approach, the user specifies a Job Manager Task. The Batch service
        launches this Task when it is ready to start the Job. The Job Manager Task
        controls all other Tasks that run under this Job, by using the Task APIs. In
        the second approach, the user directly controls the execution of Tasks under an
        active Job, by using the Task APIs. Also note: when naming Jobs, avoid
        including sensitive information such as user names or secret project names.
        This information may appear in telemetry logs accessible to Microsoft Support
        engineers.

        :param job: The Job to be created. Required.
        :type job: ~azure.batch.models.BatchJobCreateParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(job, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_create_job_request(
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [201]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace
    def list_jobs(
        self,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        filter: Optional[str] = None,
        select: Optional[List[str]] = None,
        expand: Optional[List[str]] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchJob"]:
        """Lists all of the Jobs in the specified Account.

        Lists all of the Jobs in the specified Account.

        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
         https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-jobs.
         Default value is None.
        :paramtype filter: str
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :keyword expand: An OData $expand clause. Default value is None.
        :paramtype expand: list[str]
        :return: An iterator like instance of BatchJob
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchJob]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchJob]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_jobs_request(
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    filter=filter,
                    select=select,
                    expand=expand,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchJob], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace
    def list_jobs_from_schedule(
        self,
        job_schedule_id: str,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        filter: Optional[str] = None,
        select: Optional[List[str]] = None,
        expand: Optional[List[str]] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchJob"]:
        """Lists the Jobs that have been created under the specified Job Schedule.

        Lists the Jobs that have been created under the specified Job Schedule.

        :param job_schedule_id: The ID of the Job Schedule from which you want to get a list of Jobs.
         Required.
        :type job_schedule_id: str
        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
        https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-jobs-in-a-job-schedule.
         Default value is None.
        :paramtype filter: str
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :keyword expand: An OData $expand clause. Default value is None.
        :paramtype expand: list[str]
        :return: An iterator like instance of BatchJob
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchJob]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchJob]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_jobs_from_schedule_request(
                    job_schedule_id=job_schedule_id,
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    filter=filter,
                    select=select,
                    expand=expand,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchJob], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace
    def list_job_preparation_and_release_task_status(  # pylint: disable=name-too-long
        self,
        job_id: str,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        filter: Optional[str] = None,
        select: Optional[List[str]] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchJobPreparationAndReleaseTaskStatus"]:
        """Lists the execution status of the Job Preparation and Job Release Task for the
        specified Job across the Compute Nodes where the Job has run.

        This API returns the Job Preparation and Job Release Task status on all Compute
        Nodes that have run the Job Preparation or Job Release Task. This includes
        Compute Nodes which have since been removed from the Pool. If this API is
        invoked on a Job which has no Job Preparation or Job Release Task, the Batch
        service returns HTTP status code 409 (Conflict) with an error code of
        JobPreparationTaskNotSpecified.

        :param job_id: The ID of the Job. Required.
        :type job_id: str
        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
        https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-job-preparation-and-release-status.
         Default value is None.
        :paramtype filter: str
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :return: An iterator like instance of BatchJobPreparationAndReleaseTaskStatus
        :rtype:
         ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchJobPreparationAndReleaseTaskStatus]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchJobPreparationAndReleaseTaskStatus]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_job_preparation_and_release_task_status_request(
                    job_id=job_id,
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    filter=filter,
                    select=select,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchJobPreparationAndReleaseTaskStatus], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace_async
    async def get_job_task_counts(
        self,
        job_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> _models.BatchTaskCountsResult:
        """Gets the Task counts for the specified Job.

        Task counts provide a count of the Tasks by active, running or completed Task
        state, and a count of Tasks which succeeded or failed. Tasks in the preparing
        state are counted as running. Note that the numbers returned may not always be
        up to date. If you need exact task counts, use a list query.

        :param job_id: The ID of the Job. Required.
        :type job_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: BatchTaskCountsResult. The BatchTaskCountsResult is compatible with MutableMapping
        :rtype: ~azure.batch.models.BatchTaskCountsResult
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.BatchTaskCountsResult] = kwargs.pop("cls", None)

        _request = build_batch_get_job_task_counts_request(
            job_id=job_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.BatchTaskCountsResult, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def create_certificate(  # pylint: disable=inconsistent-return-statements
        self,
        certificate: _models.BatchCertificate,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Creates a Certificate to the specified Account.

        Creates a Certificate to the specified Account.

        :param certificate: The Certificate to be created. Required.
        :type certificate: ~azure.batch.models.BatchCertificate
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(certificate, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_create_certificate_request(
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [201]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace
    def list_certificates(
        self,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        filter: Optional[str] = None,
        select: Optional[List[str]] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchCertificate"]:
        """Lists all of the Certificates that have been added to the specified Account.

        Lists all of the Certificates that have been added to the specified Account.

        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
        https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-certificates.
         Default value is None.
        :paramtype filter: str
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :return: An iterator like instance of BatchCertificate
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchCertificate]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchCertificate]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_certificates_request(
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    filter=filter,
                    select=select,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchCertificate], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace_async
    async def cancel_certificate_deletion(  # pylint: disable=inconsistent-return-statements
        self,
        thumbprint_algorithm: str,
        thumbprint: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Cancels a failed deletion of a Certificate from the specified Account.

        If you try to delete a Certificate that is being used by a Pool or Compute
        Node, the status of the Certificate changes to deleteFailed. If you decide that
        you want to continue using the Certificate, you can use this operation to set
        the status of the Certificate back to active. If you intend to delete the
        Certificate, you do not need to run this operation after the deletion failed.
        You must make sure that the Certificate is not being used by any resources, and
        then you can try again to delete the Certificate.

        :param thumbprint_algorithm: The algorithm used to derive the thumbprint parameter. This must
         be sha1. Required.
        :type thumbprint_algorithm: str
        :param thumbprint: The thumbprint of the Certificate being deleted. Required.
        :type thumbprint: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_cancel_certificate_deletion_request(
            thumbprint_algorithm=thumbprint_algorithm,
            thumbprint=thumbprint,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [204]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def delete_certificate(  # pylint: disable=inconsistent-return-statements
        self,
        thumbprint_algorithm: str,
        thumbprint: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Deletes a Certificate from the specified Account.

        You cannot delete a Certificate if a resource (Pool or Compute Node) is using
        it. Before you can delete a Certificate, you must therefore make sure that the
        Certificate is not associated with any existing Pools, the Certificate is not
        installed on any Nodes (even if you remove a Certificate from a Pool, it is not
        removed from existing Compute Nodes in that Pool until they restart), and no
        running Tasks depend on the Certificate. If you try to delete a Certificate
        that is in use, the deletion fails. The Certificate status changes to
        deleteFailed. You can use Cancel Delete Certificate to set the status back to
        active if you decide that you want to continue using the Certificate.

        :param thumbprint_algorithm: The algorithm used to derive the thumbprint parameter. This must
         be sha1. Required.
        :type thumbprint_algorithm: str
        :param thumbprint: The thumbprint of the Certificate to be deleted. Required.
        :type thumbprint: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_delete_certificate_request(
            thumbprint_algorithm=thumbprint_algorithm,
            thumbprint=thumbprint,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def get_certificate(
        self,
        thumbprint_algorithm: str,
        thumbprint: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        select: Optional[List[str]] = None,
        **kwargs: Any
    ) -> _models.BatchCertificate:
        """Gets information about the specified Certificate.

        :param thumbprint_algorithm: The algorithm used to derive the thumbprint parameter. This must
         be sha1. Required.
        :type thumbprint_algorithm: str
        :param thumbprint: The thumbprint of the Certificate to get. Required.
        :type thumbprint: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: BatchCertificate. The BatchCertificate is compatible with MutableMapping
        :rtype: ~azure.batch.models.BatchCertificate
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.BatchCertificate] = kwargs.pop("cls", None)

        _request = build_batch_get_certificate_request(
            thumbprint_algorithm=thumbprint_algorithm,
            thumbprint=thumbprint,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            select=select,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.BatchCertificate, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def job_schedule_exists(
        self,
        job_schedule_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> bool:
        """Checks the specified Job Schedule exists.

        Checks the specified Job Schedule exists.

        :param job_schedule_id: The ID of the Job Schedule which you want to check. Required.
        :type job_schedule_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: bool
        :rtype: bool
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_job_schedule_exists_request(
            job_schedule_id=job_schedule_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200, 404]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 200:
            response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
            response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
            response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
            response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore
        return 200 <= response.status_code <= 299

    @distributed_trace_async
    async def delete_job_schedule(  # pylint: disable=inconsistent-return-statements
        self,
        job_schedule_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Deletes a Job Schedule from the specified Account.

        When you delete a Job Schedule, this also deletes all Jobs and Tasks under that
        schedule. When Tasks are deleted, all the files in their working directories on
        the Compute Nodes are also deleted (the retention period is ignored). The Job
        Schedule statistics are no longer accessible once the Job Schedule is deleted,
        though they are still counted towards Account lifetime statistics.

        :param job_schedule_id: The ID of the Job Schedule to delete. Required.
        :type job_schedule_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_delete_job_schedule_request(
            job_schedule_id=job_schedule_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def get_job_schedule(
        self,
        job_schedule_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        select: Optional[List[str]] = None,
        expand: Optional[List[str]] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> _models.BatchJobSchedule:
        """Gets information about the specified Job Schedule.

        :param job_schedule_id: The ID of the Job Schedule to get. Required.
        :type job_schedule_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :keyword expand: An OData $expand clause. Default value is None.
        :paramtype expand: list[str]
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: BatchJobSchedule. The BatchJobSchedule is compatible with MutableMapping
        :rtype: ~azure.batch.models.BatchJobSchedule
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.BatchJobSchedule] = kwargs.pop("cls", None)

        _request = build_batch_get_job_schedule_request(
            job_schedule_id=job_schedule_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            select=select,
            expand=expand,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.BatchJobSchedule, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def update_job_schedule(  # pylint: disable=inconsistent-return-statements
        self,
        job_schedule_id: str,
        job_schedule: _models.BatchJobScheduleUpdateParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Updates the properties of the specified Job Schedule.

        This replaces only the Job Schedule properties specified in the request. For
        example, if the schedule property is not specified with this request, then the
        Batch service will keep the existing schedule. Changes to a Job Schedule only
        impact Jobs created by the schedule after the update has taken place; currently
        running Jobs are unaffected.

        :param job_schedule_id: The ID of the Job Schedule to update. Required.
        :type job_schedule_id: str
        :param job_schedule: The options to use for updating the Job Schedule. Required.
        :type job_schedule: ~azure.batch.models.BatchJobScheduleUpdateParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(job_schedule, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_update_job_schedule_request(
            job_schedule_id=job_schedule_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def replace_job_schedule(  # pylint: disable=inconsistent-return-statements
        self,
        job_schedule_id: str,
        job_schedule: _models.BatchJobSchedule,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Updates the properties of the specified Job Schedule.

        This fully replaces all the updatable properties of the Job Schedule. For
        example, if the schedule property is not specified with this request, then the
        Batch service will remove the existing schedule. Changes to a Job Schedule only
        impact Jobs created by the schedule after the update has taken place; currently
        running Jobs are unaffected.

        :param job_schedule_id: The ID of the Job Schedule to update. Required.
        :type job_schedule_id: str
        :param job_schedule: A Job Schedule with updated properties. Required.
        :type job_schedule: ~azure.batch.models.BatchJobSchedule
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(job_schedule, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_replace_job_schedule_request(
            job_schedule_id=job_schedule_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def disable_job_schedule(  # pylint: disable=inconsistent-return-statements
        self,
        job_schedule_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Disables a Job Schedule.

        No new Jobs will be created until the Job Schedule is enabled again.

        :param job_schedule_id: The ID of the Job Schedule to disable. Required.
        :type job_schedule_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_disable_job_schedule_request(
            job_schedule_id=job_schedule_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [204]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def enable_job_schedule(  # pylint: disable=inconsistent-return-statements
        self,
        job_schedule_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Enables a Job Schedule.

        Enables a Job Schedule.

        :param job_schedule_id: The ID of the Job Schedule to enable. Required.
        :type job_schedule_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_enable_job_schedule_request(
            job_schedule_id=job_schedule_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [204]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def terminate_job_schedule(  # pylint: disable=inconsistent-return-statements
        self,
        job_schedule_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Terminates a Job Schedule.

        Terminates a Job Schedule.

        :param job_schedule_id: The ID of the Job Schedule to terminates. Required.
        :type job_schedule_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_terminate_job_schedule_request(
            job_schedule_id=job_schedule_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def create_job_schedule(  # pylint: disable=inconsistent-return-statements
        self,
        job_schedule: _models.BatchJobScheduleCreateParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Creates a Job Schedule to the specified Account.

        Creates a Job Schedule to the specified Account.

        :param job_schedule: The Job Schedule to be created. Required.
        :type job_schedule: ~azure.batch.models.BatchJobScheduleCreateParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(job_schedule, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_create_job_schedule_request(
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [201]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace
    def list_job_schedules(
        self,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        filter: Optional[str] = None,
        select: Optional[List[str]] = None,
        expand: Optional[List[str]] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchJobSchedule"]:
        """Lists all of the Job Schedules in the specified Account.

        Lists all of the Job Schedules in the specified Account.

        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
        https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-job-schedules.
         Default value is None.
        :paramtype filter: str
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :keyword expand: An OData $expand clause. Default value is None.
        :paramtype expand: list[str]
        :return: An iterator like instance of BatchJobSchedule
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchJobSchedule]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchJobSchedule]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_job_schedules_request(
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    filter=filter,
                    select=select,
                    expand=expand,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchJobSchedule], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace_async
    async def create_task(  # pylint: disable=inconsistent-return-statements
        self,
        job_id: str,
        task: _models.BatchTaskCreateParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Creates a Task to the specified Job.

        The maximum lifetime of a Task from addition to completion is 180 days. If a
        Task has not completed within 180 days of being added it will be terminated by
        the Batch service and left in whatever state it was in at that time.

        :param job_id: The ID of the Job to which the Task is to be created. Required.
        :type job_id: str
        :param task: The Task to be created. Required.
        :type task: ~azure.batch.models.BatchTaskCreateParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(task, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_create_task_request(
            job_id=job_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [201]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace
    def list_tasks(
        self,
        job_id: str,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        filter: Optional[str] = None,
        select: Optional[List[str]] = None,
        expand: Optional[List[str]] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchTask"]:
        """Lists all of the Tasks that are associated with the specified Job.

        For multi-instance Tasks, information such as affinityId, executionInfo and
        nodeInfo refer to the primary Task. Use the list subtasks API to retrieve
        information about subtasks.

        :param job_id: The ID of the Job. Required.
        :type job_id: str
        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
         https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-tasks.
         Default value is None.
        :paramtype filter: str
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :keyword expand: An OData $expand clause. Default value is None.
        :paramtype expand: list[str]
        :return: An iterator like instance of BatchTask
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchTask]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchTask]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_tasks_request(
                    job_id=job_id,
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    filter=filter,
                    select=select,
                    expand=expand,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchTask], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace_async
    async def create_task_collection(
        self,
        job_id: str,
        task_collection: _models.BatchTaskCollection,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> _models.BatchTaskAddCollectionResult:
        """Adds a collection of Tasks to the specified Job.

        Note that each Task must have a unique ID. The Batch service may not return the
        results for each Task in the same order the Tasks were submitted in this
        request. If the server times out or the connection is closed during the
        request, the request may have been partially or fully processed, or not at all.
        In such cases, the user should re-issue the request. Note that it is up to the
        user to correctly handle failures when re-issuing a request. For example, you
        should use the same Task IDs during a retry so that if the prior operation
        succeeded, the retry will not create extra Tasks unexpectedly. If the response
        contains any Tasks which failed to add, a client can retry the request. In a
        retry, it is most efficient to resubmit only Tasks that failed to add, and to
        omit Tasks that were successfully added on the first attempt. The maximum
        lifetime of a Task from addition to completion is 180 days. If a Task has not
        completed within 180 days of being added it will be terminated by the Batch
        service and left in whatever state it was in at that time.

        :param job_id: The ID of the Job to which the Task collection is to be added. Required.
        :type job_id: str
        :param task_collection: The Tasks to be added. Required.
        :type task_collection: ~azure.batch.models.BatchTaskCollection
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: BatchTaskAddCollectionResult. The BatchTaskAddCollectionResult is compatible with
         MutableMapping
        :rtype: ~azure.batch.models.BatchTaskAddCollectionResult
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[_models.BatchTaskAddCollectionResult] = kwargs.pop("cls", None)

        _content = json.dumps(task_collection, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_create_task_collection_request(
            job_id=job_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.BatchTaskAddCollectionResult, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def delete_task(  # pylint: disable=inconsistent-return-statements
        self,
        job_id: str,
        task_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Deletes a Task from the specified Job.

        When a Task is deleted, all of the files in its directory on the Compute Node
        where it ran are also deleted (regardless of the retention time). For
        multi-instance Tasks, the delete Task operation applies synchronously to the
        primary task; subtasks and their files are then deleted asynchronously in the
        background.

        :param job_id: The ID of the Job from which to delete the Task. Required.
        :type job_id: str
        :param task_id: The ID of the Task to delete. Required.
        :type task_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_delete_task_request(
            job_id=job_id,
            task_id=task_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def get_task(
        self,
        job_id: str,
        task_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        select: Optional[List[str]] = None,
        expand: Optional[List[str]] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> _models.BatchTask:
        """Gets information about the specified Task.

        For multi-instance Tasks, information such as affinityId, executionInfo and
        nodeInfo refer to the primary Task. Use the list subtasks API to retrieve
        information about subtasks.

        :param job_id: The ID of the Job that contains the Task. Required.
        :type job_id: str
        :param task_id: The ID of the Task to get information about. Required.
        :type task_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :keyword expand: An OData $expand clause. Default value is None.
        :paramtype expand: list[str]
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: BatchTask. The BatchTask is compatible with MutableMapping
        :rtype: ~azure.batch.models.BatchTask
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.BatchTask] = kwargs.pop("cls", None)

        _request = build_batch_get_task_request(
            job_id=job_id,
            task_id=task_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            select=select,
            expand=expand,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.BatchTask, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def replace_task(  # pylint: disable=inconsistent-return-statements
        self,
        job_id: str,
        task_id: str,
        task: _models.BatchTask,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Updates the properties of the specified Task.

        :param job_id: The ID of the Job containing the Task. Required.
        :type job_id: str
        :param task_id: The ID of the Task to update. Required.
        :type task_id: str
        :param task: The Task to update. Required.
        :type task: ~azure.batch.models.BatchTask
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(task, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_replace_task_request(
            job_id=job_id,
            task_id=task_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def list_sub_tasks(
        self,
        job_id: str,
        task_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        select: Optional[List[str]] = None,
        **kwargs: Any
    ) -> _models.BatchTaskListSubtasksResult:
        """Lists all of the subtasks that are associated with the specified multi-instance
        Task.

        If the Task is not a multi-instance Task then this returns an empty collection.

        :param job_id: The ID of the Job. Required.
        :type job_id: str
        :param task_id: The ID of the Task. Required.
        :type task_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: BatchTaskListSubtasksResult. The BatchTaskListSubtasksResult is compatible with
         MutableMapping
        :rtype: ~azure.batch.models.BatchTaskListSubtasksResult
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.BatchTaskListSubtasksResult] = kwargs.pop("cls", None)

        _request = build_batch_list_sub_tasks_request(
            job_id=job_id,
            task_id=task_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            select=select,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.BatchTaskListSubtasksResult, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def terminate_task(  # pylint: disable=inconsistent-return-statements
        self,
        job_id: str,
        task_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Terminates the specified Task.

        When the Task has been terminated, it moves to the completed state. For
        multi-instance Tasks, the terminate Task operation applies synchronously to the
        primary task; subtasks are then terminated asynchronously in the background.

        :param job_id: The ID of the Job containing the Task. Required.
        :type job_id: str
        :param task_id: The ID of the Task to terminate. Required.
        :type task_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_terminate_task_request(
            job_id=job_id,
            task_id=task_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [204]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def reactivate_task(  # pylint: disable=inconsistent-return-statements
        self,
        job_id: str,
        task_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        etag: Optional[str] = None,
        match_condition: Optional[MatchConditions] = None,
        **kwargs: Any
    ) -> None:
        """Reactivates a Task, allowing it to run again even if its retry count has been
        exhausted.

        Reactivation makes a Task eligible to be retried again up to its maximum retry
        count. The Task's state is changed to active. As the Task is no longer in the
        completed state, any previous exit code or failure information is no longer
        available after reactivation. Each time a Task is reactivated, its retry count
        is reset to 0. Reactivation will fail for Tasks that are not completed or that
        previously completed successfully (with an exit code of 0). Additionally, it
        will fail if the Job has completed (or is terminating or deleting).

        :param job_id: The ID of the Job containing the Task. Required.
        :type job_id: str
        :param task_id: The ID of the Task to reactivate. Required.
        :type task_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword etag: check if resource is changed. Set None to skip checking etag. Default value is
         None.
        :paramtype etag: str
        :keyword match_condition: The match condition to use upon the etag. Default value is None.
        :paramtype match_condition: ~azure.coreMatchConditions
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        if match_condition == MatchConditions.IfNotModified:
            error_map[412] = ResourceModifiedError
        elif match_condition == MatchConditions.IfPresent:
            error_map[412] = ResourceNotFoundError
        elif match_condition == MatchConditions.IfMissing:
            error_map[412] = ResourceExistsError
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_reactivate_task_request(
            job_id=job_id,
            task_id=task_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            etag=etag,
            match_condition=match_condition,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [204]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def delete_task_file(  # pylint: disable=inconsistent-return-statements
        self,
        job_id: str,
        task_id: str,
        file_path: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        recursive: Optional[bool] = None,
        **kwargs: Any
    ) -> None:
        """Deletes the specified Task file from the Compute Node where the Task ran.

        Deletes the specified Task file from the Compute Node where the Task ran.

        :param job_id: The ID of the Job that contains the Task. Required.
        :type job_id: str
        :param task_id: The ID of the Task whose file you want to retrieve. Required.
        :type task_id: str
        :param file_path: The path to the Task file that you want to get the content of. Required.
        :type file_path: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword recursive: Whether to delete children of a directory. If the filePath parameter
         represents
         a directory instead of a file, you can set recursive to true to delete the
         directory and all of the files and subdirectories in it. If recursive is false
         then the directory must be empty or deletion will fail. Default value is None.
        :paramtype recursive: bool
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_delete_task_file_request(
            job_id=job_id,
            task_id=task_id,
            file_path=file_path,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            recursive=recursive,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def get_task_file(
        self,
        job_id: str,
        task_id: str,
        file_path: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        ocp_range: Optional[str] = None,
        **kwargs: Any
    ) -> bytes:
        """Returns the content of the specified Task file.

        :param job_id: The ID of the Job that contains the Task. Required.
        :type job_id: str
        :param task_id: The ID of the Task whose file you want to retrieve. Required.
        :type task_id: str
        :param file_path: The path to the Task file that you want to get the content of. Required.
        :type file_path: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword ocp_range: The byte range to be retrieved. The default is to retrieve the entire file.
         The
         format is bytes=startRange-endRange. Default value is None.
        :paramtype ocp_range: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: bytes
        :rtype: bytes
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[bytes] = kwargs.pop("cls", None)

        _request = build_batch_get_task_file_request(
            job_id=job_id,
            task_id=task_id,
            file_path=file_path,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            ocp_range=ocp_range,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", True)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["ocp-creation-time"] = self._deserialize("rfc-1123", response.headers.get("ocp-creation-time"))
        response_headers["ocp-batch-file-isdirectory"] = self._deserialize(
            "bool", response.headers.get("ocp-batch-file-isdirectory")
        )
        response_headers["ocp-batch-file-url"] = self._deserialize("str", response.headers.get("ocp-batch-file-url"))
        response_headers["ocp-batch-file-mode"] = self._deserialize("str", response.headers.get("ocp-batch-file-mode"))
        response_headers["content-length"] = self._deserialize("int", response.headers.get("content-length"))

        await response.read()
        deserialized = response.content

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def get_task_file_properties(
        self,
        job_id: str,
        task_id: str,
        file_path: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> bool:
        """Gets the properties of the specified Task file.

        :param job_id: The ID of the Job that contains the Task. Required.
        :type job_id: str
        :param task_id: The ID of the Task whose file you want to retrieve. Required.
        :type task_id: str
        :param file_path: The path to the Task file that you want to get the content of. Required.
        :type file_path: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: bool
        :rtype: bool
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_get_task_file_properties_request(
            job_id=job_id,
            task_id=task_id,
            file_path=file_path,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["ocp-creation-time"] = self._deserialize("rfc-1123", response.headers.get("ocp-creation-time"))
        response_headers["ocp-batch-file-isdirectory"] = self._deserialize(
            "bool", response.headers.get("ocp-batch-file-isdirectory")
        )
        response_headers["ocp-batch-file-url"] = self._deserialize("str", response.headers.get("ocp-batch-file-url"))
        response_headers["ocp-batch-file-mode"] = self._deserialize("str", response.headers.get("ocp-batch-file-mode"))
        response_headers["content-length"] = self._deserialize("int", response.headers.get("content-length"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore
        return 200 <= response.status_code <= 299

    @distributed_trace
    def list_task_files(
        self,
        job_id: str,
        task_id: str,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        filter: Optional[str] = None,
        recursive: Optional[bool] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchNodeFile"]:
        """Lists the files in a Task's directory on its Compute Node.

        Lists the files in a Task's directory on its Compute Node.

        :param job_id: The ID of the Job that contains the Task. Required.
        :type job_id: str
        :param task_id: The ID of the Task whose files you want to list. Required.
        :type task_id: str
        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
         https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-task-files.
         Default value is None.
        :paramtype filter: str
        :keyword recursive: Whether to list children of the Task directory. This parameter can be used
         in
         combination with the filter parameter to list specific type of files. Default value is None.
        :paramtype recursive: bool
        :return: An iterator like instance of BatchNodeFile
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchNodeFile]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchNodeFile]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_task_files_request(
                    job_id=job_id,
                    task_id=task_id,
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    filter=filter,
                    recursive=recursive,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchNodeFile], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace_async
    async def create_node_user(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        user: _models.BatchNodeUserCreateParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Adds a user Account to the specified Compute Node.

        You can add a user Account to a Compute Node only when it is in the idle or
        running state.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the machine on which you want to create a user Account. Required.
        :type node_id: str
        :param user: The options to use for creating the user. Required.
        :type user: ~azure.batch.models.BatchNodeUserCreateParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(user, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_create_node_user_request(
            pool_id=pool_id,
            node_id=node_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [201]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def delete_node_user(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        user_name: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Deletes a user Account from the specified Compute Node.

        You can delete a user Account to a Compute Node only when it is in the idle or
        running state.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the machine on which you want to delete a user Account. Required.
        :type node_id: str
        :param user_name: The name of the user Account to delete. Required.
        :type user_name: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_delete_node_user_request(
            pool_id=pool_id,
            node_id=node_id,
            user_name=user_name,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def replace_node_user(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        user_name: str,
        parameters: _models.BatchNodeUserUpdateParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Updates the password and expiration time of a user Account on the specified Compute Node.

        This operation replaces of all the updatable properties of the Account. For
        example, if the expiryTime element is not specified, the current value is
        replaced with the default value, not left unmodified. You can update a user
        Account on a Compute Node only when it is in the idle or running state.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the machine on which you want to update a user Account. Required.
        :type node_id: str
        :param user_name: The name of the user Account to update. Required.
        :type user_name: str
        :param parameters: The options to use for updating the user. Required.
        :type parameters: ~azure.batch.models.BatchNodeUserUpdateParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        _content = json.dumps(parameters, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_replace_node_user_request(
            pool_id=pool_id,
            node_id=node_id,
            user_name=user_name,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def get_node(
        self,
        pool_id: str,
        node_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        select: Optional[List[str]] = None,
        **kwargs: Any
    ) -> _models.BatchNode:
        """Gets information about the specified Compute Node.

        Gets information about the specified Compute Node.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node that you want to get information about. Required.
        :type node_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: BatchNode. The BatchNode is compatible with MutableMapping
        :rtype: ~azure.batch.models.BatchNode
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.BatchNode] = kwargs.pop("cls", None)

        _request = build_batch_get_node_request(
            pool_id=pool_id,
            node_id=node_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            select=select,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.BatchNode, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def reboot_node(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        parameters: Optional[_models.BatchNodeRebootParameters] = None,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Restarts the specified Compute Node.

        You can restart a Compute Node only if it is in an idle or running state.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node that you want to restart. Required.
        :type node_id: str
        :param parameters: The options to use for rebooting the Compute Node. Default value is None.
        :type parameters: ~azure.batch.models.BatchNodeRebootParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        if parameters is not None:
            _content = json.dumps(parameters, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore
        else:
            _content = None

        _request = build_batch_reboot_node_request(
            pool_id=pool_id,
            node_id=node_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def reimage_node(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        parameters: Optional[_models.BatchNodeReimageParameters] = None,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Reinstalls the operating system on the specified Compute Node.

        You can reinstall the operating system on a Compute Node only if it is in an
        idle or running state. This API can be invoked only on Pools created with the
        cloud service configuration property.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node that you want to restart. Required.
        :type node_id: str
        :param parameters: The options to use for reimaging the Compute Node. Default value is None.
        :type parameters: ~azure.batch.models.BatchNodeReimageParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        if parameters is not None:
            _content = json.dumps(parameters, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore
        else:
            _content = None

        _request = build_batch_reimage_node_request(
            pool_id=pool_id,
            node_id=node_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def disable_node_scheduling(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        parameters: Optional[_models.BatchNodeDisableSchedulingParameters] = None,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Disables Task scheduling on the specified Compute Node.

        You can disable Task scheduling on a Compute Node only if its current
        scheduling state is enabled.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node on which you want to disable Task scheduling.
         Required.
        :type node_id: str
        :param parameters: The options to use for disabling scheduling on the Compute Node. Default
         value is None.
        :type parameters: ~azure.batch.models.BatchNodeDisableSchedulingParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[None] = kwargs.pop("cls", None)

        if parameters is not None:
            _content = json.dumps(parameters, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore
        else:
            _content = None

        _request = build_batch_disable_node_scheduling_request(
            pool_id=pool_id,
            node_id=node_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def enable_node_scheduling(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> None:
        """Enables Task scheduling on the specified Compute Node.

        You can enable Task scheduling on a Compute Node only if its current scheduling
        state is disabled.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node on which you want to enable Task scheduling.
         Required.
        :type node_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_enable_node_scheduling_request(
            pool_id=pool_id,
            node_id=node_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["DataServiceId"] = self._deserialize("str", response.headers.get("DataServiceId"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def get_node_remote_login_settings(
        self,
        pool_id: str,
        node_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> _models.BatchNodeRemoteLoginSettings:
        """Gets the settings required for remote login to a Compute Node.

        Before you can remotely login to a Compute Node using the remote login
        settings, you must create a user Account on the Compute Node. This API can be
        invoked only on Pools created with the virtual machine configuration property.
        For Pools created with a cloud service configuration, see the GetRemoteDesktop
        API.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node for which to obtain the remote login settings.
         Required.
        :type node_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: BatchNodeRemoteLoginSettings. The BatchNodeRemoteLoginSettings is compatible with
         MutableMapping
        :rtype: ~azure.batch.models.BatchNodeRemoteLoginSettings
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.BatchNodeRemoteLoginSettings] = kwargs.pop("cls", None)

        _request = build_batch_get_node_remote_login_settings_request(
            pool_id=pool_id,
            node_id=node_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.BatchNodeRemoteLoginSettings, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def get_node_remote_desktop_file(
        self,
        pool_id: str,
        node_id: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> bytes:
        """Gets the Remote Desktop Protocol file for the specified Compute Node.

        Before you can access a Compute Node by using the RDP file, you must create a
        user Account on the Compute Node. This API can only be invoked on Pools created
        with a cloud service configuration. For Pools created with a virtual machine
        configuration, see the GetRemoteLoginSettings API.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node for which you want to get the Remote Desktop
         Protocol file. Required.
        :type node_id: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: bytes
        :rtype: bytes
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[bytes] = kwargs.pop("cls", None)

        _request = build_batch_get_node_remote_desktop_file_request(
            pool_id=pool_id,
            node_id=node_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(bytes, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def upload_node_logs(
        self,
        pool_id: str,
        node_id: str,
        parameters: _models.UploadBatchServiceLogsParameters,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> _models.UploadBatchServiceLogsResult:
        """Upload Azure Batch service log files from the specified Compute Node to Azure
        Blob Storage.

        This is for gathering Azure Batch service log files in an automated fashion
        from Compute Nodes if you are experiencing an error and wish to escalate to
        Azure support. The Azure Batch service log files should be shared with Azure
        support to aid in debugging issues with the Batch service.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node for which you want to get the Remote Desktop
         Protocol file. Required.
        :type node_id: str
        :param parameters: The Azure Batch service log files upload options. Required.
        :type parameters: ~azure.batch.models.UploadBatchServiceLogsParameters
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword content_type: Type of content. Default value is "application/json;
         odata=minimalmetadata".
        :paramtype content_type: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: UploadBatchServiceLogsResult. The UploadBatchServiceLogsResult is compatible with
         MutableMapping
        :rtype: ~azure.batch.models.UploadBatchServiceLogsResult
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: str = kwargs.pop(
            "content_type", _headers.pop("content-type", "application/json; odata=minimalmetadata")
        )
        cls: ClsType[_models.UploadBatchServiceLogsResult] = kwargs.pop("cls", None)

        _content = json.dumps(parameters, cls=AzureJSONEncoder, exclude_readonly=True)  # type: ignore

        _request = build_batch_upload_node_logs_request(
            pool_id=pool_id,
            node_id=node_id,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            content_type=content_type,
            api_version=self._config.api_version,
            content=_content,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.UploadBatchServiceLogsResult, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def list_nodes(
        self,
        pool_id: str,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        filter: Optional[str] = None,
        select: Optional[List[str]] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchNode"]:
        """Lists the Compute Nodes in the specified Pool.

        Lists the Compute Nodes in the specified Pool.

        :param pool_id: The ID of the Pool from which you want to list Compute Nodes. Required.
        :type pool_id: str
        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
        https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-nodes-in-a-pool.
         Default value is None.
        :paramtype filter: str
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :return: An iterator like instance of BatchNode
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchNode]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchNode]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_nodes_request(
                    pool_id=pool_id,
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    filter=filter,
                    select=select,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchNode], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace_async
    async def get_node_extension(
        self,
        pool_id: str,
        node_id: str,
        extension_name: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        select: Optional[List[str]] = None,
        **kwargs: Any
    ) -> _models.BatchNodeVMExtension:
        """Gets information about the specified Compute Node Extension.

        Gets information about the specified Compute Node Extension.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node that contains the extensions. Required.
        :type node_id: str
        :param extension_name: The name of the Compute Node Extension that you want to get information
         about. Required.
        :type extension_name: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: BatchNodeVMExtension. The BatchNodeVMExtension is compatible with MutableMapping
        :rtype: ~azure.batch.models.BatchNodeVMExtension
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.BatchNodeVMExtension] = kwargs.pop("cls", None)

        _request = build_batch_get_node_extension_request(
            pool_id=pool_id,
            node_id=node_id,
            extension_name=extension_name,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            select=select,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(_models.BatchNodeVMExtension, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def list_node_extensions(
        self,
        pool_id: str,
        node_id: str,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        select: Optional[List[str]] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchNodeVMExtension"]:
        """Lists the Compute Nodes Extensions in the specified Pool.

        Lists the Compute Nodes Extensions in the specified Pool.

        :param pool_id: The ID of the Pool that contains Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node that you want to list extensions. Required.
        :type node_id: str
        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword select: An OData $select clause. Default value is None.
        :paramtype select: list[str]
        :return: An iterator like instance of BatchNodeVMExtension
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchNodeVMExtension]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchNodeVMExtension]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_node_extensions_request(
                    pool_id=pool_id,
                    node_id=node_id,
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    select=select,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchNodeVMExtension], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)

    @distributed_trace_async
    async def delete_node_file(  # pylint: disable=inconsistent-return-statements
        self,
        pool_id: str,
        node_id: str,
        file_path: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        recursive: Optional[bool] = None,
        **kwargs: Any
    ) -> None:
        """Deletes the specified file from the Compute Node.

        Deletes the specified file from the Compute Node.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node from which you want to delete the file. Required.
        :type node_id: str
        :param file_path: The path to the file or directory that you want to delete. Required.
        :type file_path: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword recursive: Whether to delete children of a directory. If the filePath parameter
         represents
         a directory instead of a file, you can set recursive to true to delete the
         directory and all of the files and subdirectories in it. If recursive is false
         then the directory must be empty or deletion will fail. Default value is None.
        :paramtype recursive: bool
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_delete_node_file_request(
            pool_id=pool_id,
            node_id=node_id,
            file_path=file_path,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            recursive=recursive,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @distributed_trace_async
    async def get_node_file(
        self,
        pool_id: str,
        node_id: str,
        file_path: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        ocp_range: Optional[str] = None,
        **kwargs: Any
    ) -> bytes:
        """Returns the content of the specified Compute Node file.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node from which you want to delete the file. Required.
        :type node_id: str
        :param file_path: The path to the file or directory that you want to delete. Required.
        :type file_path: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword ocp_range: The byte range to be retrieved. The default is to retrieve the entire file.
         The
         format is bytes=startRange-endRange. Default value is None.
        :paramtype ocp_range: str
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: bytes
        :rtype: bytes
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[bytes] = kwargs.pop("cls", None)

        _request = build_batch_get_node_file_request(
            pool_id=pool_id,
            node_id=node_id,
            file_path=file_path,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            ocp_range=ocp_range,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["ocp-creation-time"] = self._deserialize("rfc-1123", response.headers.get("ocp-creation-time"))
        response_headers["ocp-batch-file-isdirectory"] = self._deserialize(
            "bool", response.headers.get("ocp-batch-file-isdirectory")
        )
        response_headers["ocp-batch-file-url"] = self._deserialize("str", response.headers.get("ocp-batch-file-url"))
        response_headers["ocp-batch-file-mode"] = self._deserialize("str", response.headers.get("ocp-batch-file-mode"))
        response_headers["content-length"] = self._deserialize("int", response.headers.get("content-length"))

        if _stream:
            deserialized = response.iter_bytes()
        else:
            deserialized = _deserialize(bytes, response.json())

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace_async
    async def get_node_file_properties(
        self,
        pool_id: str,
        node_id: str,
        file_path: str,
        *,
        time_out_in_seconds: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        if_modified_since: Optional[datetime.datetime] = None,
        if_unmodified_since: Optional[datetime.datetime] = None,
        **kwargs: Any
    ) -> bool:
        """Gets the properties of the specified Compute Node file.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node from which you want to delete the file. Required.
        :type node_id: str
        :param file_path: The path to the file or directory that you want to delete. Required.
        :type file_path: str
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword if_modified_since: A timestamp indicating the last modified time of the resource known
         to the
         client. The operation will be performed only if the resource on the service has
         been modified since the specified time. Default value is None.
        :paramtype if_modified_since: ~datetime.datetime
        :keyword if_unmodified_since: A timestamp indicating the last modified time of the resource
         known to the
         client. The operation will be performed only if the resource on the service has
         not been modified since the specified time. Default value is None.
        :paramtype if_unmodified_since: ~datetime.datetime
        :keyword bool stream: Whether to stream the response of this operation. Defaults to False. You
         will have to context manage the returned stream.
        :return: bool
        :rtype: bool
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_batch_get_node_file_properties_request(
            pool_id=pool_id,
            node_id=node_id,
            file_path=file_path,
            time_out_in_seconds=time_out_in_seconds,
            ocp_date=ocp_date,
            if_modified_since=if_modified_since,
            if_unmodified_since=if_unmodified_since,
            api_version=self._config.api_version,
            headers=_headers,
            params=_params,
        )
        path_format_arguments = {
            "endpoint": self._serialize.url("self._config.endpoint", self._config.endpoint, "str", skip_quote=True),
        }
        _request.url = self._client.format_url(_request.url, **path_format_arguments)

        _stream = kwargs.pop("stream", False)
        pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            if _stream:
                await response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = _deserialize(_models.BatchError, response.json())
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["client-request-id"] = self._deserialize("str", response.headers.get("client-request-id"))
        response_headers["request-id"] = self._deserialize("str", response.headers.get("request-id"))
        response_headers["etag"] = self._deserialize("str", response.headers.get("etag"))
        response_headers["last-modified"] = self._deserialize("rfc-1123", response.headers.get("last-modified"))
        response_headers["ocp-creation-time"] = self._deserialize("rfc-1123", response.headers.get("ocp-creation-time"))
        response_headers["ocp-batch-file-isdirectory"] = self._deserialize(
            "bool", response.headers.get("ocp-batch-file-isdirectory")
        )
        response_headers["ocp-batch-file-url"] = self._deserialize("str", response.headers.get("ocp-batch-file-url"))
        response_headers["ocp-batch-file-mode"] = self._deserialize("str", response.headers.get("ocp-batch-file-mode"))
        response_headers["content-length"] = self._deserialize("int", response.headers.get("content-length"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore
        return 200 <= response.status_code <= 299

    @distributed_trace
    def list_node_files(
        self,
        pool_id: str,
        node_id: str,
        *,
        maxresults: Optional[int] = None,
        ocp_date: Optional[datetime.datetime] = None,
        time_out_in_seconds: Optional[int] = None,
        filter: Optional[str] = None,
        recursive: Optional[bool] = None,
        **kwargs: Any
    ) -> AsyncIterable["_models.BatchNodeFile"]:
        """Lists all of the files in Task directories on the specified Compute Node.

        Lists all of the files in Task directories on the specified Compute Node.

        :param pool_id: The ID of the Pool that contains the Compute Node. Required.
        :type pool_id: str
        :param node_id: The ID of the Compute Node whose files you want to list. Required.
        :type node_id: str
        :keyword maxresults: The maximum number of items to return in the response. A maximum of 1000
         applications can be returned. Default value is None.
        :paramtype maxresults: int
        :keyword ocp_date: The time the request was issued. Client libraries typically set this to the
         current system clock time; set it explicitly if you are calling the REST API
         directly. Default value is None.
        :paramtype ocp_date: ~datetime.datetime
        :keyword time_out_in_seconds: Sets the maximum time that the server can spend processing the
         request,
         in seconds. The default is 30 seconds. Default value is None.
        :paramtype time_out_in_seconds: int
        :keyword filter: An OData $filter clause. For more information on constructing this filter, see
        https://docs.microsoft.com/en-us/rest/api/batchservice/odata-filters-in-batch#list-compute-node-files.
         Default value is None.
        :paramtype filter: str
        :keyword recursive: Whether to list children of a directory. Default value is None.
        :paramtype recursive: bool
        :return: An iterator like instance of BatchNodeFile
        :rtype: ~azure.core.async_paging.AsyncItemPaged[~azure.batch.models.BatchNodeFile]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[List[_models.BatchNodeFile]] = kwargs.pop("cls", None)

        error_map = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_batch_list_node_files_request(
                    pool_id=pool_id,
                    node_id=node_id,
                    maxresults=maxresults,
                    ocp_date=ocp_date,
                    time_out_in_seconds=time_out_in_seconds,
                    filter=filter,
                    recursive=recursive,
                    api_version=self._config.api_version,
                    headers=_headers,
                    params=_params,
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            else:
                # make call to next link with the client's api-version
                _parsed_next_link = urllib.parse.urlparse(next_link)
                _next_request_params = case_insensitive_dict(
                    {
                        key: [urllib.parse.quote(v) for v in value]
                        for key, value in urllib.parse.parse_qs(_parsed_next_link.query).items()
                    }
                )
                _next_request_params["api-version"] = self._config.api_version
                _request = HttpRequest(
                    "GET", urllib.parse.urljoin(next_link, _parsed_next_link.path), params=_next_request_params
                )
                path_format_arguments = {
                    "endpoint": self._serialize.url(
                        "self._config.endpoint", self._config.endpoint, "str", skip_quote=True
                    ),
                }
                _request.url = self._client.format_url(_request.url, **path_format_arguments)

            return _request

        async def extract_data(pipeline_response):
            deserialized = pipeline_response.http_response.json()
            list_of_elem = _deserialize(List[_models.BatchNodeFile], deserialized["value"])
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.get("odata.nextLink") or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                if _stream:
                    await response.read()  # Load the body in memory and close the socket
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = _deserialize(_models.BatchError, response.json())
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return AsyncItemPaged(get_next, extract_data)
