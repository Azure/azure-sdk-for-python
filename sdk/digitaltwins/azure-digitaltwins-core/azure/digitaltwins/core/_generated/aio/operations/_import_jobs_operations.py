# pylint: disable=too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
from typing import Any, AsyncIterable, Callable, Dict, Optional, TypeVar

from azure.core.async_paging import AsyncItemPaged, AsyncList
from azure.core.exceptions import ClientAuthenticationError, HttpResponseError, ResourceExistsError, ResourceNotFoundError, map_error
from azure.core.pipeline import PipelineResponse
from azure.core.pipeline.transport import AsyncHttpResponse
from azure.core.rest import HttpRequest
from azure.core.tracing.decorator import distributed_trace
from azure.core.tracing.decorator_async import distributed_trace_async
from azure.core.utils import case_insensitive_dict

from ... import models as _models
from ..._vendor import _convert_request
from ...operations._import_jobs_operations import build_add_request, build_cancel_request, build_delete_request, build_get_by_id_request, build_list_request
T = TypeVar('T')
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, AsyncHttpResponse], T, Dict[str, Any]], Any]]

class ImportJobsOperations:
    """
    .. warning::
        **DO NOT** instantiate this class directly.

        Instead, you should access the following operations through
        :class:`~azure.digitaltwins.core.aio.AzureDigitalTwinsAPI`'s
        :attr:`import_jobs` attribute.
    """

    models = _models

    def __init__(self, *args, **kwargs) -> None:
        input_args = list(args)
        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")


    @distributed_trace
    def list(
        self,
        import_jobs_list_options: Optional[_models.ImportJobsListOptions] = None,
        **kwargs: Any
    ) -> AsyncIterable[_models.ImportJobCollection]:
        """Retrieves all import jobs.
        Status codes:


        * 200 OK.

        :param import_jobs_list_options: Parameter group. Default value is None.
        :type import_jobs_list_options: ~azure.digitaltwins.core.models.ImportJobsListOptions
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: An iterator like instance of either ImportJobCollection or the result of cls(response)
        :rtype:
         ~azure.core.async_paging.AsyncItemPaged[~azure.digitaltwins.core.models.ImportJobCollection]
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2023-06-30"))  # type: str
        cls = kwargs.pop('cls', None)  # type: ClsType[_models.ImportJobCollection]

        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})
        def prepare_request(next_link=None):
            if not next_link:
                _traceparent = None
                _tracestate = None
                _max_items_per_page = None
                if import_jobs_list_options is not None:
                    _traceparent = import_jobs_list_options.traceparent
                    _tracestate = import_jobs_list_options.tracestate
                    _max_items_per_page = import_jobs_list_options.max_items_per_page
                
                request = build_list_request(
                    api_version=api_version,
                    traceparent=_traceparent,
                    tracestate=_tracestate,
                    max_items_per_page=_max_items_per_page,
                    template_url=self.list.metadata['url'],
                    headers=_headers,
                    params=_params,
                )
                request = _convert_request(request)
                request.url = self._client.format_url(request.url)  # type: ignore

            else:
                _traceparent = None
                _tracestate = None
                _max_items_per_page = None
                if import_jobs_list_options is not None:
                    _traceparent = import_jobs_list_options.traceparent
                    _tracestate = import_jobs_list_options.tracestate
                    _max_items_per_page = import_jobs_list_options.max_items_per_page
                
                request = build_list_request(
                    api_version=api_version,
                    traceparent=_traceparent,
                    tracestate=_tracestate,
                    max_items_per_page=_max_items_per_page,
                    template_url=next_link,
                    headers=_headers,
                    params=_params,
                )
                request = _convert_request(request)
                request.url = self._client.format_url(request.url)  # type: ignore
                request.method = "GET"
            return request

        async def extract_data(pipeline_response):
            deserialized = self._deserialize("ImportJobCollection", pipeline_response)
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)
            return deserialized.next_link or None, AsyncList(list_of_elem)

        async def get_next(next_link=None):
            request = prepare_request(next_link)

            pipeline_response = await self._client._pipeline.run(  # pylint: disable=protected-access
                request,
                stream=False,
                **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                raise HttpResponseError(response=response, model=error)

            return pipeline_response


        return AsyncItemPaged(
            get_next, extract_data
        )
    list.metadata = {'url': "/jobs/imports"}  # type: ignore

    @distributed_trace_async
    async def add(
        self,
        id: str,
        import_job: _models.ImportJob,
        import_jobs_add_options: Optional[_models.ImportJobsAddOptions] = None,
        **kwargs: Any
    ) -> _models.ImportJob:
        """Creates an import job.
        Status codes:


        * 201 Created
        * 400 Bad Request

          * JobLimitReached - The maximum number of import jobs allowed has been reached.
          * ValidationFailed - The import job request is not valid.

        :param id: The id for the import job. The id is unique within the service and case sensitive.
        :type id: str
        :param import_job: The import job being added.
        :type import_job: ~azure.digitaltwins.core.models.ImportJob
        :param import_jobs_add_options: Parameter group. Default value is None.
        :type import_jobs_add_options: ~azure.digitaltwins.core.models.ImportJobsAddOptions
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: ImportJob, or the result of cls(response)
        :rtype: ~azure.digitaltwins.core.models.ImportJob
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2023-06-30"))  # type: str
        content_type = kwargs.pop('content_type', _headers.pop('Content-Type', "application/json"))  # type: Optional[str]
        cls = kwargs.pop('cls', None)  # type: ClsType[_models.ImportJob]

        _traceparent = None
        _tracestate = None
        if import_jobs_add_options is not None:
            _traceparent = import_jobs_add_options.traceparent
            _tracestate = import_jobs_add_options.tracestate
        _json = self._serialize.body(import_job, 'ImportJob')

        request = build_add_request(
            id=id,
            api_version=api_version,
            content_type=content_type,
            json=_json,
            traceparent=_traceparent,
            tracestate=_tracestate,
            template_url=self.add.metadata['url'],
            headers=_headers,
            params=_params,
        )
        request = _convert_request(request)
        request.url = self._client.format_url(request.url)  # type: ignore

        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [201]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize('ImportJob', pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized

    add.metadata = {'url': "/jobs/imports/{id}"}  # type: ignore


    @distributed_trace_async
    async def get_by_id(
        self,
        id: str,
        import_jobs_get_by_id_options: Optional[_models.ImportJobsGetByIdOptions] = None,
        **kwargs: Any
    ) -> _models.ImportJob:
        """Retrieves an import job.
        Status codes:


        * 200 OK
        * 404 Not Found

          * ImportJobNotFound - The import job was not found.

        :param id: The id for the import job. The id is unique within the service and case sensitive.
        :type id: str
        :param import_jobs_get_by_id_options: Parameter group. Default value is None.
        :type import_jobs_get_by_id_options: ~azure.digitaltwins.core.models.ImportJobsGetByIdOptions
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: ImportJob, or the result of cls(response)
        :rtype: ~azure.digitaltwins.core.models.ImportJob
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2023-06-30"))  # type: str
        cls = kwargs.pop('cls', None)  # type: ClsType[_models.ImportJob]

        _traceparent = None
        _tracestate = None
        if import_jobs_get_by_id_options is not None:
            _traceparent = import_jobs_get_by_id_options.traceparent
            _tracestate = import_jobs_get_by_id_options.tracestate

        request = build_get_by_id_request(
            id=id,
            api_version=api_version,
            traceparent=_traceparent,
            tracestate=_tracestate,
            template_url=self.get_by_id.metadata['url'],
            headers=_headers,
            params=_params,
        )
        request = _convert_request(request)
        request.url = self._client.format_url(request.url)  # type: ignore

        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize('ImportJob', pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized

    get_by_id.metadata = {'url': "/jobs/imports/{id}"}  # type: ignore


    @distributed_trace_async
    async def delete(  # pylint: disable=inconsistent-return-statements
        self,
        id: str,
        import_jobs_delete_options: Optional[_models.ImportJobsDeleteOptions] = None,
        **kwargs: Any
    ) -> None:
        """Deletes an import job.
        Status codes:


        * 204 No Content
        * 400 Bad Request

          * ValidationFailed - The import job request is not valid.

        :param id: The id for the import job. The id is unique within the service and case sensitive.
        :type id: str
        :param import_jobs_delete_options: Parameter group. Default value is None.
        :type import_jobs_delete_options: ~azure.digitaltwins.core.models.ImportJobsDeleteOptions
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: None, or the result of cls(response)
        :rtype: None
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2023-06-30"))  # type: str
        cls = kwargs.pop('cls', None)  # type: ClsType[None]

        _traceparent = None
        _tracestate = None
        if import_jobs_delete_options is not None:
            _traceparent = import_jobs_delete_options.traceparent
            _tracestate = import_jobs_delete_options.tracestate

        request = build_delete_request(
            id=id,
            api_version=api_version,
            traceparent=_traceparent,
            tracestate=_tracestate,
            template_url=self.delete.metadata['url'],
            headers=_headers,
            params=_params,
        )
        request = _convert_request(request)
        request.url = self._client.format_url(request.url)  # type: ignore

        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [204]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        if cls:
            return cls(pipeline_response, None, {})

    delete.metadata = {'url': "/jobs/imports/{id}"}  # type: ignore


    @distributed_trace_async
    async def cancel(
        self,
        id: str,
        import_jobs_cancel_options: Optional[_models.ImportJobsCancelOptions] = None,
        **kwargs: Any
    ) -> _models.ImportJob:
        """Cancels an import job.
        Status codes:


        * 200 Request Accepted
        * 400 Bad Request

          * ValidationFailed - The import job request is not valid.

        :param id: The id for the import job. The id is unique within the service and case sensitive.
        :type id: str
        :param import_jobs_cancel_options: Parameter group. Default value is None.
        :type import_jobs_cancel_options: ~azure.digitaltwins.core.models.ImportJobsCancelOptions
        :keyword callable cls: A custom type or function that will be passed the direct response
        :return: ImportJob, or the result of cls(response)
        :rtype: ~azure.digitaltwins.core.models.ImportJob
        :raises: ~azure.core.exceptions.HttpResponseError
        """
        error_map = {
            401: ClientAuthenticationError, 404: ResourceNotFoundError, 409: ResourceExistsError
        }
        error_map.update(kwargs.pop('error_map', {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

        api_version = kwargs.pop('api_version', _params.pop('api-version', "2023-06-30"))  # type: str
        cls = kwargs.pop('cls', None)  # type: ClsType[_models.ImportJob]

        _traceparent = None
        _tracestate = None
        if import_jobs_cancel_options is not None:
            _traceparent = import_jobs_cancel_options.traceparent
            _tracestate = import_jobs_cancel_options.tracestate

        request = build_cancel_request(
            id=id,
            api_version=api_version,
            traceparent=_traceparent,
            tracestate=_tracestate,
            template_url=self.cancel.metadata['url'],
            headers=_headers,
            params=_params,
        )
        request = _convert_request(request)
        request.url = self._client.format_url(request.url)  # type: ignore

        pipeline_response = await self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access
            request,
            stream=False,
            **kwargs
        )
        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize('ImportJob', pipeline_response)

        if cls:
            return cls(pipeline_response, deserialized, {})

        return deserialized

    cancel.metadata = {'url': "/jobs/imports/{id}/cancel"}  # type: ignore

